{"meta":{"version":1,"warehouse":"3.0.2"},"models":{"Asset":[{"_id":"themes/landscape/source/fancybox/blank.gif","path":"fancybox/blank.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","path":"fancybox/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","path":"fancybox/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","path":"fancybox/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","path":"fancybox/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","path":"fancybox/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","path":"fancybox/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","path":"fancybox/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","path":"fancybox/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/js/script.js","path":"js/script.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","path":"css/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","path":"css/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","path":"css/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","path":"fancybox/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","path":"fancybox/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","path":"fancybox/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","path":"fancybox/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","path":"fancybox/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","path":"fancybox/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","path":"css/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","path":"css/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/landscape/source/css/images/banner.jpg","path":"css/images/banner.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/favicon.png","path":"favicon.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","path":"css/gitment.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/matery.css","path":"css/matery.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","path":"css/my-gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/css/my.css","path":"css/my.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/matery.js","path":"js/matery.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","path":"medias/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","path":"medias/comment_bg.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","path":"medias/icp.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","path":"medias/logo.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","path":"libs/animate/animate.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","path":"libs/aos/aos.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","path":"libs/aos/aos.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","path":"libs/aplayer/APlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","path":"libs/aplayer/APlayer.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","path":"libs/codeBlock/codeBlockFuction.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","path":"libs/codeBlock/codeCopy.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","path":"libs/codeBlock/codeLang.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","path":"libs/codeBlock/codeShrink.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","path":"libs/background/canvas-nest.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","path":"libs/background/ribbon-dynamic.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","path":"libs/background/ribbon-refresh.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","path":"libs/background/ribbon.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","path":"libs/cryptojs/crypto-js.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","path":"libs/dplayer/DPlayer.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","path":"libs/gitalk/gitalk.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","path":"libs/gitment/gitment-default.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","path":"libs/instantpage/instantpage.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","path":"libs/jqcloud/jqcloud-1.0.4.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","path":"libs/jqcloud/jqcloud.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","path":"libs/masonry/masonry.pkgd.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","path":"libs/others/busuanzi.pure.mini.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","path":"libs/others/clicklove.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","path":"libs/scrollprogress/scrollProgress.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","path":"libs/tocbot/tocbot.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","path":"libs/tocbot/tocbot.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","path":"medias/cover.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","path":"medias/featureimages/15.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","path":"medias/featureimages/16.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","path":"medias/featureimages/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","path":"medias/featureimages/21.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","path":"medias/featureimages/22.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","path":"medias/featureimages/23.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","path":"medias/featureimages/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","path":"medias/featureimages/7.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","path":"medias/featureimages/8.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.jpg","path":"medias/reward/alipay.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","path":"medias/reward/wechat.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","path":"libs/dplayer/DPlayer.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","path":"libs/gitment/gitment.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery.min.js","path":"libs/jquery/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","path":"libs/valine/Valine.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","path":"medias/featureimages/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","path":"medias/featureimages/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","path":"medias/featureimages/10.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","path":"medias/featureimages/11.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","path":"medias/featureimages/12.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","path":"medias/featureimages/13.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","path":"medias/featureimages/17.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","path":"medias/featureimages/18.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","path":"medias/featureimages/19.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","path":"medias/featureimages/20.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","path":"medias/featureimages/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","path":"medias/featureimages/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","path":"medias/featureimages/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","path":"medias/featureimages/9.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","path":"libs/awesome/webfonts/fa-regular-400.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","path":"libs/awesome/webfonts/fa-regular-400.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","path":"libs/awesome/webfonts/fa-regular-400.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","path":"libs/awesome/webfonts/fa-regular-400.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","path":"libs/gitalk/gitalk.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","path":"libs/lightGallery/css/lightgallery.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.eot","path":"libs/lightGallery/fonts/lg.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","path":"libs/lightGallery/fonts/lg.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","path":"libs/lightGallery/fonts/lg.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","path":"libs/lightGallery/fonts/lg.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","path":"libs/lightGallery/img/loading.gif","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","path":"libs/lightGallery/img/video-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","path":"libs/lightGallery/img/vimeo-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","path":"libs/lightGallery/img/youtube-play.png","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","path":"libs/lightGallery/js/lightgallery-all.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","path":"libs/materialize/materialize.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","path":"libs/materialize/materialize.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","path":"libs/share/css/share.min.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","path":"libs/share/fonts/iconfont.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","path":"libs/share/fonts/iconfont.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","path":"libs/share/fonts/iconfont.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","path":"libs/share/fonts/iconfont.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","path":"libs/share/js/jquery.share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","path":"libs/share/js/social-share.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","path":"libs/valine/av-min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","path":"medias/banner/0.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","path":"medias/banner/1.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","path":"medias/banner/2.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","path":"medias/banner/3.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","path":"medias/banner/5.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","path":"medias/banner/6.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","path":"libs/awesome/webfonts/fa-solid-900.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","path":"medias/featureimages/14.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","path":"libs/awesome/css/all.css","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","path":"libs/awesome/webfonts/fa-brands-400.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","path":"libs/awesome/webfonts/fa-solid-900.woff","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","path":"medias/banner/4.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","path":"libs/awesome/webfonts/fa-brands-400.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","path":"libs/awesome/webfonts/fa-brands-400.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","path":"libs/awesome/webfonts/fa-brands-400.woff2","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","path":"libs/awesome/webfonts/fa-regular-400.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","path":"libs/awesome/webfonts/fa-solid-900.ttf","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","path":"libs/awesome/webfonts/fa-solid-900.eot","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","path":"libs/echarts/echarts.min.js","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","path":"libs/awesome/webfonts/fa-brands-400.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","path":"libs/awesome/webfonts/fa-solid-900.svg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/7.jpg","path":"medias/banner/7.jpg","modified":0,"renderable":1},{"_id":"themes/hexo-theme-matery/source/medias/banner/8.jpg","path":"medias/banner/8.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"themes/landscape/.gitignore","hash":"ea2b285a29690f1eabbad0f3a158e34e9ccd1d86","modified":1581077393296},{"_id":"themes/landscape/Gruntfile.js","hash":"412e30530784993c8997aa8b1319c669b83b91c2","modified":1581077393296},{"_id":"themes/landscape/README.md","hash":"67fedfb66304f103c412f6be110bf3c40c75d4ac","modified":1581077393297},{"_id":"themes/landscape/LICENSE","hash":"82ce1e15ddeabeaaca60e2186b5a3ce42b1a9c49","modified":1581077393297},{"_id":"themes/landscape/_config.yml","hash":"ce9d2939245209b8f5c5bbbdadc917d86057d032","modified":1581077393297},{"_id":"themes/landscape/package.json","hash":"6e567a9654e61eb3f548c75edef380c2e135c433","modified":1581077393307},{"_id":"source/_posts/hello-world.md","hash":"acad91ace80b80295b11a9b7ad4c29a2dcfdd8fb","modified":1581077387284},{"_id":"themes/landscape/languages/de.yml","hash":"d45cea36c5c83d7d09afcd1c26fff4a4c513c25b","modified":1581077393298},{"_id":"themes/landscape/languages/default.yml","hash":"f26a34a7983d4bc17c65c7f0f14da598e62ce66d","modified":1581077393298},{"_id":"themes/landscape/languages/es.yml","hash":"e3b4937da4cd2d0393b8a0ba310e70fc605cc431","modified":1581077393298},{"_id":"themes/landscape/languages/ja.yml","hash":"3e2fedca096678c0c234ebffa4637828979296fa","modified":1581077393298},{"_id":"themes/landscape/languages/fr.yml","hash":"8cb0fe4b6913b4d5b662cdd0108a923c90025f85","modified":1581077393298},{"_id":"themes/landscape/languages/ko.yml","hash":"11330316e3c1262474a2b496e40dbc29f93fe01b","modified":1581077393299},{"_id":"themes/landscape/languages/nl.yml","hash":"3d82ec703d0b3287739d7cb4750a715ae83bfcb3","modified":1581077393299},{"_id":"themes/landscape/languages/no.yml","hash":"ddf2035e920a5ecb9076138c184257d9f51896a7","modified":1581077393299},{"_id":"themes/landscape/languages/pt.yml","hash":"ae2c61b30e638f74f1a42c9ce39ac08d063b30f5","modified":1581077393299},{"_id":"themes/landscape/languages/ru.yml","hash":"2a476b4c6e04900914c81378941640ac5d58a1f0","modified":1581077393299},{"_id":"themes/landscape/languages/zh-CN.yml","hash":"b057f389c6713010f97d461e48ec959b0b6f3b44","modified":1581077393300},{"_id":"themes/landscape/languages/zh-TW.yml","hash":"f5f0ca88185da7a8457760d84bf221781473bd7c","modified":1581077393300},{"_id":"themes/landscape/layout/archive.ejs","hash":"2703b07cc8ac64ae46d1d263f4653013c7e1666b","modified":1581077393305},{"_id":"themes/landscape/layout/category.ejs","hash":"765426a9c8236828dc34759e604cc2c52292835a","modified":1581077393306},{"_id":"themes/landscape/layout/layout.ejs","hash":"5d86bc48b0f1bdce9a2bb548c2f8e7a4f50d499a","modified":1581077393306},{"_id":"themes/landscape/layout/index.ejs","hash":"aa1b4456907bdb43e629be3931547e2d29ac58c8","modified":1581077393306},{"_id":"themes/landscape/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1581077393306},{"_id":"themes/landscape/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1581077393306},{"_id":"themes/landscape/layout/tag.ejs","hash":"eaa7b4ccb2ca7befb90142e4e68995fb1ea68b2e","modified":1581077393307},{"_id":"themes/landscape/scripts/fancybox.js","hash":"4c130fc242cf9b59b5df6ca5eae3b14302311e8c","modified":1581077393307},{"_id":"themes/landscape/layout/_partial/after-footer.ejs","hash":"5e3b70c028d518b8f765e29a5e2020e7ba6ed589","modified":1581077393300},{"_id":"themes/landscape/layout/_partial/article.ejs","hash":"5cf2b8a1148e6f8c4bd9ca9e3b84c7e5a59d56bc","modified":1581077393301},{"_id":"themes/landscape/layout/_partial/archive-post.ejs","hash":"5062c723721d8497eebad372f57092ade45041f4","modified":1581077393301},{"_id":"themes/landscape/layout/_partial/archive.ejs","hash":"017c412bd3d60d22e493f02918e436a32d96bb84","modified":1581077393301},{"_id":"themes/landscape/layout/_partial/footer.ejs","hash":"6faefe07f3d64e21c7743276e0f55ee1544f9d86","modified":1581077393301},{"_id":"themes/landscape/layout/_partial/google-analytics.ejs","hash":"1ccc627d7697e68fddc367c73ac09920457e5b35","modified":1581077393302},{"_id":"themes/landscape/layout/_partial/gauges-analytics.ejs","hash":"ace3000bd3e01d03041d5be24f7640b6c003a5b5","modified":1581077393301},{"_id":"themes/landscape/layout/_partial/head.ejs","hash":"a36cec48782782bac92622f369c750e5c7396510","modified":1581077393302},{"_id":"themes/landscape/layout/_partial/header.ejs","hash":"cf755454675d13a0813a922b575c06b6b74ab9fd","modified":1581077393302},{"_id":"themes/landscape/layout/_partial/mobile-nav.ejs","hash":"347cf1befd2ea637c24bd5901929d8e36e359e75","modified":1581077393302},{"_id":"themes/landscape/layout/_partial/sidebar.ejs","hash":"c70869569749a8f48cce202fa57926c06b55fdab","modified":1581077393304},{"_id":"themes/landscape/layout/_widget/archive.ejs","hash":"0fe1e52c291c9499bd05b966e0b9aac5be351c58","modified":1581077393304},{"_id":"themes/landscape/layout/_widget/category.ejs","hash":"866790acc13fed44b7ef74c3e19c300a3d6180d8","modified":1581077393304},{"_id":"themes/landscape/layout/_widget/tag.ejs","hash":"6017c54a8c3c8ff8db491cfbea3100c139da75d6","modified":1581077393305},{"_id":"themes/landscape/layout/_widget/recent_posts.ejs","hash":"16800f85ffb036d2644a26e02facd61acb3706e9","modified":1581077393305},{"_id":"themes/landscape/layout/_widget/tagcloud.ejs","hash":"7259c179aa0c41c02e467ad892292e90430aaabc","modified":1581077393305},{"_id":"themes/landscape/source/css/_extend.styl","hash":"8ab1ad313bd6707d248c5ca1ee9a5eab8d815e42","modified":1581077393308},{"_id":"themes/landscape/source/css/_variables.styl","hash":"57bb02270eef16b4823a64ba663ccf2f247f34e5","modified":1581077393311},{"_id":"themes/landscape/source/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1581077393317},{"_id":"themes/landscape/source/css/style.styl","hash":"4a3e64ee8dad5834860c30b4176882eff628ca6b","modified":1581077393317},{"_id":"themes/landscape/source/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1581077393318},{"_id":"themes/landscape/source/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1581077393318},{"_id":"themes/landscape/source/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1581077393318},{"_id":"themes/landscape/source/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1581077393319},{"_id":"themes/landscape/source/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1581077393319},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.css","hash":"2e54d51d21e68ebc4bb870f6e57d3bfb660d4f9c","modified":1581077393321},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.js","hash":"58193c802f307ec9bc9e586c0e8a13ebef45d2f8","modified":1581077393321},{"_id":"themes/landscape/source/fancybox/jquery.fancybox.pack.js","hash":"2da892a02778236b64076e5e8802ef0566e1d9e8","modified":1581077393322},{"_id":"themes/landscape/source/js/script.js","hash":"c0d368681c687258b628bacc84cc30d353de6d47","modified":1581077393322},{"_id":"themes/landscape/layout/_partial/post/category.ejs","hash":"16128d2422645e18d1b6882d4c4df17d895bd76e","modified":1581077393303},{"_id":"themes/landscape/layout/_partial/post/date.ejs","hash":"947f513f7a85fbcf085624e46dc2ae6de8185eec","modified":1581077393303},{"_id":"themes/landscape/layout/_partial/post/gallery.ejs","hash":"b0bf3f5d923c261ca2b5fabab513f1ec2708c8ca","modified":1581077393303},{"_id":"themes/landscape/layout/_partial/post/nav.ejs","hash":"cbb3819ce512bd24db8bad41b8617d46eba82fdc","modified":1581077393303},{"_id":"themes/landscape/layout/_partial/post/tag.ejs","hash":"694b5101bcc44c9f9c1cc62e5ad2fdfb4b7c7a07","modified":1581077393303},{"_id":"themes/landscape/layout/_partial/post/title.ejs","hash":"d4a460a35e2112d0c7414fd5e19b3a16093f1caf","modified":1581077393304},{"_id":"themes/landscape/source/css/_partial/archive.styl","hash":"9e574d8eb1a5285ec3b4346607414770d2f7e0ff","modified":1581077393308},{"_id":"themes/landscape/source/css/_partial/article.styl","hash":"e291bc8c5f0c21080baa549d5d9ef2f39a871ea7","modified":1581077393308},{"_id":"themes/landscape/source/css/_partial/footer.styl","hash":"6f7aa810f296d6a1a4486637b5a853d35a198938","modified":1581077393309},{"_id":"themes/landscape/source/css/_partial/comment.styl","hash":"2834870661e490775f9154d71638bfdc72e640a6","modified":1581077393309},{"_id":"themes/landscape/source/css/_partial/highlight.styl","hash":"ac19f1621305ca9f6a7b74acd211a4c0d88690bd","modified":1581077393309},{"_id":"themes/landscape/source/css/_partial/header.styl","hash":"67e59feb18eee6026717cb440d86ab9551782628","modified":1581077393309},{"_id":"themes/landscape/source/css/_partial/mobile.styl","hash":"680c7b809b62cd3ad294e822793fbd0b1a32cc33","modified":1581077393309},{"_id":"themes/landscape/source/css/_partial/sidebar-aside.styl","hash":"1fb15f13ba70d5b954f62920c6b63d26e2fb2985","modified":1581077393310},{"_id":"themes/landscape/source/css/_partial/sidebar.styl","hash":"8d971a00e644a600179b04815688d188f094012e","modified":1581077393311},{"_id":"themes/landscape/source/css/_partial/sidebar-bottom.styl","hash":"4132e25ba9680c4b911a01abc75f501cda3fa4f1","modified":1581077393311},{"_id":"themes/landscape/source/css/_util/grid.styl","hash":"1aa883ab432d9e4139c89dcbd40ae2bd1528d029","modified":1581077393311},{"_id":"themes/landscape/source/css/_util/mixin.styl","hash":"429bad87fc156eacf226c5e35b0eafc277f2504b","modified":1581077393311},{"_id":"themes/landscape/source/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1581077393312},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1581077393312},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1581077393315},{"_id":"themes/landscape/source/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1581077393319},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1581077393319},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-buttons.js","hash":"4c9c395d705d22af7da06870d18f434e2a2eeaf9","modified":1581077393320},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-media.js","hash":"e14c32cc6823b81b2f758512f13ed8eb9ef2b454","modified":1581077393320},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1581077393320},{"_id":"themes/landscape/source/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"83cdfea43632b613771691a11f56f99d85fb6dbd","modified":1581077393320},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1581077393314},{"_id":"themes/landscape/source/css/fonts/fontawesome-webfont.svg","hash":"a275426daefd3716c53561fad121d258a7f05b47","modified":1581077393313},{"_id":"themes/landscape/source/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1581077393317},{"_id":"public/2020/02/07/hello-world/index.html","hash":"7e6bcb1f5e227114fb6f80a3f959bbdc5fd4aa53","modified":1581154242778},{"_id":"public/archives/index.html","hash":"190ac7c5587f2b4bb9b682b15681fcb6faab6ce5","modified":1591596346381},{"_id":"public/archives/2020/index.html","hash":"d3c44583f607edf62aa9e8187ff6ee1baafbb76b","modified":1591596346381},{"_id":"public/archives/2020/02/index.html","hash":"df12335f6dc34fdb4cabfc3da9f6d5a210adc9ed","modified":1591596346381},{"_id":"public/index.html","hash":"1332a1231606f8e1a1b80271a2fedcaf83552de0","modified":1591596346381},{"_id":"public/fancybox/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1581077492426},{"_id":"public/fancybox/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1581077492426},{"_id":"public/fancybox/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1581077492426},{"_id":"public/fancybox/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1581077492426},{"_id":"public/fancybox/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1581077492426},{"_id":"public/css/fonts/fontawesome-webfont.eot","hash":"7619748fe34c64fb157a57f6d4ef3678f63a8f5e","modified":1581077492426},{"_id":"public/css/fonts/FontAwesome.otf","hash":"b5b4f9be85f91f10799e87a083da1d050f842734","modified":1581077492426},{"_id":"public/fancybox/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1581077492426},{"_id":"public/css/fonts/fontawesome-webfont.woff","hash":"04c3bf56d87a0828935bd6b4aee859995f321693","modified":1581077492426},{"_id":"public/fancybox/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1581077492426},{"_id":"public/css/fonts/fontawesome-webfont.ttf","hash":"7f09c97f333917034ad08fa7295e916c9f72fd3f","modified":1581077492426},{"_id":"public/fancybox/jquery.fancybox.css","hash":"aaa582fb9eb4b7092dc69fcb2d5b1c20cca58ab6","modified":1581077492426},{"_id":"public/js/script.js","hash":"2876e0b19ce557fca38d7c6f49ca55922ab666a1","modified":1581077492426},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1581077492426},{"_id":"public/fancybox/helpers/jquery.fancybox-buttons.js","hash":"dc3645529a4bf72983a39fa34c1eb9146e082019","modified":1581077492426},{"_id":"public/fancybox/helpers/jquery.fancybox-media.js","hash":"294420f9ff20f4e3584d212b0c262a00a96ecdb3","modified":1581077492426},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1581077492426},{"_id":"public/fancybox/helpers/jquery.fancybox-thumbs.js","hash":"47da1ae5401c24b5c17cc18e2730780f5c1a7a0c","modified":1581077492426},{"_id":"public/css/style.css","hash":"5f8dadd37d0052c557061018fe6f568f64fced9b","modified":1581077492426},{"_id":"public/fancybox/jquery.fancybox.js","hash":"d08b03a42d5c4ba456ef8ba33116fdbb7a9cabed","modified":1581077492426},{"_id":"public/fancybox/jquery.fancybox.pack.js","hash":"9e0d51ca1dbe66f6c0c7aefd552dc8122e694a6e","modified":1581077492426},{"_id":"public/css/images/banner.jpg","hash":"f44aa591089fcb3ec79770a1e102fd3289a7c6a6","modified":1581077492426},{"_id":"public/css/fonts/fontawesome-webfont.svg","hash":"a275426daefd3716c53561fad121d258a7f05b47","modified":1581077492426},{"_id":"themes/hexo-theme-matery/.gitignore","hash":"727607929a51db7ea10968f547c26041eee9cfff","modified":1576130609000},{"_id":"themes/hexo-theme-matery/LICENSE","hash":"7df059597099bb7dcf25d2a9aedfaf4465f72d8d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/README.md","hash":"1c9c512aeafc29afef0a2ffab2aa53ea48b6bc72","modified":1576130609000},{"_id":"themes/hexo-theme-matery/_config.yml","hash":"c9ff14ed3a001f57e8e8f20d8635cb770da7bf6f","modified":1581170051528},{"_id":"themes/hexo-theme-matery/README_CN.md","hash":"e7565b179024ef8043d34c7b8468dc5f16ba366c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/languages/default.yml","hash":"54ccc01b097c5bf6820f0edfcece1a87b78ab32d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/languages/zh-CN.yml","hash":"a957b05f70265a86a87d922e18488571809d2472","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/archive.ejs","hash":"7fe7b9028b0da9c84715c3583b6b4172c2342ac8","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/categories.ejs","hash":"8e54665cc25d7c333da7d9f312987190be6215da","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/about.ejs","hash":"ee639d0310867976b3e5fb9f92c215a17a433703","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/contact.ejs","hash":"c3396cc5b1cbb102f500554f76946f5b45ee6d54","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/category.ejs","hash":"720d02e5fc37d154b60590bb7f64a2a4651c02db","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/friends.ejs","hash":"4cb216b2a650ad5d2942047a65d0883a188c2abb","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/index.ejs","hash":"92f053ac3e335129269036f862521326f10e80d8","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/layout.ejs","hash":"ae8103ff07796e3bce5a6707a069c939c4f60d5e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/tag.ejs","hash":"0c0194cf006fab2dccf4f788075e51cd06637df4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/post.ejs","hash":"f9662a96d0f497a3b2731472b8ad871c7cbdf13a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/tags.ejs","hash":"cf9517aa6a0111355121f44615d6923e312283c7","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/favicon.png","hash":"a0d1b4ed3749a5bc08546b2c4e11bff83075d0c6","modified":1581151923221},{"_id":"themes/hexo-theme-matery/layout/_partial/back-top.ejs","hash":"47ee36a042bb6d52bbe1d0f329637e8ffcf1d0aa","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-analytics.ejs","hash":"3bbcdb474ca1dcad514bdc4b7763e17c55df04fd","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/baidu-push.ejs","hash":"2cebcc5ea3614d7f76ec36670e68050cbe611202","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover-content.ejs","hash":"b5a1371f8b3d2a90ad575f1b6d25230e97ec0e7c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/bg-cover.ejs","hash":"02191109712f61c0e487b8f0b8466597181a9004","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/disqus.ejs","hash":"a0f53d1a9b579d52e52ccad8c6e330bf3b89547e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/footer.ejs","hash":"f358674421ef21f638b3e3633a447876fe2a07a5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/gitalk.ejs","hash":"fe7c785f0536ad828d957a9565ca5c53a0cead43","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/gitment.ejs","hash":"4f3a8f243ea07644fc599bdb44cc6be1a78fb0a1","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/github-link.ejs","hash":"3aeb581bd78ab8e15b858e4c44c03bcf92f20b9e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/google-analytics.ejs","hash":"5f4992205617da5f8cc5863c62b5ec46e414e2fb","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/head.ejs","hash":"61e03d8106ee4615f5f2ebc6ef7e648f5a1f9c65","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/header.ejs","hash":"f555d813f568a2dbf6f572559020c44d13975449","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/index-cover.ejs","hash":"489e629d460ea8c732cd2c1b38d7871af84cac89","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/livere.ejs","hash":"9c3401b42ea7f26410a5593bae93ada7e57b43be","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/mobile-nav.ejs","hash":"153b80047ac06a8d06a97002a98d38111d92b494","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/navigation.ejs","hash":"5ff6fdfe973619120a9eda4505bbff4545e39ff0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/paging.ejs","hash":"e2df12cf92a82b1a7a7add2eac1db1d954bc5511","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/post-cover.ejs","hash":"68738493f40e22ff82891e3aecaa2746c8470cd0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail-toc.ejs","hash":"78a9ea7cb06f7eb7a39a854ca25864e5dc574800","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/post-detail.ejs","hash":"2a000638814aafe4d812f09ce8f1b10bca314d8d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/post-statis.ejs","hash":"04889f9031743c6b081d02fa4027b0dbfcc45ecf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/prev-next.ejs","hash":"35b6b4a0200c10be6ae9d9558367718290476f84","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/reprint-statement.ejs","hash":"01f5eef82bbcb9d432631dbb78dd51d4d4b3b8b5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/reward.ejs","hash":"8a1176c4f33a0cd00db05561ce7b8ac6bceb322c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/search.ejs","hash":"84e1073b3bef478c352c271f8169d667db42f5eb","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/share.ejs","hash":"5bf9dabd3ab2e298ead92256f5a732f27939ec66","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/social-link.ejs","hash":"6f871bd3a70f720e4e451f1f4f625cbc6d8994a4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_partial/valine.ejs","hash":"60bcc9b0a0983d631c0fb69f6d1672d895df5107","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/category-radar.ejs","hash":"f5561dd7d53d68897a33090bf677719213459b19","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/category-cloud.ejs","hash":"424ef5db791264a79c1f3338e7c43a2f445cb2ab","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/dream.ejs","hash":"ba83115ce66f4328601e567aa30f50d1410b9bfa","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/music.ejs","hash":"1b7e97c73a6c466a521a277691e19b5c057f0546","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/my-projects.ejs","hash":"dbd8df5146bd6e873535e24f09dd7cf04e17a4e4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/my-gallery.ejs","hash":"de2e0abc085b721318f35c0b5d4891230be36529","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/my-skills.ejs","hash":"89a0092df72d23093128f2fbbdc8ca7f83ebcfd9","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/post-calendar.ejs","hash":"06c5196b3115b2a30cc6001529b08f21b54ce31f","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/post-charts.ejs","hash":"a3666971c96169aac38708675dbd2df2b44a4cdd","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-cloud.ejs","hash":"fc42b72cddc231f7485cdc1fd6852b66be6add26","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/recommend.ejs","hash":"a40f466dc96cedfcde66b89acdc0a2fa8a8dfefe","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/tag-wordcloud.ejs","hash":"e3f245c42d8a7c5810f689bd9a4ac48e77217260","modified":1576130609000},{"_id":"themes/hexo-theme-matery/layout/_widget/video.ejs","hash":"4162453e7e125013c8b1ad18ffc691a6ba124b88","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/css/matery.css","hash":"6479c6f4b5941e6bb14116f5a67a01c661c7341d","modified":1581168847759},{"_id":"themes/hexo-theme-matery/source/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/js/matery.js","hash":"07ed4f743a497d7850b3fdda2a5d9beccc5a8fb5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/avatar.jpg","hash":"55f9fa8d8649aa5c28bb8c449b051ea8fb3bd2b4","modified":1581148174252},{"_id":"themes/hexo-theme-matery/source/medias/comment_bg.png","hash":"dfc93d24081884fbc58cab0f8fd19e77d31d6123","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/icp.png","hash":"5d1a1f3051c8a4ad70afa0a5488dfa7f0bb27bd5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/logo.png","hash":"251339212ded7351f3e33f77a4470ddb7191236f","modified":1581151396182},{"_id":"themes/hexo-theme-matery/source/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/15.jpg","hash":"5cf9fc64d5d74ab6ba69bb8bff580fdc22ba32d0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/16.jpg","hash":"9cac6b80b0cc8959fc8aabfbd1adcab79ebebfc9","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/2.jpg","hash":"16f1d89cdba4dce935ac0f12599e0fcfda543a93","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/21.jpg","hash":"d70b088850c3565e5b5bb9eb8fe4abe688c964cf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/22.jpg","hash":"bf5b59d193e5ca089a7fff034c222bfa2c4dc41f","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/23.jpg","hash":"ed5ac9f616d3b99af5188a10b1761884c37e93e5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/5.jpg","hash":"c3c1f36a1b1886037db604f151f335cd4599e970","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/7.jpg","hash":"a0246a4a560438938489cdd154e35f172b3f31b0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/8.jpg","hash":"5a46ca4ab4c4ab2101a2af77a31a8878bccc483c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/reward/alipay.jpg","hash":"1abc719b95d1b26f1f898e6b0a9b7609146e332f","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/reward/wechat.png","hash":"fe93385aa92fe328e01c8221a80b039be9e4e140","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/0.jpg","hash":"2066cdda98ad0035071cd4aa7bd696eb078c0b6d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/1.jpg","hash":"d16e28bd23ea3a63643826dde5eea6b7a9bdda5d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/10.jpg","hash":"838e704942de076c60894d14e5f280e2724b6f68","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/11.jpg","hash":"9ed45f95b83626e3d91d6c405eb8bfe6fcb9736a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/12.jpg","hash":"047be4239dd7e0be83243ee6b49a392a61f16b9a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/13.jpg","hash":"66706dfde7d910182c2f1dbadd0e9e917630b8dd","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/17.jpg","hash":"f168ca5b046d10a878a7b0bcfab540e2c4428887","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/18.jpg","hash":"ae23fdfaa59bc57b7ed49e90c5d59e4b68e1eea5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/19.jpg","hash":"57bc7c804b78b5cceb4eb1f9e51b734b75151b71","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/20.jpg","hash":"8271c4a327632b566ea62f546c083d08a0528e72","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/3.jpg","hash":"5e879652e032f02961a331b598a50b60ebe80a39","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/4.jpg","hash":"4eea5bdb5724ef1ed65790e481eda0d2fb176bf0","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/6.jpg","hash":"c63ff64bdd5f6c82da8804c7248fc519d23eaf0b","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/9.jpg","hash":"815c84778b721e3606c2bd7c099c7de7c53251ba","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/gitalk/gitalk.min.js","hash":"734f56442e62fe55f677e8ccae7f175445667767","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.css","hash":"80ae4aa0dba3634dd9bf59586d541d2dd8d8191c","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/0.jpg","hash":"064e0471fa5f0c7dfba79b02552591df47632122","modified":1581492812034},{"_id":"themes/hexo-theme-matery/source/medias/banner/1.jpg","hash":"c3d5ab183b39a7140941b8375e29498f9d24f343","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/3.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/5.jpg","hash":"4a08deec1dd5b4f1490e8fc23adfb75a0f88b0c4","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/6.jpg","hash":"62e9586a8cec91a160f147c424a3d1d1aea360f9","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/featureimages/14.jpg","hash":"8aeb816faca2d5eaea4cce9e881d6ff87b8c7cf1","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/banner/4.jpg","hash":"56850c3139cbd72a0eff0c35d8fac32c9c66dd6a","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-regular-400.svg","hash":"229afff648cbd17de80176e0feb969c7f514be7e","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-brands-400.svg","hash":"25612c76ded31c497effe46454d8d2bb36fb99d6","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/libs/awesome/webfonts/fa-solid-900.svg","hash":"2c026711e4dd6b6d805cc19c0e4a572e6239a05b","modified":1576130609000},{"_id":"public/medias/icp.png","hash":"5d1a1f3051c8a4ad70afa0a5488dfa7f0bb27bd5","modified":1581078802573},{"_id":"public/medias/logo.png","hash":"251339212ded7351f3e33f77a4470ddb7191236f","modified":1581151540508},{"_id":"public/favicon.png","hash":"a0d1b4ed3749a5bc08546b2c4e11bff83075d0c6","modified":1581151959610},{"_id":"public/medias/avatar.jpg","hash":"55f9fa8d8649aa5c28bb8c449b051ea8fb3bd2b4","modified":1581170086367},{"_id":"public/medias/comment_bg.png","hash":"dfc93d24081884fbc58cab0f8fd19e77d31d6123","modified":1581078802573},{"_id":"public/medias/featureimages/15.jpg","hash":"5cf9fc64d5d74ab6ba69bb8bff580fdc22ba32d0","modified":1581078802573},{"_id":"public/medias/featureimages/16.jpg","hash":"9cac6b80b0cc8959fc8aabfbd1adcab79ebebfc9","modified":1581078802573},{"_id":"public/medias/featureimages/21.jpg","hash":"d70b088850c3565e5b5bb9eb8fe4abe688c964cf","modified":1581078802573},{"_id":"public/medias/featureimages/2.jpg","hash":"16f1d89cdba4dce935ac0f12599e0fcfda543a93","modified":1581078802573},{"_id":"public/medias/featureimages/22.jpg","hash":"bf5b59d193e5ca089a7fff034c222bfa2c4dc41f","modified":1581078802573},{"_id":"public/medias/featureimages/5.jpg","hash":"c3c1f36a1b1886037db604f151f335cd4599e970","modified":1581078802573},{"_id":"public/medias/featureimages/23.jpg","hash":"ed5ac9f616d3b99af5188a10b1761884c37e93e5","modified":1581078802573},{"_id":"public/medias/featureimages/7.jpg","hash":"a0246a4a560438938489cdd154e35f172b3f31b0","modified":1581078802573},{"_id":"public/medias/featureimages/8.jpg","hash":"5a46ca4ab4c4ab2101a2af77a31a8878bccc483c","modified":1581078802573},{"_id":"public/medias/reward/alipay.jpg","hash":"1abc719b95d1b26f1f898e6b0a9b7609146e332f","modified":1581078802573},{"_id":"public/medias/reward/wechat.png","hash":"fe93385aa92fe328e01c8221a80b039be9e4e140","modified":1581078802573},{"_id":"public/medias/featureimages/13.jpg","hash":"66706dfde7d910182c2f1dbadd0e9e917630b8dd","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-regular-400.ttf","hash":"0f4bd02942a54a6b3200d9078adff88c2812e751","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-regular-400.eot","hash":"439c8afd3373acb4a73135a34e220464a89cd5e2","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff","hash":"59439d3ad31d856d78ec3e2bd9f1eafa2c7a581c","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-regular-400.woff2","hash":"f6f653b4ea8fc487bdb590d39d5a726258a55f40","modified":1581078802573},{"_id":"public/libs/lightGallery/fonts/lg.eot","hash":"54caf05a81e33d7bf04f2e420736ce6f1de5f936","modified":1581078802573},{"_id":"public/libs/lightGallery/fonts/lg.svg","hash":"9a732790adc004b22022cc60fd5f77ec4c8e3e5a","modified":1581078802573},{"_id":"public/libs/lightGallery/fonts/lg.ttf","hash":"f6421c0c397311ae09f9257aa58bcd5e9720f493","modified":1581078802573},{"_id":"public/libs/lightGallery/fonts/lg.woff","hash":"3048de344dd5cad4624e0127e58eaae4b576f574","modified":1581078802573},{"_id":"public/libs/lightGallery/img/loading.gif","hash":"15a76af2739482d8de7354abc6d8dc4fca8d145e","modified":1581078802573},{"_id":"public/libs/lightGallery/img/video-play.png","hash":"fbfdbe06aebf7d0c00da175a4810cf888d128f11","modified":1581078802573},{"_id":"public/libs/lightGallery/img/vimeo-play.png","hash":"1142b47de219dddfba2e712cd3189dec0c8b7bee","modified":1581078802573},{"_id":"public/libs/lightGallery/img/youtube-play.png","hash":"39150b45ec5fc03155b7ebeaa44f1829281788e2","modified":1581078802573},{"_id":"public/libs/share/fonts/iconfont.eot","hash":"00ff749c8e202401190cc98d56087cdda716abe4","modified":1581078802573},{"_id":"public/libs/share/fonts/iconfont.svg","hash":"f0a1b849868a6bf351ff98dc3924a4e7254eb88b","modified":1581078802573},{"_id":"public/libs/share/fonts/iconfont.woff","hash":"2e3fce1dcfbd6e2114e7bfbeaf72d3c62e15a1bd","modified":1581078802573},{"_id":"public/libs/share/fonts/iconfont.ttf","hash":"afd898f59d363887418669520b24d175f966a083","modified":1581078802573},{"_id":"public/js/matery.js","hash":"07ed4f743a497d7850b3fdda2a5d9beccc5a8fb5","modified":1581078802573},{"_id":"public/css/gitment.css","hash":"2bd15cc17dca35ac3ecc0acf167a23a1dd362acd","modified":1581078802573},{"_id":"public/js/search.js","hash":"499e11786efbb04815b54a1de317cc8606a37555","modified":1581078802573},{"_id":"public/css/my-gitalk.css","hash":"eeda46a83d0db1cc239a9cd27d544faf663f9883","modified":1581078802573},{"_id":"public/css/my.css","hash":"10577fbc30f241b126d1b51b1f56136ecba86b19","modified":1581078802573},{"_id":"public/libs/aos/aos.js","hash":"02bfb40b0c4b6e9b0b4081218357145cbb327d74","modified":1581078802573},{"_id":"public/libs/codeBlock/codeBlockFuction.js","hash":"c7ab06d27a525b15b1eb69027135269e9b9132fb","modified":1581078802573},{"_id":"public/libs/aplayer/APlayer.min.css","hash":"07372a2ba507388d0fed166d761b1c2c2a659dce","modified":1581078802573},{"_id":"public/libs/codeBlock/codeCopy.js","hash":"6d39a766af62e625f177c4d5cf3adc35eed71e61","modified":1581078802573},{"_id":"public/libs/codeBlock/codeShrink.js","hash":"201e8cd761b4be557247bdaf1ebc7c11c83194f6","modified":1581078802573},{"_id":"public/libs/background/canvas-nest.js","hash":"65333d0dbb9c1173a1b13031b230161fc42c8b2f","modified":1581078802573},{"_id":"public/libs/codeBlock/codeLang.js","hash":"bac88b4d4e3679732d29bd037c34f089cf27cf05","modified":1581078802573},{"_id":"public/libs/background/ribbon-refresh.min.js","hash":"6d98692b2cad8c746a562db18b170b35c24402f4","modified":1581078802573},{"_id":"public/libs/background/ribbon-dynamic.js","hash":"052b80c29e6bc585aa28d4504b743bdbac220a88","modified":1581078802573},{"_id":"public/libs/background/ribbon.min.js","hash":"6a99d494c030388f96f6086a7aaa0f03f3fe532e","modified":1581078802573},{"_id":"public/libs/instantpage/instantpage.js","hash":"83ce8919b1a69b2f1809ffaf99b52a8627e650e9","modified":1581078802573},{"_id":"public/libs/jqcloud/jqcloud-1.0.4.min.js","hash":"257eaae3020599e4939f50d5008a743827f25b8c","modified":1581078802573},{"_id":"public/libs/jqcloud/jqcloud.css","hash":"20d9f11a19d95c70e27cb922e0d6dccbec4eae89","modified":1581078802573},{"_id":"public/libs/others/busuanzi.pure.mini.js","hash":"6e41f31100ae7eb3a6f23f2c168f6dd56e7f7a9a","modified":1581078802573},{"_id":"public/libs/others/clicklove.js","hash":"6a39b8c683ba5dcd92f70c6ab45d1cfac3213e8e","modified":1581078802573},{"_id":"public/css/matery.css","hash":"6479c6f4b5941e6bb14116f5a67a01c661c7341d","modified":1581168854524},{"_id":"public/libs/animate/animate.min.css","hash":"97afa151569f046b2e01f27c1871646e9cd87caf","modified":1581078802573},{"_id":"public/libs/aplayer/APlayer.min.js","hash":"22caa28ff6b41a16ff40f15d38f1739e22359478","modified":1581078802573},{"_id":"public/libs/aos/aos.css","hash":"191a3705a8f63e589a50a0ff2f2c5559f1a1b6b2","modified":1581078802573},{"_id":"public/libs/cryptojs/crypto-js.min.js","hash":"5989527a378b55011a59522f41eeb3981518325c","modified":1581078802573},{"_id":"public/libs/gitalk/gitalk.css","hash":"3aac1db83b0135c521187254ff302d125cc30706","modified":1581078802573},{"_id":"public/libs/dplayer/DPlayer.min.css","hash":"f7d19655f873b813ffba5d1a17145c91f82631b8","modified":1581078802573},{"_id":"public/libs/gitment/gitment-default.css","hash":"2903c59ee06b965bef32e937bd69f5b0b2190717","modified":1581078802573},{"_id":"public/libs/masonry/masonry.pkgd.min.js","hash":"ff940b4ea68368ca0e4d5560cbb79fb147dfc3c5","modified":1581078802573},{"_id":"public/medias/featureimages/0.jpg","hash":"2066cdda98ad0035071cd4aa7bd696eb078c0b6d","modified":1581078802573},{"_id":"public/medias/featureimages/1.jpg","hash":"d16e28bd23ea3a63643826dde5eea6b7a9bdda5d","modified":1581078802573},{"_id":"public/medias/featureimages/10.jpg","hash":"838e704942de076c60894d14e5f280e2724b6f68","modified":1581078802573},{"_id":"public/medias/featureimages/11.jpg","hash":"9ed45f95b83626e3d91d6c405eb8bfe6fcb9736a","modified":1581078802573},{"_id":"public/medias/featureimages/12.jpg","hash":"047be4239dd7e0be83243ee6b49a392a61f16b9a","modified":1581078802573},{"_id":"public/medias/featureimages/17.jpg","hash":"f168ca5b046d10a878a7b0bcfab540e2c4428887","modified":1581078802573},{"_id":"public/medias/featureimages/19.jpg","hash":"57bc7c804b78b5cceb4eb1f9e51b734b75151b71","modified":1581078802573},{"_id":"public/medias/featureimages/18.jpg","hash":"ae23fdfaa59bc57b7ed49e90c5d59e4b68e1eea5","modified":1581078802573},{"_id":"public/medias/featureimages/20.jpg","hash":"8271c4a327632b566ea62f546c083d08a0528e72","modified":1581078802573},{"_id":"public/medias/featureimages/3.jpg","hash":"5e879652e032f02961a331b598a50b60ebe80a39","modified":1581078802573},{"_id":"public/medias/featureimages/6.jpg","hash":"c63ff64bdd5f6c82da8804c7248fc519d23eaf0b","modified":1581078802573},{"_id":"public/medias/featureimages/4.jpg","hash":"4eea5bdb5724ef1ed65790e481eda0d2fb176bf0","modified":1581078802573},{"_id":"public/medias/featureimages/9.jpg","hash":"815c84778b721e3606c2bd7c099c7de7c53251ba","modified":1581078802573},{"_id":"public/medias/banner/0.jpg","hash":"064e0471fa5f0c7dfba79b02552591df47632122","modified":1581492901525},{"_id":"public/medias/banner/2.jpg","hash":"8d3c8391ff161eec70f66d69e5545a9468cc52ef","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff2","hash":"9c081b88b106c6c04ecb895ba7ba7d3dcb3b55ac","modified":1581078802573},{"_id":"public/medias/featureimages/14.jpg","hash":"8aeb816faca2d5eaea4cce9e881d6ff87b8c7cf1","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff","hash":"18838f5260317da3c5ed29bf844ac8a4f7ad0529","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-solid-900.woff","hash":"92803b8753ceda573c6906774677c5a7081d2fbb","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-brands-400.eot","hash":"22f9e7d5226408eb2d0a11e118257a3ca22b8670","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-brands-400.ttf","hash":"91cbeeaceb644a971241c08362898599d6d968ce","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-brands-400.woff2","hash":"a46bd47ff0a90b812aafafda587d095cdb844271","modified":1581078802573},{"_id":"public/libs/scrollprogress/scrollProgress.min.js","hash":"777ffe5d07e85a14fbe97d846f45ffc0087251cc","modified":1581078802573},{"_id":"public/libs/tocbot/tocbot.css","hash":"15601837bf8557c2fd111e4450ed4c8495fd11a0","modified":1581078802573},{"_id":"public/libs/tocbot/tocbot.min.js","hash":"5ec27317f0270b8cf6b884c6f12025700b9a565c","modified":1581078802573},{"_id":"public/libs/share/css/share.min.css","hash":"8a778a86f3ce9a042df6be63a9f1039631e351a5","modified":1581078802573},{"_id":"public/libs/dplayer/DPlayer.min.js","hash":"c3bad7b265574fab0ae4d45867422ea1cb9d6599","modified":1581078802573},{"_id":"public/libs/gitment/gitment.js","hash":"28c02c45ce568e084cd1041dc493f83f9c6c88c6","modified":1581078802573},{"_id":"public/libs/valine/Valine.min.js","hash":"6cbdbf91e1f046dd41267a5ff0691a1fccba99df","modified":1581078802573},{"_id":"public/libs/jquery/jquery.min.js","hash":"2115753ca5fb7032aec498db7bb5dca624dbe6be","modified":1581078802573},{"_id":"public/libs/lightGallery/css/lightgallery.min.css","hash":"1b7227237f9785c66062a4811508916518e4132c","modified":1581078802573},{"_id":"public/libs/gitalk/gitalk.min.js","hash":"734f56442e62fe55f677e8ccae7f175445667767","modified":1581078802573},{"_id":"public/libs/lightGallery/js/lightgallery-all.min.js","hash":"9f5ef4bc8a0a3c746ca4f3c3e6d64493b1a977d8","modified":1581078802573},{"_id":"public/libs/materialize/materialize.min.css","hash":"580459a012f556fba86438953062013a94b201af","modified":1581078802573},{"_id":"public/libs/materialize/materialize.min.js","hash":"c8b4c65651921d888cf5f27430dfe2ad190d35bf","modified":1581078802573},{"_id":"public/libs/share/js/jquery.share.min.js","hash":"41367dcb857e02e3c417ebe68a554ce1d4430806","modified":1581078802573},{"_id":"public/libs/share/js/social-share.min.js","hash":"a3090a02786dcd4efc6355c1c1dc978add8d6827","modified":1581078802573},{"_id":"public/libs/valine/av-min.js","hash":"541efb9edc1ce425cbe3897cfc25803211fe6a05","modified":1581078802573},{"_id":"public/libs/awesome/css/all.css","hash":"ecc41e32ad2696877a1656749841f3b5543bbe3d","modified":1581078802573},{"_id":"public/medias/cover.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1581078802573},{"_id":"public/medias/banner/1.jpg","hash":"c3d5ab183b39a7140941b8375e29498f9d24f343","modified":1581078802573},{"_id":"public/medias/banner/3.jpg","hash":"d4957ff7cc5e88555cd840f2956ab0561e6f1ccf","modified":1581078802573},{"_id":"public/medias/banner/5.jpg","hash":"4a08deec1dd5b4f1490e8fc23adfb75a0f88b0c4","modified":1581078802573},{"_id":"public/medias/banner/6.jpg","hash":"62e9586a8cec91a160f147c424a3d1d1aea360f9","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-regular-400.svg","hash":"229afff648cbd17de80176e0feb969c7f514be7e","modified":1581078802573},{"_id":"public/libs/echarts/echarts.min.js","hash":"9496f386a0da4601cad22c479cc5543913a4d67f","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-solid-900.ttf","hash":"9521ed12274c2cbc910cea77657116fcf6545da3","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-solid-900.eot","hash":"cab8e84ae5682d1d556e234df9c790985888def8","modified":1581078802573},{"_id":"public/medias/banner/4.jpg","hash":"56850c3139cbd72a0eff0c35d8fac32c9c66dd6a","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-solid-900.svg","hash":"2c026711e4dd6b6d805cc19c0e4a572e6239a05b","modified":1581078802573},{"_id":"public/libs/awesome/webfonts/fa-brands-400.svg","hash":"25612c76ded31c497effe46454d8d2bb36fb99d6","modified":1581078802573},{"_id":"source/tags/index.md","hash":"c8ffee4cc836585a5246be3b7d76b8da8960095d","modified":1581079762489},{"_id":"public/tags/index.html","hash":"f70d1a9b17af85c61dc14b8c9191d714a5347373","modified":1588688234924},{"_id":"source/_posts/GCN原理.md","hash":"7b9156bdd3e1a93714786af033bfe2a0791faf8a","modified":1591596295111},{"_id":"source/about/index.md","hash":"be1fce3e68a2fb850912ebd89758f6443b38b416","modified":1581085433709},{"_id":"source/categories/index.md","hash":"5330646fc5cb431dc74f8b096aa488b3ec4464cd","modified":1581085336413},{"_id":"public/categories/index.html","hash":"bc60199a54f92e2479e71091f5f8c9b586615fe4","modified":1591596346381},{"_id":"public/about/index.html","hash":"98871690b3100e9b5bd201742b0de9b666e3d34c","modified":1591596346381},{"_id":"public/2020/02/08/GCN原理/index.html","hash":"150b69572fc77fc8a88725870f30dc2cc9adc813","modified":1591596346381},{"_id":"source/_posts/CNN的各种卷积.md","hash":"21068fa15a89f6a366077e766b0752fdb1faa2ea","modified":1581153248257},{"_id":"public/2020/02/08/CNN的各种卷积/index.html","hash":"32b6c584856c7c3ea4b0d17cd6c1d29fb88056a5","modified":1581153260674},{"_id":"public/tags/GCN-科研/index.html","hash":"08713a67fef6e42df5361f78a8b84510526457fa","modified":1583570487412},{"_id":"source/_posts/src/CNN-Filter/空间可分卷积.jpg","hash":"e7d250caa59b47d6052ceb89582454fc482af056","modified":1580214334888},{"_id":"source/_posts/src/pic/GCN-1st.png","hash":"b0ade7d574a911dfc3b71aff1413213a7f2a5ae6","modified":1580131527197},{"_id":"source/_posts/src/pic/GCN-2nd.png","hash":"81fc621582508e7b08131b219bfe86ba7e89dfa6","modified":1580131527198},{"_id":"source/_posts/src/pic/Simple-GCN-schematic.png","hash":"5c3af6421728add936eec9ff0add411139459884","modified":1580131527207},{"_id":"source/_posts/src/pic/GCN-schematic.png","hash":"c35d19a977a6132b2f36853f38457da67a90f1f2","modified":1580131527199},{"_id":"source/_posts/src/CNN-Filter/空间可分卷积2.jpg","hash":"aa25eb736a21025aa5693a89e58634ea4f9477fd","modified":1580214884341},{"_id":"source/_posts/src/CNN-Filter/转置卷积1.jpg","hash":"534ebfe4a7ba29c62031795ceef1ef9e04147e92","modified":1580212511830},{"_id":"source/_posts/src/CNN-Filter/深度可分卷积.jpg","hash":"cbc10b1e855d77c20ffe0f556b069bcb4d6789a0","modified":1580215186052},{"_id":"source/_posts/src/CNN-Filter/转置卷积2.jpg","hash":"1e048169286be589bb5c90e2f4f781ad99b0b9a5","modified":1580213107761},{"_id":"source/_posts/src/CNN-Filter/扩张卷积.jpg","hash":"0666db1b65ae7038615be4aaaa98a875f0765314","modified":1580213905061},{"_id":"source/_posts/src/CNN-Filter/分组卷积.jpg","hash":"aa4ace1ead45ef9fa44ca7018a2e4f7a710da472","modified":1580215331855},{"_id":"source/_posts/src/CNN-Filter/普通卷积的实现.jpg","hash":"4c3484bbefe20d1eb39e8ef6fea2eb16929f6aeb","modified":1580213371345},{"_id":"source/_posts/src/CNN-Filter/转置卷积的实现.jpg","hash":"b286049fbf135d5f41562cd87d9e4d69b727629a","modified":1580213463425},{"_id":"source/_posts/src/CNN-Filter/3d.jpg","hash":"a1d63bc122a263e32c21ceb71230e8cbd467485d","modified":1580132006847},{"_id":"source/_posts/src/pic/LandL2.png","hash":"0d379e0f1efcae79f7d9e0915f1183bb7c9a20a3","modified":1580131527205},{"_id":"themes/hexo-theme-matery/source/favicon_o.png","hash":"20674c497b75fc889194b47fd18ecea12303d8ec","modified":1576130609000},{"_id":"themes/hexo-theme-matery/source/medias/logo_o.png","hash":"4050259723bd418648ec40028a8020364e57a6a3","modified":1576130609000},{"_id":"public/favicon_o.png","hash":"20674c497b75fc889194b47fd18ecea12303d8ec","modified":1581151540508},{"_id":"public/medias/logo_o.png","hash":"4050259723bd418648ec40028a8020364e57a6a3","modified":1581151540508},{"_id":"public/tags/CNN-卷积-深度学习/index.html","hash":"c3066cba657557a24db1f87a7db4aba9409be740","modified":1583570487412},{"_id":"source/_posts/CNN中的各种卷积.md","hash":"21068fa15a89f6a366077e766b0752fdb1faa2ea","modified":1581153248257},{"_id":"public/2020/02/08/CNN中的各种卷积/index.html","hash":"e449d567147f2a2e8b42bf77a93594d70f75702c","modified":1581170086367},{"_id":"themes/hexo-theme-matery/source/medias/banner/7.jpg","hash":"5b442a015a38a0d6fbf5286f1717756b6eab1014","modified":1545058884280},{"_id":"public/medias/banner/7.jpg","hash":"5b442a015a38a0d6fbf5286f1717756b6eab1014","modified":1581170776075},{"_id":"source/_posts/CNN卷积.md","hash":"fa791177fb8cf4fa033ee22b02a6dc0898fe8c70","modified":1591596298690},{"_id":"source/_posts/CNN卷积/空间可分卷积.jpg","hash":"e7d250caa59b47d6052ceb89582454fc482af056","modified":1580214334888},{"_id":"source/_posts/CNN卷积/转置卷积1.jpg","hash":"534ebfe4a7ba29c62031795ceef1ef9e04147e92","modified":1580212511830},{"_id":"source/_posts/CNN卷积/空间可分卷积2.jpg","hash":"aa25eb736a21025aa5693a89e58634ea4f9477fd","modified":1580214884341},{"_id":"source/_posts/CNN卷积/深度可分卷积.jpg","hash":"cbc10b1e855d77c20ffe0f556b069bcb4d6789a0","modified":1580215186052},{"_id":"source/_posts/CNN卷积/转置卷积2.jpg","hash":"1e048169286be589bb5c90e2f4f781ad99b0b9a5","modified":1580213107761},{"_id":"source/_posts/CNN卷积/分组卷积.jpg","hash":"aa4ace1ead45ef9fa44ca7018a2e4f7a710da472","modified":1580215331855},{"_id":"source/_posts/CNN卷积/扩张卷积.jpg","hash":"0666db1b65ae7038615be4aaaa98a875f0765314","modified":1580213905061},{"_id":"source/_posts/CNN卷积/普通卷积的实现.jpg","hash":"4c3484bbefe20d1eb39e8ef6fea2eb16929f6aeb","modified":1580213371345},{"_id":"source/_posts/CNN卷积/转置卷积的实现.jpg","hash":"b286049fbf135d5f41562cd87d9e4d69b727629a","modified":1580213463425},{"_id":"source/_posts/CNN卷积/3d.jpg","hash":"a1d63bc122a263e32c21ceb71230e8cbd467485d","modified":1580132006847},{"_id":"public/2020/02/08/CNN卷积/index.html","hash":"5becccdfe16d4ec78c5f9d35a09eb11444f8b99b","modified":1591596346381},{"_id":"public/2020/02/08/CNN卷积/空间可分卷积.jpg","hash":"e7d250caa59b47d6052ceb89582454fc482af056","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/空间可分卷积2.jpg","hash":"aa25eb736a21025aa5693a89e58634ea4f9477fd","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/转置卷积1.jpg","hash":"534ebfe4a7ba29c62031795ceef1ef9e04147e92","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/深度可分卷积.jpg","hash":"cbc10b1e855d77c20ffe0f556b069bcb4d6789a0","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/转置卷积2.jpg","hash":"1e048169286be589bb5c90e2f4f781ad99b0b9a5","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/扩张卷积.jpg","hash":"0666db1b65ae7038615be4aaaa98a875f0765314","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/普通卷积的实现.jpg","hash":"4c3484bbefe20d1eb39e8ef6fea2eb16929f6aeb","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/转置卷积的实现.jpg","hash":"b286049fbf135d5f41562cd87d9e4d69b727629a","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/分组卷积.jpg","hash":"aa4ace1ead45ef9fa44ca7018a2e4f7a710da472","modified":1581245690821},{"_id":"public/2020/02/08/CNN卷积/3d.jpg","hash":"a1d63bc122a263e32c21ceb71230e8cbd467485d","modified":1581245690821},{"_id":"source/_posts/GCN原理/GCN-2nd.png","hash":"81fc621582508e7b08131b219bfe86ba7e89dfa6","modified":1580131527198},{"_id":"source/_posts/GCN原理/Simple-GCN-schematic.png","hash":"5c3af6421728add936eec9ff0add411139459884","modified":1580131527207},{"_id":"source/_posts/GCN原理/GCN-1st.png","hash":"b0ade7d574a911dfc3b71aff1413213a7f2a5ae6","modified":1580131527197},{"_id":"source/_posts/GCN原理/GCN-schematic.png","hash":"c35d19a977a6132b2f36853f38457da67a90f1f2","modified":1580131527199},{"_id":"source/_posts/GCN原理/LandL2.png","hash":"0d379e0f1efcae79f7d9e0915f1183bb7c9a20a3","modified":1580131527205},{"_id":"public/2020/02/08/GCN原理/Simple-GCN-schematic.png","hash":"5c3af6421728add936eec9ff0add411139459884","modified":1581247615025},{"_id":"public/2020/02/08/GCN原理/GCN-2nd.png","hash":"81fc621582508e7b08131b219bfe86ba7e89dfa6","modified":1581247615025},{"_id":"public/2020/02/08/GCN原理/GCN-1st.png","hash":"b0ade7d574a911dfc3b71aff1413213a7f2a5ae6","modified":1581247615025},{"_id":"public/2020/02/08/GCN原理/GCN-schematic.png","hash":"c35d19a977a6132b2f36853f38457da67a90f1f2","modified":1581247615025},{"_id":"public/2020/02/08/GCN原理/LandL2.png","hash":"0d379e0f1efcae79f7d9e0915f1183bb7c9a20a3","modified":1581247615025},{"_id":"themes/hexo-theme-matery/source/medias/banner/8.jpg","hash":"4a08deec1dd5b4f1490e8fc23adfb75a0f88b0c4","modified":1576130609000},{"_id":"public/medias/banner/8.jpg","hash":"4a08deec1dd5b4f1490e8fc23adfb75a0f88b0c4","modified":1581492901525},{"_id":"source/_posts/祝大家情人节牛批.md","hash":"f41934f70b08db7f83ba1c444c826b52aa555873","modified":1581651674066},{"_id":"public/2020/02/14/祝大家情人节牛批/index.html","hash":"9eb3059603d3adb5595cbf7ae9fe20486a52a6ef","modified":1591596346381},{"_id":"source/_posts/操作系统复习.md","hash":"85f6f67843c67d932b15b4862c8e22122046b8c7","modified":1591596308097},{"_id":"source/_posts/操作系统复习/进程调度.png","hash":"0b8f024746e6d088166edaf0d8b89fdebacd1475","modified":1581826756644},{"_id":"public/tags/计算机操作系统/index.html","hash":"f56452071f6a51ed0e6dbce14a7dc8cb68999377","modified":1581910167123},{"_id":"public/2020/02/16/操作系统复习/index.html","hash":"2a22b86ce2a7e21e48f5d1189120ca6ed38c172b","modified":1591596346381},{"_id":"public/2020/02/16/操作系统复习/进程调度.png","hash":"0b8f024746e6d088166edaf0d8b89fdebacd1475","modified":1581834744680},{"_id":"public/css/prism-line-numbers.css","hash":"e0db113a99e4a09d2161a539b1652d96e4a22fac","modified":1581910167123},{"_id":"public/css/prism-tomorrow.css","hash":"3b99487dfc9b4e51e9105a93743b92a761840e34","modified":1581910167123},{"_id":"source/_posts/操作系统复习/生产者吸烟者.png","hash":"bb6940ba659af2bc494f2fdb3d1628d25d5605ce","modified":1581913921739},{"_id":"public/tags/操作系统/index.html","hash":"93981dca135a847e1485f49115f0d6da276a3515","modified":1591596346381},{"_id":"public/2020/02/16/操作系统复习/生产者吸烟者.png","hash":"bb6940ba659af2bc494f2fdb3d1628d25d5605ce","modified":1581915880396},{"_id":"source/_posts/操作系统复习/进程七状态模型.png","hash":"57e2da1ff202e4d7800901b359bd27c72ad22a59","modified":1582085310514},{"_id":"public/2020/02/16/操作系统复习/进程七状态模型.png","hash":"57e2da1ff202e4d7800901b359bd27c72ad22a59","modified":1582092213248},{"_id":"source/_posts/Java中是值传递.md","hash":"bdf203d446b95d911c4fa2bad5809efe7e38c47c","modified":1591596279411},{"_id":"public/2020/02/21/Java中是值传递/index.html","hash":"f0c4318ff20fa961618d3f388ffbf76da7dccc42","modified":1591596346381},{"_id":"public/tags/java/index.html","hash":"3b8378a66e8878c448a0b02904c6c7610278346e","modified":1583570487412},{"_id":"source/_posts/操作系统复习/文件的层次结构.jpg","hash":"6f4c793019ad9c9d5849df6bbbe864a1bd282eaf","modified":1582633552776},{"_id":"public/2020/02/16/操作系统复习/文件的层次结构.jpg","hash":"6f4c793019ad9c9d5849df6bbbe864a1bd282eaf","modified":1582633685614},{"_id":"source/_posts/计算机网络复习.md","hash":"e776a054affd7edbfe1a3da9f64a31fed898343c","modified":1591596306505},{"_id":"public/2020/03/02/计算机网络复习/index.html","hash":"c6fe4c993cfa6e377b403a1b4041f6690308176a","modified":1591596346381},{"_id":"public/archives/2020/03/index.html","hash":"3e4a32edd07ca12e35a3647e7b72cd8c6f652fee","modified":1591596346381},{"_id":"public/tags/计算机网络/index.html","hash":"27f34d68e102a07fec9915faeb62496e3cea539c","modified":1591596346381},{"_id":"source/_posts/进程与线程-转载.md","hash":"912680007600f83c96ba618a9972806e3495aa17","modified":1591596304751},{"_id":"source/_posts/图解HTTP读书笔记.md","hash":"470bbe299b222fbb83b33b70a4501652543d78d7","modified":1591596302170},{"_id":"public/2020/03/06/图解HTTP读书笔记/index.html","hash":"a0e3d82e57a0107679db50c307c6a73676f91425","modified":1591596346381},{"_id":"source/_posts/图解HTTP读书笔记/HTTP报文.jpg","hash":"0513d0f74215d06c58709c67da12d1d988b44a42","modified":1583570338660},{"_id":"source/_posts/图解HTTP读书笔记/HTTP报文2.jpg","hash":"1b9849e428d71c6657d8e37596c59ea5eba77930","modified":1583570446074},{"_id":"public/2020/03/06/进程与线程-转载/index.html","hash":"289c0f2c1e66559e7de3acf70442ed25ebc3fd67","modified":1591596346381},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTP报文.jpg","hash":"0513d0f74215d06c58709c67da12d1d988b44a42","modified":1583570487412},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTP报文2.jpg","hash":"1b9849e428d71c6657d8e37596c59ea5eba77930","modified":1583570487412},{"_id":"source/_posts/图解HTTP读书笔记/HTTP状态码.jpg","hash":"f03409fbe5f81a8a82b0a3cc1cd2d5fc5baa1a61","modified":1583652660876},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTP状态码.jpg","hash":"f03409fbe5f81a8a82b0a3cc1cd2d5fc5baa1a61","modified":1583665010251},{"_id":"source/_posts/图解HTTP读书笔记/代理.jpg","hash":"7e7bdd552ae72438bda61391765e417fc88fd808","modified":1583755328897},{"_id":"public/2020/03/06/图解HTTP读书笔记/代理.jpg","hash":"7e7bdd552ae72438bda61391765e417fc88fd808","modified":1583756257990},{"_id":"source/_posts/图解HTTP读书笔记/实体首部字段.jpg","hash":"bb6a6c6bf15bc82f88aafb0c73ccf0b7f76bac9e","modified":1583756796342},{"_id":"source/_posts/图解HTTP读书笔记/响应首部字段.jpg","hash":"691961bf3806d9737acf1d577791d0a17ad57ba3","modified":1583756732665},{"_id":"source/_posts/图解HTTP读书笔记/请求首部字段.jpg","hash":"37d64bf83569c2ae4073d514f4cd57df7c8fec22","modified":1583756710758},{"_id":"source/_posts/图解HTTP读书笔记/通用首部字段.jpg","hash":"6f07db6903b96fa5e613d81b84ace1869a4781fb","modified":1583756616750},{"_id":"public/2020/03/06/图解HTTP读书笔记/实体首部字段.jpg","hash":"bb6a6c6bf15bc82f88aafb0c73ccf0b7f76bac9e","modified":1583759010731},{"_id":"public/2020/03/06/图解HTTP读书笔记/响应首部字段.jpg","hash":"691961bf3806d9737acf1d577791d0a17ad57ba3","modified":1583759010731},{"_id":"public/2020/03/06/图解HTTP读书笔记/通用首部字段.jpg","hash":"6f07db6903b96fa5e613d81b84ace1869a4781fb","modified":1583759010731},{"_id":"public/2020/03/06/图解HTTP读书笔记/请求首部字段.jpg","hash":"37d64bf83569c2ae4073d514f4cd57df7c8fec22","modified":1583759010731},{"_id":"source/_posts/图解HTTP读书笔记/缓存请求指令.jpg","hash":"59b6946d8e3b4084aa0ade3d0e36581dc44ec4b7","modified":1583814635983},{"_id":"source/_posts/图解HTTP读书笔记/缓存响应指令.jpg","hash":"1d857e8158131fcb2573ad7dd9a57d24f0c931e9","modified":1583814676579},{"_id":"public/2020/03/06/图解HTTP读书笔记/缓存请求指令.jpg","hash":"59b6946d8e3b4084aa0ade3d0e36581dc44ec4b7","modified":1583829749079},{"_id":"public/2020/03/06/图解HTTP读书笔记/缓存响应指令.jpg","hash":"1d857e8158131fcb2573ad7dd9a57d24f0c931e9","modified":1583829749079},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS.jpg","hash":"d1f7f3af214a2a7a012cff2789cb8a2ba47f80cc","modified":1583907151774},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS混合加密机制.jpg","hash":"7cbe27870571dc312797aa8e3668ad19483e4978","modified":1583907730981},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTPS.jpg","hash":"d1f7f3af214a2a7a012cff2789cb8a2ba47f80cc","modified":1583908998575},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTPS混合加密机制.jpg","hash":"7cbe27870571dc312797aa8e3668ad19483e4978","modified":1583908998575},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS通信步骤.jpg","hash":"8347ffe754b25c9b0337053a96edaac6215bc98b","modified":1583928989231},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS通信细节.jpg","hash":"63d535542dfbec9388fc905e4a0e28ccc9fd395d","modified":1583930081987},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTPS通信步骤.jpg","hash":"8347ffe754b25c9b0337053a96edaac6215bc98b","modified":1583930665437},{"_id":"public/2020/03/06/图解HTTP读书笔记/HTTPS通信细节.jpg","hash":"63d535542dfbec9388fc905e4a0e28ccc9fd395d","modified":1583930665437},{"_id":"source/_posts/图解HTTP读书笔记/SPDY.jpg","hash":"3ad65b69231b957fcb7456c6dd041d9149194e57","modified":1583994857354},{"_id":"public/2020/03/06/图解HTTP读书笔记/SPDY.jpg","hash":"3ad65b69231b957fcb7456c6dd041d9149194e57","modified":1583997180985},{"_id":"source/_posts/计算机网络复习/HTTP2二进制报文.jpg","hash":"dba27a9ad374e5bf9e5276c8d1bf5f9048044995","modified":1584092607362},{"_id":"source/_posts/计算机网络复习/HTTP1.1-HTTP3对比.jpg","hash":"a22b9941d1c85908bc93b49455617a81402b9b50","modified":1584098658456},{"_id":"source/_posts/计算机网络复习/QUIC-HTTPS.jpg","hash":"00d066e15d7e331e408b7fe10cc2a719e36726a8","modified":1584098745651},{"_id":"public/2020/03/02/计算机网络复习/HTTP2二进制报文.jpg","hash":"dba27a9ad374e5bf9e5276c8d1bf5f9048044995","modified":1584098840099},{"_id":"public/2020/03/02/计算机网络复习/HTTP1.1-HTTP3对比.jpg","hash":"a22b9941d1c85908bc93b49455617a81402b9b50","modified":1584098840099},{"_id":"public/2020/03/02/计算机网络复习/QUIC-HTTPS.jpg","hash":"00d066e15d7e331e408b7fe10cc2a719e36726a8","modified":1584098840099},{"_id":"source/_posts/GNN需要解决的关键问题.md","hash":"dc9084cc8be614e85446bc6e8b62c9d57736b0fa","modified":1591596268499},{"_id":"source/_posts/可视化.md","hash":"83fe044f294c19399cf899fc45cdc10c8e7188b0","modified":1591596303391},{"_id":"public/2020/04/16/GNN需要解决的关键问题/index.html","hash":"b7318689667bb3a5ec94254e7e11d3aaecbd357d","modified":1591596346381},{"_id":"public/2020/04/06/可视化/index.html","hash":"825d95d0d2e3dbf41ebfa7e5fd351834dde382a4","modified":1591596346381},{"_id":"public/tags/Java/index.html","hash":"3823b5a045aac913a3f3cd430ba310445871b88b","modified":1591596346381},{"_id":"public/tags/科研/index.html","hash":"a1cd0a3d58a891d49930c28edf28c131a3184057","modified":1591596346381},{"_id":"public/archives/2020/04/index.html","hash":"4dff2a4af5d2cb35e619f78b781f9bb1d067fee0","modified":1591596346381},{"_id":"source/_posts/可视化/t分布的q公式.jpg","hash":"5192726d3e532cace9e4876f1dd90421362f50c0","modified":1587113095889},{"_id":"public/2020/04/06/可视化/t分布的q公式.jpg","hash":"5192726d3e532cace9e4876f1dd90421362f50c0","modified":1587113337306},{"_id":"source/_posts/Tex与论文技巧.md","hash":"6cc1f099e5267724339a2dd761e2dcd470d633cb","modified":1591596289137},{"_id":"public/2020/04/24/Tex与论文技巧/index.html","hash":"f54e72dc1276c1061ac6f8f087dce276993c6261","modified":1591596346381},{"_id":"public/page/2/index.html","hash":"bc507ca05aaf85e9c5a16ad10cd0a32660ca849d","modified":1591596346381},{"_id":"source/_posts/于式麻酱拌面.md","hash":"1236a31cc4fe10b7060ccb2f21809fa5ae5a3aad","modified":1591596300003},{"_id":"public/2020/04/24/于式麻酱拌面/index.html","hash":"18c9ea32778514ca12d74e94f35ec9925071942b","modified":1591596346381},{"_id":"public/tags/程序员美食/index.html","hash":"498385f6da60ba7257d69fed2e0e44f0aeecd7cf","modified":1591596346381},{"_id":"source/_posts/于氏炸鸡翅.md","hash":"a9eb28dd6358cb7b7a8bb8800338f596bf9c9bcb","modified":1591596301191},{"_id":"public/2020/05/05/于氏炸鸡翅/index.html","hash":"330018e2e338f8b9ade1b850b27fdefa4ca1b868","modified":1591596346381},{"_id":"public/archives/page/2/index.html","hash":"2a95696dd8817bd74cec4020b54bf0cbca752f69","modified":1591596346381},{"_id":"public/archives/2020/page/2/index.html","hash":"6083705e978b64bcd5b6c0c01369847f5e64c571","modified":1591596346381},{"_id":"public/archives/2020/05/index.html","hash":"2a45958d3f0fface25ea3753e5c5e0df1cf97157","modified":1591596346381},{"_id":"source/_posts/于氏麻辣小龙虾.md","hash":"a4243ebaa73fc9a9f2e7db643347eec0a4117729","modified":1591596297004},{"_id":"public/2020/05/05/于氏麻辣小龙虾/index.html","hash":"06d8011859ce9bc38675ebf6f6cdac0f19da0cd2","modified":1591596346381},{"_id":"public/categories/开发/index.html","hash":"b8ff220d6ab9f6cf2103989dab068b165c857e85","modified":1591596346381},{"_id":"public/categories/美食/index.html","hash":"1428acac4b8a9f398cb47926bd6f7df94695ff32","modified":1591596346381},{"_id":"public/categories/科研/index.html","hash":"c90e0ecab583653f993583282a708646573ccca7","modified":1591596346381},{"_id":"public/categories/专业课/index.html","hash":"0417d0f4a76a0c8819a998c87fb918fade8614db","modified":1591596346381}],"Category":[{"name":"科研","_id":"ckb63ddfi0000boyma36jdyc8"},{"name":"开发","_id":"ckb63ddft0005boym5t7j5l8v"},{"name":"美食","_id":"ckb63ddfv0009boym0f0m4a3y"},{"name":"专业课","_id":"ckb63ddfx000eboym8ifb94fh"}],"Data":[],"Page":[{"title":"tags","date":"2020-02-07T12:47:58.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2020-02-07 20:47:58\ntype: \"tags\"\nlayout: \"tags\"\n---\n","updated":"2020-02-07T12:49:22.489Z","path":"tags/index.html","comments":1,"_id":"ck6c630iv00005oym294jhxc3","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"about","date":"2020-02-07T14:23:21.000Z","type":"about","layout":"about","_content":"","source":"about/index.md","raw":"---\ntitle: about\ndate: 2020-02-07 22:23:21\ntype: \"about\"\nlayout: \"about\"\n---\n","updated":"2020-02-07T14:23:53.709Z","path":"about/index.html","comments":1,"_id":"ck6d7oxkt00012sym3y4l6tcp","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"categories","date":"2020-02-07T14:21:29.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2020-02-07 22:21:29\ntype: \"categories\"\nlayout: \"categories\"\n---\n","updated":"2020-02-07T14:22:16.413Z","path":"categories/index.html","comments":1,"_id":"ck6d7oxkx00022sym3whm79v4","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"GCN的原理","date":"2020-02-08T06:38:14.000Z","mathjax":true,"_content":"\n### GCN的由来和最初的原理\n* Graph上的拉普拉斯矩阵L：\n$$L = D - A$$ 其中D是度矩阵，A是邻接矩阵。\n对L进行对称归一化：\n$$L = I - D^{-1/2} A D^{-1/2} $$ 拉普拉斯矩阵具有良好的性质，它是**对称半正定**的，特征分解可以写成：\n$$L = U \\Lambda U^T$$ 其中$U$为正交阵，即$UU^T = I$。\n* GCN源于传统的傅里叶变换：\n$$F(w) = \\mathcal{F}[f(t)] = \\int f(t)e^{-jwt}dt$$ 其中$e^{-jwt}$是傅里叶变换的基函数，它是拉普拉斯算子$\\Delta$的特征函数，其中w与特征值有关。\n拉普拉斯算子$\\Delta$与$e^{-jwt}$满足特征方程：\n$$\\Delta e^{-jwt} = \\frac{\\partial^2 e^{-jwt}}{\\partial t^2} = -w^2 e^{-jwt}$$\n* 对应到Graph上的傅里叶变换：\n$$F(\\lambda_l) = \\hat{f}(\\lambda_l) = \\sum\\limits_{i=1}^{n} f(i)u_l(i)$$ 这里$u_l(i)$对应传统傅里叶变换中的基函数，$u_l(i)$在这为拉普拉斯矩阵的特征向量矩阵$U$的各个分量，具体为第$l$个特征向量的第$i$个分量。写成矩阵形式：\n\n$$\\left[ \\begin{matrix} \\hat{f}(\\lambda_1)\\\\ \\hat{f}(\\lambda_2)\\\\ \\vdots \\\\ \\hat{f}(\\lambda_n) \\end{matrix} \\right] = \\left[ \\begin{matrix} u_1(1) & u_1(2) & \\cdots & u_1(n)\\\\ u_2(1) & u_2(2) & \\cdots & u_2(n)\\\\ \\vdots \\\\ u_n(1) & u_n(2) & \\cdots & u_n(n) \\end{matrix} \\right] = \\left[ \\begin{matrix} f(\\lambda_1)\\\\ f(\\lambda_2)\\\\ \\vdots \\\\ f(\\lambda_n) \\end{matrix} \\right]$$\n\n改写为矩阵形式，$U^T$即为拉普拉斯矩阵分解后的特征向量矩阵的转置：\n$$\\hat{f} = U^T f$$ 对应的逆变换：\n$$f = U \\hat{f}$$\n* **图卷积**\n* 传统卷积: (卷积的傅里叶变换等于傅里叶变换的乘积)\n$$\\mathcal{F}[f*h] = \\hat{f} \\cdot \\hat{h}$$\n\n变换形式：\n\n$$f*h = \\mathcal{F}^{-1} [\\hat{f} \\cdot \\hat{h}]$$\n* 传统卷积推广到Graph上：\n设$f$为待卷积函数，$h$为卷积核，即滤波器，\n$$f*h = U \\left[ \\begin{matrix} \\hat{h}_1\\\\ & \\hat{h}_2 \\\\ & & \\ddots\\\\ & & & \\hat{h}_n \\end{matrix} \\right] U^T f$$ \n**这个滤波器的傅里叶变换 $\\hat{h}_i$ 也就是我们要设计的部分！**\n把上面矩阵写成符号表示：\n$$f * h = U [(U^T h) \\odot (U^T f)]$$\n**把$\\hat{h}_i$看成卷积上的滤波器，即卷积核，我们希望卷积核能捕捉“局部特征”，所以定义$\\hat{h}_i$为拉普拉斯矩阵的函数 $h(L)$。**\n注意$L$和$\\Lambda$是有关联的，所以我们把 $\\hat{h}_i$ 进一步定义成 $\\Lambda$ 的函数(为什么这么定义后边能看出来)：\n$$\\hat{h} = g_{\\theta}(\\Lambda)$$\n，其中$\\theta$代表参数。然后改写卷积公式：\n$$g_{\\theta}*x = U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T x$$\n，由于特征分解的计算复杂度是相当高的，所以我们引入**Chebyshev多项式**对$g_{\\theta}(\\Lambda)$进行展开。\n切比雪夫多项式的定义：\n$$T_0(x) = 1; T_1(x) = x; T_{n+1}(x) = 2xT_{n}(x) - T_{n-1}(x)$$，进一步，n次多项式按切比雪夫多项式的展开式：\n$$p(x) = \\sum\\limits_{k=0}^{K} a_n T_{k}(x)$$\n然后，把$g_{\\theta}(\\Lambda)$按chebyshev多项式展开：\n$$g_{\\theta}(\\Lambda) \\approx \\sum\\limits_{k=0}^{K} \\theta_{k} T_k(\\tilde{\\Lambda})$$\n,其中，**$\\tilde{\\Lambda} = \\frac{2}{\\lambda_{max}} \\Lambda - I$,放缩到$[-1,1]$之间，保证每阶chebyshev多项式的收敛性**。\n又因为，\n$$L^K = (U \\Lambda U^T) ^ K = U \\Lambda^K U^T$$，把$U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T$对应成$\\tilde{L}$的函数。对$\\tilde{\\Lambda}$为自变量，其切比雪夫多项式，有：\n$$T_0(\\tilde{\\Lambda}) = I, T_1(\\tilde{\\Lambda}) = \\tilde{\\Lambda}, T_2(\\tilde{\\Lambda}) = 2\\tilde{\\Lambda}^2 - I$$，$U \\cdot T_i(\\tilde \\Lambda) \\cdot U^T$则对应成：\n$$T_0(\\tilde{L}) = I, T_1(\\tilde{L}) = \\tilde{L}, T_2(\\tilde{L}) = 2\\tilde{L}^2 - I$$，继续改写卷积公式：\n$$g_{\\theta'} * x = \\sum\\limits_{k=0}^{K} \\theta'_{k} T_k(\\tilde{L}) x \\tag{1}$$, 其中，$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I$。这时候，根据chebyshev多项式，可以把$T_k(\\tilde{L})$看成是$\\tilde{L}$的幂级数。\n现在首先以拉普拉斯矩阵$L$为例，分析一下他的谱性质：对于归一化的$L$矩阵：\n$$L = I - D^{-1/2} A D^{-1/2}$$,先分析右半边：其特征方程可以写成：\n$$D^{-1/2} A D^{-1/2} \\vec{p} = \\lambda \\vec{p}$$,左乘$D^{-1/2}$,\n$$D^{-1} A D^{-1/2} \\vec{p} = \\lambda D^{-1/2} \\vec{p}$$,特征值不变，特征向量变成$D^{-1/2} \\vec{p}$。所以对称归一化的A矩阵与随机游走归一化的A矩阵特征值是相同的。\n很容易可以得到，$\\|D^{-1}A\\|_1 = 1$，其实他的1-范数和$\\infty$-范数都是1。由范数的性质，一个矩阵的所有的特征值的绝对值都小于等于该矩阵的任意范数。\n$$|\\lambda| \\leq \\|D^{-1}A\\|_1 = 1$$\n,所以特征值范围是$[-1,1]$。所以L的特征值范围是$[0,2]$。\n现在做一个近似，$\\lambda_{max} \\approx 2$, 所以：\n$$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I = L - I$$。 现在回到卷积的公式(1)，我们手动让$K = 1$，代表1-order Chebyshe Filter，即一阶切比雪夫滤波器。\n$$g_{\\theta'} * x = (\\theta'_0 I + \\theta'_1 \\tilde{L}) x = (\\theta'_0 I + \\theta'_1 (L - I))) x$$，令$\\theta'_0 = -\\theta'_1 = \\theta$,继续改写：\n$$g_{\\theta'} * x = (\\theta'_0 I + \\theta'_1 \\tilde{L}) x = \\theta (I + D^{-1/2} A D^{-1/2}) x \\tag{2}$$\n,**现在得到的矩阵就是1-order Chebyshe Filter**。切比雪夫多项式里的$K$就代表了近邻的阶数（层数）。举个例子，以$K=2$为例，我们计算一下$L$和$L^2$来对比一下。\n\n![](./LandL2.png)\n<center>Simple-GCN原理图</center>\n\n可以看出，**K每增加1，高阶近邻位置上产生权值，即与多一层的近邻产生联系。\n不过，高阶的近邻与中心点的关联逐渐减小**，这也正与**滤波器的\"局部性\"** 相契合。以$K=2$为例，分析一下chebyshe展开：\n$$\\theta_0 I + \\theta_1 \\tilde{L} + \\theta_2 \\tilde{L}^2 = (\\theta_0 - \\theta_1 + \\theta_2) I + (\\theta_1 - 2\\theta_2) L + \\theta_2 L^2$$\n，自行代入，我们可以发现：所有的$\\theta_i$都是一个常数，即**对同阶近邻来说，不论它属于谁的邻域，都共享同一个权值**$\\theta_i$，这样有优点也有缺点。\n**优点：** 对大规模图来说，参数只有$K+1$个，参数量小。\n**缺点：** 不能在不同的邻域内分配不同的权值。\n\n#### GCN的发展\n后来，**1-order Chebyshev滤波器被改进,采用了Renormalization Trick**：\n$$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$$,A和D分别是加了自环(self-loops)后的邻接矩阵和度矩阵。\nGCN中初始的first-order Chebyshev filter是：$S_{1-order} = I + D^{-1/2}AD^{-1/2}$，归一化的拉普拉斯矩阵：$\\Delta_{sym} = I - D^{-1/2}AD^{-1/2}$，所以一阶切比雪夫滤波器变成：$S_{1-order} = 2I - \\Delta_{sym}$。然后对于$S^K_{1-order}$，滤波系数是$g_i = (2 - \\lambda_i)^K$,当$\\lambda < 1$时随着K增加系数爆炸式增长，不好！\n然后采用了【再归一化】，$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$,然后现在的拉普拉斯矩阵就变成了$\\tilde{D}_{sym} = I - \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$，滤波器系数变为$g_i = (1 - \\tilde{\\lambda}_i)^K$,性能变好了！\n\n**从此，目前的GCN框架变成了：**\n\n![](./GCN-schematic.png)\n<center>GCN原理图</center>\n\n给定一个图，$G = (V, A)$，V是顶点集，A是邻接矩阵（对称阵）。用D表示图G的度矩阵，$D=diag(d_1,\\cdots,d_n)$。用$H^{(i)}$表示图卷积中的结点特征。\n输入的结点特征矩阵：\n$$X = \\{x_1^T,x_2^T,\\cdots,x_n^T\\}^T \\in \\mathbb{R}^{n \\times d}$$\n初始特征:$$H^{(0)} = X$$\n图卷积包括三个步骤：特征传播、线性变换、非线性激活。\n##### 特征传播：\n给初始的邻接矩阵 A 添加自环(self-loops):\n$$\\tilde{A} = A + I$$ 用 $\\tilde{D}$ 表示 $\\tilde{A}$ 的度矩阵。\n定义归一化的邻接矩阵：\n$$S = \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}$$ 这个S在所有层都是一样的，直接通过$\\tilde{A}$即可求得。\n第k层的特征传播：\n$$\\tilde{H}^{(k)} \\leftarrow SH^{(k-1)}$$\n分开写：\n$$\\tilde{h}^{k}_{i} \\leftarrow \\frac{1}{d_i+1}h_i^{(k-1)} + \\sum\\limits_{j=1}^{n} \\frac{a_{ij}}{\\sqrt{(d_i+1)(d_j+1)}} h_j^{(k-1)}$$\n##### 特征变换 + 非线性激活：\n每一层有个权值矩阵$\\theta^{(k)}$\n$$H^{(k)} \\leftarrow ReLU(\\tilde{H^{(k)}} \\theta^{(k)})$$\n##### 分类器：\n$$Y_{GCN} = softmax(SH^{(k-1)} \\theta^{(k)})$$\n##### 参数细节：\n**图卷积的层数控制了图卷积的感受野，即随着层数K加深，与更高阶的近邻产生关系**。\n\n### GCN与LLE和线性变换的关系 \n现在的主流GCN框架：\n$$H^{(k+1)} = ReLU\\left(S H^{(k)} W^{(k)}\\right)$$,其中$H^{(0)} = X$。以$K = 0$为例，分析第一层网络：\n$$H^{(1)} = ReLU\\left(S H^{(0)} W^{(0)}\\right)$$,**左半部分$Y=S X$,本质就是LLE**：\nLLE在每个高维点的局部拟合超平面，用k-近邻来线性表示被拟合点，所以在高维空间中，这个高维拟合（高维重建）过程可以用公式表示为:\n$$\\hat{X} = X W = (W^T X^T)^T$$,$X \\in \\mathbb{R}^{D\\times n}$是按列排布的高维数据点，每列是一个高维样本点；$W \\in \\mathbb{R}^{n \\times n}$是对应每个被重建点的权值向量$\\vec{w_i}$，对应$W$矩阵的第 $i$ 列，这个向量的第j个位置上的值即为重建第i个点所需的第j个权值(对应第j个点)，非近邻点权值就是0。\n**LLE与GCN的左半部分对比，是同样的，LLE里的$W^T$和$X^T$分别对应GCN中的$S$和$H^{(0)}$。** 其实，从$A$矩阵的归一化上来看，GCN中的$S$与LLE里的$W$也是相通的，因为LLE的W也有一个$\\sum_j w_{ij} = 1$的约束。\n**右边就是一个纯粹的线性变换$W$，可以把它看成是\"特征增强\"。** 同样可以类比线性降维的通式：\n$$Y = W^T X = (X^T W)^T$$, **这里的$X^T$和$W$分别对应GCN里的$S H^{(0)}$和$W^{(0)}$**。\n**所以，一层GCN就相当于LLE和线性变换的集成。对于GCN，左边的$SH$我们把它称为特征按近邻进行聚合，再乘$W$叫做线性变换（特征增强）。** \n所以，$S$是我们可以优化的点，$S \\odot M$对$S$做hadamard积，就相当于加权了，这个思想在ST-GCN和很多论文中已经被提出了。\n\n\n### 新论文 Simple Graph Convolution\n它认为图卷积GCN和多层感知机MLP类似，只不过每一层当中对特征按照其近邻进行了平均化。这篇文章认为图卷积受目前普通卷积神经网络的影响，一开始就加入了非线性变换，还把网络层数搞得很深，于是他们把图卷积进行了简化，去掉了非线性激活，把图卷积网络改成了一个逻辑回归，在某些数据上表现不错。\n![](./Simple-GCN-schematic.png)\n<center>Simple-GCN原理图</center>\n\n##### 图卷积的线性化：\n$$Y = softmax(S\\dots SSX \\theta^{(1)}\\dots \\theta^{(k)})$$ 所有的S都是一样的，可以用$S^K$表示。然后后面的所有变换矩阵乘起来变成了一个矩阵$\\theta = \\theta^{(1)}\\dots \\theta^{(k)}$。\n然后就变成了一个多分类的逻辑回归：\n$$Y = softmax(S^K X \\theta)$$\n$S^K$可以在预处理阶段就可完成，因为需要用到的东西都是已知的。这样，\n$$\\tilde{X} = S^K X$$ 然后$softmax(\\tilde{X} \\theta)$就变成了单纯的多分类逻辑回归。优化可以直接利用逻辑回归的优化方法，如随机梯度下降（SGD）等。\n\n### GCN优化\n#### DeepGCNs 系列\nGCN初始版本，kpif&welling那个，在core数据集上只用到了2-hop近邻。其实GCN深度增加会降低模型效果，因为过度平滑问题，所有最初的GCN层数不能很深。\n\n后来有人讨论了GCN的模型深度问题，用了ResGCN，DenseGCN，加深了网络层数，并提高了performance。\n\n\n","source":"_posts/GCN原理.md","raw":"---\ntitle: GCN的原理\ndate: 2020-02-08 14:38:14\ntags: 科研\ncategories: 科研\nmathjax: true\n---\n\n### GCN的由来和最初的原理\n* Graph上的拉普拉斯矩阵L：\n$$L = D - A$$ 其中D是度矩阵，A是邻接矩阵。\n对L进行对称归一化：\n$$L = I - D^{-1/2} A D^{-1/2} $$ 拉普拉斯矩阵具有良好的性质，它是**对称半正定**的，特征分解可以写成：\n$$L = U \\Lambda U^T$$ 其中$U$为正交阵，即$UU^T = I$。\n* GCN源于传统的傅里叶变换：\n$$F(w) = \\mathcal{F}[f(t)] = \\int f(t)e^{-jwt}dt$$ 其中$e^{-jwt}$是傅里叶变换的基函数，它是拉普拉斯算子$\\Delta$的特征函数，其中w与特征值有关。\n拉普拉斯算子$\\Delta$与$e^{-jwt}$满足特征方程：\n$$\\Delta e^{-jwt} = \\frac{\\partial^2 e^{-jwt}}{\\partial t^2} = -w^2 e^{-jwt}$$\n* 对应到Graph上的傅里叶变换：\n$$F(\\lambda_l) = \\hat{f}(\\lambda_l) = \\sum\\limits_{i=1}^{n} f(i)u_l(i)$$ 这里$u_l(i)$对应传统傅里叶变换中的基函数，$u_l(i)$在这为拉普拉斯矩阵的特征向量矩阵$U$的各个分量，具体为第$l$个特征向量的第$i$个分量。写成矩阵形式：\n\n$$\\left[ \\begin{matrix} \\hat{f}(\\lambda_1)\\\\ \\hat{f}(\\lambda_2)\\\\ \\vdots \\\\ \\hat{f}(\\lambda_n) \\end{matrix} \\right] = \\left[ \\begin{matrix} u_1(1) & u_1(2) & \\cdots & u_1(n)\\\\ u_2(1) & u_2(2) & \\cdots & u_2(n)\\\\ \\vdots \\\\ u_n(1) & u_n(2) & \\cdots & u_n(n) \\end{matrix} \\right] = \\left[ \\begin{matrix} f(\\lambda_1)\\\\ f(\\lambda_2)\\\\ \\vdots \\\\ f(\\lambda_n) \\end{matrix} \\right]$$\n\n改写为矩阵形式，$U^T$即为拉普拉斯矩阵分解后的特征向量矩阵的转置：\n$$\\hat{f} = U^T f$$ 对应的逆变换：\n$$f = U \\hat{f}$$\n* **图卷积**\n* 传统卷积: (卷积的傅里叶变换等于傅里叶变换的乘积)\n$$\\mathcal{F}[f*h] = \\hat{f} \\cdot \\hat{h}$$\n\n变换形式：\n\n$$f*h = \\mathcal{F}^{-1} [\\hat{f} \\cdot \\hat{h}]$$\n* 传统卷积推广到Graph上：\n设$f$为待卷积函数，$h$为卷积核，即滤波器，\n$$f*h = U \\left[ \\begin{matrix} \\hat{h}_1\\\\ & \\hat{h}_2 \\\\ & & \\ddots\\\\ & & & \\hat{h}_n \\end{matrix} \\right] U^T f$$ \n**这个滤波器的傅里叶变换 $\\hat{h}_i$ 也就是我们要设计的部分！**\n把上面矩阵写成符号表示：\n$$f * h = U [(U^T h) \\odot (U^T f)]$$\n**把$\\hat{h}_i$看成卷积上的滤波器，即卷积核，我们希望卷积核能捕捉“局部特征”，所以定义$\\hat{h}_i$为拉普拉斯矩阵的函数 $h(L)$。**\n注意$L$和$\\Lambda$是有关联的，所以我们把 $\\hat{h}_i$ 进一步定义成 $\\Lambda$ 的函数(为什么这么定义后边能看出来)：\n$$\\hat{h} = g_{\\theta}(\\Lambda)$$\n，其中$\\theta$代表参数。然后改写卷积公式：\n$$g_{\\theta}*x = U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T x$$\n，由于特征分解的计算复杂度是相当高的，所以我们引入**Chebyshev多项式**对$g_{\\theta}(\\Lambda)$进行展开。\n切比雪夫多项式的定义：\n$$T_0(x) = 1; T_1(x) = x; T_{n+1}(x) = 2xT_{n}(x) - T_{n-1}(x)$$，进一步，n次多项式按切比雪夫多项式的展开式：\n$$p(x) = \\sum\\limits_{k=0}^{K} a_n T_{k}(x)$$\n然后，把$g_{\\theta}(\\Lambda)$按chebyshev多项式展开：\n$$g_{\\theta}(\\Lambda) \\approx \\sum\\limits_{k=0}^{K} \\theta_{k} T_k(\\tilde{\\Lambda})$$\n,其中，**$\\tilde{\\Lambda} = \\frac{2}{\\lambda_{max}} \\Lambda - I$,放缩到$[-1,1]$之间，保证每阶chebyshev多项式的收敛性**。\n又因为，\n$$L^K = (U \\Lambda U^T) ^ K = U \\Lambda^K U^T$$，把$U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T$对应成$\\tilde{L}$的函数。对$\\tilde{\\Lambda}$为自变量，其切比雪夫多项式，有：\n$$T_0(\\tilde{\\Lambda}) = I, T_1(\\tilde{\\Lambda}) = \\tilde{\\Lambda}, T_2(\\tilde{\\Lambda}) = 2\\tilde{\\Lambda}^2 - I$$，$U \\cdot T_i(\\tilde \\Lambda) \\cdot U^T$则对应成：\n$$T_0(\\tilde{L}) = I, T_1(\\tilde{L}) = \\tilde{L}, T_2(\\tilde{L}) = 2\\tilde{L}^2 - I$$，继续改写卷积公式：\n$$g_{\\theta'} * x = \\sum\\limits_{k=0}^{K} \\theta'_{k} T_k(\\tilde{L}) x \\tag{1}$$, 其中，$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I$。这时候，根据chebyshev多项式，可以把$T_k(\\tilde{L})$看成是$\\tilde{L}$的幂级数。\n现在首先以拉普拉斯矩阵$L$为例，分析一下他的谱性质：对于归一化的$L$矩阵：\n$$L = I - D^{-1/2} A D^{-1/2}$$,先分析右半边：其特征方程可以写成：\n$$D^{-1/2} A D^{-1/2} \\vec{p} = \\lambda \\vec{p}$$,左乘$D^{-1/2}$,\n$$D^{-1} A D^{-1/2} \\vec{p} = \\lambda D^{-1/2} \\vec{p}$$,特征值不变，特征向量变成$D^{-1/2} \\vec{p}$。所以对称归一化的A矩阵与随机游走归一化的A矩阵特征值是相同的。\n很容易可以得到，$\\|D^{-1}A\\|_1 = 1$，其实他的1-范数和$\\infty$-范数都是1。由范数的性质，一个矩阵的所有的特征值的绝对值都小于等于该矩阵的任意范数。\n$$|\\lambda| \\leq \\|D^{-1}A\\|_1 = 1$$\n,所以特征值范围是$[-1,1]$。所以L的特征值范围是$[0,2]$。\n现在做一个近似，$\\lambda_{max} \\approx 2$, 所以：\n$$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I = L - I$$。 现在回到卷积的公式(1)，我们手动让$K = 1$，代表1-order Chebyshe Filter，即一阶切比雪夫滤波器。\n$$g_{\\theta'} * x = (\\theta'_0 I + \\theta'_1 \\tilde{L}) x = (\\theta'_0 I + \\theta'_1 (L - I))) x$$，令$\\theta'_0 = -\\theta'_1 = \\theta$,继续改写：\n$$g_{\\theta'} * x = (\\theta'_0 I + \\theta'_1 \\tilde{L}) x = \\theta (I + D^{-1/2} A D^{-1/2}) x \\tag{2}$$\n,**现在得到的矩阵就是1-order Chebyshe Filter**。切比雪夫多项式里的$K$就代表了近邻的阶数（层数）。举个例子，以$K=2$为例，我们计算一下$L$和$L^2$来对比一下。\n\n![](./LandL2.png)\n<center>Simple-GCN原理图</center>\n\n可以看出，**K每增加1，高阶近邻位置上产生权值，即与多一层的近邻产生联系。\n不过，高阶的近邻与中心点的关联逐渐减小**，这也正与**滤波器的\"局部性\"** 相契合。以$K=2$为例，分析一下chebyshe展开：\n$$\\theta_0 I + \\theta_1 \\tilde{L} + \\theta_2 \\tilde{L}^2 = (\\theta_0 - \\theta_1 + \\theta_2) I + (\\theta_1 - 2\\theta_2) L + \\theta_2 L^2$$\n，自行代入，我们可以发现：所有的$\\theta_i$都是一个常数，即**对同阶近邻来说，不论它属于谁的邻域，都共享同一个权值**$\\theta_i$，这样有优点也有缺点。\n**优点：** 对大规模图来说，参数只有$K+1$个，参数量小。\n**缺点：** 不能在不同的邻域内分配不同的权值。\n\n#### GCN的发展\n后来，**1-order Chebyshev滤波器被改进,采用了Renormalization Trick**：\n$$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$$,A和D分别是加了自环(self-loops)后的邻接矩阵和度矩阵。\nGCN中初始的first-order Chebyshev filter是：$S_{1-order} = I + D^{-1/2}AD^{-1/2}$，归一化的拉普拉斯矩阵：$\\Delta_{sym} = I - D^{-1/2}AD^{-1/2}$，所以一阶切比雪夫滤波器变成：$S_{1-order} = 2I - \\Delta_{sym}$。然后对于$S^K_{1-order}$，滤波系数是$g_i = (2 - \\lambda_i)^K$,当$\\lambda < 1$时随着K增加系数爆炸式增长，不好！\n然后采用了【再归一化】，$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$,然后现在的拉普拉斯矩阵就变成了$\\tilde{D}_{sym} = I - \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$，滤波器系数变为$g_i = (1 - \\tilde{\\lambda}_i)^K$,性能变好了！\n\n**从此，目前的GCN框架变成了：**\n\n![](./GCN-schematic.png)\n<center>GCN原理图</center>\n\n给定一个图，$G = (V, A)$，V是顶点集，A是邻接矩阵（对称阵）。用D表示图G的度矩阵，$D=diag(d_1,\\cdots,d_n)$。用$H^{(i)}$表示图卷积中的结点特征。\n输入的结点特征矩阵：\n$$X = \\{x_1^T,x_2^T,\\cdots,x_n^T\\}^T \\in \\mathbb{R}^{n \\times d}$$\n初始特征:$$H^{(0)} = X$$\n图卷积包括三个步骤：特征传播、线性变换、非线性激活。\n##### 特征传播：\n给初始的邻接矩阵 A 添加自环(self-loops):\n$$\\tilde{A} = A + I$$ 用 $\\tilde{D}$ 表示 $\\tilde{A}$ 的度矩阵。\n定义归一化的邻接矩阵：\n$$S = \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}$$ 这个S在所有层都是一样的，直接通过$\\tilde{A}$即可求得。\n第k层的特征传播：\n$$\\tilde{H}^{(k)} \\leftarrow SH^{(k-1)}$$\n分开写：\n$$\\tilde{h}^{k}_{i} \\leftarrow \\frac{1}{d_i+1}h_i^{(k-1)} + \\sum\\limits_{j=1}^{n} \\frac{a_{ij}}{\\sqrt{(d_i+1)(d_j+1)}} h_j^{(k-1)}$$\n##### 特征变换 + 非线性激活：\n每一层有个权值矩阵$\\theta^{(k)}$\n$$H^{(k)} \\leftarrow ReLU(\\tilde{H^{(k)}} \\theta^{(k)})$$\n##### 分类器：\n$$Y_{GCN} = softmax(SH^{(k-1)} \\theta^{(k)})$$\n##### 参数细节：\n**图卷积的层数控制了图卷积的感受野，即随着层数K加深，与更高阶的近邻产生关系**。\n\n### GCN与LLE和线性变换的关系 \n现在的主流GCN框架：\n$$H^{(k+1)} = ReLU\\left(S H^{(k)} W^{(k)}\\right)$$,其中$H^{(0)} = X$。以$K = 0$为例，分析第一层网络：\n$$H^{(1)} = ReLU\\left(S H^{(0)} W^{(0)}\\right)$$,**左半部分$Y=S X$,本质就是LLE**：\nLLE在每个高维点的局部拟合超平面，用k-近邻来线性表示被拟合点，所以在高维空间中，这个高维拟合（高维重建）过程可以用公式表示为:\n$$\\hat{X} = X W = (W^T X^T)^T$$,$X \\in \\mathbb{R}^{D\\times n}$是按列排布的高维数据点，每列是一个高维样本点；$W \\in \\mathbb{R}^{n \\times n}$是对应每个被重建点的权值向量$\\vec{w_i}$，对应$W$矩阵的第 $i$ 列，这个向量的第j个位置上的值即为重建第i个点所需的第j个权值(对应第j个点)，非近邻点权值就是0。\n**LLE与GCN的左半部分对比，是同样的，LLE里的$W^T$和$X^T$分别对应GCN中的$S$和$H^{(0)}$。** 其实，从$A$矩阵的归一化上来看，GCN中的$S$与LLE里的$W$也是相通的，因为LLE的W也有一个$\\sum_j w_{ij} = 1$的约束。\n**右边就是一个纯粹的线性变换$W$，可以把它看成是\"特征增强\"。** 同样可以类比线性降维的通式：\n$$Y = W^T X = (X^T W)^T$$, **这里的$X^T$和$W$分别对应GCN里的$S H^{(0)}$和$W^{(0)}$**。\n**所以，一层GCN就相当于LLE和线性变换的集成。对于GCN，左边的$SH$我们把它称为特征按近邻进行聚合，再乘$W$叫做线性变换（特征增强）。** \n所以，$S$是我们可以优化的点，$S \\odot M$对$S$做hadamard积，就相当于加权了，这个思想在ST-GCN和很多论文中已经被提出了。\n\n\n### 新论文 Simple Graph Convolution\n它认为图卷积GCN和多层感知机MLP类似，只不过每一层当中对特征按照其近邻进行了平均化。这篇文章认为图卷积受目前普通卷积神经网络的影响，一开始就加入了非线性变换，还把网络层数搞得很深，于是他们把图卷积进行了简化，去掉了非线性激活，把图卷积网络改成了一个逻辑回归，在某些数据上表现不错。\n![](./Simple-GCN-schematic.png)\n<center>Simple-GCN原理图</center>\n\n##### 图卷积的线性化：\n$$Y = softmax(S\\dots SSX \\theta^{(1)}\\dots \\theta^{(k)})$$ 所有的S都是一样的，可以用$S^K$表示。然后后面的所有变换矩阵乘起来变成了一个矩阵$\\theta = \\theta^{(1)}\\dots \\theta^{(k)}$。\n然后就变成了一个多分类的逻辑回归：\n$$Y = softmax(S^K X \\theta)$$\n$S^K$可以在预处理阶段就可完成，因为需要用到的东西都是已知的。这样，\n$$\\tilde{X} = S^K X$$ 然后$softmax(\\tilde{X} \\theta)$就变成了单纯的多分类逻辑回归。优化可以直接利用逻辑回归的优化方法，如随机梯度下降（SGD）等。\n\n### GCN优化\n#### DeepGCNs 系列\nGCN初始版本，kpif&welling那个，在core数据集上只用到了2-hop近邻。其实GCN深度增加会降低模型效果，因为过度平滑问题，所有最初的GCN层数不能很深。\n\n后来有人讨论了GCN的模型深度问题，用了ResGCN，DenseGCN，加深了网络层数，并提高了performance。\n\n\n","slug":"GCN原理","published":1,"updated":"2020-06-08T06:04:55.111Z","_id":"ck6d7oxkn00002sym510c6icq","comments":1,"layout":"post","photos":[],"link":"","content":"<h3 id=\"GCN的由来和最初的原理\"><a href=\"#GCN的由来和最初的原理\" class=\"headerlink\" title=\"GCN的由来和最初的原理\"></a>GCN的由来和最初的原理</h3><ul>\n<li>Graph上的拉普拉斯矩阵L：<br>$$L = D - A$$ 其中D是度矩阵，A是邻接矩阵。<br>对L进行对称归一化：<br>$$L = I - D^{-1/2} A D^{-1/2} $$ 拉普拉斯矩阵具有良好的性质，它是<strong>对称半正定</strong>的，特征分解可以写成：<br>$$L = U \\Lambda U^T$$ 其中$U$为正交阵，即$UU^T = I$。</li>\n<li>GCN源于传统的傅里叶变换：<br>$$F(w) = \\mathcal{F}[f(t)] = \\int f(t)e^{-jwt}dt$$ 其中$e^{-jwt}$是傅里叶变换的基函数，它是拉普拉斯算子$\\Delta$的特征函数，其中w与特征值有关。<br>拉普拉斯算子$\\Delta$与$e^{-jwt}$满足特征方程：<br>$$\\Delta e^{-jwt} = \\frac{\\partial^2 e^{-jwt}}{\\partial t^2} = -w^2 e^{-jwt}$$</li>\n<li>对应到Graph上的傅里叶变换：<br>$$F(\\lambda_l) = \\hat{f}(\\lambda_l) = \\sum\\limits_{i=1}^{n} f(i)u_l(i)$$ 这里$u_l(i)$对应传统傅里叶变换中的基函数，$u_l(i)$在这为拉普拉斯矩阵的特征向量矩阵$U$的各个分量，具体为第$l$个特征向量的第$i$个分量。写成矩阵形式：</li>\n</ul>\n<p>$$\\left[ \\begin{matrix} \\hat{f}(\\lambda_1)\\ \\hat{f}(\\lambda_2)\\ \\vdots \\ \\hat{f}(\\lambda_n) \\end{matrix} \\right] = \\left[ \\begin{matrix} u_1(1) &amp; u_1(2) &amp; \\cdots &amp; u_1(n)\\ u_2(1) &amp; u_2(2) &amp; \\cdots &amp; u_2(n)\\ \\vdots \\ u_n(1) &amp; u_n(2) &amp; \\cdots &amp; u_n(n) \\end{matrix} \\right] = \\left[ \\begin{matrix} f(\\lambda_1)\\ f(\\lambda_2)\\ \\vdots \\ f(\\lambda_n) \\end{matrix} \\right]$$</p>\n<p>改写为矩阵形式，$U^T$即为拉普拉斯矩阵分解后的特征向量矩阵的转置：<br>$$\\hat{f} = U^T f$$ 对应的逆变换：<br>$$f = U \\hat{f}$$</p>\n<ul>\n<li><strong>图卷积</strong></li>\n<li>传统卷积: (卷积的傅里叶变换等于傅里叶变换的乘积)<br>$$\\mathcal{F}[f*h] = \\hat{f} \\cdot \\hat{h}$$</li>\n</ul>\n<p>变换形式：</p>\n<p>$$f*h = \\mathcal{F}^{-1} [\\hat{f} \\cdot \\hat{h}]$$</p>\n<ul>\n<li>传统卷积推广到Graph上：<br>设$f$为待卷积函数，$h$为卷积核，即滤波器，<br>$$f*h = U \\left[ \\begin{matrix} \\hat{h}_1\\ &amp; \\hat{h}_2 \\ &amp; &amp; \\ddots\\ &amp; &amp; &amp; \\hat{h}_n \\end{matrix} \\right] U^T f$$ </li>\n<li><em>这个滤波器的傅里叶变换 $\\hat{h}_i$ 也就是我们要设计的部分！*</em><br>把上面矩阵写成符号表示：<br>$$f * h = U [(U^T h) \\odot (U^T f)]$$</li>\n<li><em>把$\\hat{h}_i$看成卷积上的滤波器，即卷积核，我们希望卷积核能捕捉“局部特征”，所以定义$\\hat{h}_i$为拉普拉斯矩阵的函数 $h(L)$。*</em><br>注意$L$和$\\Lambda$是有关联的，所以我们把 $\\hat{h}<em>i$ 进一步定义成 $\\Lambda$ 的函数(为什么这么定义后边能看出来)：<br>$$\\hat{h} = g</em>{\\theta}(\\Lambda)$$<br>，其中$\\theta$代表参数。然后改写卷积公式：<br>$$g_{\\theta}<em>x = U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T x$$<br>，由于特征分解的计算复杂度是相当高的，所以我们引入*</em>Chebyshev多项式<strong>对$g_{\\theta}(\\Lambda)$进行展开。<br>切比雪夫多项式的定义：<br>$$T_0(x) = 1; T_1(x) = x; T_{n+1}(x) = 2xT_{n}(x) - T_{n-1}(x)$$，进一步，n次多项式按切比雪夫多项式的展开式：<br>$$p(x) = \\sum\\limits_{k=0}^{K} a_n T_{k}(x)$$<br>然后，把$g_{\\theta}(\\Lambda)$按chebyshev多项式展开：<br>$$g_{\\theta}(\\Lambda) \\approx \\sum\\limits_{k=0}^{K} \\theta_{k} T_k(\\tilde{\\Lambda})$$<br>,其中，</strong>$\\tilde{\\Lambda} = \\frac{2}{\\lambda_{max}} \\Lambda - I$,放缩到$[-1,1]$之间，保证每阶chebyshev多项式的收敛性<strong>。<br>又因为，<br>$$L^K = (U \\Lambda U^T) ^ K = U \\Lambda^K U^T$$，把$U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T$对应成$\\tilde{L}$的函数。对$\\tilde{\\Lambda}$为自变量，其切比雪夫多项式，有：<br>$$T_0(\\tilde{\\Lambda}) = I, T_1(\\tilde{\\Lambda}) = \\tilde{\\Lambda}, T_2(\\tilde{\\Lambda}) = 2\\tilde{\\Lambda}^2 - I$$，$U \\cdot T_i(\\tilde \\Lambda) \\cdot U^T$则对应成：<br>$$T_0(\\tilde{L}) = I, T_1(\\tilde{L}) = \\tilde{L}, T_2(\\tilde{L}) = 2\\tilde{L}^2 - I$$，继续改写卷积公式：<br>$$g_{\\theta’} * x = \\sum\\limits_{k=0}^{K} \\theta’<em>{k} T_k(\\tilde{L}) x \\tag{1}$$, 其中，$\\tilde{L} = \\frac{2}{\\lambda</em>{max}}L - I$。这时候，根据chebyshev多项式，可以把$T_k(\\tilde{L})$看成是$\\tilde{L}$的幂级数。<br>现在首先以拉普拉斯矩阵$L$为例，分析一下他的谱性质：对于归一化的$L$矩阵：<br>$$L = I - D^{-1/2} A D^{-1/2}$$,先分析右半边：其特征方程可以写成：<br>$$D^{-1/2} A D^{-1/2} \\vec{p} = \\lambda \\vec{p}$$,左乘$D^{-1/2}$,<br>$$D^{-1} A D^{-1/2} \\vec{p} = \\lambda D^{-1/2} \\vec{p}$$,特征值不变，特征向量变成$D^{-1/2} \\vec{p}$。所以对称归一化的A矩阵与随机游走归一化的A矩阵特征值是相同的。<br>很容易可以得到，$|D^{-1}A|<em>1 = 1$，其实他的1-范数和$\\infty$-范数都是1。由范数的性质，一个矩阵的所有的特征值的绝对值都小于等于该矩阵的任意范数。<br>$$|\\lambda| \\leq |D^{-1}A|_1 = 1$$<br>,所以特征值范围是$[-1,1]$。所以L的特征值范围是$[0,2]$。<br>现在做一个近似，$\\lambda</em>{max} \\approx 2$, 所以：<br>$$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I = L - I$$。 现在回到卷积的公式(1)，我们手动让$K = 1$，代表1-order Chebyshe Filter，即一阶切比雪夫滤波器。<br>$$g_{\\theta’} * x = (\\theta’<em>0 I + \\theta’_1 \\tilde{L}) x = (\\theta’_0 I + \\theta’_1 (L - I))) x$$，令$\\theta’_0 = -\\theta’_1 = \\theta$,继续改写：<br>$$g</em>{\\theta’} * x = (\\theta’_0 I + \\theta’_1 \\tilde{L}) x = \\theta (I + D^{-1/2} A D^{-1/2}) x \\tag{2}$$<br>,</strong>现在得到的矩阵就是1-order Chebyshe Filter**。切比雪夫多项式里的$K$就代表了近邻的阶数（层数）。举个例子，以$K=2$为例，我们计算一下$L$和$L^2$来对比一下。</li>\n</ul>\n<p><img src=\"./LandL2.png\" alt=\"\"></p>\n<center>Simple-GCN原理图</center>\n\n<p>可以看出，<strong>K每增加1，高阶近邻位置上产生权值，即与多一层的近邻产生联系。<br>不过，高阶的近邻与中心点的关联逐渐减小</strong>，这也正与<strong>滤波器的”局部性”</strong> 相契合。以$K=2$为例，分析一下chebyshe展开：<br>$$\\theta_0 I + \\theta_1 \\tilde{L} + \\theta_2 \\tilde{L}^2 = (\\theta_0 - \\theta_1 + \\theta_2) I + (\\theta_1 - 2\\theta_2) L + \\theta_2 L^2$$<br>，自行代入，我们可以发现：所有的$\\theta_i$都是一个常数，即<strong>对同阶近邻来说，不论它属于谁的邻域，都共享同一个权值</strong>$\\theta_i$，这样有优点也有缺点。<br><strong>优点：</strong> 对大规模图来说，参数只有$K+1$个，参数量小。<br><strong>缺点：</strong> 不能在不同的邻域内分配不同的权值。</p>\n<h4 id=\"GCN的发展\"><a href=\"#GCN的发展\" class=\"headerlink\" title=\"GCN的发展\"></a>GCN的发展</h4><p>后来，<strong>1-order Chebyshev滤波器被改进,采用了Renormalization Trick</strong>：<br>$$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$$,A和D分别是加了自环(self-loops)后的邻接矩阵和度矩阵。<br>GCN中初始的first-order Chebyshev filter是：$S_{1-order} = I + D^{-1/2}AD^{-1/2}$，归一化的拉普拉斯矩阵：$\\Delta_{sym} = I - D^{-1/2}AD^{-1/2}$，所以一阶切比雪夫滤波器变成：$S_{1-order} = 2I - \\Delta_{sym}$。然后对于$S^K_{1-order}$，滤波系数是$g_i = (2 - \\lambda_i)^K$,当$\\lambda &lt; 1$时随着K增加系数爆炸式增长，不好！<br>然后采用了【再归一化】，$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$,然后现在的拉普拉斯矩阵就变成了$\\tilde{D}_{sym} = I - \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$，滤波器系数变为$g_i = (1 - \\tilde{\\lambda}_i)^K$,性能变好了！</p>\n<p><strong>从此，目前的GCN框架变成了：</strong></p>\n<p><img src=\"./GCN-schematic.png\" alt=\"\"></p>\n<center>GCN原理图</center>\n\n<p>给定一个图，$G = (V, A)$，V是顶点集，A是邻接矩阵（对称阵）。用D表示图G的度矩阵，$D=diag(d_1,\\cdots,d_n)$。用$H^{(i)}$表示图卷积中的结点特征。<br>输入的结点特征矩阵：<br>$$X = {x_1^T,x_2^T,\\cdots,x_n^T}^T \\in \\mathbb{R}^{n \\times d}$$<br>初始特征:$$H^{(0)} = X$$<br>图卷积包括三个步骤：特征传播、线性变换、非线性激活。</p>\n<h5 id=\"特征传播：\"><a href=\"#特征传播：\" class=\"headerlink\" title=\"特征传播：\"></a>特征传播：</h5><p>给初始的邻接矩阵 A 添加自环(self-loops):<br>$$\\tilde{A} = A + I$$ 用 $\\tilde{D}$ 表示 $\\tilde{A}$ 的度矩阵。<br>定义归一化的邻接矩阵：<br>$$S = \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}$$ 这个S在所有层都是一样的，直接通过$\\tilde{A}$即可求得。<br>第k层的特征传播：<br>$$\\tilde{H}^{(k)} \\leftarrow SH^{(k-1)}$$<br>分开写：<br>$$\\tilde{h}^{k}<em>{i} \\leftarrow \\frac{1}{d_i+1}h_i^{(k-1)} + \\sum\\limits</em>{j=1}^{n} \\frac{a_{ij}}{\\sqrt{(d_i+1)(d_j+1)}} h_j^{(k-1)}$$</p>\n<h5 id=\"特征变换-非线性激活：\"><a href=\"#特征变换-非线性激活：\" class=\"headerlink\" title=\"特征变换 + 非线性激活：\"></a>特征变换 + 非线性激活：</h5><p>每一层有个权值矩阵$\\theta^{(k)}$<br>$$H^{(k)} \\leftarrow ReLU(\\tilde{H^{(k)}} \\theta^{(k)})$$</p>\n<h5 id=\"分类器：\"><a href=\"#分类器：\" class=\"headerlink\" title=\"分类器：\"></a>分类器：</h5><p>$$Y_{GCN} = softmax(SH^{(k-1)} \\theta^{(k)})$$</p>\n<h5 id=\"参数细节：\"><a href=\"#参数细节：\" class=\"headerlink\" title=\"参数细节：\"></a>参数细节：</h5><p><strong>图卷积的层数控制了图卷积的感受野，即随着层数K加深，与更高阶的近邻产生关系</strong>。</p>\n<h3 id=\"GCN与LLE和线性变换的关系\"><a href=\"#GCN与LLE和线性变换的关系\" class=\"headerlink\" title=\"GCN与LLE和线性变换的关系\"></a>GCN与LLE和线性变换的关系</h3><p>现在的主流GCN框架：<br>$$H^{(k+1)} = ReLU\\left(S H^{(k)} W^{(k)}\\right)$$,其中$H^{(0)} = X$。以$K = 0$为例，分析第一层网络：<br>$$H^{(1)} = ReLU\\left(S H^{(0)} W^{(0)}\\right)$$,<strong>左半部分$Y=S X$,本质就是LLE</strong>：<br>LLE在每个高维点的局部拟合超平面，用k-近邻来线性表示被拟合点，所以在高维空间中，这个高维拟合（高维重建）过程可以用公式表示为:<br>$$\\hat{X} = X W = (W^T X^T)^T$$,$X \\in \\mathbb{R}^{D\\times n}$是按列排布的高维数据点，每列是一个高维样本点；$W \\in \\mathbb{R}^{n \\times n}$是对应每个被重建点的权值向量$\\vec{w_i}$，对应$W$矩阵的第 $i$ 列，这个向量的第j个位置上的值即为重建第i个点所需的第j个权值(对应第j个点)，非近邻点权值就是0。<br><strong>LLE与GCN的左半部分对比，是同样的，LLE里的$W^T$和$X^T$分别对应GCN中的$S$和$H^{(0)}$。</strong> 其实，从$A$矩阵的归一化上来看，GCN中的$S$与LLE里的$W$也是相通的，因为LLE的W也有一个$\\sum_j w_{ij} = 1$的约束。<br><strong>右边就是一个纯粹的线性变换$W$，可以把它看成是”特征增强”。</strong> 同样可以类比线性降维的通式：<br>$$Y = W^T X = (X^T W)^T$$, <strong>这里的$X^T$和$W$分别对应GCN里的$S H^{(0)}$和$W^{(0)}$</strong>。<br><strong>所以，一层GCN就相当于LLE和线性变换的集成。对于GCN，左边的$SH$我们把它称为特征按近邻进行聚合，再乘$W$叫做线性变换（特征增强）。</strong><br>所以，$S$是我们可以优化的点，$S \\odot M$对$S$做hadamard积，就相当于加权了，这个思想在ST-GCN和很多论文中已经被提出了。</p>\n<h3 id=\"新论文-Simple-Graph-Convolution\"><a href=\"#新论文-Simple-Graph-Convolution\" class=\"headerlink\" title=\"新论文 Simple Graph Convolution\"></a>新论文 Simple Graph Convolution</h3><p>它认为图卷积GCN和多层感知机MLP类似，只不过每一层当中对特征按照其近邻进行了平均化。这篇文章认为图卷积受目前普通卷积神经网络的影响，一开始就加入了非线性变换，还把网络层数搞得很深，于是他们把图卷积进行了简化，去掉了非线性激活，把图卷积网络改成了一个逻辑回归，在某些数据上表现不错。<br><img src=\"./Simple-GCN-schematic.png\" alt=\"\"></p>\n<center>Simple-GCN原理图</center>\n\n<h5 id=\"图卷积的线性化：\"><a href=\"#图卷积的线性化：\" class=\"headerlink\" title=\"图卷积的线性化：\"></a>图卷积的线性化：</h5><p>$$Y = softmax(S\\dots SSX \\theta^{(1)}\\dots \\theta^{(k)})$$ 所有的S都是一样的，可以用$S^K$表示。然后后面的所有变换矩阵乘起来变成了一个矩阵$\\theta = \\theta^{(1)}\\dots \\theta^{(k)}$。<br>然后就变成了一个多分类的逻辑回归：<br>$$Y = softmax(S^K X \\theta)$$<br>$S^K$可以在预处理阶段就可完成，因为需要用到的东西都是已知的。这样，<br>$$\\tilde{X} = S^K X$$ 然后$softmax(\\tilde{X} \\theta)$就变成了单纯的多分类逻辑回归。优化可以直接利用逻辑回归的优化方法，如随机梯度下降（SGD）等。</p>\n<h3 id=\"GCN优化\"><a href=\"#GCN优化\" class=\"headerlink\" title=\"GCN优化\"></a>GCN优化</h3><h4 id=\"DeepGCNs-系列\"><a href=\"#DeepGCNs-系列\" class=\"headerlink\" title=\"DeepGCNs 系列\"></a>DeepGCNs 系列</h4><p>GCN初始版本，kpif&amp;welling那个，在core数据集上只用到了2-hop近邻。其实GCN深度增加会降低模型效果，因为过度平滑问题，所有最初的GCN层数不能很深。</p>\n<p>后来有人讨论了GCN的模型深度问题，用了ResGCN，DenseGCN，加深了网络层数，并提高了performance。</p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"GCN的由来和最初的原理\"><a href=\"#GCN的由来和最初的原理\" class=\"headerlink\" title=\"GCN的由来和最初的原理\"></a>GCN的由来和最初的原理</h3><ul>\n<li>Graph上的拉普拉斯矩阵L：<br>$$L = D - A$$ 其中D是度矩阵，A是邻接矩阵。<br>对L进行对称归一化：<br>$$L = I - D^{-1/2} A D^{-1/2} $$ 拉普拉斯矩阵具有良好的性质，它是<strong>对称半正定</strong>的，特征分解可以写成：<br>$$L = U \\Lambda U^T$$ 其中$U$为正交阵，即$UU^T = I$。</li>\n<li>GCN源于传统的傅里叶变换：<br>$$F(w) = \\mathcal{F}[f(t)] = \\int f(t)e^{-jwt}dt$$ 其中$e^{-jwt}$是傅里叶变换的基函数，它是拉普拉斯算子$\\Delta$的特征函数，其中w与特征值有关。<br>拉普拉斯算子$\\Delta$与$e^{-jwt}$满足特征方程：<br>$$\\Delta e^{-jwt} = \\frac{\\partial^2 e^{-jwt}}{\\partial t^2} = -w^2 e^{-jwt}$$</li>\n<li>对应到Graph上的傅里叶变换：<br>$$F(\\lambda_l) = \\hat{f}(\\lambda_l) = \\sum\\limits_{i=1}^{n} f(i)u_l(i)$$ 这里$u_l(i)$对应传统傅里叶变换中的基函数，$u_l(i)$在这为拉普拉斯矩阵的特征向量矩阵$U$的各个分量，具体为第$l$个特征向量的第$i$个分量。写成矩阵形式：</li>\n</ul>\n<p>$$\\left[ \\begin{matrix} \\hat{f}(\\lambda_1)\\ \\hat{f}(\\lambda_2)\\ \\vdots \\ \\hat{f}(\\lambda_n) \\end{matrix} \\right] = \\left[ \\begin{matrix} u_1(1) &amp; u_1(2) &amp; \\cdots &amp; u_1(n)\\ u_2(1) &amp; u_2(2) &amp; \\cdots &amp; u_2(n)\\ \\vdots \\ u_n(1) &amp; u_n(2) &amp; \\cdots &amp; u_n(n) \\end{matrix} \\right] = \\left[ \\begin{matrix} f(\\lambda_1)\\ f(\\lambda_2)\\ \\vdots \\ f(\\lambda_n) \\end{matrix} \\right]$$</p>\n<p>改写为矩阵形式，$U^T$即为拉普拉斯矩阵分解后的特征向量矩阵的转置：<br>$$\\hat{f} = U^T f$$ 对应的逆变换：<br>$$f = U \\hat{f}$$</p>\n<ul>\n<li><strong>图卷积</strong></li>\n<li>传统卷积: (卷积的傅里叶变换等于傅里叶变换的乘积)<br>$$\\mathcal{F}[f*h] = \\hat{f} \\cdot \\hat{h}$$</li>\n</ul>\n<p>变换形式：</p>\n<p>$$f*h = \\mathcal{F}^{-1} [\\hat{f} \\cdot \\hat{h}]$$</p>\n<ul>\n<li>传统卷积推广到Graph上：<br>设$f$为待卷积函数，$h$为卷积核，即滤波器，<br>$$f*h = U \\left[ \\begin{matrix} \\hat{h}_1\\ &amp; \\hat{h}_2 \\ &amp; &amp; \\ddots\\ &amp; &amp; &amp; \\hat{h}_n \\end{matrix} \\right] U^T f$$ </li>\n<li><em>这个滤波器的傅里叶变换 $\\hat{h}_i$ 也就是我们要设计的部分！*</em><br>把上面矩阵写成符号表示：<br>$$f * h = U [(U^T h) \\odot (U^T f)]$$</li>\n<li><em>把$\\hat{h}_i$看成卷积上的滤波器，即卷积核，我们希望卷积核能捕捉“局部特征”，所以定义$\\hat{h}_i$为拉普拉斯矩阵的函数 $h(L)$。*</em><br>注意$L$和$\\Lambda$是有关联的，所以我们把 $\\hat{h}<em>i$ 进一步定义成 $\\Lambda$ 的函数(为什么这么定义后边能看出来)：<br>$$\\hat{h} = g</em>{\\theta}(\\Lambda)$$<br>，其中$\\theta$代表参数。然后改写卷积公式：<br>$$g_{\\theta}<em>x = U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T x$$<br>，由于特征分解的计算复杂度是相当高的，所以我们引入*</em>Chebyshev多项式<strong>对$g_{\\theta}(\\Lambda)$进行展开。<br>切比雪夫多项式的定义：<br>$$T_0(x) = 1; T_1(x) = x; T_{n+1}(x) = 2xT_{n}(x) - T_{n-1}(x)$$，进一步，n次多项式按切比雪夫多项式的展开式：<br>$$p(x) = \\sum\\limits_{k=0}^{K} a_n T_{k}(x)$$<br>然后，把$g_{\\theta}(\\Lambda)$按chebyshev多项式展开：<br>$$g_{\\theta}(\\Lambda) \\approx \\sum\\limits_{k=0}^{K} \\theta_{k} T_k(\\tilde{\\Lambda})$$<br>,其中，</strong>$\\tilde{\\Lambda} = \\frac{2}{\\lambda_{max}} \\Lambda - I$,放缩到$[-1,1]$之间，保证每阶chebyshev多项式的收敛性<strong>。<br>又因为，<br>$$L^K = (U \\Lambda U^T) ^ K = U \\Lambda^K U^T$$，把$U \\cdot g_{\\theta}(\\Lambda) \\cdot U^T$对应成$\\tilde{L}$的函数。对$\\tilde{\\Lambda}$为自变量，其切比雪夫多项式，有：<br>$$T_0(\\tilde{\\Lambda}) = I, T_1(\\tilde{\\Lambda}) = \\tilde{\\Lambda}, T_2(\\tilde{\\Lambda}) = 2\\tilde{\\Lambda}^2 - I$$，$U \\cdot T_i(\\tilde \\Lambda) \\cdot U^T$则对应成：<br>$$T_0(\\tilde{L}) = I, T_1(\\tilde{L}) = \\tilde{L}, T_2(\\tilde{L}) = 2\\tilde{L}^2 - I$$，继续改写卷积公式：<br>$$g_{\\theta’} * x = \\sum\\limits_{k=0}^{K} \\theta’<em>{k} T_k(\\tilde{L}) x \\tag{1}$$, 其中，$\\tilde{L} = \\frac{2}{\\lambda</em>{max}}L - I$。这时候，根据chebyshev多项式，可以把$T_k(\\tilde{L})$看成是$\\tilde{L}$的幂级数。<br>现在首先以拉普拉斯矩阵$L$为例，分析一下他的谱性质：对于归一化的$L$矩阵：<br>$$L = I - D^{-1/2} A D^{-1/2}$$,先分析右半边：其特征方程可以写成：<br>$$D^{-1/2} A D^{-1/2} \\vec{p} = \\lambda \\vec{p}$$,左乘$D^{-1/2}$,<br>$$D^{-1} A D^{-1/2} \\vec{p} = \\lambda D^{-1/2} \\vec{p}$$,特征值不变，特征向量变成$D^{-1/2} \\vec{p}$。所以对称归一化的A矩阵与随机游走归一化的A矩阵特征值是相同的。<br>很容易可以得到，$|D^{-1}A|<em>1 = 1$，其实他的1-范数和$\\infty$-范数都是1。由范数的性质，一个矩阵的所有的特征值的绝对值都小于等于该矩阵的任意范数。<br>$$|\\lambda| \\leq |D^{-1}A|_1 = 1$$<br>,所以特征值范围是$[-1,1]$。所以L的特征值范围是$[0,2]$。<br>现在做一个近似，$\\lambda</em>{max} \\approx 2$, 所以：<br>$$\\tilde{L} = \\frac{2}{\\lambda_{max}}L - I = L - I$$。 现在回到卷积的公式(1)，我们手动让$K = 1$，代表1-order Chebyshe Filter，即一阶切比雪夫滤波器。<br>$$g_{\\theta’} * x = (\\theta’<em>0 I + \\theta’_1 \\tilde{L}) x = (\\theta’_0 I + \\theta’_1 (L - I))) x$$，令$\\theta’_0 = -\\theta’_1 = \\theta$,继续改写：<br>$$g</em>{\\theta’} * x = (\\theta’_0 I + \\theta’_1 \\tilde{L}) x = \\theta (I + D^{-1/2} A D^{-1/2}) x \\tag{2}$$<br>,</strong>现在得到的矩阵就是1-order Chebyshe Filter**。切比雪夫多项式里的$K$就代表了近邻的阶数（层数）。举个例子，以$K=2$为例，我们计算一下$L$和$L^2$来对比一下。</li>\n</ul>\n<p><img src=\"./LandL2.png\" alt=\"\"></p>\n<center>Simple-GCN原理图</center>\n\n<p>可以看出，<strong>K每增加1，高阶近邻位置上产生权值，即与多一层的近邻产生联系。<br>不过，高阶的近邻与中心点的关联逐渐减小</strong>，这也正与<strong>滤波器的”局部性”</strong> 相契合。以$K=2$为例，分析一下chebyshe展开：<br>$$\\theta_0 I + \\theta_1 \\tilde{L} + \\theta_2 \\tilde{L}^2 = (\\theta_0 - \\theta_1 + \\theta_2) I + (\\theta_1 - 2\\theta_2) L + \\theta_2 L^2$$<br>，自行代入，我们可以发现：所有的$\\theta_i$都是一个常数，即<strong>对同阶近邻来说，不论它属于谁的邻域，都共享同一个权值</strong>$\\theta_i$，这样有优点也有缺点。<br><strong>优点：</strong> 对大规模图来说，参数只有$K+1$个，参数量小。<br><strong>缺点：</strong> 不能在不同的邻域内分配不同的权值。</p>\n<h4 id=\"GCN的发展\"><a href=\"#GCN的发展\" class=\"headerlink\" title=\"GCN的发展\"></a>GCN的发展</h4><p>后来，<strong>1-order Chebyshev滤波器被改进,采用了Renormalization Trick</strong>：<br>$$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$$,A和D分别是加了自环(self-loops)后的邻接矩阵和度矩阵。<br>GCN中初始的first-order Chebyshev filter是：$S_{1-order} = I + D^{-1/2}AD^{-1/2}$，归一化的拉普拉斯矩阵：$\\Delta_{sym} = I - D^{-1/2}AD^{-1/2}$，所以一阶切比雪夫滤波器变成：$S_{1-order} = 2I - \\Delta_{sym}$。然后对于$S^K_{1-order}$，滤波系数是$g_i = (2 - \\lambda_i)^K$,当$\\lambda &lt; 1$时随着K增加系数爆炸式增长，不好！<br>然后采用了【再归一化】，$S = \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$,然后现在的拉普拉斯矩阵就变成了$\\tilde{D}_{sym} = I - \\tilde{D}^{-1/2}\\tilde{A}\\tilde{D}^{-1/2}$，滤波器系数变为$g_i = (1 - \\tilde{\\lambda}_i)^K$,性能变好了！</p>\n<p><strong>从此，目前的GCN框架变成了：</strong></p>\n<p><img src=\"./GCN-schematic.png\" alt=\"\"></p>\n<center>GCN原理图</center>\n\n<p>给定一个图，$G = (V, A)$，V是顶点集，A是邻接矩阵（对称阵）。用D表示图G的度矩阵，$D=diag(d_1,\\cdots,d_n)$。用$H^{(i)}$表示图卷积中的结点特征。<br>输入的结点特征矩阵：<br>$$X = {x_1^T,x_2^T,\\cdots,x_n^T}^T \\in \\mathbb{R}^{n \\times d}$$<br>初始特征:$$H^{(0)} = X$$<br>图卷积包括三个步骤：特征传播、线性变换、非线性激活。</p>\n<h5 id=\"特征传播：\"><a href=\"#特征传播：\" class=\"headerlink\" title=\"特征传播：\"></a>特征传播：</h5><p>给初始的邻接矩阵 A 添加自环(self-loops):<br>$$\\tilde{A} = A + I$$ 用 $\\tilde{D}$ 表示 $\\tilde{A}$ 的度矩阵。<br>定义归一化的邻接矩阵：<br>$$S = \\tilde{D}^{-\\frac{1}{2}} \\tilde{A} \\tilde{D}^{-\\frac{1}{2}}$$ 这个S在所有层都是一样的，直接通过$\\tilde{A}$即可求得。<br>第k层的特征传播：<br>$$\\tilde{H}^{(k)} \\leftarrow SH^{(k-1)}$$<br>分开写：<br>$$\\tilde{h}^{k}<em>{i} \\leftarrow \\frac{1}{d_i+1}h_i^{(k-1)} + \\sum\\limits</em>{j=1}^{n} \\frac{a_{ij}}{\\sqrt{(d_i+1)(d_j+1)}} h_j^{(k-1)}$$</p>\n<h5 id=\"特征变换-非线性激活：\"><a href=\"#特征变换-非线性激活：\" class=\"headerlink\" title=\"特征变换 + 非线性激活：\"></a>特征变换 + 非线性激活：</h5><p>每一层有个权值矩阵$\\theta^{(k)}$<br>$$H^{(k)} \\leftarrow ReLU(\\tilde{H^{(k)}} \\theta^{(k)})$$</p>\n<h5 id=\"分类器：\"><a href=\"#分类器：\" class=\"headerlink\" title=\"分类器：\"></a>分类器：</h5><p>$$Y_{GCN} = softmax(SH^{(k-1)} \\theta^{(k)})$$</p>\n<h5 id=\"参数细节：\"><a href=\"#参数细节：\" class=\"headerlink\" title=\"参数细节：\"></a>参数细节：</h5><p><strong>图卷积的层数控制了图卷积的感受野，即随着层数K加深，与更高阶的近邻产生关系</strong>。</p>\n<h3 id=\"GCN与LLE和线性变换的关系\"><a href=\"#GCN与LLE和线性变换的关系\" class=\"headerlink\" title=\"GCN与LLE和线性变换的关系\"></a>GCN与LLE和线性变换的关系</h3><p>现在的主流GCN框架：<br>$$H^{(k+1)} = ReLU\\left(S H^{(k)} W^{(k)}\\right)$$,其中$H^{(0)} = X$。以$K = 0$为例，分析第一层网络：<br>$$H^{(1)} = ReLU\\left(S H^{(0)} W^{(0)}\\right)$$,<strong>左半部分$Y=S X$,本质就是LLE</strong>：<br>LLE在每个高维点的局部拟合超平面，用k-近邻来线性表示被拟合点，所以在高维空间中，这个高维拟合（高维重建）过程可以用公式表示为:<br>$$\\hat{X} = X W = (W^T X^T)^T$$,$X \\in \\mathbb{R}^{D\\times n}$是按列排布的高维数据点，每列是一个高维样本点；$W \\in \\mathbb{R}^{n \\times n}$是对应每个被重建点的权值向量$\\vec{w_i}$，对应$W$矩阵的第 $i$ 列，这个向量的第j个位置上的值即为重建第i个点所需的第j个权值(对应第j个点)，非近邻点权值就是0。<br><strong>LLE与GCN的左半部分对比，是同样的，LLE里的$W^T$和$X^T$分别对应GCN中的$S$和$H^{(0)}$。</strong> 其实，从$A$矩阵的归一化上来看，GCN中的$S$与LLE里的$W$也是相通的，因为LLE的W也有一个$\\sum_j w_{ij} = 1$的约束。<br><strong>右边就是一个纯粹的线性变换$W$，可以把它看成是”特征增强”。</strong> 同样可以类比线性降维的通式：<br>$$Y = W^T X = (X^T W)^T$$, <strong>这里的$X^T$和$W$分别对应GCN里的$S H^{(0)}$和$W^{(0)}$</strong>。<br><strong>所以，一层GCN就相当于LLE和线性变换的集成。对于GCN，左边的$SH$我们把它称为特征按近邻进行聚合，再乘$W$叫做线性变换（特征增强）。</strong><br>所以，$S$是我们可以优化的点，$S \\odot M$对$S$做hadamard积，就相当于加权了，这个思想在ST-GCN和很多论文中已经被提出了。</p>\n<h3 id=\"新论文-Simple-Graph-Convolution\"><a href=\"#新论文-Simple-Graph-Convolution\" class=\"headerlink\" title=\"新论文 Simple Graph Convolution\"></a>新论文 Simple Graph Convolution</h3><p>它认为图卷积GCN和多层感知机MLP类似，只不过每一层当中对特征按照其近邻进行了平均化。这篇文章认为图卷积受目前普通卷积神经网络的影响，一开始就加入了非线性变换，还把网络层数搞得很深，于是他们把图卷积进行了简化，去掉了非线性激活，把图卷积网络改成了一个逻辑回归，在某些数据上表现不错。<br><img src=\"./Simple-GCN-schematic.png\" alt=\"\"></p>\n<center>Simple-GCN原理图</center>\n\n<h5 id=\"图卷积的线性化：\"><a href=\"#图卷积的线性化：\" class=\"headerlink\" title=\"图卷积的线性化：\"></a>图卷积的线性化：</h5><p>$$Y = softmax(S\\dots SSX \\theta^{(1)}\\dots \\theta^{(k)})$$ 所有的S都是一样的，可以用$S^K$表示。然后后面的所有变换矩阵乘起来变成了一个矩阵$\\theta = \\theta^{(1)}\\dots \\theta^{(k)}$。<br>然后就变成了一个多分类的逻辑回归：<br>$$Y = softmax(S^K X \\theta)$$<br>$S^K$可以在预处理阶段就可完成，因为需要用到的东西都是已知的。这样，<br>$$\\tilde{X} = S^K X$$ 然后$softmax(\\tilde{X} \\theta)$就变成了单纯的多分类逻辑回归。优化可以直接利用逻辑回归的优化方法，如随机梯度下降（SGD）等。</p>\n<h3 id=\"GCN优化\"><a href=\"#GCN优化\" class=\"headerlink\" title=\"GCN优化\"></a>GCN优化</h3><h4 id=\"DeepGCNs-系列\"><a href=\"#DeepGCNs-系列\" class=\"headerlink\" title=\"DeepGCNs 系列\"></a>DeepGCNs 系列</h4><p>GCN初始版本，kpif&amp;welling那个，在core数据集上只用到了2-hop近邻。其实GCN深度增加会降低模型效果，因为过度平滑问题，所有最初的GCN层数不能很深。</p>\n<p>后来有人讨论了GCN的模型深度问题，用了ResGCN，DenseGCN，加深了网络层数，并提高了performance。</p>\n"},{"title":"CNN中的各种卷积","date":"2020-02-08T06:38:14.000Z","_content":"\n***\n### 深度学习中的各种卷积\n***\n#### 3D卷积\n* 3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。\n\n<center>\n    <img src=\"./3d.jpg\" width=400>\n</center>\n<center>3D卷积</center>\n\n* 3D 卷积可以描述 3D 空间中目标的空间关系。\n***\n#### 转置卷积（去卷积）\n* 进行与普通卷积方向相反的转换，即小图变大图，执行上采样\n* 转置卷积在文献中也被称为去卷积或 fractionally strided convolution\n\n<center>\n<figure class=\"half\">\n    <img src=\"./转置卷积1.jpg\" title=\"logo\" width=\"200\">\n    <img src=\"./转置卷积2.jpg\" title=\"logo\" width=\"200\">\n</figure>\n</center>\n<center>转置卷积</center>\n\n<center>\n    <img src=\"./普通卷积的实现.jpg\" width=\"500\">\n</center>\n<center>普通卷积的实现</center>\n\n<center>\n    <img src=\"./转置卷积的实现.jpg\" width=\"500\">\n</center>\n<center>转置卷积的实现</center>\n\n* 可以看出，转置卷积在计算机运算上的实现，相当于把sparse矩阵进行了转置。这也是转置卷积的由来。\n***\n#### 扩张卷积（Atrous 卷积）\n* 直观而言，扩张卷积就是通过在核元素之间插入空格来使核「膨胀」。新增的参数 l（扩张率）表示我们希望将核加宽的程度。具体实现可能各不相同，但通常是在核元素之间插入 l-1 个空格。\n\n<center>\n    <img src=\"./扩张卷积.jpg\" width=\"300\">\n</center>\n<center>扩张卷积</center>\n\n***\n#### 可分卷积\n##### 空间可分卷积\n* 空间可分卷积是将一个卷积分解为两个单独的运算。\n* 在卷积中，3×3 核直接与图像卷积。在空间可分卷积中，3×1 核首先与图像卷积，然后再应用 1×3 核。这样，执行同样的操作时仅需 6 个参数，而不是 9 个。\n<center>\n    <img src=\"./空间可分卷积.jpg\" width=\"300\">\n    <img src=\"./空间可分卷积2.jpg\" width=\"500\">\n</center>\n<center>空间可分卷积</center>\n\n##### 深度可分卷积\n* 第一步：我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。\n<center>\n    <img src=\"./深度可分卷积.jpg\" width=\"700\">\n</center>\n<center>深度可分卷积</center>\n\n* 第二步，为了扩展深度，我们应用一个核大小为 1×1×3 的 1×1 卷积。将 5×5×3 的输入图像与每个 1×1×3 的核卷积，可得到大小为 5×5×1 的映射图。在应用了 128 个 1×1 卷积之后，我们得到大小为 5×5×128 的层。\n* 效率高！这样的成本大概仅有 2D 卷积的 12%！\n***\n#### 分组卷积\n* 在每个过滤器分组中，每个过滤器的深度仅有名义上的 2D 卷积的一半。它们的深度是 Din/2。每个过滤器分组包含 Dout/2 个过滤器。第一个过滤器分组（红色）与输入层的前一半（[:, :, 0:Din/2]）卷积，而第二个过滤器分组（橙色）与输入层的后一半（[:, :, Din/2:Din]）卷积。因此，每个过滤器分组都会创建 Dout/2 个通道。整体而言，两个分组会创建 2×Dout/2 = Dout 个通道。然后我们将这些通道堆叠在一起，得到有 Dout 个通道的输出层。\n<center>\n    <img src=\"./分组卷积.jpg\" width=\"500\">\n</center>\n<center>分组卷积</center>\n\n***\n","source":"_posts/CNN卷积.md","raw":"---\ntitle: CNN中的各种卷积\ndate: 2020-02-08 14:38:14\ntags: 科研\ncategories: 科研\n---\n\n***\n### 深度学习中的各种卷积\n***\n#### 3D卷积\n* 3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。\n\n<center>\n    <img src=\"./3d.jpg\" width=400>\n</center>\n<center>3D卷积</center>\n\n* 3D 卷积可以描述 3D 空间中目标的空间关系。\n***\n#### 转置卷积（去卷积）\n* 进行与普通卷积方向相反的转换，即小图变大图，执行上采样\n* 转置卷积在文献中也被称为去卷积或 fractionally strided convolution\n\n<center>\n<figure class=\"half\">\n    <img src=\"./转置卷积1.jpg\" title=\"logo\" width=\"200\">\n    <img src=\"./转置卷积2.jpg\" title=\"logo\" width=\"200\">\n</figure>\n</center>\n<center>转置卷积</center>\n\n<center>\n    <img src=\"./普通卷积的实现.jpg\" width=\"500\">\n</center>\n<center>普通卷积的实现</center>\n\n<center>\n    <img src=\"./转置卷积的实现.jpg\" width=\"500\">\n</center>\n<center>转置卷积的实现</center>\n\n* 可以看出，转置卷积在计算机运算上的实现，相当于把sparse矩阵进行了转置。这也是转置卷积的由来。\n***\n#### 扩张卷积（Atrous 卷积）\n* 直观而言，扩张卷积就是通过在核元素之间插入空格来使核「膨胀」。新增的参数 l（扩张率）表示我们希望将核加宽的程度。具体实现可能各不相同，但通常是在核元素之间插入 l-1 个空格。\n\n<center>\n    <img src=\"./扩张卷积.jpg\" width=\"300\">\n</center>\n<center>扩张卷积</center>\n\n***\n#### 可分卷积\n##### 空间可分卷积\n* 空间可分卷积是将一个卷积分解为两个单独的运算。\n* 在卷积中，3×3 核直接与图像卷积。在空间可分卷积中，3×1 核首先与图像卷积，然后再应用 1×3 核。这样，执行同样的操作时仅需 6 个参数，而不是 9 个。\n<center>\n    <img src=\"./空间可分卷积.jpg\" width=\"300\">\n    <img src=\"./空间可分卷积2.jpg\" width=\"500\">\n</center>\n<center>空间可分卷积</center>\n\n##### 深度可分卷积\n* 第一步：我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。\n<center>\n    <img src=\"./深度可分卷积.jpg\" width=\"700\">\n</center>\n<center>深度可分卷积</center>\n\n* 第二步，为了扩展深度，我们应用一个核大小为 1×1×3 的 1×1 卷积。将 5×5×3 的输入图像与每个 1×1×3 的核卷积，可得到大小为 5×5×1 的映射图。在应用了 128 个 1×1 卷积之后，我们得到大小为 5×5×128 的层。\n* 效率高！这样的成本大概仅有 2D 卷积的 12%！\n***\n#### 分组卷积\n* 在每个过滤器分组中，每个过滤器的深度仅有名义上的 2D 卷积的一半。它们的深度是 Din/2。每个过滤器分组包含 Dout/2 个过滤器。第一个过滤器分组（红色）与输入层的前一半（[:, :, 0:Din/2]）卷积，而第二个过滤器分组（橙色）与输入层的后一半（[:, :, Din/2:Din]）卷积。因此，每个过滤器分组都会创建 Dout/2 个通道。整体而言，两个分组会创建 2×Dout/2 = Dout 个通道。然后我们将这些通道堆叠在一起，得到有 Dout 个通道的输出层。\n<center>\n    <img src=\"./分组卷积.jpg\" width=\"500\">\n</center>\n<center>分组卷积</center>\n\n***\n","slug":"CNN卷积","published":1,"updated":"2020-06-08T06:04:58.690Z","_id":"ck6ewuw1i000044ym6u4eeblf","comments":1,"layout":"post","photos":[],"link":"","content":"<hr>\n<h3 id=\"深度学习中的各种卷积\"><a href=\"#深度学习中的各种卷积\" class=\"headerlink\" title=\"深度学习中的各种卷积\"></a>深度学习中的各种卷积</h3><hr>\n<h4 id=\"3D卷积\"><a href=\"#3D卷积\" class=\"headerlink\" title=\"3D卷积\"></a>3D卷积</h4><ul>\n<li>3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。</li>\n</ul>\n<center>\n    <img src=\"./3d.jpg\" width=400>\n</center>\n<center>3D卷积</center>\n\n<ul>\n<li>3D 卷积可以描述 3D 空间中目标的空间关系。</li>\n</ul>\n<hr>\n<h4 id=\"转置卷积（去卷积）\"><a href=\"#转置卷积（去卷积）\" class=\"headerlink\" title=\"转置卷积（去卷积）\"></a>转置卷积（去卷积）</h4><ul>\n<li>进行与普通卷积方向相反的转换，即小图变大图，执行上采样</li>\n<li>转置卷积在文献中也被称为去卷积或 fractionally strided convolution</li>\n</ul>\n<center>\n<figure class=\"half\">\n    <img src=\"./转置卷积1.jpg\" title=\"logo\" width=\"200\">\n    <img src=\"./转置卷积2.jpg\" title=\"logo\" width=\"200\">\n</figure>\n</center>\n<center>转置卷积</center>\n\n<center>\n    <img src=\"./普通卷积的实现.jpg\" width=\"500\">\n</center>\n<center>普通卷积的实现</center>\n\n<center>\n    <img src=\"./转置卷积的实现.jpg\" width=\"500\">\n</center>\n<center>转置卷积的实现</center>\n\n<ul>\n<li>可以看出，转置卷积在计算机运算上的实现，相当于把sparse矩阵进行了转置。这也是转置卷积的由来。</li>\n</ul>\n<hr>\n<h4 id=\"扩张卷积（Atrous-卷积）\"><a href=\"#扩张卷积（Atrous-卷积）\" class=\"headerlink\" title=\"扩张卷积（Atrous 卷积）\"></a>扩张卷积（Atrous 卷积）</h4><ul>\n<li>直观而言，扩张卷积就是通过在核元素之间插入空格来使核「膨胀」。新增的参数 l（扩张率）表示我们希望将核加宽的程度。具体实现可能各不相同，但通常是在核元素之间插入 l-1 个空格。</li>\n</ul>\n<center>\n    <img src=\"./扩张卷积.jpg\" width=\"300\">\n</center>\n<center>扩张卷积</center>\n\n<hr>\n<h4 id=\"可分卷积\"><a href=\"#可分卷积\" class=\"headerlink\" title=\"可分卷积\"></a>可分卷积</h4><h5 id=\"空间可分卷积\"><a href=\"#空间可分卷积\" class=\"headerlink\" title=\"空间可分卷积\"></a>空间可分卷积</h5><ul>\n<li>空间可分卷积是将一个卷积分解为两个单独的运算。</li>\n<li>在卷积中，3×3 核直接与图像卷积。在空间可分卷积中，3×1 核首先与图像卷积，然后再应用 1×3 核。这样，执行同样的操作时仅需 6 个参数，而不是 9 个。<center>\n  <img src=\"./空间可分卷积.jpg\" width=\"300\">\n  <img src=\"./空间可分卷积2.jpg\" width=\"500\">\n</center>\n<center>空间可分卷积</center>\n\n</li>\n</ul>\n<h5 id=\"深度可分卷积\"><a href=\"#深度可分卷积\" class=\"headerlink\" title=\"深度可分卷积\"></a>深度可分卷积</h5><ul>\n<li><p>第一步：我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。</p>\n<center>\n  <img src=\"./深度可分卷积.jpg\" width=\"700\">\n</center>\n<center>深度可分卷积</center>\n</li>\n<li><p>第二步，为了扩展深度，我们应用一个核大小为 1×1×3 的 1×1 卷积。将 5×5×3 的输入图像与每个 1×1×3 的核卷积，可得到大小为 5×5×1 的映射图。在应用了 128 个 1×1 卷积之后，我们得到大小为 5×5×128 的层。</p>\n</li>\n<li><p>效率高！这样的成本大概仅有 2D 卷积的 12%！</p>\n</li>\n</ul>\n<hr>\n<h4 id=\"分组卷积\"><a href=\"#分组卷积\" class=\"headerlink\" title=\"分组卷积\"></a>分组卷积</h4><ul>\n<li>在每个过滤器分组中，每个过滤器的深度仅有名义上的 2D 卷积的一半。它们的深度是 Din/2。每个过滤器分组包含 Dout/2 个过滤器。第一个过滤器分组（红色）与输入层的前一半（[:, :, 0:Din/2]）卷积，而第二个过滤器分组（橙色）与输入层的后一半（[:, :, Din/2:Din]）卷积。因此，每个过滤器分组都会创建 Dout/2 个通道。整体而言，两个分组会创建 2×Dout/2 = Dout 个通道。然后我们将这些通道堆叠在一起，得到有 Dout 个通道的输出层。<center>\n  <img src=\"./分组卷积.jpg\" width=\"500\">\n</center>\n<center>分组卷积</center>\n\n</li>\n</ul>\n<hr>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<h3 id=\"深度学习中的各种卷积\"><a href=\"#深度学习中的各种卷积\" class=\"headerlink\" title=\"深度学习中的各种卷积\"></a>深度学习中的各种卷积</h3><hr>\n<h4 id=\"3D卷积\"><a href=\"#3D卷积\" class=\"headerlink\" title=\"3D卷积\"></a>3D卷积</h4><ul>\n<li>3D 过滤器可以在所有三个方向（图像的高度、宽度、通道）上移动。在每个位置，逐元素的乘法和加法都会提供一个数值。因为过滤器是滑过一个 3D 空间，所以输出数值也按 3D 空间排布。也就是说输出是一个 3D 数据。</li>\n</ul>\n<center>\n    <img src=\"./3d.jpg\" width=400>\n</center>\n<center>3D卷积</center>\n\n<ul>\n<li>3D 卷积可以描述 3D 空间中目标的空间关系。</li>\n</ul>\n<hr>\n<h4 id=\"转置卷积（去卷积）\"><a href=\"#转置卷积（去卷积）\" class=\"headerlink\" title=\"转置卷积（去卷积）\"></a>转置卷积（去卷积）</h4><ul>\n<li>进行与普通卷积方向相反的转换，即小图变大图，执行上采样</li>\n<li>转置卷积在文献中也被称为去卷积或 fractionally strided convolution</li>\n</ul>\n<center>\n<figure class=\"half\">\n    <img src=\"./转置卷积1.jpg\" title=\"logo\" width=\"200\">\n    <img src=\"./转置卷积2.jpg\" title=\"logo\" width=\"200\">\n</figure>\n</center>\n<center>转置卷积</center>\n\n<center>\n    <img src=\"./普通卷积的实现.jpg\" width=\"500\">\n</center>\n<center>普通卷积的实现</center>\n\n<center>\n    <img src=\"./转置卷积的实现.jpg\" width=\"500\">\n</center>\n<center>转置卷积的实现</center>\n\n<ul>\n<li>可以看出，转置卷积在计算机运算上的实现，相当于把sparse矩阵进行了转置。这也是转置卷积的由来。</li>\n</ul>\n<hr>\n<h4 id=\"扩张卷积（Atrous-卷积）\"><a href=\"#扩张卷积（Atrous-卷积）\" class=\"headerlink\" title=\"扩张卷积（Atrous 卷积）\"></a>扩张卷积（Atrous 卷积）</h4><ul>\n<li>直观而言，扩张卷积就是通过在核元素之间插入空格来使核「膨胀」。新增的参数 l（扩张率）表示我们希望将核加宽的程度。具体实现可能各不相同，但通常是在核元素之间插入 l-1 个空格。</li>\n</ul>\n<center>\n    <img src=\"./扩张卷积.jpg\" width=\"300\">\n</center>\n<center>扩张卷积</center>\n\n<hr>\n<h4 id=\"可分卷积\"><a href=\"#可分卷积\" class=\"headerlink\" title=\"可分卷积\"></a>可分卷积</h4><h5 id=\"空间可分卷积\"><a href=\"#空间可分卷积\" class=\"headerlink\" title=\"空间可分卷积\"></a>空间可分卷积</h5><ul>\n<li>空间可分卷积是将一个卷积分解为两个单独的运算。</li>\n<li>在卷积中，3×3 核直接与图像卷积。在空间可分卷积中，3×1 核首先与图像卷积，然后再应用 1×3 核。这样，执行同样的操作时仅需 6 个参数，而不是 9 个。<center>\n  <img src=\"./空间可分卷积.jpg\" width=\"300\">\n  <img src=\"./空间可分卷积2.jpg\" width=\"500\">\n</center>\n<center>空间可分卷积</center>\n\n</li>\n</ul>\n<h5 id=\"深度可分卷积\"><a href=\"#深度可分卷积\" class=\"headerlink\" title=\"深度可分卷积\"></a>深度可分卷积</h5><ul>\n<li><p>第一步：我们不使用 2D 卷积中大小为 3×3×3 的单个过滤器，而是分开使用 3 个核。每个过滤器的大小为 3×3×1。每个核与输入层的一个通道卷积（仅一个通道，而非所有通道！）。每个这样的卷积都能提供大小为 5×5×1 的映射图。然后我们将这些映射图堆叠在一起，创建一个 5×5×3 的图像。经过这个操作之后，我们得到大小为 5×5×3 的输出。</p>\n<center>\n  <img src=\"./深度可分卷积.jpg\" width=\"700\">\n</center>\n<center>深度可分卷积</center>\n</li>\n<li><p>第二步，为了扩展深度，我们应用一个核大小为 1×1×3 的 1×1 卷积。将 5×5×3 的输入图像与每个 1×1×3 的核卷积，可得到大小为 5×5×1 的映射图。在应用了 128 个 1×1 卷积之后，我们得到大小为 5×5×128 的层。</p>\n</li>\n<li><p>效率高！这样的成本大概仅有 2D 卷积的 12%！</p>\n</li>\n</ul>\n<hr>\n<h4 id=\"分组卷积\"><a href=\"#分组卷积\" class=\"headerlink\" title=\"分组卷积\"></a>分组卷积</h4><ul>\n<li>在每个过滤器分组中，每个过滤器的深度仅有名义上的 2D 卷积的一半。它们的深度是 Din/2。每个过滤器分组包含 Dout/2 个过滤器。第一个过滤器分组（红色）与输入层的前一半（[:, :, 0:Din/2]）卷积，而第二个过滤器分组（橙色）与输入层的后一半（[:, :, Din/2:Din]）卷积。因此，每个过滤器分组都会创建 Dout/2 个通道。整体而言，两个分组会创建 2×Dout/2 = Dout 个通道。然后我们将这些通道堆叠在一起，得到有 Dout 个通道的输出层。<center>\n  <img src=\"./分组卷积.jpg\" width=\"500\">\n</center>\n<center>分组卷积</center>\n\n</li>\n</ul>\n<hr>\n"},{"title":"祝大家情人节牛批","date":"2020-02-14T03:39:36.000Z","_content":"\n上邪，\n我欲与君相知，\n长命无绝衰。\n山无陵，\n江水为竭。\n冬雷震震，\n夏雨雪。\n天地合，\n乃敢与君绝。\n\n祝大家情人节牛批！","source":"_posts/祝大家情人节牛批.md","raw":"---\ntitle: 祝大家情人节牛批\ndate: 2020-02-14 11:39:36\ntags:\n---\n\n上邪，\n我欲与君相知，\n长命无绝衰。\n山无陵，\n江水为竭。\n冬雷震震，\n夏雨雪。\n天地合，\n乃敢与君绝。\n\n祝大家情人节牛批！","slug":"祝大家情人节牛批","published":1,"updated":"2020-02-14T03:41:14.066Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ck6lmkssc00003gymg91b7yni","content":"<p>上邪，<br>我欲与君相知，<br>长命无绝衰。<br>山无陵，<br>江水为竭。<br>冬雷震震，<br>夏雨雪。<br>天地合，<br>乃敢与君绝。</p>\n<p>祝大家情人节牛批！</p>\n","site":{"data":{}},"excerpt":"","more":"<p>上邪，<br>我欲与君相知，<br>长命无绝衰。<br>山无陵，<br>江水为竭。<br>冬雷震震，<br>夏雨雪。<br>天地合，<br>乃敢与君绝。</p>\n<p>祝大家情人节牛批！</p>\n"},{"title":"操作系统复习","date":"2020-02-16T02:56:25.000Z","_content":"<font color=#0000FF>\n\n<center>\n\n# 操作系统知识点复习 \n</center>\n\n## 操作系统之进程与线程 \n### 进程\n进程控制块PCB：系统为每个运行的程序配置的数据结构，用来描述进程的各种信息（代码存放位置等）。操作系统通过PCB来管理进程。\n进程实体：由程序段、数据段、PCB三部分组成。其中PCB是进程存在的唯一标志。\n进程定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。进程强调“动态性”。\n进程的状态：运行态Running、就绪态Ready、阻塞态Blocked。另外两种：创建态、终止态。\n进程的组织方式：链接方式（队列）、索引方式（表）\n进程的控制：用“原语”实现，即“原子操作”。原语在执行时不允许中断，属于操作系统内核的一部分。\n### 进程通信：\n* 共享存储：互斥的，同时只允许一个进程访问共享空间。\n* 消息传递\n    - 直接通信\n    - 间接通信：先发到“信箱”\n* 管道通信：在内存中开辟一个大小固定的缓冲区。\n    - 各个进程对管道的访问是互斥的；\n    - 管道是半双工的，一个管道同一时刻只能单向传输。全双工要两个管道。\n\n### 线程：\n* 每个进程可能包含多个线程，来提高并发度。\n* 线程是程序执行的最小单位。\n* 引入线程后，进程是系统资源分配的基本单位，线程是调度的基本单位。\n* 进程间并发，线程间并发。同一进程的线程间并发不用切换进程环境，减小了系统开销。\n\n线程的实现方式：\n* 用户级线程：对应操作系统的用户态。\n* 内核级线程：对应操作系统的核心态。\n    - 内核级线程才是处理机分配的单位，用户级线程先映射到内核级线程上。\n    - 多线程模型：多对一、一对一、多对多。\n\n进程调度：\n* 作业调度：高级调度 \n* 内存调度：中级调度 \n    - 挂起状态：除PCB外，某 进程资源暂时调到外存中等待。分为就绪挂起和阻塞挂起。\n* 进程调度：低级调度 \n<center>\n    <img src=\"./进程调度.png\" >\n</center>\n<center>图1 三层进程调度</center>\n\n### 进程互斥与进程同步\n* 进程互斥：当一个进程访问某临界资源时，另一个要访问该资源的进程必须等待。\n    - 系统资源的两种共享方式：互斥共享、同时共享。\n    - 临界资源：互斥共享，同一时间段只允许一个进程使用。\n    - 对临界资源的互斥访问，在逻辑上分为四部分：\n\n```C\ndo {\n    entry section; // 进入区：检查是否可进入临界区，若可进入则上锁\n    critical section; // 临界区：访问临界资源\n    exit section; // 退出区：解锁\n    remainder section; // 剩余区：其他处理\n} while (true)\n```\n\n* 进程互斥的原则：\n    - 空闲让进：临界区空闲，允许一个进程立即进入\n    - 忙则等待：临界区被锁，其他进程必须等待\n    - 有限等待：保证要访问临界区的进程不会饥饿，能在有限时间内进入\n    - 让权等待：若一个进程不能进入临界区，应立即释放处理机，防止忙等待\n\n* 进程同步：并发的进程因直接制约而互相发送消息、进行相互合作、相互等待，使得各进程按一定的速度执行的过程。\n\n* 使用信号量机制(P、V操作)实现进程互斥、进程同步：\n    - 用进程阻塞避免了“忙等”\n    - P、V操作对应 wait() 和 signal() 原语，实现系统资源的申请和释放\n    - 无资源可用则自我阻塞block()，用完资源后唤醒等待队列中的进程wakeup()\n    - 实现互斥关系时，设置互斥信号量S的初始值为1，在临界区之前执行P(S)，在临界区之后执行V(S)\n    - 实现同步关系时，即操作有先后，设置同步信号量S的初始值为0，要在“前操作”之后执行V(S)，在“后操作”之前执行P(S)，这样无论哪个进程先运行，都能保证同步\n\n```C\n/* 记录型信号量的定义 */\ntypedef struct {\n    int value;          //剩余资源数\n    struct process *L;  //等待队列\n} semaphore;\n```\n```C\n/* 某进程要是用资源时，使用wait()原语申请 */\nvoid wait (semaphore S) {\n    S.value--;\n    if (S.value < 0) {\n        block(S.L);\n    }\n}\n```\n```C\n/* 某进程使用完资源后，使用signal()原语释放资源 */\nvoid signal(semaphore S) {\n    S.value++;\n    if (S.value <= 0) {\n        wakeup(S.L);\n    }\n}\n```\n\n##### 生产者消费者问题：进程互斥与进程同步\n* 问题描述：\n    - 生产者、消费者共享一个初始为空、大小为n的缓冲区\n    - 当缓冲区未满时，生产者可以生产产品并放入缓冲区，否则必须等待\n    - 当缓冲区未空时，消费者可以从缓冲区中取走产品，否则必须等待\n    - 缓冲区是临界资源，必须互斥访问\n\n对于单生产者、单消费者问题：\n```C\nsemaphore mutex = 1;    //互斥信号量，互斥访问buffer\nsemaphore empty = n;    //同步信号量，表示buffer中的空闲位置\nsemaphore full = 0;     //同步信号量，表示buffer中的产品数\nproducer() {\n    while (1) {\n        produce a product;\n        P(empty);   //有空闲位置才会生产\n        P(mutex);\n        put the product to buffer;\n        V(mutex);\n        V(full);\n    }\n}\nconsumer() {\n    while (1) {\n        P(full);    //有产品才会消费\n        P(mutex);\n        take a product from buffer;\n        V(mutex);\n        V(empty);\n        consume the product;\n    }\n}\n```\n\n* P、P和P、V不可颠倒，否则会引发死锁，V、V无所谓\n* 多生产者、多消费者问题类似，分析好相互之间的制约关系和对buffer的互斥关系\n* 生产者吸烟者问题：单生产者、多消费者问题，改变一下代码逻辑即可\n\n<center>\n    <img src=\"./生产者吸烟者.png\" >\n</center>\n<center>图2 吸烟者轮流吸烟问题</center>\n\n* 读者、写者问题：1个写者，n个读者；读写互斥；读者与读者不互斥；第一个开始读的负责加锁，最后一个读完的负责解锁。设置一个计数器count记录当前的读进程数。\n\n### 管程\n* 管程的组成：\n    - 局部于管程的共享数据结构说明\n    - 初始化共享数据的语句\n    - 对共享数据进行操作的函数（过程）\n    - 管程有一个名字\n* 特征：\n    - 数据只能被这些过程访问\n    - 进程对管程的访问是互斥的\n    - 把同步、互斥等操作进行了封装，解决信号量机制麻烦易出错的问题\n\n管程：\n```C\nmonitor ProducerConsumer \n    condition full, empty;      //同步条件量\n    int count = 0;              //缓冲区产品数\n    void insert(Item item) {    //生产者把产品放入缓冲区\n        if (count == N) {       //若缓冲区满，则生产者进程阻塞\n            wait(full);\n        }\n        count++;\n        insert_item(item);\n        if (count == 1) {       //如果之前是空，唤醒消费者进程\n            signal(empty);\n        }\n    }\n    Item remove() {             //消费者从缓冲区取走产品\n        if (count == 0) {       //若缓冲区空，阻塞消费者进程\n            wait(empty);\n        }\n        count--;\n        if (count == N - 1) {   //若之前缓冲区满，唤醒生产者进程\n            signal(full);\n        }\n        return remove_item();\n    }\nend monitor;\n```\n生产者进程：\n```C\nproducer() {\n    while (1) {\n        item = produce a product;\n        ProducerConsumer.insert(item);\n    }\n}\n```\n消费者进程：\n```C\nconsumer() {\n    while (1) {\n        item = ProducerConsumer.remove();\n        consume item;\n    }\n}\n```\n\n* java中的 synchronized 关键字能实现类似于管程的机制\n\n### 死锁\n死锁：在并发环境下，各进程因竞争资源而造成相互循环等待，进而导致各进程都阻塞的现象。\n饥饿：进程长期得不到资源，无法推进。\n* 银行家算法：避免死锁\n    - 检查此次申请是否超过了之前声明的最大需求数；\n    - 检查此时系统剩余可用资源能否满足这次申请；\n    - 试着分配，更改各数据结构；\n    - 用安全性算法检查此次分配会不会导致系统进入“不安全状态”，如果会则阻塞该进程。\n* 安全性算法：\n    - 检查当前剩余可用资源能否满足某个进程的最大需求；\n    - 如果能，就把该进程加入安全序列；等进程结束，把该进程持有的资源全部回收。\n    - 不断重复这个过程，看最终能否把所有进程都加入安全序列。\n\n<font color=#FF0000>\n\n### 操作系统之进程问题集锦\n1. 进程和线程以及它们的区别？\n    - 进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现操作系统的并发。\n    - 线程是进程的子任务，是CPU调度的基本单位，用于保证程序的实时性，实现进程内部的并发。\n    - 一个程序至少一个进程，一个进程至少一个线程，线程依赖于进程存在。\n    - 进程拥有独立的内存单元，同一个进程的不同线程间共享该进程的内存单元。\n2. 进程间通信的几种方式？\n\n3. 线程同步的方式？\n\n4. 死锁？\n\n</font>\n\n## 操作系统之内存管理\n* 内存分为系统区和用户区。\n* 内存管理：\n    - 内存空间的分配与回收\n    - 虚拟内存技术从逻辑上对内存空间进行扩充\n    - 实现地址转换：逻辑地址与物理地址的转换\n    - 内存保护，保证各进程之间互不干扰\n\n* 交换技术：当内存空间紧张时，系统将内存中某些进程暂时换出外存，并把外存中某些已具备条件的进程换入内存。\n    - 进程在内存与磁盘间动态调度。\n    - 被调出内存的进程PCB会保留在内存中，用于记录外存位置等信息。\n    - 被换出的进程数据被存放在磁盘的“对换区”，储存空间连续分配，I/O速度比文件区快。\n    - 被调出内存的进程处于挂起态suspend。下面是进程的七状态模型：\n\n<center>\n    <img src=\"./进程七状态模型.png\" >\n</center>\n<center>图3 进程的七状态模型</center>\n\n* 内存的动态分区分配：不预先划分内存分区，而是在进程装入内存时，根据进程大小动态地建立分区，分区大小刚好满足进程需要。动态分区分配不会产生内部碎片，但有外部碎片。\n    - 内部碎片：分配给某进程的内存区域太大，有没被利用的部分。\n    - 外部碎片：内存中的空闲分区由于空间太小而难以利用。\n    - 外部碎片可以通过“紧凑技术”Compaction来进行合并，紧凑技术会把现有的进程的内存空间首尾相接，时间代价较高。\n\n### 分页存储\n* 基本分页存储管理：内存分为多个小空间的页框（内存块），把进程按页框大小分页，各个页面离散地分配到各个内存块中，这样有利于减小碎片。使用页表来保存页面地址。\n    - 地址变换机构实现目标内存单元的查找。\n    - 在地址变换机构的基础上，加入“快表”，实质是一种缓存，加速地址变换。\n    - 多级页表，避免单级页表占用内存中很多个连续的页框的问题。多级页表对原始页表进行分块，内存中只放入进程最近需要的页表。\n* 请求分页存储管理：不一次把程序所有资源调入内存，需要使用时由操作系统调入内存，若内存不够则需要使用页面置换算法把当前不用的信息调出到外存。\n#### 页面置换算法\n* 最佳置换算法 OPT：每次选择淘汰的页面是以后永不使用或最长时间内不会被使用的。无法实现。\n* 先进先出置换算法 FIFO：每次淘汰的页面是最早进入内存的页面。使用队列实现。\n* 最近最久未使用置换算法 LRU：每次淘汰的页面是最近最久未使用的页面。在页表项中添加访问字段记录未访问的时间。\n* 时钟置换算法 CLOCK：每个页面设置一个访问位，把所有页面连成循环队列。当某页被访问时，访问位=1。当要淘汰一个页面时，检查循环队列的访问位，找第一个访问位=0的页换出；若遍历时该位是1，则置0。若第一遍遍历没找到=0的，再找第二遍，肯定能找到=0的。\n* 改进型的时钟置换算法：在CLOCK算法的基础上，还考虑页面有没有被修改过，避免被修改过的页面被换出时的I/O操作。\n#### 页面分配策略\n* 驻留集：请求分页存储管理中给进程分配的内存块的集合。\n* 策略：\n    - 固定分配、局部置换：程序运行前分配固定数量内存块，内存缺页时在自己进程内部换页。\n    - 可变分配、全局置换：缺页时分配新物理块，可能来自空闲物理块或换出其他进程页面。\n    - 可变分配、局部置换：应对频繁缺页的进程会多分配内存块，反之回收内存块。\n* 颠簸（抖动）：页面频繁换入换出。主要原因是分给该进程的内存块不够。\n\n### 分段存储\n* 定义：进程的地址空间，按照逻辑功能被划分为若干个段，每个段有自己的段名（方便用户编程），并且每个段从0开始编址\n* 内存分配规则：以段为单位进行内存分配，每个段在内存中占连续的地址空间，但各段之间可以不相邻。\n* 分段系统的逻辑地址：一个地址（假设32位，0\\~31）由高M位表示段号（比如16\\~31），低N位表示段内偏移（比如0~15）。段号的多少决定分段个数，段内偏移决定每个段长。\n* 分段存储的寻址：使用“段映射表”，简称段表。每个段对应段表中的一个项，记录该段在内存中的起始地址（基址）和段长。寻址过程：\n    - 拿到一个段的逻辑地址，在段表寄存器中查询该段号是否越界（段号与段表长度比较）。\n    - 利用段表寄存器找到段表基址，再利用段号找到该段的基址。\n    - 利用段表项判断段内偏移是否超过该段的长度，然后再计算物理地址。\n* 分段、分页管理对比：\n    - 页是信息的物理单位。分页的目的是实现离散分配，提高内存的利用率。是系统行为，对用户不可见。\n    - 段是信息的逻辑单位。分段的目的是满足用户需求，一个段通常包含一组逻辑模块的信息。分段对用户可见，用户编程需要显式地给出段名。\n    - 页的大小固定；段的长度不固定，取决于用户编写的程序。\n    - 分段按逻辑功能来分，更容易实现信息（指非临界资源）的共享和保护。\n* 段页式管理：逻辑地址结构是二维的：段号、页号、页内地址。\n    - 分段对用户可见。\n    - 分页由操作系统自己完成，对用户不可见。\n    - 寻址：一个进程被分为N个段，先查段表，确定该段的页表位置，再查页表，确定存放的内存块号。\n\n### 虚拟内存\n在程序装入内存时，将即将用到的部分先转入内存，暂时不用的留在外存；当所访问的信息不在内存时，操作系统负责将所需信息调入内存；当内存空间不够时，操作系统将内存中暂时不用的信息调出到外存。\n\n## 操作系统之文件管理\n### 文件的逻辑结构\n* 文件按逻辑结构可分为：\n    - 无结构文件：由二进制流或字符流组成，无明显逻辑结构。如txt文件。\n    - 有结构文件：由记录组成，分为定长记录、可变长记录。\n        - 顺序文件：若为定长记录，则可以快速检索和实现随机存取。\n        - 索引文件：利用索引表。可以支持随机存取和快速检索。\n        - 索引顺序文件\n* 文件目录结构：\n    - 单级目录：不允许文件重名\n    - 两级目录：不能对文件进行分类\n    - 树形目录：不方便文件共享\n    - 无环图目录\n### 文件的物理结构\n* 文件分配方式：\n    - 连续分配：为文件分配连续磁盘块。\n    - 链接分配\n        - 隐式链接：每个盘块存放指向下个盘块的指针。\n        - 显式链接：用文件分配表FAT显式记录盘块的先后关系。\n    - 索引分配：允许文件离散地分配在各个磁盘块中，每个文件对应一张索引表，记录文件各逻辑块对应的物理块。索引表所在的磁盘块叫索引块，文件数据所在的磁盘块叫数据块。若索引表太大：\n        - 链接方案：索引表分块存放，依次链接。这样会使磁盘I/O次数过多。\n        - 多层索引：类似于多级页表。这样索引对小文件不利。\n        - 混合索引：小文件直接用顶级索引表进行一级索引，大文件可以多级索引。\n### 文件存储空间管理\n* 磁盘在逻辑上分为文件卷，每个文件卷又课分为目录区、文件区\n    - 目录区：包含文件目录、空闲表、位示图、超级块等用于文件管理的数据\n* 文件的存储空间管理方法：\n    - 空闲表法：空闲表记录连续空闲区的起始盘块号和盘块数，回收时把相邻的空闲区合并\n    - 空闲链表法：采用链表连接各个空闲区间\n        - 空闲盘块链：以盘块为单位连接\n        - 空闲盘区链：把相邻盘块看成盘区，把盘区相连\n    - 位示图法：用1个bit指示每个盘块是否空闲\n    - 成组链接法：UNIX采用的方式，适用于大型文件系统。\n        - 设置一个“超级块”，系统启动后读入内存中，并保证其与外存中的“超级块”数据一致。\n        - 每一组空闲区间链接起来，超级块中存放下一组空闲区间的盘块数，和该组盘块的盘块号。\n* 文件的基本操作\n    - 创建\n    - 删除\n    - 打开：打开文件表，每个进程有自己的打开文件表，系统有总的打开文件表\n    - 关闭：删除进程打开文件表中的表项，然后系统的打开文件表中打开计数器减1\n    - 读\n    - 写\n* 文件共享\n    - 硬链接：某用户删除文件时，只删除该用户的目录项，链接计数器-1，当删到链接计数器为0才真正删除该文件\n    - 软链接：用link型文件记录该共享文件的存放路径，访问该文件时按路径查询多级目录，访问速度比硬链接慢，相当于Windows操作系统中的快捷方式\n* 文件保护\n    - 口令保护\n    - 加密保护\n    - 访问控制：使用访问控制表ACL记录各个用户对文件的权限\n\n<center>\n    <img src=\"./文件的层次结构.png\" >\n</center>\n<center>图4 文件的层次结构</center>\n\n* 57\n\n\n\n</font>\n\n\n## issues\n\n1. 不同操作系统的CPU竞争策略与 `Thread.Sleep(0)`。\n\n- Unix系统使用时间片算法：所有进程组成进程队列，操作系统按照顺序给进程分配CPU使用时间；如果时间片结束时进程还在运行，则CPU被剥夺并分配给另一个进程，然后该进程被移到队尾。\n- Windows系统使用抢占式算法：操作系统根据各进程的优先级、节时间来确定程序运行顺序；在进程执行完毕或者主动挂起后，操作系统会重新计算总优先级。\n- `Thread.Sleep(0)`的作用就是触发操作系统立即进行一次CPU竞争。","source":"_posts/操作系统复习.md","raw":"---\ntitle: 操作系统复习\ndate: 2020-02-16 10:56:25\ntags: 操作系统\ncategories: 专业课\n---\n<font color=#0000FF>\n\n<center>\n\n# 操作系统知识点复习 \n</center>\n\n## 操作系统之进程与线程 \n### 进程\n进程控制块PCB：系统为每个运行的程序配置的数据结构，用来描述进程的各种信息（代码存放位置等）。操作系统通过PCB来管理进程。\n进程实体：由程序段、数据段、PCB三部分组成。其中PCB是进程存在的唯一标志。\n进程定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。进程强调“动态性”。\n进程的状态：运行态Running、就绪态Ready、阻塞态Blocked。另外两种：创建态、终止态。\n进程的组织方式：链接方式（队列）、索引方式（表）\n进程的控制：用“原语”实现，即“原子操作”。原语在执行时不允许中断，属于操作系统内核的一部分。\n### 进程通信：\n* 共享存储：互斥的，同时只允许一个进程访问共享空间。\n* 消息传递\n    - 直接通信\n    - 间接通信：先发到“信箱”\n* 管道通信：在内存中开辟一个大小固定的缓冲区。\n    - 各个进程对管道的访问是互斥的；\n    - 管道是半双工的，一个管道同一时刻只能单向传输。全双工要两个管道。\n\n### 线程：\n* 每个进程可能包含多个线程，来提高并发度。\n* 线程是程序执行的最小单位。\n* 引入线程后，进程是系统资源分配的基本单位，线程是调度的基本单位。\n* 进程间并发，线程间并发。同一进程的线程间并发不用切换进程环境，减小了系统开销。\n\n线程的实现方式：\n* 用户级线程：对应操作系统的用户态。\n* 内核级线程：对应操作系统的核心态。\n    - 内核级线程才是处理机分配的单位，用户级线程先映射到内核级线程上。\n    - 多线程模型：多对一、一对一、多对多。\n\n进程调度：\n* 作业调度：高级调度 \n* 内存调度：中级调度 \n    - 挂起状态：除PCB外，某 进程资源暂时调到外存中等待。分为就绪挂起和阻塞挂起。\n* 进程调度：低级调度 \n<center>\n    <img src=\"./进程调度.png\" >\n</center>\n<center>图1 三层进程调度</center>\n\n### 进程互斥与进程同步\n* 进程互斥：当一个进程访问某临界资源时，另一个要访问该资源的进程必须等待。\n    - 系统资源的两种共享方式：互斥共享、同时共享。\n    - 临界资源：互斥共享，同一时间段只允许一个进程使用。\n    - 对临界资源的互斥访问，在逻辑上分为四部分：\n\n```C\ndo {\n    entry section; // 进入区：检查是否可进入临界区，若可进入则上锁\n    critical section; // 临界区：访问临界资源\n    exit section; // 退出区：解锁\n    remainder section; // 剩余区：其他处理\n} while (true)\n```\n\n* 进程互斥的原则：\n    - 空闲让进：临界区空闲，允许一个进程立即进入\n    - 忙则等待：临界区被锁，其他进程必须等待\n    - 有限等待：保证要访问临界区的进程不会饥饿，能在有限时间内进入\n    - 让权等待：若一个进程不能进入临界区，应立即释放处理机，防止忙等待\n\n* 进程同步：并发的进程因直接制约而互相发送消息、进行相互合作、相互等待，使得各进程按一定的速度执行的过程。\n\n* 使用信号量机制(P、V操作)实现进程互斥、进程同步：\n    - 用进程阻塞避免了“忙等”\n    - P、V操作对应 wait() 和 signal() 原语，实现系统资源的申请和释放\n    - 无资源可用则自我阻塞block()，用完资源后唤醒等待队列中的进程wakeup()\n    - 实现互斥关系时，设置互斥信号量S的初始值为1，在临界区之前执行P(S)，在临界区之后执行V(S)\n    - 实现同步关系时，即操作有先后，设置同步信号量S的初始值为0，要在“前操作”之后执行V(S)，在“后操作”之前执行P(S)，这样无论哪个进程先运行，都能保证同步\n\n```C\n/* 记录型信号量的定义 */\ntypedef struct {\n    int value;          //剩余资源数\n    struct process *L;  //等待队列\n} semaphore;\n```\n```C\n/* 某进程要是用资源时，使用wait()原语申请 */\nvoid wait (semaphore S) {\n    S.value--;\n    if (S.value < 0) {\n        block(S.L);\n    }\n}\n```\n```C\n/* 某进程使用完资源后，使用signal()原语释放资源 */\nvoid signal(semaphore S) {\n    S.value++;\n    if (S.value <= 0) {\n        wakeup(S.L);\n    }\n}\n```\n\n##### 生产者消费者问题：进程互斥与进程同步\n* 问题描述：\n    - 生产者、消费者共享一个初始为空、大小为n的缓冲区\n    - 当缓冲区未满时，生产者可以生产产品并放入缓冲区，否则必须等待\n    - 当缓冲区未空时，消费者可以从缓冲区中取走产品，否则必须等待\n    - 缓冲区是临界资源，必须互斥访问\n\n对于单生产者、单消费者问题：\n```C\nsemaphore mutex = 1;    //互斥信号量，互斥访问buffer\nsemaphore empty = n;    //同步信号量，表示buffer中的空闲位置\nsemaphore full = 0;     //同步信号量，表示buffer中的产品数\nproducer() {\n    while (1) {\n        produce a product;\n        P(empty);   //有空闲位置才会生产\n        P(mutex);\n        put the product to buffer;\n        V(mutex);\n        V(full);\n    }\n}\nconsumer() {\n    while (1) {\n        P(full);    //有产品才会消费\n        P(mutex);\n        take a product from buffer;\n        V(mutex);\n        V(empty);\n        consume the product;\n    }\n}\n```\n\n* P、P和P、V不可颠倒，否则会引发死锁，V、V无所谓\n* 多生产者、多消费者问题类似，分析好相互之间的制约关系和对buffer的互斥关系\n* 生产者吸烟者问题：单生产者、多消费者问题，改变一下代码逻辑即可\n\n<center>\n    <img src=\"./生产者吸烟者.png\" >\n</center>\n<center>图2 吸烟者轮流吸烟问题</center>\n\n* 读者、写者问题：1个写者，n个读者；读写互斥；读者与读者不互斥；第一个开始读的负责加锁，最后一个读完的负责解锁。设置一个计数器count记录当前的读进程数。\n\n### 管程\n* 管程的组成：\n    - 局部于管程的共享数据结构说明\n    - 初始化共享数据的语句\n    - 对共享数据进行操作的函数（过程）\n    - 管程有一个名字\n* 特征：\n    - 数据只能被这些过程访问\n    - 进程对管程的访问是互斥的\n    - 把同步、互斥等操作进行了封装，解决信号量机制麻烦易出错的问题\n\n管程：\n```C\nmonitor ProducerConsumer \n    condition full, empty;      //同步条件量\n    int count = 0;              //缓冲区产品数\n    void insert(Item item) {    //生产者把产品放入缓冲区\n        if (count == N) {       //若缓冲区满，则生产者进程阻塞\n            wait(full);\n        }\n        count++;\n        insert_item(item);\n        if (count == 1) {       //如果之前是空，唤醒消费者进程\n            signal(empty);\n        }\n    }\n    Item remove() {             //消费者从缓冲区取走产品\n        if (count == 0) {       //若缓冲区空，阻塞消费者进程\n            wait(empty);\n        }\n        count--;\n        if (count == N - 1) {   //若之前缓冲区满，唤醒生产者进程\n            signal(full);\n        }\n        return remove_item();\n    }\nend monitor;\n```\n生产者进程：\n```C\nproducer() {\n    while (1) {\n        item = produce a product;\n        ProducerConsumer.insert(item);\n    }\n}\n```\n消费者进程：\n```C\nconsumer() {\n    while (1) {\n        item = ProducerConsumer.remove();\n        consume item;\n    }\n}\n```\n\n* java中的 synchronized 关键字能实现类似于管程的机制\n\n### 死锁\n死锁：在并发环境下，各进程因竞争资源而造成相互循环等待，进而导致各进程都阻塞的现象。\n饥饿：进程长期得不到资源，无法推进。\n* 银行家算法：避免死锁\n    - 检查此次申请是否超过了之前声明的最大需求数；\n    - 检查此时系统剩余可用资源能否满足这次申请；\n    - 试着分配，更改各数据结构；\n    - 用安全性算法检查此次分配会不会导致系统进入“不安全状态”，如果会则阻塞该进程。\n* 安全性算法：\n    - 检查当前剩余可用资源能否满足某个进程的最大需求；\n    - 如果能，就把该进程加入安全序列；等进程结束，把该进程持有的资源全部回收。\n    - 不断重复这个过程，看最终能否把所有进程都加入安全序列。\n\n<font color=#FF0000>\n\n### 操作系统之进程问题集锦\n1. 进程和线程以及它们的区别？\n    - 进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现操作系统的并发。\n    - 线程是进程的子任务，是CPU调度的基本单位，用于保证程序的实时性，实现进程内部的并发。\n    - 一个程序至少一个进程，一个进程至少一个线程，线程依赖于进程存在。\n    - 进程拥有独立的内存单元，同一个进程的不同线程间共享该进程的内存单元。\n2. 进程间通信的几种方式？\n\n3. 线程同步的方式？\n\n4. 死锁？\n\n</font>\n\n## 操作系统之内存管理\n* 内存分为系统区和用户区。\n* 内存管理：\n    - 内存空间的分配与回收\n    - 虚拟内存技术从逻辑上对内存空间进行扩充\n    - 实现地址转换：逻辑地址与物理地址的转换\n    - 内存保护，保证各进程之间互不干扰\n\n* 交换技术：当内存空间紧张时，系统将内存中某些进程暂时换出外存，并把外存中某些已具备条件的进程换入内存。\n    - 进程在内存与磁盘间动态调度。\n    - 被调出内存的进程PCB会保留在内存中，用于记录外存位置等信息。\n    - 被换出的进程数据被存放在磁盘的“对换区”，储存空间连续分配，I/O速度比文件区快。\n    - 被调出内存的进程处于挂起态suspend。下面是进程的七状态模型：\n\n<center>\n    <img src=\"./进程七状态模型.png\" >\n</center>\n<center>图3 进程的七状态模型</center>\n\n* 内存的动态分区分配：不预先划分内存分区，而是在进程装入内存时，根据进程大小动态地建立分区，分区大小刚好满足进程需要。动态分区分配不会产生内部碎片，但有外部碎片。\n    - 内部碎片：分配给某进程的内存区域太大，有没被利用的部分。\n    - 外部碎片：内存中的空闲分区由于空间太小而难以利用。\n    - 外部碎片可以通过“紧凑技术”Compaction来进行合并，紧凑技术会把现有的进程的内存空间首尾相接，时间代价较高。\n\n### 分页存储\n* 基本分页存储管理：内存分为多个小空间的页框（内存块），把进程按页框大小分页，各个页面离散地分配到各个内存块中，这样有利于减小碎片。使用页表来保存页面地址。\n    - 地址变换机构实现目标内存单元的查找。\n    - 在地址变换机构的基础上，加入“快表”，实质是一种缓存，加速地址变换。\n    - 多级页表，避免单级页表占用内存中很多个连续的页框的问题。多级页表对原始页表进行分块，内存中只放入进程最近需要的页表。\n* 请求分页存储管理：不一次把程序所有资源调入内存，需要使用时由操作系统调入内存，若内存不够则需要使用页面置换算法把当前不用的信息调出到外存。\n#### 页面置换算法\n* 最佳置换算法 OPT：每次选择淘汰的页面是以后永不使用或最长时间内不会被使用的。无法实现。\n* 先进先出置换算法 FIFO：每次淘汰的页面是最早进入内存的页面。使用队列实现。\n* 最近最久未使用置换算法 LRU：每次淘汰的页面是最近最久未使用的页面。在页表项中添加访问字段记录未访问的时间。\n* 时钟置换算法 CLOCK：每个页面设置一个访问位，把所有页面连成循环队列。当某页被访问时，访问位=1。当要淘汰一个页面时，检查循环队列的访问位，找第一个访问位=0的页换出；若遍历时该位是1，则置0。若第一遍遍历没找到=0的，再找第二遍，肯定能找到=0的。\n* 改进型的时钟置换算法：在CLOCK算法的基础上，还考虑页面有没有被修改过，避免被修改过的页面被换出时的I/O操作。\n#### 页面分配策略\n* 驻留集：请求分页存储管理中给进程分配的内存块的集合。\n* 策略：\n    - 固定分配、局部置换：程序运行前分配固定数量内存块，内存缺页时在自己进程内部换页。\n    - 可变分配、全局置换：缺页时分配新物理块，可能来自空闲物理块或换出其他进程页面。\n    - 可变分配、局部置换：应对频繁缺页的进程会多分配内存块，反之回收内存块。\n* 颠簸（抖动）：页面频繁换入换出。主要原因是分给该进程的内存块不够。\n\n### 分段存储\n* 定义：进程的地址空间，按照逻辑功能被划分为若干个段，每个段有自己的段名（方便用户编程），并且每个段从0开始编址\n* 内存分配规则：以段为单位进行内存分配，每个段在内存中占连续的地址空间，但各段之间可以不相邻。\n* 分段系统的逻辑地址：一个地址（假设32位，0\\~31）由高M位表示段号（比如16\\~31），低N位表示段内偏移（比如0~15）。段号的多少决定分段个数，段内偏移决定每个段长。\n* 分段存储的寻址：使用“段映射表”，简称段表。每个段对应段表中的一个项，记录该段在内存中的起始地址（基址）和段长。寻址过程：\n    - 拿到一个段的逻辑地址，在段表寄存器中查询该段号是否越界（段号与段表长度比较）。\n    - 利用段表寄存器找到段表基址，再利用段号找到该段的基址。\n    - 利用段表项判断段内偏移是否超过该段的长度，然后再计算物理地址。\n* 分段、分页管理对比：\n    - 页是信息的物理单位。分页的目的是实现离散分配，提高内存的利用率。是系统行为，对用户不可见。\n    - 段是信息的逻辑单位。分段的目的是满足用户需求，一个段通常包含一组逻辑模块的信息。分段对用户可见，用户编程需要显式地给出段名。\n    - 页的大小固定；段的长度不固定，取决于用户编写的程序。\n    - 分段按逻辑功能来分，更容易实现信息（指非临界资源）的共享和保护。\n* 段页式管理：逻辑地址结构是二维的：段号、页号、页内地址。\n    - 分段对用户可见。\n    - 分页由操作系统自己完成，对用户不可见。\n    - 寻址：一个进程被分为N个段，先查段表，确定该段的页表位置，再查页表，确定存放的内存块号。\n\n### 虚拟内存\n在程序装入内存时，将即将用到的部分先转入内存，暂时不用的留在外存；当所访问的信息不在内存时，操作系统负责将所需信息调入内存；当内存空间不够时，操作系统将内存中暂时不用的信息调出到外存。\n\n## 操作系统之文件管理\n### 文件的逻辑结构\n* 文件按逻辑结构可分为：\n    - 无结构文件：由二进制流或字符流组成，无明显逻辑结构。如txt文件。\n    - 有结构文件：由记录组成，分为定长记录、可变长记录。\n        - 顺序文件：若为定长记录，则可以快速检索和实现随机存取。\n        - 索引文件：利用索引表。可以支持随机存取和快速检索。\n        - 索引顺序文件\n* 文件目录结构：\n    - 单级目录：不允许文件重名\n    - 两级目录：不能对文件进行分类\n    - 树形目录：不方便文件共享\n    - 无环图目录\n### 文件的物理结构\n* 文件分配方式：\n    - 连续分配：为文件分配连续磁盘块。\n    - 链接分配\n        - 隐式链接：每个盘块存放指向下个盘块的指针。\n        - 显式链接：用文件分配表FAT显式记录盘块的先后关系。\n    - 索引分配：允许文件离散地分配在各个磁盘块中，每个文件对应一张索引表，记录文件各逻辑块对应的物理块。索引表所在的磁盘块叫索引块，文件数据所在的磁盘块叫数据块。若索引表太大：\n        - 链接方案：索引表分块存放，依次链接。这样会使磁盘I/O次数过多。\n        - 多层索引：类似于多级页表。这样索引对小文件不利。\n        - 混合索引：小文件直接用顶级索引表进行一级索引，大文件可以多级索引。\n### 文件存储空间管理\n* 磁盘在逻辑上分为文件卷，每个文件卷又课分为目录区、文件区\n    - 目录区：包含文件目录、空闲表、位示图、超级块等用于文件管理的数据\n* 文件的存储空间管理方法：\n    - 空闲表法：空闲表记录连续空闲区的起始盘块号和盘块数，回收时把相邻的空闲区合并\n    - 空闲链表法：采用链表连接各个空闲区间\n        - 空闲盘块链：以盘块为单位连接\n        - 空闲盘区链：把相邻盘块看成盘区，把盘区相连\n    - 位示图法：用1个bit指示每个盘块是否空闲\n    - 成组链接法：UNIX采用的方式，适用于大型文件系统。\n        - 设置一个“超级块”，系统启动后读入内存中，并保证其与外存中的“超级块”数据一致。\n        - 每一组空闲区间链接起来，超级块中存放下一组空闲区间的盘块数，和该组盘块的盘块号。\n* 文件的基本操作\n    - 创建\n    - 删除\n    - 打开：打开文件表，每个进程有自己的打开文件表，系统有总的打开文件表\n    - 关闭：删除进程打开文件表中的表项，然后系统的打开文件表中打开计数器减1\n    - 读\n    - 写\n* 文件共享\n    - 硬链接：某用户删除文件时，只删除该用户的目录项，链接计数器-1，当删到链接计数器为0才真正删除该文件\n    - 软链接：用link型文件记录该共享文件的存放路径，访问该文件时按路径查询多级目录，访问速度比硬链接慢，相当于Windows操作系统中的快捷方式\n* 文件保护\n    - 口令保护\n    - 加密保护\n    - 访问控制：使用访问控制表ACL记录各个用户对文件的权限\n\n<center>\n    <img src=\"./文件的层次结构.png\" >\n</center>\n<center>图4 文件的层次结构</center>\n\n* 57\n\n\n\n</font>\n\n\n## issues\n\n1. 不同操作系统的CPU竞争策略与 `Thread.Sleep(0)`。\n\n- Unix系统使用时间片算法：所有进程组成进程队列，操作系统按照顺序给进程分配CPU使用时间；如果时间片结束时进程还在运行，则CPU被剥夺并分配给另一个进程，然后该进程被移到队尾。\n- Windows系统使用抢占式算法：操作系统根据各进程的优先级、节时间来确定程序运行顺序；在进程执行完毕或者主动挂起后，操作系统会重新计算总优先级。\n- `Thread.Sleep(0)`的作用就是触发操作系统立即进行一次CPU竞争。","slug":"操作系统复习","published":1,"updated":"2020-06-08T06:05:08.097Z","_id":"ck6onkcvj0000z8ymb13k6dya","comments":1,"layout":"post","photos":[],"link":"","content":"<font color=#0000FF>\n\n<center>\n\n<h1 id=\"操作系统知识点复习\"><a href=\"#操作系统知识点复习\" class=\"headerlink\" title=\"操作系统知识点复习\"></a>操作系统知识点复习</h1></center>\n\n<h2 id=\"操作系统之进程与线程\"><a href=\"#操作系统之进程与线程\" class=\"headerlink\" title=\"操作系统之进程与线程\"></a>操作系统之进程与线程</h2><h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p>进程控制块PCB：系统为每个运行的程序配置的数据结构，用来描述进程的各种信息（代码存放位置等）。操作系统通过PCB来管理进程。<br>进程实体：由程序段、数据段、PCB三部分组成。其中PCB是进程存在的唯一标志。<br>进程定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。进程强调“动态性”。<br>进程的状态：运行态Running、就绪态Ready、阻塞态Blocked。另外两种：创建态、终止态。<br>进程的组织方式：链接方式（队列）、索引方式（表）<br>进程的控制：用“原语”实现，即“原子操作”。原语在执行时不允许中断，属于操作系统内核的一部分。</p>\n<h3 id=\"进程通信：\"><a href=\"#进程通信：\" class=\"headerlink\" title=\"进程通信：\"></a>进程通信：</h3><ul>\n<li>共享存储：互斥的，同时只允许一个进程访问共享空间。</li>\n<li>消息传递<ul>\n<li>直接通信</li>\n<li>间接通信：先发到“信箱”</li>\n</ul>\n</li>\n<li>管道通信：在内存中开辟一个大小固定的缓冲区。<ul>\n<li>各个进程对管道的访问是互斥的；</li>\n<li>管道是半双工的，一个管道同一时刻只能单向传输。全双工要两个管道。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"线程：\"><a href=\"#线程：\" class=\"headerlink\" title=\"线程：\"></a>线程：</h3><ul>\n<li>每个进程可能包含多个线程，来提高并发度。</li>\n<li>线程是程序执行的最小单位。</li>\n<li>引入线程后，进程是系统资源分配的基本单位，线程是调度的基本单位。</li>\n<li>进程间并发，线程间并发。同一进程的线程间并发不用切换进程环境，减小了系统开销。</li>\n</ul>\n<p>线程的实现方式：</p>\n<ul>\n<li>用户级线程：对应操作系统的用户态。</li>\n<li>内核级线程：对应操作系统的核心态。<ul>\n<li>内核级线程才是处理机分配的单位，用户级线程先映射到内核级线程上。</li>\n<li>多线程模型：多对一、一对一、多对多。</li>\n</ul>\n</li>\n</ul>\n<p>进程调度：</p>\n<ul>\n<li>作业调度：高级调度 </li>\n<li>内存调度：中级调度 <ul>\n<li>挂起状态：除PCB外，某 进程资源暂时调到外存中等待。分为就绪挂起和阻塞挂起。</li>\n</ul>\n</li>\n<li>进程调度：低级调度 <center>\n  <img src=\"./进程调度.png\" >\n</center>\n<center>图1 三层进程调度</center>\n\n</li>\n</ul>\n<h3 id=\"进程互斥与进程同步\"><a href=\"#进程互斥与进程同步\" class=\"headerlink\" title=\"进程互斥与进程同步\"></a>进程互斥与进程同步</h3><ul>\n<li>进程互斥：当一个进程访问某临界资源时，另一个要访问该资源的进程必须等待。<ul>\n<li>系统资源的两种共享方式：互斥共享、同时共享。</li>\n<li>临界资源：互斥共享，同一时间段只允许一个进程使用。</li>\n<li>对临界资源的互斥访问，在逻辑上分为四部分：</li>\n</ul>\n</li>\n</ul>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">do {\n    entry section; // 进入区：检查是否可进入临界区，若可进入则上锁\n    critical section; // 临界区：访问临界资源\n    exit section; // 退出区：解锁\n    remainder section; // 剩余区：其他处理\n} while (true)<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li><p>进程互斥的原则：</p>\n<ul>\n<li>空闲让进：临界区空闲，允许一个进程立即进入</li>\n<li>忙则等待：临界区被锁，其他进程必须等待</li>\n<li>有限等待：保证要访问临界区的进程不会饥饿，能在有限时间内进入</li>\n<li>让权等待：若一个进程不能进入临界区，应立即释放处理机，防止忙等待</li>\n</ul>\n</li>\n<li><p>进程同步：并发的进程因直接制约而互相发送消息、进行相互合作、相互等待，使得各进程按一定的速度执行的过程。</p>\n</li>\n<li><p>使用信号量机制(P、V操作)实现进程互斥、进程同步：</p>\n<ul>\n<li>用进程阻塞避免了“忙等”</li>\n<li>P、V操作对应 wait() 和 signal() 原语，实现系统资源的申请和释放</li>\n<li>无资源可用则自我阻塞block()，用完资源后唤醒等待队列中的进程wakeup()</li>\n<li>实现互斥关系时，设置互斥信号量S的初始值为1，在临界区之前执行P(S)，在临界区之后执行V(S)</li>\n<li>实现同步关系时，即操作有先后，设置同步信号量S的初始值为0，要在“前操作”之后执行V(S)，在“后操作”之前执行P(S)，这样无论哪个进程先运行，都能保证同步</li>\n</ul>\n</li>\n</ul>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">/* 记录型信号量的定义 */\ntypedef struct {\n    int value;          //剩余资源数\n    struct process *L;  //等待队列\n} semaphore;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">/* 某进程要是用资源时，使用wait()原语申请 */\nvoid wait (semaphore S) {\n    S.value--;\n    if (S.value < 0) {\n        block(S.L);\n    }\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">/* 某进程使用完资源后，使用signal()原语释放资源 */\nvoid signal(semaphore S) {\n    S.value++;\n    if (S.value <= 0) {\n        wakeup(S.L);\n    }\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h5 id=\"生产者消费者问题：进程互斥与进程同步\"><a href=\"#生产者消费者问题：进程互斥与进程同步\" class=\"headerlink\" title=\"生产者消费者问题：进程互斥与进程同步\"></a>生产者消费者问题：进程互斥与进程同步</h5><ul>\n<li>问题描述：<ul>\n<li>生产者、消费者共享一个初始为空、大小为n的缓冲区</li>\n<li>当缓冲区未满时，生产者可以生产产品并放入缓冲区，否则必须等待</li>\n<li>当缓冲区未空时，消费者可以从缓冲区中取走产品，否则必须等待</li>\n<li>缓冲区是临界资源，必须互斥访问</li>\n</ul>\n</li>\n</ul>\n<p>对于单生产者、单消费者问题：</p>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">semaphore mutex = 1;    //互斥信号量，互斥访问buffer\nsemaphore empty = n;    //同步信号量，表示buffer中的空闲位置\nsemaphore full = 0;     //同步信号量，表示buffer中的产品数\nproducer() {\n    while (1) {\n        produce a product;\n        P(empty);   //有空闲位置才会生产\n        P(mutex);\n        put the product to buffer;\n        V(mutex);\n        V(full);\n    }\n}\nconsumer() {\n    while (1) {\n        P(full);    //有产品才会消费\n        P(mutex);\n        take a product from buffer;\n        V(mutex);\n        V(empty);\n        consume the product;\n    }\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>P、P和P、V不可颠倒，否则会引发死锁，V、V无所谓</li>\n<li>多生产者、多消费者问题类似，分析好相互之间的制约关系和对buffer的互斥关系</li>\n<li>生产者吸烟者问题：单生产者、多消费者问题，改变一下代码逻辑即可</li>\n</ul>\n<center>\n    <img src=\"./生产者吸烟者.png\" >\n</center>\n<center>图2 吸烟者轮流吸烟问题</center>\n\n<ul>\n<li>读者、写者问题：1个写者，n个读者；读写互斥；读者与读者不互斥；第一个开始读的负责加锁，最后一个读完的负责解锁。设置一个计数器count记录当前的读进程数。</li>\n</ul>\n<h3 id=\"管程\"><a href=\"#管程\" class=\"headerlink\" title=\"管程\"></a>管程</h3><ul>\n<li>管程的组成：<ul>\n<li>局部于管程的共享数据结构说明</li>\n<li>初始化共享数据的语句</li>\n<li>对共享数据进行操作的函数（过程）</li>\n<li>管程有一个名字</li>\n</ul>\n</li>\n<li>特征：<ul>\n<li>数据只能被这些过程访问</li>\n<li>进程对管程的访问是互斥的</li>\n<li>把同步、互斥等操作进行了封装，解决信号量机制麻烦易出错的问题</li>\n</ul>\n</li>\n</ul>\n<p>管程：</p>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">monitor ProducerConsumer \n    condition full, empty;      //同步条件量\n    int count = 0;              //缓冲区产品数\n    void insert(Item item) {    //生产者把产品放入缓冲区\n        if (count == N) {       //若缓冲区满，则生产者进程阻塞\n            wait(full);\n        }\n        count++;\n        insert_item(item);\n        if (count == 1) {       //如果之前是空，唤醒消费者进程\n            signal(empty);\n        }\n    }\n    Item remove() {             //消费者从缓冲区取走产品\n        if (count == 0) {       //若缓冲区空，阻塞消费者进程\n            wait(empty);\n        }\n        count--;\n        if (count == N - 1) {   //若之前缓冲区满，唤醒生产者进程\n            signal(full);\n        }\n        return remove_item();\n    }\nend monitor;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>生产者进程：</p>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">producer() {\n    while (1) {\n        item = produce a product;\n        ProducerConsumer.insert(item);\n    }\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>消费者进程：</p>\n<pre class=\"line-numbers language-C\"><code class=\"language-C\">consumer() {\n    while (1) {\n        item = ProducerConsumer.remove();\n        consume item;\n    }\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<ul>\n<li>java中的 synchronized 关键字能实现类似于管程的机制</li>\n</ul>\n<h3 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h3><p>死锁：在并发环境下，各进程因竞争资源而造成相互循环等待，进而导致各进程都阻塞的现象。<br>饥饿：进程长期得不到资源，无法推进。</p>\n<ul>\n<li>银行家算法：避免死锁<ul>\n<li>检查此次申请是否超过了之前声明的最大需求数；</li>\n<li>检查此时系统剩余可用资源能否满足这次申请；</li>\n<li>试着分配，更改各数据结构；</li>\n<li>用安全性算法检查此次分配会不会导致系统进入“不安全状态”，如果会则阻塞该进程。</li>\n</ul>\n</li>\n<li>安全性算法：<ul>\n<li>检查当前剩余可用资源能否满足某个进程的最大需求；</li>\n<li>如果能，就把该进程加入安全序列；等进程结束，把该进程持有的资源全部回收。</li>\n<li>不断重复这个过程，看最终能否把所有进程都加入安全序列。</li>\n</ul>\n</li>\n</ul>\n<font color=#FF0000>\n\n<h3 id=\"操作系统之进程问题集锦\"><a href=\"#操作系统之进程问题集锦\" class=\"headerlink\" title=\"操作系统之进程问题集锦\"></a>操作系统之进程问题集锦</h3><ol>\n<li><p>进程和线程以及它们的区别？</p>\n<ul>\n<li>进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现操作系统的并发。</li>\n<li>线程是进程的子任务，是CPU调度的基本单位，用于保证程序的实时性，实现进程内部的并发。</li>\n<li>一个程序至少一个进程，一个进程至少一个线程，线程依赖于进程存在。</li>\n<li>进程拥有独立的内存单元，同一个进程的不同线程间共享该进程的内存单元。</li>\n</ul>\n</li>\n<li><p>进程间通信的几种方式？</p>\n</li>\n<li><p>线程同步的方式？</p>\n</li>\n<li><p>死锁？</p>\n</li>\n</ol>\n</font>\n\n<h2 id=\"操作系统之内存管理\"><a href=\"#操作系统之内存管理\" class=\"headerlink\" title=\"操作系统之内存管理\"></a>操作系统之内存管理</h2><ul>\n<li><p>内存分为系统区和用户区。</p>\n</li>\n<li><p>内存管理：</p>\n<ul>\n<li>内存空间的分配与回收</li>\n<li>虚拟内存技术从逻辑上对内存空间进行扩充</li>\n<li>实现地址转换：逻辑地址与物理地址的转换</li>\n<li>内存保护，保证各进程之间互不干扰</li>\n</ul>\n</li>\n<li><p>交换技术：当内存空间紧张时，系统将内存中某些进程暂时换出外存，并把外存中某些已具备条件的进程换入内存。</p>\n<ul>\n<li>进程在内存与磁盘间动态调度。</li>\n<li>被调出内存的进程PCB会保留在内存中，用于记录外存位置等信息。</li>\n<li>被换出的进程数据被存放在磁盘的“对换区”，储存空间连续分配，I/O速度比文件区快。</li>\n<li>被调出内存的进程处于挂起态suspend。下面是进程的七状态模型：</li>\n</ul>\n</li>\n</ul>\n<center>\n    <img src=\"./进程七状态模型.png\" >\n</center>\n<center>图3 进程的七状态模型</center>\n\n<ul>\n<li>内存的动态分区分配：不预先划分内存分区，而是在进程装入内存时，根据进程大小动态地建立分区，分区大小刚好满足进程需要。动态分区分配不会产生内部碎片，但有外部碎片。<ul>\n<li>内部碎片：分配给某进程的内存区域太大，有没被利用的部分。</li>\n<li>外部碎片：内存中的空闲分区由于空间太小而难以利用。</li>\n<li>外部碎片可以通过“紧凑技术”Compaction来进行合并，紧凑技术会把现有的进程的内存空间首尾相接，时间代价较高。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分页存储\"><a href=\"#分页存储\" class=\"headerlink\" title=\"分页存储\"></a>分页存储</h3><ul>\n<li>基本分页存储管理：内存分为多个小空间的页框（内存块），把进程按页框大小分页，各个页面离散地分配到各个内存块中，这样有利于减小碎片。使用页表来保存页面地址。<ul>\n<li>地址变换机构实现目标内存单元的查找。</li>\n<li>在地址变换机构的基础上，加入“快表”，实质是一种缓存，加速地址变换。</li>\n<li>多级页表，避免单级页表占用内存中很多个连续的页框的问题。多级页表对原始页表进行分块，内存中只放入进程最近需要的页表。</li>\n</ul>\n</li>\n<li>请求分页存储管理：不一次把程序所有资源调入内存，需要使用时由操作系统调入内存，若内存不够则需要使用页面置换算法把当前不用的信息调出到外存。<h4 id=\"页面置换算法\"><a href=\"#页面置换算法\" class=\"headerlink\" title=\"页面置换算法\"></a>页面置换算法</h4></li>\n<li>最佳置换算法 OPT：每次选择淘汰的页面是以后永不使用或最长时间内不会被使用的。无法实现。</li>\n<li>先进先出置换算法 FIFO：每次淘汰的页面是最早进入内存的页面。使用队列实现。</li>\n<li>最近最久未使用置换算法 LRU：每次淘汰的页面是最近最久未使用的页面。在页表项中添加访问字段记录未访问的时间。</li>\n<li>时钟置换算法 CLOCK：每个页面设置一个访问位，把所有页面连成循环队列。当某页被访问时，访问位=1。当要淘汰一个页面时，检查循环队列的访问位，找第一个访问位=0的页换出；若遍历时该位是1，则置0。若第一遍遍历没找到=0的，再找第二遍，肯定能找到=0的。</li>\n<li>改进型的时钟置换算法：在CLOCK算法的基础上，还考虑页面有没有被修改过，避免被修改过的页面被换出时的I/O操作。<h4 id=\"页面分配策略\"><a href=\"#页面分配策略\" class=\"headerlink\" title=\"页面分配策略\"></a>页面分配策略</h4></li>\n<li>驻留集：请求分页存储管理中给进程分配的内存块的集合。</li>\n<li>策略：<ul>\n<li>固定分配、局部置换：程序运行前分配固定数量内存块，内存缺页时在自己进程内部换页。</li>\n<li>可变分配、全局置换：缺页时分配新物理块，可能来自空闲物理块或换出其他进程页面。</li>\n<li>可变分配、局部置换：应对频繁缺页的进程会多分配内存块，反之回收内存块。</li>\n</ul>\n</li>\n<li>颠簸（抖动）：页面频繁换入换出。主要原因是分给该进程的内存块不够。</li>\n</ul>\n<h3 id=\"分段存储\"><a href=\"#分段存储\" class=\"headerlink\" title=\"分段存储\"></a>分段存储</h3><ul>\n<li>定义：进程的地址空间，按照逻辑功能被划分为若干个段，每个段有自己的段名（方便用户编程），并且每个段从0开始编址</li>\n<li>内存分配规则：以段为单位进行内存分配，每个段在内存中占连续的地址空间，但各段之间可以不相邻。</li>\n<li>分段系统的逻辑地址：一个地址（假设32位，0~31）由高M位表示段号（比如16~31），低N位表示段内偏移（比如0~15）。段号的多少决定分段个数，段内偏移决定每个段长。</li>\n<li>分段存储的寻址：使用“段映射表”，简称段表。每个段对应段表中的一个项，记录该段在内存中的起始地址（基址）和段长。寻址过程：<ul>\n<li>拿到一个段的逻辑地址，在段表寄存器中查询该段号是否越界（段号与段表长度比较）。</li>\n<li>利用段表寄存器找到段表基址，再利用段号找到该段的基址。</li>\n<li>利用段表项判断段内偏移是否超过该段的长度，然后再计算物理地址。</li>\n</ul>\n</li>\n<li>分段、分页管理对比：<ul>\n<li>页是信息的物理单位。分页的目的是实现离散分配，提高内存的利用率。是系统行为，对用户不可见。</li>\n<li>段是信息的逻辑单位。分段的目的是满足用户需求，一个段通常包含一组逻辑模块的信息。分段对用户可见，用户编程需要显式地给出段名。</li>\n<li>页的大小固定；段的长度不固定，取决于用户编写的程序。</li>\n<li>分段按逻辑功能来分，更容易实现信息（指非临界资源）的共享和保护。</li>\n</ul>\n</li>\n<li>段页式管理：逻辑地址结构是二维的：段号、页号、页内地址。<ul>\n<li>分段对用户可见。</li>\n<li>分页由操作系统自己完成，对用户不可见。</li>\n<li>寻址：一个进程被分为N个段，先查段表，确定该段的页表位置，再查页表，确定存放的内存块号。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"虚拟内存\"><a href=\"#虚拟内存\" class=\"headerlink\" title=\"虚拟内存\"></a>虚拟内存</h3><p>在程序装入内存时，将即将用到的部分先转入内存，暂时不用的留在外存；当所访问的信息不在内存时，操作系统负责将所需信息调入内存；当内存空间不够时，操作系统将内存中暂时不用的信息调出到外存。</p>\n<h2 id=\"操作系统之文件管理\"><a href=\"#操作系统之文件管理\" class=\"headerlink\" title=\"操作系统之文件管理\"></a>操作系统之文件管理</h2><h3 id=\"文件的逻辑结构\"><a href=\"#文件的逻辑结构\" class=\"headerlink\" title=\"文件的逻辑结构\"></a>文件的逻辑结构</h3><ul>\n<li>文件按逻辑结构可分为：<ul>\n<li>无结构文件：由二进制流或字符流组成，无明显逻辑结构。如txt文件。</li>\n<li>有结构文件：由记录组成，分为定长记录、可变长记录。<ul>\n<li>顺序文件：若为定长记录，则可以快速检索和实现随机存取。</li>\n<li>索引文件：利用索引表。可以支持随机存取和快速检索。</li>\n<li>索引顺序文件</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>文件目录结构：<ul>\n<li>单级目录：不允许文件重名</li>\n<li>两级目录：不能对文件进行分类</li>\n<li>树形目录：不方便文件共享</li>\n<li>无环图目录<h3 id=\"文件的物理结构\"><a href=\"#文件的物理结构\" class=\"headerlink\" title=\"文件的物理结构\"></a>文件的物理结构</h3></li>\n</ul>\n</li>\n<li>文件分配方式：<ul>\n<li>连续分配：为文件分配连续磁盘块。</li>\n<li>链接分配<ul>\n<li>隐式链接：每个盘块存放指向下个盘块的指针。</li>\n<li>显式链接：用文件分配表FAT显式记录盘块的先后关系。</li>\n</ul>\n</li>\n<li>索引分配：允许文件离散地分配在各个磁盘块中，每个文件对应一张索引表，记录文件各逻辑块对应的物理块。索引表所在的磁盘块叫索引块，文件数据所在的磁盘块叫数据块。若索引表太大：<ul>\n<li>链接方案：索引表分块存放，依次链接。这样会使磁盘I/O次数过多。</li>\n<li>多层索引：类似于多级页表。这样索引对小文件不利。</li>\n<li>混合索引：小文件直接用顶级索引表进行一级索引，大文件可以多级索引。<h3 id=\"文件存储空间管理\"><a href=\"#文件存储空间管理\" class=\"headerlink\" title=\"文件存储空间管理\"></a>文件存储空间管理</h3></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>磁盘在逻辑上分为文件卷，每个文件卷又课分为目录区、文件区<ul>\n<li>目录区：包含文件目录、空闲表、位示图、超级块等用于文件管理的数据</li>\n</ul>\n</li>\n<li>文件的存储空间管理方法：<ul>\n<li>空闲表法：空闲表记录连续空闲区的起始盘块号和盘块数，回收时把相邻的空闲区合并</li>\n<li>空闲链表法：采用链表连接各个空闲区间<ul>\n<li>空闲盘块链：以盘块为单位连接</li>\n<li>空闲盘区链：把相邻盘块看成盘区，把盘区相连</li>\n</ul>\n</li>\n<li>位示图法：用1个bit指示每个盘块是否空闲</li>\n<li>成组链接法：UNIX采用的方式，适用于大型文件系统。<ul>\n<li>设置一个“超级块”，系统启动后读入内存中，并保证其与外存中的“超级块”数据一致。</li>\n<li>每一组空闲区间链接起来，超级块中存放下一组空闲区间的盘块数，和该组盘块的盘块号。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>文件的基本操作<ul>\n<li>创建</li>\n<li>删除</li>\n<li>打开：打开文件表，每个进程有自己的打开文件表，系统有总的打开文件表</li>\n<li>关闭：删除进程打开文件表中的表项，然后系统的打开文件表中打开计数器减1</li>\n<li>读</li>\n<li>写</li>\n</ul>\n</li>\n<li>文件共享<ul>\n<li>硬链接：某用户删除文件时，只删除该用户的目录项，链接计数器-1，当删到链接计数器为0才真正删除该文件</li>\n<li>软链接：用link型文件记录该共享文件的存放路径，访问该文件时按路径查询多级目录，访问速度比硬链接慢，相当于Windows操作系统中的快捷方式</li>\n</ul>\n</li>\n<li>文件保护<ul>\n<li>口令保护</li>\n<li>加密保护</li>\n<li>访问控制：使用访问控制表ACL记录各个用户对文件的权限</li>\n</ul>\n</li>\n</ul>\n<center>\n    <img src=\"./文件的层次结构.png\" >\n</center>\n<center>图4 文件的层次结构</center>\n\n<ul>\n<li>57</li>\n</ul>\n</font>\n\n\n<h2 id=\"issues\"><a href=\"#issues\" class=\"headerlink\" title=\"issues\"></a>issues</h2><ol>\n<li>不同操作系统的CPU竞争策略与 <code>Thread.Sleep(0)</code>。</li>\n</ol>\n<ul>\n<li>Unix系统使用时间片算法：所有进程组成进程队列，操作系统按照顺序给进程分配CPU使用时间；如果时间片结束时进程还在运行，则CPU被剥夺并分配给另一个进程，然后该进程被移到队尾。</li>\n<li>Windows系统使用抢占式算法：操作系统根据各进程的优先级、节时间来确定程序运行顺序；在进程执行完毕或者主动挂起后，操作系统会重新计算总优先级。</li>\n<li><code>Thread.Sleep(0)</code>的作用就是触发操作系统立即进行一次CPU竞争。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<font color=#0000FF>\n\n<center>\n\n<h1 id=\"操作系统知识点复习\"><a href=\"#操作系统知识点复习\" class=\"headerlink\" title=\"操作系统知识点复习\"></a>操作系统知识点复习</h1></center>\n\n<h2 id=\"操作系统之进程与线程\"><a href=\"#操作系统之进程与线程\" class=\"headerlink\" title=\"操作系统之进程与线程\"></a>操作系统之进程与线程</h2><h3 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h3><p>进程控制块PCB：系统为每个运行的程序配置的数据结构，用来描述进程的各种信息（代码存放位置等）。操作系统通过PCB来管理进程。<br>进程实体：由程序段、数据段、PCB三部分组成。其中PCB是进程存在的唯一标志。<br>进程定义：进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。进程强调“动态性”。<br>进程的状态：运行态Running、就绪态Ready、阻塞态Blocked。另外两种：创建态、终止态。<br>进程的组织方式：链接方式（队列）、索引方式（表）<br>进程的控制：用“原语”实现，即“原子操作”。原语在执行时不允许中断，属于操作系统内核的一部分。</p>\n<h3 id=\"进程通信：\"><a href=\"#进程通信：\" class=\"headerlink\" title=\"进程通信：\"></a>进程通信：</h3><ul>\n<li>共享存储：互斥的，同时只允许一个进程访问共享空间。</li>\n<li>消息传递<ul>\n<li>直接通信</li>\n<li>间接通信：先发到“信箱”</li>\n</ul>\n</li>\n<li>管道通信：在内存中开辟一个大小固定的缓冲区。<ul>\n<li>各个进程对管道的访问是互斥的；</li>\n<li>管道是半双工的，一个管道同一时刻只能单向传输。全双工要两个管道。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"线程：\"><a href=\"#线程：\" class=\"headerlink\" title=\"线程：\"></a>线程：</h3><ul>\n<li>每个进程可能包含多个线程，来提高并发度。</li>\n<li>线程是程序执行的最小单位。</li>\n<li>引入线程后，进程是系统资源分配的基本单位，线程是调度的基本单位。</li>\n<li>进程间并发，线程间并发。同一进程的线程间并发不用切换进程环境，减小了系统开销。</li>\n</ul>\n<p>线程的实现方式：</p>\n<ul>\n<li>用户级线程：对应操作系统的用户态。</li>\n<li>内核级线程：对应操作系统的核心态。<ul>\n<li>内核级线程才是处理机分配的单位，用户级线程先映射到内核级线程上。</li>\n<li>多线程模型：多对一、一对一、多对多。</li>\n</ul>\n</li>\n</ul>\n<p>进程调度：</p>\n<ul>\n<li>作业调度：高级调度 </li>\n<li>内存调度：中级调度 <ul>\n<li>挂起状态：除PCB外，某 进程资源暂时调到外存中等待。分为就绪挂起和阻塞挂起。</li>\n</ul>\n</li>\n<li>进程调度：低级调度 <center>\n  <img src=\"./进程调度.png\" >\n</center>\n<center>图1 三层进程调度</center>\n\n</li>\n</ul>\n<h3 id=\"进程互斥与进程同步\"><a href=\"#进程互斥与进程同步\" class=\"headerlink\" title=\"进程互斥与进程同步\"></a>进程互斥与进程同步</h3><ul>\n<li>进程互斥：当一个进程访问某临界资源时，另一个要访问该资源的进程必须等待。<ul>\n<li>系统资源的两种共享方式：互斥共享、同时共享。</li>\n<li>临界资源：互斥共享，同一时间段只允许一个进程使用。</li>\n<li>对临界资源的互斥访问，在逻辑上分为四部分：</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"C\">do {\n    entry section; // 进入区：检查是否可进入临界区，若可进入则上锁\n    critical section; // 临界区：访问临界资源\n    exit section; // 退出区：解锁\n    remainder section; // 剩余区：其他处理\n} while (true)</code></pre>\n<ul>\n<li><p>进程互斥的原则：</p>\n<ul>\n<li>空闲让进：临界区空闲，允许一个进程立即进入</li>\n<li>忙则等待：临界区被锁，其他进程必须等待</li>\n<li>有限等待：保证要访问临界区的进程不会饥饿，能在有限时间内进入</li>\n<li>让权等待：若一个进程不能进入临界区，应立即释放处理机，防止忙等待</li>\n</ul>\n</li>\n<li><p>进程同步：并发的进程因直接制约而互相发送消息、进行相互合作、相互等待，使得各进程按一定的速度执行的过程。</p>\n</li>\n<li><p>使用信号量机制(P、V操作)实现进程互斥、进程同步：</p>\n<ul>\n<li>用进程阻塞避免了“忙等”</li>\n<li>P、V操作对应 wait() 和 signal() 原语，实现系统资源的申请和释放</li>\n<li>无资源可用则自我阻塞block()，用完资源后唤醒等待队列中的进程wakeup()</li>\n<li>实现互斥关系时，设置互斥信号量S的初始值为1，在临界区之前执行P(S)，在临界区之后执行V(S)</li>\n<li>实现同步关系时，即操作有先后，设置同步信号量S的初始值为0，要在“前操作”之后执行V(S)，在“后操作”之前执行P(S)，这样无论哪个进程先运行，都能保证同步</li>\n</ul>\n</li>\n</ul>\n<pre><code class=\"C\">/* 记录型信号量的定义 */\ntypedef struct {\n    int value;          //剩余资源数\n    struct process *L;  //等待队列\n} semaphore;</code></pre>\n<pre><code class=\"C\">/* 某进程要是用资源时，使用wait()原语申请 */\nvoid wait (semaphore S) {\n    S.value--;\n    if (S.value &lt; 0) {\n        block(S.L);\n    }\n}</code></pre>\n<pre><code class=\"C\">/* 某进程使用完资源后，使用signal()原语释放资源 */\nvoid signal(semaphore S) {\n    S.value++;\n    if (S.value &lt;= 0) {\n        wakeup(S.L);\n    }\n}</code></pre>\n<h5 id=\"生产者消费者问题：进程互斥与进程同步\"><a href=\"#生产者消费者问题：进程互斥与进程同步\" class=\"headerlink\" title=\"生产者消费者问题：进程互斥与进程同步\"></a>生产者消费者问题：进程互斥与进程同步</h5><ul>\n<li>问题描述：<ul>\n<li>生产者、消费者共享一个初始为空、大小为n的缓冲区</li>\n<li>当缓冲区未满时，生产者可以生产产品并放入缓冲区，否则必须等待</li>\n<li>当缓冲区未空时，消费者可以从缓冲区中取走产品，否则必须等待</li>\n<li>缓冲区是临界资源，必须互斥访问</li>\n</ul>\n</li>\n</ul>\n<p>对于单生产者、单消费者问题：</p>\n<pre><code class=\"C\">semaphore mutex = 1;    //互斥信号量，互斥访问buffer\nsemaphore empty = n;    //同步信号量，表示buffer中的空闲位置\nsemaphore full = 0;     //同步信号量，表示buffer中的产品数\nproducer() {\n    while (1) {\n        produce a product;\n        P(empty);   //有空闲位置才会生产\n        P(mutex);\n        put the product to buffer;\n        V(mutex);\n        V(full);\n    }\n}\nconsumer() {\n    while (1) {\n        P(full);    //有产品才会消费\n        P(mutex);\n        take a product from buffer;\n        V(mutex);\n        V(empty);\n        consume the product;\n    }\n}</code></pre>\n<ul>\n<li>P、P和P、V不可颠倒，否则会引发死锁，V、V无所谓</li>\n<li>多生产者、多消费者问题类似，分析好相互之间的制约关系和对buffer的互斥关系</li>\n<li>生产者吸烟者问题：单生产者、多消费者问题，改变一下代码逻辑即可</li>\n</ul>\n<center>\n    <img src=\"./生产者吸烟者.png\" >\n</center>\n<center>图2 吸烟者轮流吸烟问题</center>\n\n<ul>\n<li>读者、写者问题：1个写者，n个读者；读写互斥；读者与读者不互斥；第一个开始读的负责加锁，最后一个读完的负责解锁。设置一个计数器count记录当前的读进程数。</li>\n</ul>\n<h3 id=\"管程\"><a href=\"#管程\" class=\"headerlink\" title=\"管程\"></a>管程</h3><ul>\n<li>管程的组成：<ul>\n<li>局部于管程的共享数据结构说明</li>\n<li>初始化共享数据的语句</li>\n<li>对共享数据进行操作的函数（过程）</li>\n<li>管程有一个名字</li>\n</ul>\n</li>\n<li>特征：<ul>\n<li>数据只能被这些过程访问</li>\n<li>进程对管程的访问是互斥的</li>\n<li>把同步、互斥等操作进行了封装，解决信号量机制麻烦易出错的问题</li>\n</ul>\n</li>\n</ul>\n<p>管程：</p>\n<pre><code class=\"C\">monitor ProducerConsumer \n    condition full, empty;      //同步条件量\n    int count = 0;              //缓冲区产品数\n    void insert(Item item) {    //生产者把产品放入缓冲区\n        if (count == N) {       //若缓冲区满，则生产者进程阻塞\n            wait(full);\n        }\n        count++;\n        insert_item(item);\n        if (count == 1) {       //如果之前是空，唤醒消费者进程\n            signal(empty);\n        }\n    }\n    Item remove() {             //消费者从缓冲区取走产品\n        if (count == 0) {       //若缓冲区空，阻塞消费者进程\n            wait(empty);\n        }\n        count--;\n        if (count == N - 1) {   //若之前缓冲区满，唤醒生产者进程\n            signal(full);\n        }\n        return remove_item();\n    }\nend monitor;</code></pre>\n<p>生产者进程：</p>\n<pre><code class=\"C\">producer() {\n    while (1) {\n        item = produce a product;\n        ProducerConsumer.insert(item);\n    }\n}</code></pre>\n<p>消费者进程：</p>\n<pre><code class=\"C\">consumer() {\n    while (1) {\n        item = ProducerConsumer.remove();\n        consume item;\n    }\n}</code></pre>\n<ul>\n<li>java中的 synchronized 关键字能实现类似于管程的机制</li>\n</ul>\n<h3 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h3><p>死锁：在并发环境下，各进程因竞争资源而造成相互循环等待，进而导致各进程都阻塞的现象。<br>饥饿：进程长期得不到资源，无法推进。</p>\n<ul>\n<li>银行家算法：避免死锁<ul>\n<li>检查此次申请是否超过了之前声明的最大需求数；</li>\n<li>检查此时系统剩余可用资源能否满足这次申请；</li>\n<li>试着分配，更改各数据结构；</li>\n<li>用安全性算法检查此次分配会不会导致系统进入“不安全状态”，如果会则阻塞该进程。</li>\n</ul>\n</li>\n<li>安全性算法：<ul>\n<li>检查当前剩余可用资源能否满足某个进程的最大需求；</li>\n<li>如果能，就把该进程加入安全序列；等进程结束，把该进程持有的资源全部回收。</li>\n<li>不断重复这个过程，看最终能否把所有进程都加入安全序列。</li>\n</ul>\n</li>\n</ul>\n<font color=#FF0000>\n\n<h3 id=\"操作系统之进程问题集锦\"><a href=\"#操作系统之进程问题集锦\" class=\"headerlink\" title=\"操作系统之进程问题集锦\"></a>操作系统之进程问题集锦</h3><ol>\n<li><p>进程和线程以及它们的区别？</p>\n<ul>\n<li>进程是对运行时程序的封装，是系统进行资源调度和分配的基本单位，实现操作系统的并发。</li>\n<li>线程是进程的子任务，是CPU调度的基本单位，用于保证程序的实时性，实现进程内部的并发。</li>\n<li>一个程序至少一个进程，一个进程至少一个线程，线程依赖于进程存在。</li>\n<li>进程拥有独立的内存单元，同一个进程的不同线程间共享该进程的内存单元。</li>\n</ul>\n</li>\n<li><p>进程间通信的几种方式？</p>\n</li>\n<li><p>线程同步的方式？</p>\n</li>\n<li><p>死锁？</p>\n</li>\n</ol>\n</font>\n\n<h2 id=\"操作系统之内存管理\"><a href=\"#操作系统之内存管理\" class=\"headerlink\" title=\"操作系统之内存管理\"></a>操作系统之内存管理</h2><ul>\n<li><p>内存分为系统区和用户区。</p>\n</li>\n<li><p>内存管理：</p>\n<ul>\n<li>内存空间的分配与回收</li>\n<li>虚拟内存技术从逻辑上对内存空间进行扩充</li>\n<li>实现地址转换：逻辑地址与物理地址的转换</li>\n<li>内存保护，保证各进程之间互不干扰</li>\n</ul>\n</li>\n<li><p>交换技术：当内存空间紧张时，系统将内存中某些进程暂时换出外存，并把外存中某些已具备条件的进程换入内存。</p>\n<ul>\n<li>进程在内存与磁盘间动态调度。</li>\n<li>被调出内存的进程PCB会保留在内存中，用于记录外存位置等信息。</li>\n<li>被换出的进程数据被存放在磁盘的“对换区”，储存空间连续分配，I/O速度比文件区快。</li>\n<li>被调出内存的进程处于挂起态suspend。下面是进程的七状态模型：</li>\n</ul>\n</li>\n</ul>\n<center>\n    <img src=\"./进程七状态模型.png\" >\n</center>\n<center>图3 进程的七状态模型</center>\n\n<ul>\n<li>内存的动态分区分配：不预先划分内存分区，而是在进程装入内存时，根据进程大小动态地建立分区，分区大小刚好满足进程需要。动态分区分配不会产生内部碎片，但有外部碎片。<ul>\n<li>内部碎片：分配给某进程的内存区域太大，有没被利用的部分。</li>\n<li>外部碎片：内存中的空闲分区由于空间太小而难以利用。</li>\n<li>外部碎片可以通过“紧凑技术”Compaction来进行合并，紧凑技术会把现有的进程的内存空间首尾相接，时间代价较高。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"分页存储\"><a href=\"#分页存储\" class=\"headerlink\" title=\"分页存储\"></a>分页存储</h3><ul>\n<li>基本分页存储管理：内存分为多个小空间的页框（内存块），把进程按页框大小分页，各个页面离散地分配到各个内存块中，这样有利于减小碎片。使用页表来保存页面地址。<ul>\n<li>地址变换机构实现目标内存单元的查找。</li>\n<li>在地址变换机构的基础上，加入“快表”，实质是一种缓存，加速地址变换。</li>\n<li>多级页表，避免单级页表占用内存中很多个连续的页框的问题。多级页表对原始页表进行分块，内存中只放入进程最近需要的页表。</li>\n</ul>\n</li>\n<li>请求分页存储管理：不一次把程序所有资源调入内存，需要使用时由操作系统调入内存，若内存不够则需要使用页面置换算法把当前不用的信息调出到外存。<h4 id=\"页面置换算法\"><a href=\"#页面置换算法\" class=\"headerlink\" title=\"页面置换算法\"></a>页面置换算法</h4></li>\n<li>最佳置换算法 OPT：每次选择淘汰的页面是以后永不使用或最长时间内不会被使用的。无法实现。</li>\n<li>先进先出置换算法 FIFO：每次淘汰的页面是最早进入内存的页面。使用队列实现。</li>\n<li>最近最久未使用置换算法 LRU：每次淘汰的页面是最近最久未使用的页面。在页表项中添加访问字段记录未访问的时间。</li>\n<li>时钟置换算法 CLOCK：每个页面设置一个访问位，把所有页面连成循环队列。当某页被访问时，访问位=1。当要淘汰一个页面时，检查循环队列的访问位，找第一个访问位=0的页换出；若遍历时该位是1，则置0。若第一遍遍历没找到=0的，再找第二遍，肯定能找到=0的。</li>\n<li>改进型的时钟置换算法：在CLOCK算法的基础上，还考虑页面有没有被修改过，避免被修改过的页面被换出时的I/O操作。<h4 id=\"页面分配策略\"><a href=\"#页面分配策略\" class=\"headerlink\" title=\"页面分配策略\"></a>页面分配策略</h4></li>\n<li>驻留集：请求分页存储管理中给进程分配的内存块的集合。</li>\n<li>策略：<ul>\n<li>固定分配、局部置换：程序运行前分配固定数量内存块，内存缺页时在自己进程内部换页。</li>\n<li>可变分配、全局置换：缺页时分配新物理块，可能来自空闲物理块或换出其他进程页面。</li>\n<li>可变分配、局部置换：应对频繁缺页的进程会多分配内存块，反之回收内存块。</li>\n</ul>\n</li>\n<li>颠簸（抖动）：页面频繁换入换出。主要原因是分给该进程的内存块不够。</li>\n</ul>\n<h3 id=\"分段存储\"><a href=\"#分段存储\" class=\"headerlink\" title=\"分段存储\"></a>分段存储</h3><ul>\n<li>定义：进程的地址空间，按照逻辑功能被划分为若干个段，每个段有自己的段名（方便用户编程），并且每个段从0开始编址</li>\n<li>内存分配规则：以段为单位进行内存分配，每个段在内存中占连续的地址空间，但各段之间可以不相邻。</li>\n<li>分段系统的逻辑地址：一个地址（假设32位，0~31）由高M位表示段号（比如16~31），低N位表示段内偏移（比如0~15）。段号的多少决定分段个数，段内偏移决定每个段长。</li>\n<li>分段存储的寻址：使用“段映射表”，简称段表。每个段对应段表中的一个项，记录该段在内存中的起始地址（基址）和段长。寻址过程：<ul>\n<li>拿到一个段的逻辑地址，在段表寄存器中查询该段号是否越界（段号与段表长度比较）。</li>\n<li>利用段表寄存器找到段表基址，再利用段号找到该段的基址。</li>\n<li>利用段表项判断段内偏移是否超过该段的长度，然后再计算物理地址。</li>\n</ul>\n</li>\n<li>分段、分页管理对比：<ul>\n<li>页是信息的物理单位。分页的目的是实现离散分配，提高内存的利用率。是系统行为，对用户不可见。</li>\n<li>段是信息的逻辑单位。分段的目的是满足用户需求，一个段通常包含一组逻辑模块的信息。分段对用户可见，用户编程需要显式地给出段名。</li>\n<li>页的大小固定；段的长度不固定，取决于用户编写的程序。</li>\n<li>分段按逻辑功能来分，更容易实现信息（指非临界资源）的共享和保护。</li>\n</ul>\n</li>\n<li>段页式管理：逻辑地址结构是二维的：段号、页号、页内地址。<ul>\n<li>分段对用户可见。</li>\n<li>分页由操作系统自己完成，对用户不可见。</li>\n<li>寻址：一个进程被分为N个段，先查段表，确定该段的页表位置，再查页表，确定存放的内存块号。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"虚拟内存\"><a href=\"#虚拟内存\" class=\"headerlink\" title=\"虚拟内存\"></a>虚拟内存</h3><p>在程序装入内存时，将即将用到的部分先转入内存，暂时不用的留在外存；当所访问的信息不在内存时，操作系统负责将所需信息调入内存；当内存空间不够时，操作系统将内存中暂时不用的信息调出到外存。</p>\n<h2 id=\"操作系统之文件管理\"><a href=\"#操作系统之文件管理\" class=\"headerlink\" title=\"操作系统之文件管理\"></a>操作系统之文件管理</h2><h3 id=\"文件的逻辑结构\"><a href=\"#文件的逻辑结构\" class=\"headerlink\" title=\"文件的逻辑结构\"></a>文件的逻辑结构</h3><ul>\n<li>文件按逻辑结构可分为：<ul>\n<li>无结构文件：由二进制流或字符流组成，无明显逻辑结构。如txt文件。</li>\n<li>有结构文件：由记录组成，分为定长记录、可变长记录。<ul>\n<li>顺序文件：若为定长记录，则可以快速检索和实现随机存取。</li>\n<li>索引文件：利用索引表。可以支持随机存取和快速检索。</li>\n<li>索引顺序文件</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>文件目录结构：<ul>\n<li>单级目录：不允许文件重名</li>\n<li>两级目录：不能对文件进行分类</li>\n<li>树形目录：不方便文件共享</li>\n<li>无环图目录<h3 id=\"文件的物理结构\"><a href=\"#文件的物理结构\" class=\"headerlink\" title=\"文件的物理结构\"></a>文件的物理结构</h3></li>\n</ul>\n</li>\n<li>文件分配方式：<ul>\n<li>连续分配：为文件分配连续磁盘块。</li>\n<li>链接分配<ul>\n<li>隐式链接：每个盘块存放指向下个盘块的指针。</li>\n<li>显式链接：用文件分配表FAT显式记录盘块的先后关系。</li>\n</ul>\n</li>\n<li>索引分配：允许文件离散地分配在各个磁盘块中，每个文件对应一张索引表，记录文件各逻辑块对应的物理块。索引表所在的磁盘块叫索引块，文件数据所在的磁盘块叫数据块。若索引表太大：<ul>\n<li>链接方案：索引表分块存放，依次链接。这样会使磁盘I/O次数过多。</li>\n<li>多层索引：类似于多级页表。这样索引对小文件不利。</li>\n<li>混合索引：小文件直接用顶级索引表进行一级索引，大文件可以多级索引。<h3 id=\"文件存储空间管理\"><a href=\"#文件存储空间管理\" class=\"headerlink\" title=\"文件存储空间管理\"></a>文件存储空间管理</h3></li>\n</ul>\n</li>\n</ul>\n</li>\n<li>磁盘在逻辑上分为文件卷，每个文件卷又课分为目录区、文件区<ul>\n<li>目录区：包含文件目录、空闲表、位示图、超级块等用于文件管理的数据</li>\n</ul>\n</li>\n<li>文件的存储空间管理方法：<ul>\n<li>空闲表法：空闲表记录连续空闲区的起始盘块号和盘块数，回收时把相邻的空闲区合并</li>\n<li>空闲链表法：采用链表连接各个空闲区间<ul>\n<li>空闲盘块链：以盘块为单位连接</li>\n<li>空闲盘区链：把相邻盘块看成盘区，把盘区相连</li>\n</ul>\n</li>\n<li>位示图法：用1个bit指示每个盘块是否空闲</li>\n<li>成组链接法：UNIX采用的方式，适用于大型文件系统。<ul>\n<li>设置一个“超级块”，系统启动后读入内存中，并保证其与外存中的“超级块”数据一致。</li>\n<li>每一组空闲区间链接起来，超级块中存放下一组空闲区间的盘块数，和该组盘块的盘块号。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>文件的基本操作<ul>\n<li>创建</li>\n<li>删除</li>\n<li>打开：打开文件表，每个进程有自己的打开文件表，系统有总的打开文件表</li>\n<li>关闭：删除进程打开文件表中的表项，然后系统的打开文件表中打开计数器减1</li>\n<li>读</li>\n<li>写</li>\n</ul>\n</li>\n<li>文件共享<ul>\n<li>硬链接：某用户删除文件时，只删除该用户的目录项，链接计数器-1，当删到链接计数器为0才真正删除该文件</li>\n<li>软链接：用link型文件记录该共享文件的存放路径，访问该文件时按路径查询多级目录，访问速度比硬链接慢，相当于Windows操作系统中的快捷方式</li>\n</ul>\n</li>\n<li>文件保护<ul>\n<li>口令保护</li>\n<li>加密保护</li>\n<li>访问控制：使用访问控制表ACL记录各个用户对文件的权限</li>\n</ul>\n</li>\n</ul>\n<center>\n    <img src=\"./文件的层次结构.png\" >\n</center>\n<center>图4 文件的层次结构</center>\n\n<ul>\n<li>57</li>\n</ul>\n</font>\n\n\n<h2 id=\"issues\"><a href=\"#issues\" class=\"headerlink\" title=\"issues\"></a>issues</h2><ol>\n<li>不同操作系统的CPU竞争策略与 <code>Thread.Sleep(0)</code>。</li>\n</ol>\n<ul>\n<li>Unix系统使用时间片算法：所有进程组成进程队列，操作系统按照顺序给进程分配CPU使用时间；如果时间片结束时进程还在运行，则CPU被剥夺并分配给另一个进程，然后该进程被移到队尾。</li>\n<li>Windows系统使用抢占式算法：操作系统根据各进程的优先级、节时间来确定程序运行顺序；在进程执行完毕或者主动挂起后，操作系统会重新计算总优先级。</li>\n<li><code>Thread.Sleep(0)</code>的作用就是触发操作系统立即进行一次CPU竞争。</li>\n</ul>\n"},{"title":"Java中是值传递","date":"2020-02-21T04:30:43.000Z","_content":"\n<center>\n\n# Java中只有值传递\n</center>\n今天看了一篇博客，对java中的参数传递有了进一步的认识。\n\n> 之前的错误认识：传递的参数如果是普通类型，就是值传递；如果是对象，就是引用传递。\n\n## 值传递与引用传递\n> 值传递：调用函数时将实参复制一份传递给函数，如果后续在函数中对这个参数进行了修改，不会影响被复制的实参。\n> 引用传递：调用函数时直接把实参的地址传递给函数，如果后续在函数中对这个参数进行了修改，将直接影响到被传递的实参。\n\n假设有一个对象：\n```java\nclass User {\n\n    public int id;\n\n    public String name;\n\n    public User(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n}\n```\n\n\n之前会迷惑人的例子，乍一看是引用传递：\n```java\npublic class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, \"yuyang\");\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user.name = \"zgxh\";\n        System.out.println(user);\n    }\n}\n```\n输出：\n> test.User@5594a1b5\ntest.User@5594a1b5\ntest.User@5594a1b5\n1zgxh\n\n然而并不是真的引用传递。下面的例子说明虽然传递了对象，但没改变被传递变量：\n```java\npublic class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, \"yuyang\");\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user = new User(2, \"zgxh\");\n        System.out.println(user);\n    }\n}\n```\n输出：\n> test.User@5594a1b5\ntest.User@6a5fc7f7\ntest.User@5594a1b5\n1yuyang\n\n**总结：Java中只有值传递，对于对象参数，值的内容是对象引用的地址。**","source":"_posts/Java中是值传递.md","raw":"---\ntitle: Java中是值传递\ndate: 2020-02-21 12:30:43\ntags: Java\ncategories: 开发\n---\n\n<center>\n\n# Java中只有值传递\n</center>\n今天看了一篇博客，对java中的参数传递有了进一步的认识。\n\n> 之前的错误认识：传递的参数如果是普通类型，就是值传递；如果是对象，就是引用传递。\n\n## 值传递与引用传递\n> 值传递：调用函数时将实参复制一份传递给函数，如果后续在函数中对这个参数进行了修改，不会影响被复制的实参。\n> 引用传递：调用函数时直接把实参的地址传递给函数，如果后续在函数中对这个参数进行了修改，将直接影响到被传递的实参。\n\n假设有一个对象：\n```java\nclass User {\n\n    public int id;\n\n    public String name;\n\n    public User(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n}\n```\n\n\n之前会迷惑人的例子，乍一看是引用传递：\n```java\npublic class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, \"yuyang\");\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user.name = \"zgxh\";\n        System.out.println(user);\n    }\n}\n```\n输出：\n> test.User@5594a1b5\ntest.User@5594a1b5\ntest.User@5594a1b5\n1zgxh\n\n然而并不是真的引用传递。下面的例子说明虽然传递了对象，但没改变被传递变量：\n```java\npublic class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, \"yuyang\");\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user = new User(2, \"zgxh\");\n        System.out.println(user);\n    }\n}\n```\n输出：\n> test.User@5594a1b5\ntest.User@6a5fc7f7\ntest.User@5594a1b5\n1yuyang\n\n**总结：Java中只有值传递，对于对象参数，值的内容是对象引用的地址。**","slug":"Java中是值传递","published":1,"updated":"2020-06-08T06:04:39.411Z","_id":"ck6vr4tl900000cymalysbnud","comments":1,"layout":"post","photos":[],"link":"","content":"<center>\n\n<h1 id=\"Java中只有值传递\"><a href=\"#Java中只有值传递\" class=\"headerlink\" title=\"Java中只有值传递\"></a>Java中只有值传递</h1></center>\n今天看了一篇博客，对java中的参数传递有了进一步的认识。\n\n<blockquote>\n<p>之前的错误认识：传递的参数如果是普通类型，就是值传递；如果是对象，就是引用传递。</p>\n</blockquote>\n<h2 id=\"值传递与引用传递\"><a href=\"#值传递与引用传递\" class=\"headerlink\" title=\"值传递与引用传递\"></a>值传递与引用传递</h2><blockquote>\n<p>值传递：调用函数时将实参复制一份传递给函数，如果后续在函数中对这个参数进行了修改，不会影响被复制的实参。<br>引用传递：调用函数时直接把实参的地址传递给函数，如果后续在函数中对这个参数进行了修改，将直接影响到被传递的实参。</p>\n</blockquote>\n<p>假设有一个对象：</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">User</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">int</span> id<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> String name<span class=\"token punctuation\">;</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token function\">User</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> id<span class=\"token punctuation\">,</span> String name<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>id <span class=\"token operator\">=</span> id<span class=\"token punctuation\">;</span>\n        <span class=\"token keyword\">this</span><span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> name<span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>之前会迷惑人的例子，乍一看是引用传递：</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Value</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        User mainUser <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">User</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"yuyang\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        Value value <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Value</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        value<span class=\"token punctuation\">.</span><span class=\"token function\">change</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">.</span>id <span class=\"token operator\">+</span> mainUser<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">change</span><span class=\"token punctuation\">(</span>User user<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        user<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> <span class=\"token string\">\"zgxh\"</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>user<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>输出：</p>\n<blockquote>\n<p>test.User@5594a1b5<br>test.User@5594a1b5<br>test.User@5594a1b5<br>1zgxh</p>\n</blockquote>\n<p>然而并不是真的引用传递。下面的例子说明虽然传递了对象，但没改变被传递变量：</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\"><span class=\"token keyword\">public</span> <span class=\"token keyword\">class</span> <span class=\"token class-name\">Value</span> <span class=\"token punctuation\">{</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">static</span> <span class=\"token keyword\">void</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span>String<span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span> args<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        User mainUser <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">User</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"yuyang\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        Value value <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">Value</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        value<span class=\"token punctuation\">.</span><span class=\"token function\">change</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>mainUser<span class=\"token punctuation\">.</span>id <span class=\"token operator\">+</span> mainUser<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token keyword\">public</span> <span class=\"token keyword\">void</span> <span class=\"token function\">change</span><span class=\"token punctuation\">(</span>User user<span class=\"token punctuation\">)</span> <span class=\"token punctuation\">{</span>\n        user <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">User</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"zgxh\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n        System<span class=\"token punctuation\">.</span>out<span class=\"token punctuation\">.</span><span class=\"token function\">println</span><span class=\"token punctuation\">(</span>user<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<p>输出：</p>\n<blockquote>\n<p>test.User@5594a1b5<br>test.User@6a5fc7f7<br>test.User@5594a1b5<br>1yuyang</p>\n</blockquote>\n<p><strong>总结：Java中只有值传递，对于对象参数，值的内容是对象引用的地址。</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<center>\n\n<h1 id=\"Java中只有值传递\"><a href=\"#Java中只有值传递\" class=\"headerlink\" title=\"Java中只有值传递\"></a>Java中只有值传递</h1></center>\n今天看了一篇博客，对java中的参数传递有了进一步的认识。\n\n<blockquote>\n<p>之前的错误认识：传递的参数如果是普通类型，就是值传递；如果是对象，就是引用传递。</p>\n</blockquote>\n<h2 id=\"值传递与引用传递\"><a href=\"#值传递与引用传递\" class=\"headerlink\" title=\"值传递与引用传递\"></a>值传递与引用传递</h2><blockquote>\n<p>值传递：调用函数时将实参复制一份传递给函数，如果后续在函数中对这个参数进行了修改，不会影响被复制的实参。<br>引用传递：调用函数时直接把实参的地址传递给函数，如果后续在函数中对这个参数进行了修改，将直接影响到被传递的实参。</p>\n</blockquote>\n<p>假设有一个对象：</p>\n<pre><code class=\"java\">class User {\n\n    public int id;\n\n    public String name;\n\n    public User(int id, String name) {\n        this.id = id;\n        this.name = name;\n    }\n}</code></pre>\n<p>之前会迷惑人的例子，乍一看是引用传递：</p>\n<pre><code class=\"java\">public class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, &quot;yuyang&quot;);\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user.name = &quot;zgxh&quot;;\n        System.out.println(user);\n    }\n}</code></pre>\n<p>输出：</p>\n<blockquote>\n<p>test.User@5594a1b5<br>test.User@5594a1b5<br>test.User@5594a1b5<br>1zgxh</p>\n</blockquote>\n<p>然而并不是真的引用传递。下面的例子说明虽然传递了对象，但没改变被传递变量：</p>\n<pre><code class=\"java\">public class Value {\n\n    public static void main(String[] args) {\n        User mainUser = new User(1, &quot;yuyang&quot;);\n        System.out.println(mainUser);\n        Value value = new Value();\n        value.change(mainUser);\n        System.out.println(mainUser);\n        System.out.println(mainUser.id + mainUser.name);\n    }\n\n    public void change(User user) {\n        user = new User(2, &quot;zgxh&quot;);\n        System.out.println(user);\n    }\n}</code></pre>\n<p>输出：</p>\n<blockquote>\n<p>test.User@5594a1b5<br>test.User@6a5fc7f7<br>test.User@5594a1b5<br>1yuyang</p>\n</blockquote>\n<p><strong>总结：Java中只有值传递，对于对象参数，值的内容是对象引用的地址。</strong></p>\n"},{"title":"计算机网络复习","date":"2020-03-02T03:29:33.000Z","_content":"\n# 计算机网络复习\n\n\nIP协议\n\n### 多HTTP请求问题\n\n1. 收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？\n\n答：\n前提条件：从HTTP/1.1开始，TCP连接是默认持续连接的，首部字段Connection:keep-alive，关闭时请求中写明Connection:close。\n\nHTTP/1.1支持了管道传输pipeline，即在同一个TCP连接内，客户端可以发起多个请求，但是服务器会按请求的顺序响应。如果前面的请求处理的慢，会造成队头阻塞，性能一般。\n\n如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP/2：\n\n- 如果能则使用 Multiplexing 在该连接上进行多路传输（不过未必所有挂在该域名的资源都使用同一个 TCP 连接获取，但 Multiplexing 很可能被用到）；\n- 如果不能使用 HTTP/2，或者使用不了HTTPS （因为HTTP/2都是在HTTPS上实现的），则即为HTTP/1.1，HTTP/1.1的每个TCP连接在同一时刻只处理一个请求，则浏览器会在一个Host上建立多个TCP连接，连接的最大数量取决于浏览器设置。这些TCP连接会在空闲的时候被浏览器用来发送新的请求，若所有的TCP连接都在占用，则只能等待。\n\n### HTTP/2 的改进\n\n- HTTP/2**基于HTTPS**，安全性有保障。\n- 头部压缩：如果同时发出多个请求，它们的头一样或者相似的话，HTTP/2协议会消除重复。\n    - **HPACK算法**：在Client和Server同时维护索引表，分为静态索引表与动态索引表，静态索引表来定义常用的HTTP Header，请求时只需发送索引位置即可。不在静态表中的值用动态索引表，通过huffman编码动态缓存到索引来压缩头部。动态表与静态表共通组成了索引表的索引空间。  https://www.jianshu.com/p/f44b930cfcac\n- 采用了**二进制形式**，头和数据题都是二进制，统称为帧 frame。二进制对计算机友好，增加了数据传输效率。\n\n<center>\n    <img src=\"./HTTP2二进制报文.jpg)\" >\n</center>\n\n- **多路复用**：HTTP/2同一个TCP连接中可并发多个请求或响应，不会产生队头阻塞。\n\n- **数据流**：HTTP/2同一个TCP连接中可并发多个请求或响应，每个数据包可能属于不同的请求或响应。\n    - 每个请求或响应对应的数据包，称一个数据流 Stream，每个Stream有独立编号，其中客户端发送的为奇数，服务器发送的为偶数。\n    - 客户端可以指定数据流的优先级。\n\n- **服务器推送**：Server主动向Client发送消息。\n\n#### HTTP/2 的缺陷\n\n多个HTTP请求复用一个TCP连接，下层的TCP协议不知道有多少个HTTP请求，一旦发生丢包，就会触发TCP的重传机制，阻塞所有HTTP请求。\n\n### HTTP/3 的改进\n\n把 TCP 改成了 UDP ，UDP 本身不管顺序、丢包，是不可靠传输。\n但基于 UDP 的 **QUIC协议** 实现类似 TCP 的可靠传输。\n- 当某个流丢包，只阻塞该流，其他流不受影响。\n- 使用了 TLS/1.3 和头部压缩算法 QPack\n- QUIC建立连接减少了交互次数。\n\n<center>\n    <img src=\"./HTTP1.1-HTTP3对比.jpg)\" >\n</center>\n\n<center>\n    <img src=\"./QUIC-HTTPS.jpg)\" >\n</center>\n\nQUIC是新协议，很多网络设备不支持，还在普及。\n\n\n","source":"_posts/计算机网络复习.md","raw":"---\ntitle: 计算机网络复习\ndate: 2020-03-02 11:29:33\ntags: 计算机网络\ncategories: 专业课\n---\n\n# 计算机网络复习\n\n\nIP协议\n\n### 多HTTP请求问题\n\n1. 收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？\n\n答：\n前提条件：从HTTP/1.1开始，TCP连接是默认持续连接的，首部字段Connection:keep-alive，关闭时请求中写明Connection:close。\n\nHTTP/1.1支持了管道传输pipeline，即在同一个TCP连接内，客户端可以发起多个请求，但是服务器会按请求的顺序响应。如果前面的请求处理的慢，会造成队头阻塞，性能一般。\n\n如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP/2：\n\n- 如果能则使用 Multiplexing 在该连接上进行多路传输（不过未必所有挂在该域名的资源都使用同一个 TCP 连接获取，但 Multiplexing 很可能被用到）；\n- 如果不能使用 HTTP/2，或者使用不了HTTPS （因为HTTP/2都是在HTTPS上实现的），则即为HTTP/1.1，HTTP/1.1的每个TCP连接在同一时刻只处理一个请求，则浏览器会在一个Host上建立多个TCP连接，连接的最大数量取决于浏览器设置。这些TCP连接会在空闲的时候被浏览器用来发送新的请求，若所有的TCP连接都在占用，则只能等待。\n\n### HTTP/2 的改进\n\n- HTTP/2**基于HTTPS**，安全性有保障。\n- 头部压缩：如果同时发出多个请求，它们的头一样或者相似的话，HTTP/2协议会消除重复。\n    - **HPACK算法**：在Client和Server同时维护索引表，分为静态索引表与动态索引表，静态索引表来定义常用的HTTP Header，请求时只需发送索引位置即可。不在静态表中的值用动态索引表，通过huffman编码动态缓存到索引来压缩头部。动态表与静态表共通组成了索引表的索引空间。  https://www.jianshu.com/p/f44b930cfcac\n- 采用了**二进制形式**，头和数据题都是二进制，统称为帧 frame。二进制对计算机友好，增加了数据传输效率。\n\n<center>\n    <img src=\"./HTTP2二进制报文.jpg)\" >\n</center>\n\n- **多路复用**：HTTP/2同一个TCP连接中可并发多个请求或响应，不会产生队头阻塞。\n\n- **数据流**：HTTP/2同一个TCP连接中可并发多个请求或响应，每个数据包可能属于不同的请求或响应。\n    - 每个请求或响应对应的数据包，称一个数据流 Stream，每个Stream有独立编号，其中客户端发送的为奇数，服务器发送的为偶数。\n    - 客户端可以指定数据流的优先级。\n\n- **服务器推送**：Server主动向Client发送消息。\n\n#### HTTP/2 的缺陷\n\n多个HTTP请求复用一个TCP连接，下层的TCP协议不知道有多少个HTTP请求，一旦发生丢包，就会触发TCP的重传机制，阻塞所有HTTP请求。\n\n### HTTP/3 的改进\n\n把 TCP 改成了 UDP ，UDP 本身不管顺序、丢包，是不可靠传输。\n但基于 UDP 的 **QUIC协议** 实现类似 TCP 的可靠传输。\n- 当某个流丢包，只阻塞该流，其他流不受影响。\n- 使用了 TLS/1.3 和头部压缩算法 QPack\n- QUIC建立连接减少了交互次数。\n\n<center>\n    <img src=\"./HTTP1.1-HTTP3对比.jpg)\" >\n</center>\n\n<center>\n    <img src=\"./QUIC-HTTPS.jpg)\" >\n</center>\n\nQUIC是新协议，很多网络设备不支持，还在普及。\n\n\n","slug":"计算机网络复习","published":1,"updated":"2020-06-08T06:05:06.505Z","_id":"ck79wtrez0000fcym2x2i00t7","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"计算机网络复习\"><a href=\"#计算机网络复习\" class=\"headerlink\" title=\"计算机网络复习\"></a>计算机网络复习</h1><p>IP协议</p>\n<h3 id=\"多HTTP请求问题\"><a href=\"#多HTTP请求问题\" class=\"headerlink\" title=\"多HTTP请求问题\"></a>多HTTP请求问题</h3><ol>\n<li>收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？</li>\n</ol>\n<p>答：<br>前提条件：从HTTP/1.1开始，TCP连接是默认持续连接的，首部字段Connection:keep-alive，关闭时请求中写明Connection:close。</p>\n<p>HTTP/1.1支持了管道传输pipeline，即在同一个TCP连接内，客户端可以发起多个请求，但是服务器会按请求的顺序响应。如果前面的请求处理的慢，会造成队头阻塞，性能一般。</p>\n<p>如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP/2：</p>\n<ul>\n<li>如果能则使用 Multiplexing 在该连接上进行多路传输（不过未必所有挂在该域名的资源都使用同一个 TCP 连接获取，但 Multiplexing 很可能被用到）；</li>\n<li>如果不能使用 HTTP/2，或者使用不了HTTPS （因为HTTP/2都是在HTTPS上实现的），则即为HTTP/1.1，HTTP/1.1的每个TCP连接在同一时刻只处理一个请求，则浏览器会在一个Host上建立多个TCP连接，连接的最大数量取决于浏览器设置。这些TCP连接会在空闲的时候被浏览器用来发送新的请求，若所有的TCP连接都在占用，则只能等待。</li>\n</ul>\n<h3 id=\"HTTP-2-的改进\"><a href=\"#HTTP-2-的改进\" class=\"headerlink\" title=\"HTTP/2 的改进\"></a>HTTP/2 的改进</h3><ul>\n<li>HTTP/2<strong>基于HTTPS</strong>，安全性有保障。</li>\n<li>头部压缩：如果同时发出多个请求，它们的头一样或者相似的话，HTTP/2协议会消除重复。<ul>\n<li><strong>HPACK算法</strong>：在Client和Server同时维护索引表，分为静态索引表与动态索引表，静态索引表来定义常用的HTTP Header，请求时只需发送索引位置即可。不在静态表中的值用动态索引表，通过huffman编码动态缓存到索引来压缩头部。动态表与静态表共通组成了索引表的索引空间。  <a href=\"https://www.jianshu.com/p/f44b930cfcac\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f44b930cfcac</a></li>\n</ul>\n</li>\n<li>采用了<strong>二进制形式</strong>，头和数据题都是二进制，统称为帧 frame。二进制对计算机友好，增加了数据传输效率。</li>\n</ul>\n<center>\n    <img src=\"./HTTP2二进制报文.jpg)\" >\n</center>\n\n<ul>\n<li><p><strong>多路复用</strong>：HTTP/2同一个TCP连接中可并发多个请求或响应，不会产生队头阻塞。</p>\n</li>\n<li><p><strong>数据流</strong>：HTTP/2同一个TCP连接中可并发多个请求或响应，每个数据包可能属于不同的请求或响应。</p>\n<ul>\n<li>每个请求或响应对应的数据包，称一个数据流 Stream，每个Stream有独立编号，其中客户端发送的为奇数，服务器发送的为偶数。</li>\n<li>客户端可以指定数据流的优先级。</li>\n</ul>\n</li>\n<li><p><strong>服务器推送</strong>：Server主动向Client发送消息。</p>\n</li>\n</ul>\n<h4 id=\"HTTP-2-的缺陷\"><a href=\"#HTTP-2-的缺陷\" class=\"headerlink\" title=\"HTTP/2 的缺陷\"></a>HTTP/2 的缺陷</h4><p>多个HTTP请求复用一个TCP连接，下层的TCP协议不知道有多少个HTTP请求，一旦发生丢包，就会触发TCP的重传机制，阻塞所有HTTP请求。</p>\n<h3 id=\"HTTP-3-的改进\"><a href=\"#HTTP-3-的改进\" class=\"headerlink\" title=\"HTTP/3 的改进\"></a>HTTP/3 的改进</h3><p>把 TCP 改成了 UDP ，UDP 本身不管顺序、丢包，是不可靠传输。<br>但基于 UDP 的 <strong>QUIC协议</strong> 实现类似 TCP 的可靠传输。</p>\n<ul>\n<li>当某个流丢包，只阻塞该流，其他流不受影响。</li>\n<li>使用了 TLS/1.3 和头部压缩算法 QPack</li>\n<li>QUIC建立连接减少了交互次数。</li>\n</ul>\n<center>\n    <img src=\"./HTTP1.1-HTTP3对比.jpg)\" >\n</center>\n\n<center>\n    <img src=\"./QUIC-HTTPS.jpg)\" >\n</center>\n\n<p>QUIC是新协议，很多网络设备不支持，还在普及。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"计算机网络复习\"><a href=\"#计算机网络复习\" class=\"headerlink\" title=\"计算机网络复习\"></a>计算机网络复习</h1><p>IP协议</p>\n<h3 id=\"多HTTP请求问题\"><a href=\"#多HTTP请求问题\" class=\"headerlink\" title=\"多HTTP请求问题\"></a>多HTTP请求问题</h3><ol>\n<li>收到的 HTML 如果包含几十个图片标签，这些图片是以什么方式、什么顺序、建立了多少连接、使用什么协议被下载下来的呢？</li>\n</ol>\n<p>答：<br>前提条件：从HTTP/1.1开始，TCP连接是默认持续连接的，首部字段Connection:keep-alive，关闭时请求中写明Connection:close。</p>\n<p>HTTP/1.1支持了管道传输pipeline，即在同一个TCP连接内，客户端可以发起多个请求，但是服务器会按请求的顺序响应。如果前面的请求处理的慢，会造成队头阻塞，性能一般。</p>\n<p>如果图片都是 HTTPS 连接并且在同一个域名下，那么浏览器在 SSL 握手之后会和服务器商量能不能用 HTTP/2：</p>\n<ul>\n<li>如果能则使用 Multiplexing 在该连接上进行多路传输（不过未必所有挂在该域名的资源都使用同一个 TCP 连接获取，但 Multiplexing 很可能被用到）；</li>\n<li>如果不能使用 HTTP/2，或者使用不了HTTPS （因为HTTP/2都是在HTTPS上实现的），则即为HTTP/1.1，HTTP/1.1的每个TCP连接在同一时刻只处理一个请求，则浏览器会在一个Host上建立多个TCP连接，连接的最大数量取决于浏览器设置。这些TCP连接会在空闲的时候被浏览器用来发送新的请求，若所有的TCP连接都在占用，则只能等待。</li>\n</ul>\n<h3 id=\"HTTP-2-的改进\"><a href=\"#HTTP-2-的改进\" class=\"headerlink\" title=\"HTTP/2 的改进\"></a>HTTP/2 的改进</h3><ul>\n<li>HTTP/2<strong>基于HTTPS</strong>，安全性有保障。</li>\n<li>头部压缩：如果同时发出多个请求，它们的头一样或者相似的话，HTTP/2协议会消除重复。<ul>\n<li><strong>HPACK算法</strong>：在Client和Server同时维护索引表，分为静态索引表与动态索引表，静态索引表来定义常用的HTTP Header，请求时只需发送索引位置即可。不在静态表中的值用动态索引表，通过huffman编码动态缓存到索引来压缩头部。动态表与静态表共通组成了索引表的索引空间。  <a href=\"https://www.jianshu.com/p/f44b930cfcac\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/f44b930cfcac</a></li>\n</ul>\n</li>\n<li>采用了<strong>二进制形式</strong>，头和数据题都是二进制，统称为帧 frame。二进制对计算机友好，增加了数据传输效率。</li>\n</ul>\n<center>\n    <img src=\"./HTTP2二进制报文.jpg)\" >\n</center>\n\n<ul>\n<li><p><strong>多路复用</strong>：HTTP/2同一个TCP连接中可并发多个请求或响应，不会产生队头阻塞。</p>\n</li>\n<li><p><strong>数据流</strong>：HTTP/2同一个TCP连接中可并发多个请求或响应，每个数据包可能属于不同的请求或响应。</p>\n<ul>\n<li>每个请求或响应对应的数据包，称一个数据流 Stream，每个Stream有独立编号，其中客户端发送的为奇数，服务器发送的为偶数。</li>\n<li>客户端可以指定数据流的优先级。</li>\n</ul>\n</li>\n<li><p><strong>服务器推送</strong>：Server主动向Client发送消息。</p>\n</li>\n</ul>\n<h4 id=\"HTTP-2-的缺陷\"><a href=\"#HTTP-2-的缺陷\" class=\"headerlink\" title=\"HTTP/2 的缺陷\"></a>HTTP/2 的缺陷</h4><p>多个HTTP请求复用一个TCP连接，下层的TCP协议不知道有多少个HTTP请求，一旦发生丢包，就会触发TCP的重传机制，阻塞所有HTTP请求。</p>\n<h3 id=\"HTTP-3-的改进\"><a href=\"#HTTP-3-的改进\" class=\"headerlink\" title=\"HTTP/3 的改进\"></a>HTTP/3 的改进</h3><p>把 TCP 改成了 UDP ，UDP 本身不管顺序、丢包，是不可靠传输。<br>但基于 UDP 的 <strong>QUIC协议</strong> 实现类似 TCP 的可靠传输。</p>\n<ul>\n<li>当某个流丢包，只阻塞该流，其他流不受影响。</li>\n<li>使用了 TLS/1.3 和头部压缩算法 QPack</li>\n<li>QUIC建立连接减少了交互次数。</li>\n</ul>\n<center>\n    <img src=\"./HTTP1.1-HTTP3对比.jpg)\" >\n</center>\n\n<center>\n    <img src=\"./QUIC-HTTPS.jpg)\" >\n</center>\n\n<p>QUIC是新协议，很多网络设备不支持，还在普及。</p>\n"},{"title":"《图解HTTP》读书笔记","date":"2020-03-06T14:19:11.000Z","_content":"\n# 第一章 Web基础\n\n- 客户端：通过发送请求来获取服务器资源的web浏览器等\n- HTTP：HyperText Transfer Protocol\n\n## TCP/IP\n\nTCP/IP协议族按层次分为：应用层、传输层、网络层、数据链路层\n- 应用层：决定了向用户提供应用服务时通信的活动。\n    - FTP(File Transfer protocol)、DNS服务(Domain Name System)、HTTP协议等\n- 传输层：提供处于网络连接中的两台计算机之间的数据传输。\n    - TCP协议(Transmission Control Protocol)、UDP协议(User Data Protocol)\n- 网络层：选择传输路线来处理数据包，数据包是网络传输的最小数据单位。\n    - IP协议(Internet Protocol)\n- 数据链路层：处理连接网络的硬件部分。\n\n## 与HTTP密切相关的协议\n\n### IP协议\n\n- 位于网络层，负责传输数据包。\n- 传输根据IP地址和MAC地址。\n- 使用ARP协议(Address Resolution Protocol)来解析地址：ARP协议可以通过IP地址反查出MAC地址。\n- 网络通信的中转机制称为 路由选择。\n\n### TCP协议\n\n- 提供可靠的字节流服务。\n    - 把大块数据分割成以报文段为单位的数据包\n    - 可以保证传输的准确可靠性\n- 三次握手：发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。\n\n### DNS服务\n\nDNS协议通过域名找IP地址，或者通过IP地址反查域名。\n\n## URI和URL\n\nURI：Uniform Resource Indentifier 统一资源标识符\nURI用字符串标识某一互联网资源，URL标识资源在互联网上所处的位置。\n- URL是URI的子集\n\n# 第二章 简单的HTTP协议\n\n- HTTP请求的报文包括：请求方法、请求URI、协议版本、可选的请求head字段、内容实体。\n- 响应报文包括：协议版本、状态码、状态码对应的原因短语、可选的相应head字段、实体主体。\n- HTTP协议是无状态协议，对发送过的请求或响应不做持久化处理。\n    - 为了实现状态保持，引入了Cookie技术。\n- HTTP/1.1支持的请求方法：\n    - GET\n    - POST\n    - PUT\n    - HEAD\n    - DELETE\n    - OPTIONS请求方法：查询指定URI支持的方法。\n    - TRACE:追踪路径\n    - CONNECT:用隧道协议连接代理\n\n## 持久连接\n\nHTTP Persistent Connections，只要任意一端没有明确提出断开连接，则保持TCP连接状态。\n\n- 减少了TCP连接重复建立和断开的额外开销。\n\n管线化 pipelining：并行发送HTTP请求。\n\n## Cookie\n\nCookie技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。\n\n- Cookie会根据Server端反馈的响应报文中的一个叫做Set-Cookie字段，通知Client端保存Cookie，当下次Client再往Server发送HTTP请求时，Client会自动在请求报文中加入Cookie值。\n- Server端收到Client发送的Cookie后，检查是哪个Client发送的连接请求，然后对比Server上的记录，得到之前的状态信息。\n\n# 第三章 HTTP报文\n\n## HTTP报文\n\nHTTP报文结构：\n- 报文首部\n- 空行 CR+LF， 回车并换行\n- 报文主体\n\n请求报文首部：\n- 请求行：请求方法 + URI + HTTP版本\n- 首部字段：请求首部、通用首部、实体首部\n- 其他：Cookie等\n\n响应报文首部：\n- 状态行：响应状态码 + 原因短语 + HTTP版本\n- 首部字段：响应首部、通用首部、实体首部\n- 其他：Cookie等\n\n<center>\n    <img src=\"./HTTP报文.jpg\" >\n</center>\n\n<center>\n    <img src=\"./HTTP报文2.jpg\" >\n</center>\n\n## 压缩编码传输\n\n报文主体和实体主体的差异：\n- 报文 message：HTTP通信中的基本单位，由 8 bit组字节流 组成，通过HTTP通信传输。\n- 实体 entity：传输中的有效载荷数据，包括实体首部和实体主体。\n- HTTP报文主体用于传输请求或响应的实体主体。通常二者相等，当编码后，实体主体内容变化，二者则产生差异。\n\n分块传输编码：在传输大数据时，把数据分块，让浏览器逐步显示页面。\n- 每个块用十六进制标记大小，最后一块用 0(CR+LF) 标记\n\n## 范围请求\n\n指定请求的范围，只获取部分资源。\n- 对于范围请求，响应会返回状态码 206 Partial Content\n- 对于多重范围的 范围请求，响应先在首部content-type标明multipart/byteranges，再返回报文。\n- HTTP首部的Content-Type对应Spring MVC中RequestMapping的consumes参数，表示HTTP请求中的媒体类型，二者需对应。\n\n## 内容协商\n\nClient与Server交涉响应资源内容，然后Server提供给Client最合适的资源形式。\n- 判断基准包括：语言、字符集、编码方式等。\n- 包括首部字段：Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Language\n- Accept字段对应Spring MVC中RequestMapping的produces参数，当Accept字段包含produces指定的返回内容类型时才可返回。\n\n协商类型：\n- 服务器驱动协商 Server-driven Negotiation：服务器自动参考请求首部\n- 客户端驱动协商 Client-driven Negotiation：用户自选浏览器选项，或者js脚本自动选择，如按os类型或web浏览器类型选择。\n- 透明协商 Transparent Negotiation：Server和Client各自进行内容协商。\n\n# 第四章 HTTP状态码\n\n正常：2XX\n错误：4XX，5XX\n\n<center>\n    <img src=\"./HTTP状态码.jpg\" >\n</center>\n\n## 常使用的14种状态码\n\n### 200 OK\n\n- 请求成功处理，内容正常返回。\n\n### 204 No Content\n\n- 请求成功处理，但响应报文不含实体主体，即没有资源返回。\n- 浏览器页面不更新。\n\n### 206 Partial Content\n\n- 客服端进行了范围请求，服务器成功执行了这部分GET请求。\n- 响应报文中包含Content-Range指定的范围内容。\n\n### 301 Moved Permanently\n\n- 永久性重定向。\n- 表示请求的资源已被分配了新的URI。\n\n### 302 Found\n\n- 临时性重定向。\n- 表示请求的资源被临时分配了新的URI，希望用户本次能用新的URI访问。\n\n### 303 See Other\n\n与302类似，不过303明确提示客户端应该用 GET 方法去另一URI获取资源。\n\n**当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。**\n\n### 304 Not Modified\n\n客户端发送了带条件的请求，服务器允许访问，但没找到符合条件的资源。\n- 虽然在3XX类别中，但与重定向无关。\n- 附带的条件指GET请求包含：If-Match, If-Modified-Since, If-None-Match, If-Range, If-Unmodiried-Since\n\n### 307 Temporary Redirect\n\n临时重定向，与302含义相同。\n- 307会遵守标准，不会把POST变成GET\n\n### 400 Bad Request\n\n表示请求报文中存在语法错误。\n\n### 401 Unauthorized\n\n表示发送的请求需要有认证信息。\n- HTTP认证、BASIC认证、DIGEST认证\n\n### 403 Forbidden\n\n请求的资源被服务器拒绝。\n- 原因：如没有访问权限等。\n\n### 404 Not Found\n\n表明服务器上无法找到请求的资源。\n\n### 500 Internet Server Error\n\n表示Server端在执行请求时发生了错误。\n\n### 503 Service Unavailable\n\n表示服务器暂时超负载，或正在进行停机维护，无法处理请求。\n\n# 第五章 Web服务器\n\n## 虚拟主机\n\n一台服务器搭建多个web站点。\n- 此时多个web站点域名由DNS解析后对应同一个IP，所以在发送HTTP请求时，须在Host首部完整指定主机名或URI。\n\n## 通信数据转发\n\n### 代理\n\n位于Server与Client之间，接收Client的请求转发给Server，同时接收Server的响应转发给Client。\n\n<center>\n    <img src=\"./代理.jpg\" >\n</center>\n\n- **缓存代理**：代理转发服务器响应时保存缓存，再次收到对相同资源的请求时直接从代理缓存返回响应。\n    - 缓存服务器是代理服务器的一种。\n    - 即使存在缓存，也会因为Client要求、缓存有效期等因素向源服务器确认资源有效性。若缓存过期则重新从源服务器获取资源。\n    - 另一种缓存是**客户端浏览器缓存**，若过期则重新请求资源。\n- **透明代理**：转发请求或响应时，不对报文加工处理。反之，非透明代理。\n\n### 网关\n\n网关是转发其他服务器通信数据的服务器。\n- 网关能使服务器提供非HTTP协议服务。\n- 利用网关能提高通信的安全性。（在Client与网关之间加密来确保连接安全）\n\n### 隧道\n\n隧道可按要求建立一条Client到Server的通信线路，并使用SSL等手段进行加密。\n- 确保Client与Server之间安全通信。\n\n# 第六章 HTTP首部\n\n## HTTP/1.1 首部字段 47种\n\n### 通用首部字段\n\n<center>\n    <img src=\"./通用首部字段.jpg\" >\n</center>\n\n#### Cache-Control\n\n用于控制缓存行为。\n\n<center>\n    <img src=\"./缓存请求指令.jpg\" >\n</center>\n\n<center>\n    <img src=\"./缓存响应指令.jpg\" >\n</center>\n\n#### Connection\n\n- 控制不再转发给代理的首部字段\n\n```java\nConnection: 不再转发的首部字段名\n```\n\n- 管理持久连接: HTTP/1.1默认连接为持久连接，当Server想断开连接时，则指定Connection字段为close。\n\n#### Date\n\n表明创建HTTP报文的日期和时间。\n\n#### Pragma\n\n为与HTTP/1.0兼容而保留。\n\n```java\nCache-Control: no-cache\nPragma: no-cache        // 兼容HTTP/1.1之前的版本\n```\n\n#### Upgrade\n\n检测HTTP协议或其他协议是否可用更高版本进行通信。\n\n#### Transfer-Encoding\n\n规定传输报文主体时采用的编码方式，HTTP/1.1的传输编码方式只对分块传输编码有效。\n\n```java\nUpgrade: TLS/1.0        // Upgrade字段仅限于Client与邻接服务器之间\nConnection: Upgrade     // 所以使用Upgrade时需要额外指定这句话\n```\n\n#### Via\n\n- 追踪报文的传输路径，每经过代理或网关，现在Via字段中附加该服务器信息，然后再转发\n- 避免请求回环的发生\n\n### 请求首部字段\n\n<center>\n    <img src=\"./请求首部字段.jpg\" >\n</center>\n\n#### Accept\n\n通知Server用户代理能够处理的媒体类型、及优先级。\n- 用q=xx来指定优先级权重。\n- 优先返回权重高的媒体类型。\n\n#### Accept-Charset\n\n通知服务器用户代理支持的字符集及字符集的相对优先顺序.\n\n#### Accept-Encoding\n\n用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。\n- 可一次性指定多种内容编码。\n\n#### Accept-Language\n\n用来告知服务器用户代理能够处理的自然语言集（指中文或英文等）.\n\n#### Authorization\n\n告知服务器，用户代理的认证信息。\n- 一般，想要通过Server认证的用户代理会在接收到服务器的401状态码响应后，把Authorization字段加入到请求中。\n\n#### Host\n\n告知服务器，请求的资源所处的互联网主机名和端口号。\n- 与虚拟主机的工作机制有关。\n\n#### If-Range\n\n若指定的If-Range字段值（ETag或时间）和请求资源的ETag值或时间相一致时，则作为范围请求处理。反之，返回全部资源。\n\n### 响应首部字段\n\n<center>\n    <img src=\"./响应首部字段.jpg\" >\n</center>\n\n#### Age\n\n告知Client，源服务器在多久前创建了响应。\n- 若创建该响应的服务器是缓存服务器，则Age值是指缓存后的响应再次发起认证到认证完成的时间。\n- 创建代理响应时必须加上首部字段Age。\n\n### 实体首部字段\n\n<center>\n    <img src=\"./实体首部字段.jpg\" >\n</center>\n\n#### Content-Location\n\n当返回资源与实际请求的对象内容不同时，Content-Location会注明报文主体返回资源对应的URI。\n\n#### Content-MD5\n\n是一串由MD5算法生成的值，目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。\n- 但其对内容的改变无从查证，也无法检测传输过程中的恶意篡改。\n\n## 其他高频首部字段\n\nCookie：请求首部字段。Client想获得HTTP状态管理支持时，就会在请求中包含从Server接收到的Cookie。\nSet-Cookie：响应首部字段。是服务器开始管理Client时，告知Client的Cookie信息。\n\n# 第七章 HTTPS\n\n**SSL： Secure Socket Layer， 安全套接层\nTLS： Transport Layer Security， 安全层传输协议**\n\nSSL是独立于HTTP的协议，是当今世界上应用最为广泛的网络安全技术。\n\n与SSL组合使用的HTTP称为**HTTPS （HTTP Secure，超文本安全传输协议）**。\nHTTP over SSL\n\nSSL提供了证书手段来确认服务器。证书由值得信任的第三方机构颁发，来证明服务器和客户端的身份。\n\n## HTTPS=HTTP+加密+认证+完整性保护\n\nHTTP直接和TCP通信。\nHTTPS则使用了SSL，HTTP先和SSL通信，SSL再和TCP通信。\n\n<center>\n    <img src=\"./HTTPS.jpg\" >\n</center>\n\n共享密钥加密：加密和解密使用同一个密钥。\n\nSSL采用了**公开密钥加密** （Public-Key cryptography），使用非对称密钥。\n- 私有密钥 private key\n- 公开密钥 public key\n- **发送密文方使用对方的公开密钥进行加密，对方收到密文后，用自己的私有密钥进行解密。**\n\n### HTTPS采用混合加密机制\n\n共享密钥加密 + 公开密钥加密\n\n<center>\n    <img src=\"./HTTPS混合加密机制.jpg\" >\n</center>\n\n使用**公开密钥证书**来确保公开密钥的正确性。\n\n## HTTPS通信步骤\n\n<center>\n    <img src=\"./HTTPS通信步骤.jpg\" >\n</center>\n\n1. Client发送Client Hello报文来开始SSL通信。（报文中包括Client支持的SSL版本、加密组件列表(加密算法、密钥长度等)）\n2. Server回复Server Hello报文。（内容同样包括SSL版本、**筛选的**加密组件）\n3. Server发送Certificate报文。（包含**公钥**，之后Client发送的报文会以该公钥进行加密）\n4. Server发送Server Hello Done报文，代表最初阶段的SSL第一次握手协商结束。\n5. Client发送Client Key Exchange报文。（包含Pre-master secret随机密码串）\n6. Client发送Change Cipher Spec报文，提示Server之后的通信采用Pre-master secret加密。\n7. Client发送Finished报文。（包含从连接开始的全部报文的整体校验值）\n8. Server发送Change Cipher Spec报文。\n9. Server发送Finished报文。\n10. 服务器与客户端Finished报文交换完毕，**SSL连接成功建立**。开始在SSL的保护下进行应用层协议通信，发送HTTP请求。\n11. 应用层协议通信，回复HTTP响应。\n12. HTTP通信结束时由客户端断开连接，通过发送close_notify报文。之后发送TCP FIN报文来关闭与TCP的通信。\n\n- 为了保护报文的完整性，在应用层发送数据时附加MAC （Message Authentication Code）的报文摘要来检测报文是否被篡改。\n\n<center>\n    <img src=\"./HTTPS通信细节.jpg\" >\n</center>\n\n## TLS和SSL\n\nHTTPS通信使用SSL和TLS两个协议。\n- TLS是以SSL 3.0为原型开发的协议，可与SSL统称为SSL。\n\n## HTTPS比HTTP慢2~100倍\n\n1. 通信慢，需要额外进行SSL通信，消耗网络资源大。\n2. HTTPS需要做服务器、客户端双方加密、解密，消耗CPU、内存等硬件资源。\n\n所以一般只在包含个人信息等敏感数据时，才进行HTTPS加密通信。\n\n# 第八章 认证机制\n\nHTTP/1.1使用的认证方式：\n- BASIC认证\n    - 采用Base64编码，解码不需要任何附加信息，安全性差。\n- DIGEST认证\n- SSL客户端认证\n    - 利用HTTPS的客户端证书进行认证客户端，客户端证书要钱\n    - 再利用密码来确定用户本人\n- FormBase认证（基于表单认证）\n    - 由Web应用各自实现，没有标准\n\n# 第九章 基于HTTP的功能追加协议\n\n## Ajax 技术\n\nAsynchronous JavaScript and XML， 异步JS与XML技术，从已加载完毕的Web页面上发起HTTP请求，只更新局部页面，但可能导致大量请求产生。\n\n## Comet 技术\n\n客户端发送内容更新请求时，Server先挂起响应，一旦Server有内容更新，直接主动给客户端返回响应，实现实时更新。\n- 但为了维持TCP连接会消耗更多资源。\n\n## SPDY 协议\n\n为了在协议级别消除HTTP的瓶颈。\n没有完全改写HTTP，而是在TCP/IP的应用层与传输层之间新加入会话层，控制数据流动；但还是采用HTTP进行通信连接。\n\n<center>\n    <img src=\"./SPDY.jpg\" >\n</center>\n\n- 通过单一TCP连接，可无限制处理多个HTTP请求。\n- 可给请求逐个分配优先级。\n- 压缩HTTP请求和响应的首部。\n- 支持服务器向客户端的推送。\n- 服务器可主动提示客户端请求所需的资源。\n\n## WebSocket：全双工通信标准\n\n- 支持Server到Client的推送。\n- 建立起WebSocket连接后，一直保持连接状态，通信时开销减少；WebSocket首部信息小，通信量也减少。\n- 在HTTP连接建立后，进行一次握手来实现WebSocket通信。\n\n```java\nUpgrade: websocket\nConnection: Upgrade\n```\n","source":"_posts/图解HTTP读书笔记.md","raw":"---\ntitle: 《图解HTTP》读书笔记\ndate: 2020-03-06 22:19:11\ntags: 计算机网络\ncategories: 专业课\n---\n\n# 第一章 Web基础\n\n- 客户端：通过发送请求来获取服务器资源的web浏览器等\n- HTTP：HyperText Transfer Protocol\n\n## TCP/IP\n\nTCP/IP协议族按层次分为：应用层、传输层、网络层、数据链路层\n- 应用层：决定了向用户提供应用服务时通信的活动。\n    - FTP(File Transfer protocol)、DNS服务(Domain Name System)、HTTP协议等\n- 传输层：提供处于网络连接中的两台计算机之间的数据传输。\n    - TCP协议(Transmission Control Protocol)、UDP协议(User Data Protocol)\n- 网络层：选择传输路线来处理数据包，数据包是网络传输的最小数据单位。\n    - IP协议(Internet Protocol)\n- 数据链路层：处理连接网络的硬件部分。\n\n## 与HTTP密切相关的协议\n\n### IP协议\n\n- 位于网络层，负责传输数据包。\n- 传输根据IP地址和MAC地址。\n- 使用ARP协议(Address Resolution Protocol)来解析地址：ARP协议可以通过IP地址反查出MAC地址。\n- 网络通信的中转机制称为 路由选择。\n\n### TCP协议\n\n- 提供可靠的字节流服务。\n    - 把大块数据分割成以报文段为单位的数据包\n    - 可以保证传输的准确可靠性\n- 三次握手：发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。\n\n### DNS服务\n\nDNS协议通过域名找IP地址，或者通过IP地址反查域名。\n\n## URI和URL\n\nURI：Uniform Resource Indentifier 统一资源标识符\nURI用字符串标识某一互联网资源，URL标识资源在互联网上所处的位置。\n- URL是URI的子集\n\n# 第二章 简单的HTTP协议\n\n- HTTP请求的报文包括：请求方法、请求URI、协议版本、可选的请求head字段、内容实体。\n- 响应报文包括：协议版本、状态码、状态码对应的原因短语、可选的相应head字段、实体主体。\n- HTTP协议是无状态协议，对发送过的请求或响应不做持久化处理。\n    - 为了实现状态保持，引入了Cookie技术。\n- HTTP/1.1支持的请求方法：\n    - GET\n    - POST\n    - PUT\n    - HEAD\n    - DELETE\n    - OPTIONS请求方法：查询指定URI支持的方法。\n    - TRACE:追踪路径\n    - CONNECT:用隧道协议连接代理\n\n## 持久连接\n\nHTTP Persistent Connections，只要任意一端没有明确提出断开连接，则保持TCP连接状态。\n\n- 减少了TCP连接重复建立和断开的额外开销。\n\n管线化 pipelining：并行发送HTTP请求。\n\n## Cookie\n\nCookie技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。\n\n- Cookie会根据Server端反馈的响应报文中的一个叫做Set-Cookie字段，通知Client端保存Cookie，当下次Client再往Server发送HTTP请求时，Client会自动在请求报文中加入Cookie值。\n- Server端收到Client发送的Cookie后，检查是哪个Client发送的连接请求，然后对比Server上的记录，得到之前的状态信息。\n\n# 第三章 HTTP报文\n\n## HTTP报文\n\nHTTP报文结构：\n- 报文首部\n- 空行 CR+LF， 回车并换行\n- 报文主体\n\n请求报文首部：\n- 请求行：请求方法 + URI + HTTP版本\n- 首部字段：请求首部、通用首部、实体首部\n- 其他：Cookie等\n\n响应报文首部：\n- 状态行：响应状态码 + 原因短语 + HTTP版本\n- 首部字段：响应首部、通用首部、实体首部\n- 其他：Cookie等\n\n<center>\n    <img src=\"./HTTP报文.jpg\" >\n</center>\n\n<center>\n    <img src=\"./HTTP报文2.jpg\" >\n</center>\n\n## 压缩编码传输\n\n报文主体和实体主体的差异：\n- 报文 message：HTTP通信中的基本单位，由 8 bit组字节流 组成，通过HTTP通信传输。\n- 实体 entity：传输中的有效载荷数据，包括实体首部和实体主体。\n- HTTP报文主体用于传输请求或响应的实体主体。通常二者相等，当编码后，实体主体内容变化，二者则产生差异。\n\n分块传输编码：在传输大数据时，把数据分块，让浏览器逐步显示页面。\n- 每个块用十六进制标记大小，最后一块用 0(CR+LF) 标记\n\n## 范围请求\n\n指定请求的范围，只获取部分资源。\n- 对于范围请求，响应会返回状态码 206 Partial Content\n- 对于多重范围的 范围请求，响应先在首部content-type标明multipart/byteranges，再返回报文。\n- HTTP首部的Content-Type对应Spring MVC中RequestMapping的consumes参数，表示HTTP请求中的媒体类型，二者需对应。\n\n## 内容协商\n\nClient与Server交涉响应资源内容，然后Server提供给Client最合适的资源形式。\n- 判断基准包括：语言、字符集、编码方式等。\n- 包括首部字段：Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Language\n- Accept字段对应Spring MVC中RequestMapping的produces参数，当Accept字段包含produces指定的返回内容类型时才可返回。\n\n协商类型：\n- 服务器驱动协商 Server-driven Negotiation：服务器自动参考请求首部\n- 客户端驱动协商 Client-driven Negotiation：用户自选浏览器选项，或者js脚本自动选择，如按os类型或web浏览器类型选择。\n- 透明协商 Transparent Negotiation：Server和Client各自进行内容协商。\n\n# 第四章 HTTP状态码\n\n正常：2XX\n错误：4XX，5XX\n\n<center>\n    <img src=\"./HTTP状态码.jpg\" >\n</center>\n\n## 常使用的14种状态码\n\n### 200 OK\n\n- 请求成功处理，内容正常返回。\n\n### 204 No Content\n\n- 请求成功处理，但响应报文不含实体主体，即没有资源返回。\n- 浏览器页面不更新。\n\n### 206 Partial Content\n\n- 客服端进行了范围请求，服务器成功执行了这部分GET请求。\n- 响应报文中包含Content-Range指定的范围内容。\n\n### 301 Moved Permanently\n\n- 永久性重定向。\n- 表示请求的资源已被分配了新的URI。\n\n### 302 Found\n\n- 临时性重定向。\n- 表示请求的资源被临时分配了新的URI，希望用户本次能用新的URI访问。\n\n### 303 See Other\n\n与302类似，不过303明确提示客户端应该用 GET 方法去另一URI获取资源。\n\n**当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。**\n\n### 304 Not Modified\n\n客户端发送了带条件的请求，服务器允许访问，但没找到符合条件的资源。\n- 虽然在3XX类别中，但与重定向无关。\n- 附带的条件指GET请求包含：If-Match, If-Modified-Since, If-None-Match, If-Range, If-Unmodiried-Since\n\n### 307 Temporary Redirect\n\n临时重定向，与302含义相同。\n- 307会遵守标准，不会把POST变成GET\n\n### 400 Bad Request\n\n表示请求报文中存在语法错误。\n\n### 401 Unauthorized\n\n表示发送的请求需要有认证信息。\n- HTTP认证、BASIC认证、DIGEST认证\n\n### 403 Forbidden\n\n请求的资源被服务器拒绝。\n- 原因：如没有访问权限等。\n\n### 404 Not Found\n\n表明服务器上无法找到请求的资源。\n\n### 500 Internet Server Error\n\n表示Server端在执行请求时发生了错误。\n\n### 503 Service Unavailable\n\n表示服务器暂时超负载，或正在进行停机维护，无法处理请求。\n\n# 第五章 Web服务器\n\n## 虚拟主机\n\n一台服务器搭建多个web站点。\n- 此时多个web站点域名由DNS解析后对应同一个IP，所以在发送HTTP请求时，须在Host首部完整指定主机名或URI。\n\n## 通信数据转发\n\n### 代理\n\n位于Server与Client之间，接收Client的请求转发给Server，同时接收Server的响应转发给Client。\n\n<center>\n    <img src=\"./代理.jpg\" >\n</center>\n\n- **缓存代理**：代理转发服务器响应时保存缓存，再次收到对相同资源的请求时直接从代理缓存返回响应。\n    - 缓存服务器是代理服务器的一种。\n    - 即使存在缓存，也会因为Client要求、缓存有效期等因素向源服务器确认资源有效性。若缓存过期则重新从源服务器获取资源。\n    - 另一种缓存是**客户端浏览器缓存**，若过期则重新请求资源。\n- **透明代理**：转发请求或响应时，不对报文加工处理。反之，非透明代理。\n\n### 网关\n\n网关是转发其他服务器通信数据的服务器。\n- 网关能使服务器提供非HTTP协议服务。\n- 利用网关能提高通信的安全性。（在Client与网关之间加密来确保连接安全）\n\n### 隧道\n\n隧道可按要求建立一条Client到Server的通信线路，并使用SSL等手段进行加密。\n- 确保Client与Server之间安全通信。\n\n# 第六章 HTTP首部\n\n## HTTP/1.1 首部字段 47种\n\n### 通用首部字段\n\n<center>\n    <img src=\"./通用首部字段.jpg\" >\n</center>\n\n#### Cache-Control\n\n用于控制缓存行为。\n\n<center>\n    <img src=\"./缓存请求指令.jpg\" >\n</center>\n\n<center>\n    <img src=\"./缓存响应指令.jpg\" >\n</center>\n\n#### Connection\n\n- 控制不再转发给代理的首部字段\n\n```java\nConnection: 不再转发的首部字段名\n```\n\n- 管理持久连接: HTTP/1.1默认连接为持久连接，当Server想断开连接时，则指定Connection字段为close。\n\n#### Date\n\n表明创建HTTP报文的日期和时间。\n\n#### Pragma\n\n为与HTTP/1.0兼容而保留。\n\n```java\nCache-Control: no-cache\nPragma: no-cache        // 兼容HTTP/1.1之前的版本\n```\n\n#### Upgrade\n\n检测HTTP协议或其他协议是否可用更高版本进行通信。\n\n#### Transfer-Encoding\n\n规定传输报文主体时采用的编码方式，HTTP/1.1的传输编码方式只对分块传输编码有效。\n\n```java\nUpgrade: TLS/1.0        // Upgrade字段仅限于Client与邻接服务器之间\nConnection: Upgrade     // 所以使用Upgrade时需要额外指定这句话\n```\n\n#### Via\n\n- 追踪报文的传输路径，每经过代理或网关，现在Via字段中附加该服务器信息，然后再转发\n- 避免请求回环的发生\n\n### 请求首部字段\n\n<center>\n    <img src=\"./请求首部字段.jpg\" >\n</center>\n\n#### Accept\n\n通知Server用户代理能够处理的媒体类型、及优先级。\n- 用q=xx来指定优先级权重。\n- 优先返回权重高的媒体类型。\n\n#### Accept-Charset\n\n通知服务器用户代理支持的字符集及字符集的相对优先顺序.\n\n#### Accept-Encoding\n\n用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。\n- 可一次性指定多种内容编码。\n\n#### Accept-Language\n\n用来告知服务器用户代理能够处理的自然语言集（指中文或英文等）.\n\n#### Authorization\n\n告知服务器，用户代理的认证信息。\n- 一般，想要通过Server认证的用户代理会在接收到服务器的401状态码响应后，把Authorization字段加入到请求中。\n\n#### Host\n\n告知服务器，请求的资源所处的互联网主机名和端口号。\n- 与虚拟主机的工作机制有关。\n\n#### If-Range\n\n若指定的If-Range字段值（ETag或时间）和请求资源的ETag值或时间相一致时，则作为范围请求处理。反之，返回全部资源。\n\n### 响应首部字段\n\n<center>\n    <img src=\"./响应首部字段.jpg\" >\n</center>\n\n#### Age\n\n告知Client，源服务器在多久前创建了响应。\n- 若创建该响应的服务器是缓存服务器，则Age值是指缓存后的响应再次发起认证到认证完成的时间。\n- 创建代理响应时必须加上首部字段Age。\n\n### 实体首部字段\n\n<center>\n    <img src=\"./实体首部字段.jpg\" >\n</center>\n\n#### Content-Location\n\n当返回资源与实际请求的对象内容不同时，Content-Location会注明报文主体返回资源对应的URI。\n\n#### Content-MD5\n\n是一串由MD5算法生成的值，目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。\n- 但其对内容的改变无从查证，也无法检测传输过程中的恶意篡改。\n\n## 其他高频首部字段\n\nCookie：请求首部字段。Client想获得HTTP状态管理支持时，就会在请求中包含从Server接收到的Cookie。\nSet-Cookie：响应首部字段。是服务器开始管理Client时，告知Client的Cookie信息。\n\n# 第七章 HTTPS\n\n**SSL： Secure Socket Layer， 安全套接层\nTLS： Transport Layer Security， 安全层传输协议**\n\nSSL是独立于HTTP的协议，是当今世界上应用最为广泛的网络安全技术。\n\n与SSL组合使用的HTTP称为**HTTPS （HTTP Secure，超文本安全传输协议）**。\nHTTP over SSL\n\nSSL提供了证书手段来确认服务器。证书由值得信任的第三方机构颁发，来证明服务器和客户端的身份。\n\n## HTTPS=HTTP+加密+认证+完整性保护\n\nHTTP直接和TCP通信。\nHTTPS则使用了SSL，HTTP先和SSL通信，SSL再和TCP通信。\n\n<center>\n    <img src=\"./HTTPS.jpg\" >\n</center>\n\n共享密钥加密：加密和解密使用同一个密钥。\n\nSSL采用了**公开密钥加密** （Public-Key cryptography），使用非对称密钥。\n- 私有密钥 private key\n- 公开密钥 public key\n- **发送密文方使用对方的公开密钥进行加密，对方收到密文后，用自己的私有密钥进行解密。**\n\n### HTTPS采用混合加密机制\n\n共享密钥加密 + 公开密钥加密\n\n<center>\n    <img src=\"./HTTPS混合加密机制.jpg\" >\n</center>\n\n使用**公开密钥证书**来确保公开密钥的正确性。\n\n## HTTPS通信步骤\n\n<center>\n    <img src=\"./HTTPS通信步骤.jpg\" >\n</center>\n\n1. Client发送Client Hello报文来开始SSL通信。（报文中包括Client支持的SSL版本、加密组件列表(加密算法、密钥长度等)）\n2. Server回复Server Hello报文。（内容同样包括SSL版本、**筛选的**加密组件）\n3. Server发送Certificate报文。（包含**公钥**，之后Client发送的报文会以该公钥进行加密）\n4. Server发送Server Hello Done报文，代表最初阶段的SSL第一次握手协商结束。\n5. Client发送Client Key Exchange报文。（包含Pre-master secret随机密码串）\n6. Client发送Change Cipher Spec报文，提示Server之后的通信采用Pre-master secret加密。\n7. Client发送Finished报文。（包含从连接开始的全部报文的整体校验值）\n8. Server发送Change Cipher Spec报文。\n9. Server发送Finished报文。\n10. 服务器与客户端Finished报文交换完毕，**SSL连接成功建立**。开始在SSL的保护下进行应用层协议通信，发送HTTP请求。\n11. 应用层协议通信，回复HTTP响应。\n12. HTTP通信结束时由客户端断开连接，通过发送close_notify报文。之后发送TCP FIN报文来关闭与TCP的通信。\n\n- 为了保护报文的完整性，在应用层发送数据时附加MAC （Message Authentication Code）的报文摘要来检测报文是否被篡改。\n\n<center>\n    <img src=\"./HTTPS通信细节.jpg\" >\n</center>\n\n## TLS和SSL\n\nHTTPS通信使用SSL和TLS两个协议。\n- TLS是以SSL 3.0为原型开发的协议，可与SSL统称为SSL。\n\n## HTTPS比HTTP慢2~100倍\n\n1. 通信慢，需要额外进行SSL通信，消耗网络资源大。\n2. HTTPS需要做服务器、客户端双方加密、解密，消耗CPU、内存等硬件资源。\n\n所以一般只在包含个人信息等敏感数据时，才进行HTTPS加密通信。\n\n# 第八章 认证机制\n\nHTTP/1.1使用的认证方式：\n- BASIC认证\n    - 采用Base64编码，解码不需要任何附加信息，安全性差。\n- DIGEST认证\n- SSL客户端认证\n    - 利用HTTPS的客户端证书进行认证客户端，客户端证书要钱\n    - 再利用密码来确定用户本人\n- FormBase认证（基于表单认证）\n    - 由Web应用各自实现，没有标准\n\n# 第九章 基于HTTP的功能追加协议\n\n## Ajax 技术\n\nAsynchronous JavaScript and XML， 异步JS与XML技术，从已加载完毕的Web页面上发起HTTP请求，只更新局部页面，但可能导致大量请求产生。\n\n## Comet 技术\n\n客户端发送内容更新请求时，Server先挂起响应，一旦Server有内容更新，直接主动给客户端返回响应，实现实时更新。\n- 但为了维持TCP连接会消耗更多资源。\n\n## SPDY 协议\n\n为了在协议级别消除HTTP的瓶颈。\n没有完全改写HTTP，而是在TCP/IP的应用层与传输层之间新加入会话层，控制数据流动；但还是采用HTTP进行通信连接。\n\n<center>\n    <img src=\"./SPDY.jpg\" >\n</center>\n\n- 通过单一TCP连接，可无限制处理多个HTTP请求。\n- 可给请求逐个分配优先级。\n- 压缩HTTP请求和响应的首部。\n- 支持服务器向客户端的推送。\n- 服务器可主动提示客户端请求所需的资源。\n\n## WebSocket：全双工通信标准\n\n- 支持Server到Client的推送。\n- 建立起WebSocket连接后，一直保持连接状态，通信时开销减少；WebSocket首部信息小，通信量也减少。\n- 在HTTP连接建立后，进行一次握手来实现WebSocket通信。\n\n```java\nUpgrade: websocket\nConnection: Upgrade\n```\n","slug":"图解HTTP读书笔记","published":1,"updated":"2020-06-08T06:05:02.170Z","_id":"ck7gch1d40000iwym03bb2esa","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"第一章-Web基础\"><a href=\"#第一章-Web基础\" class=\"headerlink\" title=\"第一章 Web基础\"></a>第一章 Web基础</h1><ul>\n<li>客户端：通过发送请求来获取服务器资源的web浏览器等</li>\n<li>HTTP：HyperText Transfer Protocol</li>\n</ul>\n<h2 id=\"TCP-IP\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h2><p>TCP/IP协议族按层次分为：应用层、传输层、网络层、数据链路层</p>\n<ul>\n<li>应用层：决定了向用户提供应用服务时通信的活动。<ul>\n<li>FTP(File Transfer protocol)、DNS服务(Domain Name System)、HTTP协议等</li>\n</ul>\n</li>\n<li>传输层：提供处于网络连接中的两台计算机之间的数据传输。<ul>\n<li>TCP协议(Transmission Control Protocol)、UDP协议(User Data Protocol)</li>\n</ul>\n</li>\n<li>网络层：选择传输路线来处理数据包，数据包是网络传输的最小数据单位。<ul>\n<li>IP协议(Internet Protocol)</li>\n</ul>\n</li>\n<li>数据链路层：处理连接网络的硬件部分。</li>\n</ul>\n<h2 id=\"与HTTP密切相关的协议\"><a href=\"#与HTTP密切相关的协议\" class=\"headerlink\" title=\"与HTTP密切相关的协议\"></a>与HTTP密切相关的协议</h2><h3 id=\"IP协议\"><a href=\"#IP协议\" class=\"headerlink\" title=\"IP协议\"></a>IP协议</h3><ul>\n<li>位于网络层，负责传输数据包。</li>\n<li>传输根据IP地址和MAC地址。</li>\n<li>使用ARP协议(Address Resolution Protocol)来解析地址：ARP协议可以通过IP地址反查出MAC地址。</li>\n<li>网络通信的中转机制称为 路由选择。</li>\n</ul>\n<h3 id=\"TCP协议\"><a href=\"#TCP协议\" class=\"headerlink\" title=\"TCP协议\"></a>TCP协议</h3><ul>\n<li>提供可靠的字节流服务。<ul>\n<li>把大块数据分割成以报文段为单位的数据包</li>\n<li>可以保证传输的准确可靠性</li>\n</ul>\n</li>\n<li>三次握手：发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。</li>\n</ul>\n<h3 id=\"DNS服务\"><a href=\"#DNS服务\" class=\"headerlink\" title=\"DNS服务\"></a>DNS服务</h3><p>DNS协议通过域名找IP地址，或者通过IP地址反查域名。</p>\n<h2 id=\"URI和URL\"><a href=\"#URI和URL\" class=\"headerlink\" title=\"URI和URL\"></a>URI和URL</h2><p>URI：Uniform Resource Indentifier 统一资源标识符<br>URI用字符串标识某一互联网资源，URL标识资源在互联网上所处的位置。</p>\n<ul>\n<li>URL是URI的子集</li>\n</ul>\n<h1 id=\"第二章-简单的HTTP协议\"><a href=\"#第二章-简单的HTTP协议\" class=\"headerlink\" title=\"第二章 简单的HTTP协议\"></a>第二章 简单的HTTP协议</h1><ul>\n<li>HTTP请求的报文包括：请求方法、请求URI、协议版本、可选的请求head字段、内容实体。</li>\n<li>响应报文包括：协议版本、状态码、状态码对应的原因短语、可选的相应head字段、实体主体。</li>\n<li>HTTP协议是无状态协议，对发送过的请求或响应不做持久化处理。<ul>\n<li>为了实现状态保持，引入了Cookie技术。</li>\n</ul>\n</li>\n<li>HTTP/1.1支持的请求方法：<ul>\n<li>GET</li>\n<li>POST</li>\n<li>PUT</li>\n<li>HEAD</li>\n<li>DELETE</li>\n<li>OPTIONS请求方法：查询指定URI支持的方法。</li>\n<li>TRACE:追踪路径</li>\n<li>CONNECT:用隧道协议连接代理</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"持久连接\"><a href=\"#持久连接\" class=\"headerlink\" title=\"持久连接\"></a>持久连接</h2><p>HTTP Persistent Connections，只要任意一端没有明确提出断开连接，则保持TCP连接状态。</p>\n<ul>\n<li>减少了TCP连接重复建立和断开的额外开销。</li>\n</ul>\n<p>管线化 pipelining：并行发送HTTP请求。</p>\n<h2 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h2><p>Cookie技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。</p>\n<ul>\n<li>Cookie会根据Server端反馈的响应报文中的一个叫做Set-Cookie字段，通知Client端保存Cookie，当下次Client再往Server发送HTTP请求时，Client会自动在请求报文中加入Cookie值。</li>\n<li>Server端收到Client发送的Cookie后，检查是哪个Client发送的连接请求，然后对比Server上的记录，得到之前的状态信息。</li>\n</ul>\n<h1 id=\"第三章-HTTP报文\"><a href=\"#第三章-HTTP报文\" class=\"headerlink\" title=\"第三章 HTTP报文\"></a>第三章 HTTP报文</h1><h2 id=\"HTTP报文\"><a href=\"#HTTP报文\" class=\"headerlink\" title=\"HTTP报文\"></a>HTTP报文</h2><p>HTTP报文结构：</p>\n<ul>\n<li>报文首部</li>\n<li>空行 CR+LF， 回车并换行</li>\n<li>报文主体</li>\n</ul>\n<p>请求报文首部：</p>\n<ul>\n<li>请求行：请求方法 + URI + HTTP版本</li>\n<li>首部字段：请求首部、通用首部、实体首部</li>\n<li>其他：Cookie等</li>\n</ul>\n<p>响应报文首部：</p>\n<ul>\n<li>状态行：响应状态码 + 原因短语 + HTTP版本</li>\n<li>首部字段：响应首部、通用首部、实体首部</li>\n<li>其他：Cookie等</li>\n</ul>\n<center>\n    <img src=\"./HTTP报文.jpg\" >\n</center>\n\n<center>\n    <img src=\"./HTTP报文2.jpg\" >\n</center>\n\n<h2 id=\"压缩编码传输\"><a href=\"#压缩编码传输\" class=\"headerlink\" title=\"压缩编码传输\"></a>压缩编码传输</h2><p>报文主体和实体主体的差异：</p>\n<ul>\n<li>报文 message：HTTP通信中的基本单位，由 8 bit组字节流 组成，通过HTTP通信传输。</li>\n<li>实体 entity：传输中的有效载荷数据，包括实体首部和实体主体。</li>\n<li>HTTP报文主体用于传输请求或响应的实体主体。通常二者相等，当编码后，实体主体内容变化，二者则产生差异。</li>\n</ul>\n<p>分块传输编码：在传输大数据时，把数据分块，让浏览器逐步显示页面。</p>\n<ul>\n<li>每个块用十六进制标记大小，最后一块用 0(CR+LF) 标记</li>\n</ul>\n<h2 id=\"范围请求\"><a href=\"#范围请求\" class=\"headerlink\" title=\"范围请求\"></a>范围请求</h2><p>指定请求的范围，只获取部分资源。</p>\n<ul>\n<li>对于范围请求，响应会返回状态码 206 Partial Content</li>\n<li>对于多重范围的 范围请求，响应先在首部content-type标明multipart/byteranges，再返回报文。</li>\n<li>HTTP首部的Content-Type对应Spring MVC中RequestMapping的consumes参数，表示HTTP请求中的媒体类型，二者需对应。</li>\n</ul>\n<h2 id=\"内容协商\"><a href=\"#内容协商\" class=\"headerlink\" title=\"内容协商\"></a>内容协商</h2><p>Client与Server交涉响应资源内容，然后Server提供给Client最合适的资源形式。</p>\n<ul>\n<li>判断基准包括：语言、字符集、编码方式等。</li>\n<li>包括首部字段：Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Language</li>\n<li>Accept字段对应Spring MVC中RequestMapping的produces参数，当Accept字段包含produces指定的返回内容类型时才可返回。</li>\n</ul>\n<p>协商类型：</p>\n<ul>\n<li>服务器驱动协商 Server-driven Negotiation：服务器自动参考请求首部</li>\n<li>客户端驱动协商 Client-driven Negotiation：用户自选浏览器选项，或者js脚本自动选择，如按os类型或web浏览器类型选择。</li>\n<li>透明协商 Transparent Negotiation：Server和Client各自进行内容协商。</li>\n</ul>\n<h1 id=\"第四章-HTTP状态码\"><a href=\"#第四章-HTTP状态码\" class=\"headerlink\" title=\"第四章 HTTP状态码\"></a>第四章 HTTP状态码</h1><p>正常：2XX<br>错误：4XX，5XX</p>\n<center>\n    <img src=\"./HTTP状态码.jpg\" >\n</center>\n\n<h2 id=\"常使用的14种状态码\"><a href=\"#常使用的14种状态码\" class=\"headerlink\" title=\"常使用的14种状态码\"></a>常使用的14种状态码</h2><h3 id=\"200-OK\"><a href=\"#200-OK\" class=\"headerlink\" title=\"200 OK\"></a>200 OK</h3><ul>\n<li>请求成功处理，内容正常返回。</li>\n</ul>\n<h3 id=\"204-No-Content\"><a href=\"#204-No-Content\" class=\"headerlink\" title=\"204 No Content\"></a>204 No Content</h3><ul>\n<li>请求成功处理，但响应报文不含实体主体，即没有资源返回。</li>\n<li>浏览器页面不更新。</li>\n</ul>\n<h3 id=\"206-Partial-Content\"><a href=\"#206-Partial-Content\" class=\"headerlink\" title=\"206 Partial Content\"></a>206 Partial Content</h3><ul>\n<li>客服端进行了范围请求，服务器成功执行了这部分GET请求。</li>\n<li>响应报文中包含Content-Range指定的范围内容。</li>\n</ul>\n<h3 id=\"301-Moved-Permanently\"><a href=\"#301-Moved-Permanently\" class=\"headerlink\" title=\"301 Moved Permanently\"></a>301 Moved Permanently</h3><ul>\n<li>永久性重定向。</li>\n<li>表示请求的资源已被分配了新的URI。</li>\n</ul>\n<h3 id=\"302-Found\"><a href=\"#302-Found\" class=\"headerlink\" title=\"302 Found\"></a>302 Found</h3><ul>\n<li>临时性重定向。</li>\n<li>表示请求的资源被临时分配了新的URI，希望用户本次能用新的URI访问。</li>\n</ul>\n<h3 id=\"303-See-Other\"><a href=\"#303-See-Other\" class=\"headerlink\" title=\"303 See Other\"></a>303 See Other</h3><p>与302类似，不过303明确提示客户端应该用 GET 方法去另一URI获取资源。</p>\n<p><strong>当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。</strong></p>\n<h3 id=\"304-Not-Modified\"><a href=\"#304-Not-Modified\" class=\"headerlink\" title=\"304 Not Modified\"></a>304 Not Modified</h3><p>客户端发送了带条件的请求，服务器允许访问，但没找到符合条件的资源。</p>\n<ul>\n<li>虽然在3XX类别中，但与重定向无关。</li>\n<li>附带的条件指GET请求包含：If-Match, If-Modified-Since, If-None-Match, If-Range, If-Unmodiried-Since</li>\n</ul>\n<h3 id=\"307-Temporary-Redirect\"><a href=\"#307-Temporary-Redirect\" class=\"headerlink\" title=\"307 Temporary Redirect\"></a>307 Temporary Redirect</h3><p>临时重定向，与302含义相同。</p>\n<ul>\n<li>307会遵守标准，不会把POST变成GET</li>\n</ul>\n<h3 id=\"400-Bad-Request\"><a href=\"#400-Bad-Request\" class=\"headerlink\" title=\"400 Bad Request\"></a>400 Bad Request</h3><p>表示请求报文中存在语法错误。</p>\n<h3 id=\"401-Unauthorized\"><a href=\"#401-Unauthorized\" class=\"headerlink\" title=\"401 Unauthorized\"></a>401 Unauthorized</h3><p>表示发送的请求需要有认证信息。</p>\n<ul>\n<li>HTTP认证、BASIC认证、DIGEST认证</li>\n</ul>\n<h3 id=\"403-Forbidden\"><a href=\"#403-Forbidden\" class=\"headerlink\" title=\"403 Forbidden\"></a>403 Forbidden</h3><p>请求的资源被服务器拒绝。</p>\n<ul>\n<li>原因：如没有访问权限等。</li>\n</ul>\n<h3 id=\"404-Not-Found\"><a href=\"#404-Not-Found\" class=\"headerlink\" title=\"404 Not Found\"></a>404 Not Found</h3><p>表明服务器上无法找到请求的资源。</p>\n<h3 id=\"500-Internet-Server-Error\"><a href=\"#500-Internet-Server-Error\" class=\"headerlink\" title=\"500 Internet Server Error\"></a>500 Internet Server Error</h3><p>表示Server端在执行请求时发生了错误。</p>\n<h3 id=\"503-Service-Unavailable\"><a href=\"#503-Service-Unavailable\" class=\"headerlink\" title=\"503 Service Unavailable\"></a>503 Service Unavailable</h3><p>表示服务器暂时超负载，或正在进行停机维护，无法处理请求。</p>\n<h1 id=\"第五章-Web服务器\"><a href=\"#第五章-Web服务器\" class=\"headerlink\" title=\"第五章 Web服务器\"></a>第五章 Web服务器</h1><h2 id=\"虚拟主机\"><a href=\"#虚拟主机\" class=\"headerlink\" title=\"虚拟主机\"></a>虚拟主机</h2><p>一台服务器搭建多个web站点。</p>\n<ul>\n<li>此时多个web站点域名由DNS解析后对应同一个IP，所以在发送HTTP请求时，须在Host首部完整指定主机名或URI。</li>\n</ul>\n<h2 id=\"通信数据转发\"><a href=\"#通信数据转发\" class=\"headerlink\" title=\"通信数据转发\"></a>通信数据转发</h2><h3 id=\"代理\"><a href=\"#代理\" class=\"headerlink\" title=\"代理\"></a>代理</h3><p>位于Server与Client之间，接收Client的请求转发给Server，同时接收Server的响应转发给Client。</p>\n<center>\n    <img src=\"./代理.jpg\" >\n</center>\n\n<ul>\n<li><strong>缓存代理</strong>：代理转发服务器响应时保存缓存，再次收到对相同资源的请求时直接从代理缓存返回响应。<ul>\n<li>缓存服务器是代理服务器的一种。</li>\n<li>即使存在缓存，也会因为Client要求、缓存有效期等因素向源服务器确认资源有效性。若缓存过期则重新从源服务器获取资源。</li>\n<li>另一种缓存是<strong>客户端浏览器缓存</strong>，若过期则重新请求资源。</li>\n</ul>\n</li>\n<li><strong>透明代理</strong>：转发请求或响应时，不对报文加工处理。反之，非透明代理。</li>\n</ul>\n<h3 id=\"网关\"><a href=\"#网关\" class=\"headerlink\" title=\"网关\"></a>网关</h3><p>网关是转发其他服务器通信数据的服务器。</p>\n<ul>\n<li>网关能使服务器提供非HTTP协议服务。</li>\n<li>利用网关能提高通信的安全性。（在Client与网关之间加密来确保连接安全）</li>\n</ul>\n<h3 id=\"隧道\"><a href=\"#隧道\" class=\"headerlink\" title=\"隧道\"></a>隧道</h3><p>隧道可按要求建立一条Client到Server的通信线路，并使用SSL等手段进行加密。</p>\n<ul>\n<li>确保Client与Server之间安全通信。</li>\n</ul>\n<h1 id=\"第六章-HTTP首部\"><a href=\"#第六章-HTTP首部\" class=\"headerlink\" title=\"第六章 HTTP首部\"></a>第六章 HTTP首部</h1><h2 id=\"HTTP-1-1-首部字段-47种\"><a href=\"#HTTP-1-1-首部字段-47种\" class=\"headerlink\" title=\"HTTP/1.1 首部字段 47种\"></a>HTTP/1.1 首部字段 47种</h2><h3 id=\"通用首部字段\"><a href=\"#通用首部字段\" class=\"headerlink\" title=\"通用首部字段\"></a>通用首部字段</h3><center>\n    <img src=\"./通用首部字段.jpg\" >\n</center>\n\n<h4 id=\"Cache-Control\"><a href=\"#Cache-Control\" class=\"headerlink\" title=\"Cache-Control\"></a>Cache-Control</h4><p>用于控制缓存行为。</p>\n<center>\n    <img src=\"./缓存请求指令.jpg\" >\n</center>\n\n<center>\n    <img src=\"./缓存响应指令.jpg\" >\n</center>\n\n<h4 id=\"Connection\"><a href=\"#Connection\" class=\"headerlink\" title=\"Connection\"></a>Connection</h4><ul>\n<li>控制不再转发给代理的首部字段</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Connection<span class=\"token operator\">:</span> 不再转发的首部字段名<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n<ul>\n<li>管理持久连接: HTTP/1.1默认连接为持久连接，当Server想断开连接时，则指定Connection字段为close。</li>\n</ul>\n<h4 id=\"Date\"><a href=\"#Date\" class=\"headerlink\" title=\"Date\"></a>Date</h4><p>表明创建HTTP报文的日期和时间。</p>\n<h4 id=\"Pragma\"><a href=\"#Pragma\" class=\"headerlink\" title=\"Pragma\"></a>Pragma</h4><p>为与HTTP/1.0兼容而保留。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Cache<span class=\"token operator\">-</span>Control<span class=\"token operator\">:</span> no<span class=\"token operator\">-</span>cache\nPragma<span class=\"token operator\">:</span> no<span class=\"token operator\">-</span>cache        <span class=\"token comment\" spellcheck=\"true\">// 兼容HTTP/1.1之前的版本</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"Upgrade\"><a href=\"#Upgrade\" class=\"headerlink\" title=\"Upgrade\"></a>Upgrade</h4><p>检测HTTP协议或其他协议是否可用更高版本进行通信。</p>\n<h4 id=\"Transfer-Encoding\"><a href=\"#Transfer-Encoding\" class=\"headerlink\" title=\"Transfer-Encoding\"></a>Transfer-Encoding</h4><p>规定传输报文主体时采用的编码方式，HTTP/1.1的传输编码方式只对分块传输编码有效。</p>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Upgrade<span class=\"token operator\">:</span> TLS<span class=\"token operator\">/</span><span class=\"token number\">1.0</span>        <span class=\"token comment\" spellcheck=\"true\">// Upgrade字段仅限于Client与邻接服务器之间</span>\nConnection<span class=\"token operator\">:</span> Upgrade     <span class=\"token comment\" spellcheck=\"true\">// 所以使用Upgrade时需要额外指定这句话</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n<h4 id=\"Via\"><a href=\"#Via\" class=\"headerlink\" title=\"Via\"></a>Via</h4><ul>\n<li>追踪报文的传输路径，每经过代理或网关，现在Via字段中附加该服务器信息，然后再转发</li>\n<li>避免请求回环的发生</li>\n</ul>\n<h3 id=\"请求首部字段\"><a href=\"#请求首部字段\" class=\"headerlink\" title=\"请求首部字段\"></a>请求首部字段</h3><center>\n    <img src=\"./请求首部字段.jpg\" >\n</center>\n\n<h4 id=\"Accept\"><a href=\"#Accept\" class=\"headerlink\" title=\"Accept\"></a>Accept</h4><p>通知Server用户代理能够处理的媒体类型、及优先级。</p>\n<ul>\n<li>用q=xx来指定优先级权重。</li>\n<li>优先返回权重高的媒体类型。</li>\n</ul>\n<h4 id=\"Accept-Charset\"><a href=\"#Accept-Charset\" class=\"headerlink\" title=\"Accept-Charset\"></a>Accept-Charset</h4><p>通知服务器用户代理支持的字符集及字符集的相对优先顺序.</p>\n<h4 id=\"Accept-Encoding\"><a href=\"#Accept-Encoding\" class=\"headerlink\" title=\"Accept-Encoding\"></a>Accept-Encoding</h4><p>用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。</p>\n<ul>\n<li>可一次性指定多种内容编码。</li>\n</ul>\n<h4 id=\"Accept-Language\"><a href=\"#Accept-Language\" class=\"headerlink\" title=\"Accept-Language\"></a>Accept-Language</h4><p>用来告知服务器用户代理能够处理的自然语言集（指中文或英文等）.</p>\n<h4 id=\"Authorization\"><a href=\"#Authorization\" class=\"headerlink\" title=\"Authorization\"></a>Authorization</h4><p>告知服务器，用户代理的认证信息。</p>\n<ul>\n<li>一般，想要通过Server认证的用户代理会在接收到服务器的401状态码响应后，把Authorization字段加入到请求中。</li>\n</ul>\n<h4 id=\"Host\"><a href=\"#Host\" class=\"headerlink\" title=\"Host\"></a>Host</h4><p>告知服务器，请求的资源所处的互联网主机名和端口号。</p>\n<ul>\n<li>与虚拟主机的工作机制有关。</li>\n</ul>\n<h4 id=\"If-Range\"><a href=\"#If-Range\" class=\"headerlink\" title=\"If-Range\"></a>If-Range</h4><p>若指定的If-Range字段值（ETag或时间）和请求资源的ETag值或时间相一致时，则作为范围请求处理。反之，返回全部资源。</p>\n<h3 id=\"响应首部字段\"><a href=\"#响应首部字段\" class=\"headerlink\" title=\"响应首部字段\"></a>响应首部字段</h3><center>\n    <img src=\"./响应首部字段.jpg\" >\n</center>\n\n<h4 id=\"Age\"><a href=\"#Age\" class=\"headerlink\" title=\"Age\"></a>Age</h4><p>告知Client，源服务器在多久前创建了响应。</p>\n<ul>\n<li>若创建该响应的服务器是缓存服务器，则Age值是指缓存后的响应再次发起认证到认证完成的时间。</li>\n<li>创建代理响应时必须加上首部字段Age。</li>\n</ul>\n<h3 id=\"实体首部字段\"><a href=\"#实体首部字段\" class=\"headerlink\" title=\"实体首部字段\"></a>实体首部字段</h3><center>\n    <img src=\"./实体首部字段.jpg\" >\n</center>\n\n<h4 id=\"Content-Location\"><a href=\"#Content-Location\" class=\"headerlink\" title=\"Content-Location\"></a>Content-Location</h4><p>当返回资源与实际请求的对象内容不同时，Content-Location会注明报文主体返回资源对应的URI。</p>\n<h4 id=\"Content-MD5\"><a href=\"#Content-MD5\" class=\"headerlink\" title=\"Content-MD5\"></a>Content-MD5</h4><p>是一串由MD5算法生成的值，目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。</p>\n<ul>\n<li>但其对内容的改变无从查证，也无法检测传输过程中的恶意篡改。</li>\n</ul>\n<h2 id=\"其他高频首部字段\"><a href=\"#其他高频首部字段\" class=\"headerlink\" title=\"其他高频首部字段\"></a>其他高频首部字段</h2><p>Cookie：请求首部字段。Client想获得HTTP状态管理支持时，就会在请求中包含从Server接收到的Cookie。<br>Set-Cookie：响应首部字段。是服务器开始管理Client时，告知Client的Cookie信息。</p>\n<h1 id=\"第七章-HTTPS\"><a href=\"#第七章-HTTPS\" class=\"headerlink\" title=\"第七章 HTTPS\"></a>第七章 HTTPS</h1><p><strong>SSL： Secure Socket Layer， 安全套接层<br>TLS： Transport Layer Security， 安全层传输协议</strong></p>\n<p>SSL是独立于HTTP的协议，是当今世界上应用最为广泛的网络安全技术。</p>\n<p>与SSL组合使用的HTTP称为<strong>HTTPS （HTTP Secure，超文本安全传输协议）</strong>。<br>HTTP over SSL</p>\n<p>SSL提供了证书手段来确认服务器。证书由值得信任的第三方机构颁发，来证明服务器和客户端的身份。</p>\n<h2 id=\"HTTPS-HTTP-加密-认证-完整性保护\"><a href=\"#HTTPS-HTTP-加密-认证-完整性保护\" class=\"headerlink\" title=\"HTTPS=HTTP+加密+认证+完整性保护\"></a>HTTPS=HTTP+加密+认证+完整性保护</h2><p>HTTP直接和TCP通信。<br>HTTPS则使用了SSL，HTTP先和SSL通信，SSL再和TCP通信。</p>\n<center>\n    <img src=\"./HTTPS.jpg\" >\n</center>\n\n<p>共享密钥加密：加密和解密使用同一个密钥。</p>\n<p>SSL采用了<strong>公开密钥加密</strong> （Public-Key cryptography），使用非对称密钥。</p>\n<ul>\n<li>私有密钥 private key</li>\n<li>公开密钥 public key</li>\n<li><strong>发送密文方使用对方的公开密钥进行加密，对方收到密文后，用自己的私有密钥进行解密。</strong></li>\n</ul>\n<h3 id=\"HTTPS采用混合加密机制\"><a href=\"#HTTPS采用混合加密机制\" class=\"headerlink\" title=\"HTTPS采用混合加密机制\"></a>HTTPS采用混合加密机制</h3><p>共享密钥加密 + 公开密钥加密</p>\n<center>\n    <img src=\"./HTTPS混合加密机制.jpg\" >\n</center>\n\n<p>使用<strong>公开密钥证书</strong>来确保公开密钥的正确性。</p>\n<h2 id=\"HTTPS通信步骤\"><a href=\"#HTTPS通信步骤\" class=\"headerlink\" title=\"HTTPS通信步骤\"></a>HTTPS通信步骤</h2><center>\n    <img src=\"./HTTPS通信步骤.jpg\" >\n</center>\n\n<ol>\n<li>Client发送Client Hello报文来开始SSL通信。（报文中包括Client支持的SSL版本、加密组件列表(加密算法、密钥长度等)）</li>\n<li>Server回复Server Hello报文。（内容同样包括SSL版本、<strong>筛选的</strong>加密组件）</li>\n<li>Server发送Certificate报文。（包含<strong>公钥</strong>，之后Client发送的报文会以该公钥进行加密）</li>\n<li>Server发送Server Hello Done报文，代表最初阶段的SSL第一次握手协商结束。</li>\n<li>Client发送Client Key Exchange报文。（包含Pre-master secret随机密码串）</li>\n<li>Client发送Change Cipher Spec报文，提示Server之后的通信采用Pre-master secret加密。</li>\n<li>Client发送Finished报文。（包含从连接开始的全部报文的整体校验值）</li>\n<li>Server发送Change Cipher Spec报文。</li>\n<li>Server发送Finished报文。</li>\n<li>服务器与客户端Finished报文交换完毕，<strong>SSL连接成功建立</strong>。开始在SSL的保护下进行应用层协议通信，发送HTTP请求。</li>\n<li>应用层协议通信，回复HTTP响应。</li>\n<li>HTTP通信结束时由客户端断开连接，通过发送close_notify报文。之后发送TCP FIN报文来关闭与TCP的通信。</li>\n</ol>\n<ul>\n<li>为了保护报文的完整性，在应用层发送数据时附加MAC （Message Authentication Code）的报文摘要来检测报文是否被篡改。</li>\n</ul>\n<center>\n    <img src=\"./HTTPS通信细节.jpg\" >\n</center>\n\n<h2 id=\"TLS和SSL\"><a href=\"#TLS和SSL\" class=\"headerlink\" title=\"TLS和SSL\"></a>TLS和SSL</h2><p>HTTPS通信使用SSL和TLS两个协议。</p>\n<ul>\n<li>TLS是以SSL 3.0为原型开发的协议，可与SSL统称为SSL。</li>\n</ul>\n<h2 id=\"HTTPS比HTTP慢2-100倍\"><a href=\"#HTTPS比HTTP慢2-100倍\" class=\"headerlink\" title=\"HTTPS比HTTP慢2~100倍\"></a>HTTPS比HTTP慢2~100倍</h2><ol>\n<li>通信慢，需要额外进行SSL通信，消耗网络资源大。</li>\n<li>HTTPS需要做服务器、客户端双方加密、解密，消耗CPU、内存等硬件资源。</li>\n</ol>\n<p>所以一般只在包含个人信息等敏感数据时，才进行HTTPS加密通信。</p>\n<h1 id=\"第八章-认证机制\"><a href=\"#第八章-认证机制\" class=\"headerlink\" title=\"第八章 认证机制\"></a>第八章 认证机制</h1><p>HTTP/1.1使用的认证方式：</p>\n<ul>\n<li>BASIC认证<ul>\n<li>采用Base64编码，解码不需要任何附加信息，安全性差。</li>\n</ul>\n</li>\n<li>DIGEST认证</li>\n<li>SSL客户端认证<ul>\n<li>利用HTTPS的客户端证书进行认证客户端，客户端证书要钱</li>\n<li>再利用密码来确定用户本人</li>\n</ul>\n</li>\n<li>FormBase认证（基于表单认证）<ul>\n<li>由Web应用各自实现，没有标准</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"第九章-基于HTTP的功能追加协议\"><a href=\"#第九章-基于HTTP的功能追加协议\" class=\"headerlink\" title=\"第九章 基于HTTP的功能追加协议\"></a>第九章 基于HTTP的功能追加协议</h1><h2 id=\"Ajax-技术\"><a href=\"#Ajax-技术\" class=\"headerlink\" title=\"Ajax 技术\"></a>Ajax 技术</h2><p>Asynchronous JavaScript and XML， 异步JS与XML技术，从已加载完毕的Web页面上发起HTTP请求，只更新局部页面，但可能导致大量请求产生。</p>\n<h2 id=\"Comet-技术\"><a href=\"#Comet-技术\" class=\"headerlink\" title=\"Comet 技术\"></a>Comet 技术</h2><p>客户端发送内容更新请求时，Server先挂起响应，一旦Server有内容更新，直接主动给客户端返回响应，实现实时更新。</p>\n<ul>\n<li>但为了维持TCP连接会消耗更多资源。</li>\n</ul>\n<h2 id=\"SPDY-协议\"><a href=\"#SPDY-协议\" class=\"headerlink\" title=\"SPDY 协议\"></a>SPDY 协议</h2><p>为了在协议级别消除HTTP的瓶颈。<br>没有完全改写HTTP，而是在TCP/IP的应用层与传输层之间新加入会话层，控制数据流动；但还是采用HTTP进行通信连接。</p>\n<center>\n    <img src=\"./SPDY.jpg\" >\n</center>\n\n<ul>\n<li>通过单一TCP连接，可无限制处理多个HTTP请求。</li>\n<li>可给请求逐个分配优先级。</li>\n<li>压缩HTTP请求和响应的首部。</li>\n<li>支持服务器向客户端的推送。</li>\n<li>服务器可主动提示客户端请求所需的资源。</li>\n</ul>\n<h2 id=\"WebSocket：全双工通信标准\"><a href=\"#WebSocket：全双工通信标准\" class=\"headerlink\" title=\"WebSocket：全双工通信标准\"></a>WebSocket：全双工通信标准</h2><ul>\n<li>支持Server到Client的推送。</li>\n<li>建立起WebSocket连接后，一直保持连接状态，通信时开销减少；WebSocket首部信息小，通信量也减少。</li>\n<li>在HTTP连接建立后，进行一次握手来实现WebSocket通信。</li>\n</ul>\n<pre class=\"line-numbers language-java\"><code class=\"language-java\">Upgrade<span class=\"token operator\">:</span> websocket\nConnection<span class=\"token operator\">:</span> Upgrade<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"第一章-Web基础\"><a href=\"#第一章-Web基础\" class=\"headerlink\" title=\"第一章 Web基础\"></a>第一章 Web基础</h1><ul>\n<li>客户端：通过发送请求来获取服务器资源的web浏览器等</li>\n<li>HTTP：HyperText Transfer Protocol</li>\n</ul>\n<h2 id=\"TCP-IP\"><a href=\"#TCP-IP\" class=\"headerlink\" title=\"TCP/IP\"></a>TCP/IP</h2><p>TCP/IP协议族按层次分为：应用层、传输层、网络层、数据链路层</p>\n<ul>\n<li>应用层：决定了向用户提供应用服务时通信的活动。<ul>\n<li>FTP(File Transfer protocol)、DNS服务(Domain Name System)、HTTP协议等</li>\n</ul>\n</li>\n<li>传输层：提供处于网络连接中的两台计算机之间的数据传输。<ul>\n<li>TCP协议(Transmission Control Protocol)、UDP协议(User Data Protocol)</li>\n</ul>\n</li>\n<li>网络层：选择传输路线来处理数据包，数据包是网络传输的最小数据单位。<ul>\n<li>IP协议(Internet Protocol)</li>\n</ul>\n</li>\n<li>数据链路层：处理连接网络的硬件部分。</li>\n</ul>\n<h2 id=\"与HTTP密切相关的协议\"><a href=\"#与HTTP密切相关的协议\" class=\"headerlink\" title=\"与HTTP密切相关的协议\"></a>与HTTP密切相关的协议</h2><h3 id=\"IP协议\"><a href=\"#IP协议\" class=\"headerlink\" title=\"IP协议\"></a>IP协议</h3><ul>\n<li>位于网络层，负责传输数据包。</li>\n<li>传输根据IP地址和MAC地址。</li>\n<li>使用ARP协议(Address Resolution Protocol)来解析地址：ARP协议可以通过IP地址反查出MAC地址。</li>\n<li>网络通信的中转机制称为 路由选择。</li>\n</ul>\n<h3 id=\"TCP协议\"><a href=\"#TCP协议\" class=\"headerlink\" title=\"TCP协议\"></a>TCP协议</h3><ul>\n<li>提供可靠的字节流服务。<ul>\n<li>把大块数据分割成以报文段为单位的数据包</li>\n<li>可以保证传输的准确可靠性</li>\n</ul>\n</li>\n<li>三次握手：发送端首先发送一个带 SYN 标志的数据包给对方。接收端收到后，回传一个带有 SYN/ACK 标志的数据包以示传达确认信息。最后，发送端再回传一个带 ACK 标志的数据包，代表“握手”结束。</li>\n</ul>\n<h3 id=\"DNS服务\"><a href=\"#DNS服务\" class=\"headerlink\" title=\"DNS服务\"></a>DNS服务</h3><p>DNS协议通过域名找IP地址，或者通过IP地址反查域名。</p>\n<h2 id=\"URI和URL\"><a href=\"#URI和URL\" class=\"headerlink\" title=\"URI和URL\"></a>URI和URL</h2><p>URI：Uniform Resource Indentifier 统一资源标识符<br>URI用字符串标识某一互联网资源，URL标识资源在互联网上所处的位置。</p>\n<ul>\n<li>URL是URI的子集</li>\n</ul>\n<h1 id=\"第二章-简单的HTTP协议\"><a href=\"#第二章-简单的HTTP协议\" class=\"headerlink\" title=\"第二章 简单的HTTP协议\"></a>第二章 简单的HTTP协议</h1><ul>\n<li>HTTP请求的报文包括：请求方法、请求URI、协议版本、可选的请求head字段、内容实体。</li>\n<li>响应报文包括：协议版本、状态码、状态码对应的原因短语、可选的相应head字段、实体主体。</li>\n<li>HTTP协议是无状态协议，对发送过的请求或响应不做持久化处理。<ul>\n<li>为了实现状态保持，引入了Cookie技术。</li>\n</ul>\n</li>\n<li>HTTP/1.1支持的请求方法：<ul>\n<li>GET</li>\n<li>POST</li>\n<li>PUT</li>\n<li>HEAD</li>\n<li>DELETE</li>\n<li>OPTIONS请求方法：查询指定URI支持的方法。</li>\n<li>TRACE:追踪路径</li>\n<li>CONNECT:用隧道协议连接代理</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"持久连接\"><a href=\"#持久连接\" class=\"headerlink\" title=\"持久连接\"></a>持久连接</h2><p>HTTP Persistent Connections，只要任意一端没有明确提出断开连接，则保持TCP连接状态。</p>\n<ul>\n<li>减少了TCP连接重复建立和断开的额外开销。</li>\n</ul>\n<p>管线化 pipelining：并行发送HTTP请求。</p>\n<h2 id=\"Cookie\"><a href=\"#Cookie\" class=\"headerlink\" title=\"Cookie\"></a>Cookie</h2><p>Cookie技术通过在请求和响应报文中写入Cookie信息来控制客户端的状态。</p>\n<ul>\n<li>Cookie会根据Server端反馈的响应报文中的一个叫做Set-Cookie字段，通知Client端保存Cookie，当下次Client再往Server发送HTTP请求时，Client会自动在请求报文中加入Cookie值。</li>\n<li>Server端收到Client发送的Cookie后，检查是哪个Client发送的连接请求，然后对比Server上的记录，得到之前的状态信息。</li>\n</ul>\n<h1 id=\"第三章-HTTP报文\"><a href=\"#第三章-HTTP报文\" class=\"headerlink\" title=\"第三章 HTTP报文\"></a>第三章 HTTP报文</h1><h2 id=\"HTTP报文\"><a href=\"#HTTP报文\" class=\"headerlink\" title=\"HTTP报文\"></a>HTTP报文</h2><p>HTTP报文结构：</p>\n<ul>\n<li>报文首部</li>\n<li>空行 CR+LF， 回车并换行</li>\n<li>报文主体</li>\n</ul>\n<p>请求报文首部：</p>\n<ul>\n<li>请求行：请求方法 + URI + HTTP版本</li>\n<li>首部字段：请求首部、通用首部、实体首部</li>\n<li>其他：Cookie等</li>\n</ul>\n<p>响应报文首部：</p>\n<ul>\n<li>状态行：响应状态码 + 原因短语 + HTTP版本</li>\n<li>首部字段：响应首部、通用首部、实体首部</li>\n<li>其他：Cookie等</li>\n</ul>\n<center>\n    <img src=\"./HTTP报文.jpg\" >\n</center>\n\n<center>\n    <img src=\"./HTTP报文2.jpg\" >\n</center>\n\n<h2 id=\"压缩编码传输\"><a href=\"#压缩编码传输\" class=\"headerlink\" title=\"压缩编码传输\"></a>压缩编码传输</h2><p>报文主体和实体主体的差异：</p>\n<ul>\n<li>报文 message：HTTP通信中的基本单位，由 8 bit组字节流 组成，通过HTTP通信传输。</li>\n<li>实体 entity：传输中的有效载荷数据，包括实体首部和实体主体。</li>\n<li>HTTP报文主体用于传输请求或响应的实体主体。通常二者相等，当编码后，实体主体内容变化，二者则产生差异。</li>\n</ul>\n<p>分块传输编码：在传输大数据时，把数据分块，让浏览器逐步显示页面。</p>\n<ul>\n<li>每个块用十六进制标记大小，最后一块用 0(CR+LF) 标记</li>\n</ul>\n<h2 id=\"范围请求\"><a href=\"#范围请求\" class=\"headerlink\" title=\"范围请求\"></a>范围请求</h2><p>指定请求的范围，只获取部分资源。</p>\n<ul>\n<li>对于范围请求，响应会返回状态码 206 Partial Content</li>\n<li>对于多重范围的 范围请求，响应先在首部content-type标明multipart/byteranges，再返回报文。</li>\n<li>HTTP首部的Content-Type对应Spring MVC中RequestMapping的consumes参数，表示HTTP请求中的媒体类型，二者需对应。</li>\n</ul>\n<h2 id=\"内容协商\"><a href=\"#内容协商\" class=\"headerlink\" title=\"内容协商\"></a>内容协商</h2><p>Client与Server交涉响应资源内容，然后Server提供给Client最合适的资源形式。</p>\n<ul>\n<li>判断基准包括：语言、字符集、编码方式等。</li>\n<li>包括首部字段：Accept, Accept-Charset, Accept-Encoding, Accept-Language, Content-Language</li>\n<li>Accept字段对应Spring MVC中RequestMapping的produces参数，当Accept字段包含produces指定的返回内容类型时才可返回。</li>\n</ul>\n<p>协商类型：</p>\n<ul>\n<li>服务器驱动协商 Server-driven Negotiation：服务器自动参考请求首部</li>\n<li>客户端驱动协商 Client-driven Negotiation：用户自选浏览器选项，或者js脚本自动选择，如按os类型或web浏览器类型选择。</li>\n<li>透明协商 Transparent Negotiation：Server和Client各自进行内容协商。</li>\n</ul>\n<h1 id=\"第四章-HTTP状态码\"><a href=\"#第四章-HTTP状态码\" class=\"headerlink\" title=\"第四章 HTTP状态码\"></a>第四章 HTTP状态码</h1><p>正常：2XX<br>错误：4XX，5XX</p>\n<center>\n    <img src=\"./HTTP状态码.jpg\" >\n</center>\n\n<h2 id=\"常使用的14种状态码\"><a href=\"#常使用的14种状态码\" class=\"headerlink\" title=\"常使用的14种状态码\"></a>常使用的14种状态码</h2><h3 id=\"200-OK\"><a href=\"#200-OK\" class=\"headerlink\" title=\"200 OK\"></a>200 OK</h3><ul>\n<li>请求成功处理，内容正常返回。</li>\n</ul>\n<h3 id=\"204-No-Content\"><a href=\"#204-No-Content\" class=\"headerlink\" title=\"204 No Content\"></a>204 No Content</h3><ul>\n<li>请求成功处理，但响应报文不含实体主体，即没有资源返回。</li>\n<li>浏览器页面不更新。</li>\n</ul>\n<h3 id=\"206-Partial-Content\"><a href=\"#206-Partial-Content\" class=\"headerlink\" title=\"206 Partial Content\"></a>206 Partial Content</h3><ul>\n<li>客服端进行了范围请求，服务器成功执行了这部分GET请求。</li>\n<li>响应报文中包含Content-Range指定的范围内容。</li>\n</ul>\n<h3 id=\"301-Moved-Permanently\"><a href=\"#301-Moved-Permanently\" class=\"headerlink\" title=\"301 Moved Permanently\"></a>301 Moved Permanently</h3><ul>\n<li>永久性重定向。</li>\n<li>表示请求的资源已被分配了新的URI。</li>\n</ul>\n<h3 id=\"302-Found\"><a href=\"#302-Found\" class=\"headerlink\" title=\"302 Found\"></a>302 Found</h3><ul>\n<li>临时性重定向。</li>\n<li>表示请求的资源被临时分配了新的URI，希望用户本次能用新的URI访问。</li>\n</ul>\n<h3 id=\"303-See-Other\"><a href=\"#303-See-Other\" class=\"headerlink\" title=\"303 See Other\"></a>303 See Other</h3><p>与302类似，不过303明确提示客户端应该用 GET 方法去另一URI获取资源。</p>\n<p><strong>当 301、302、303 响应状态码返回时，几乎所有的浏览器都会把POST 改成 GET，并删除请求报文内的主体，之后请求会自动再次发送。</strong></p>\n<h3 id=\"304-Not-Modified\"><a href=\"#304-Not-Modified\" class=\"headerlink\" title=\"304 Not Modified\"></a>304 Not Modified</h3><p>客户端发送了带条件的请求，服务器允许访问，但没找到符合条件的资源。</p>\n<ul>\n<li>虽然在3XX类别中，但与重定向无关。</li>\n<li>附带的条件指GET请求包含：If-Match, If-Modified-Since, If-None-Match, If-Range, If-Unmodiried-Since</li>\n</ul>\n<h3 id=\"307-Temporary-Redirect\"><a href=\"#307-Temporary-Redirect\" class=\"headerlink\" title=\"307 Temporary Redirect\"></a>307 Temporary Redirect</h3><p>临时重定向，与302含义相同。</p>\n<ul>\n<li>307会遵守标准，不会把POST变成GET</li>\n</ul>\n<h3 id=\"400-Bad-Request\"><a href=\"#400-Bad-Request\" class=\"headerlink\" title=\"400 Bad Request\"></a>400 Bad Request</h3><p>表示请求报文中存在语法错误。</p>\n<h3 id=\"401-Unauthorized\"><a href=\"#401-Unauthorized\" class=\"headerlink\" title=\"401 Unauthorized\"></a>401 Unauthorized</h3><p>表示发送的请求需要有认证信息。</p>\n<ul>\n<li>HTTP认证、BASIC认证、DIGEST认证</li>\n</ul>\n<h3 id=\"403-Forbidden\"><a href=\"#403-Forbidden\" class=\"headerlink\" title=\"403 Forbidden\"></a>403 Forbidden</h3><p>请求的资源被服务器拒绝。</p>\n<ul>\n<li>原因：如没有访问权限等。</li>\n</ul>\n<h3 id=\"404-Not-Found\"><a href=\"#404-Not-Found\" class=\"headerlink\" title=\"404 Not Found\"></a>404 Not Found</h3><p>表明服务器上无法找到请求的资源。</p>\n<h3 id=\"500-Internet-Server-Error\"><a href=\"#500-Internet-Server-Error\" class=\"headerlink\" title=\"500 Internet Server Error\"></a>500 Internet Server Error</h3><p>表示Server端在执行请求时发生了错误。</p>\n<h3 id=\"503-Service-Unavailable\"><a href=\"#503-Service-Unavailable\" class=\"headerlink\" title=\"503 Service Unavailable\"></a>503 Service Unavailable</h3><p>表示服务器暂时超负载，或正在进行停机维护，无法处理请求。</p>\n<h1 id=\"第五章-Web服务器\"><a href=\"#第五章-Web服务器\" class=\"headerlink\" title=\"第五章 Web服务器\"></a>第五章 Web服务器</h1><h2 id=\"虚拟主机\"><a href=\"#虚拟主机\" class=\"headerlink\" title=\"虚拟主机\"></a>虚拟主机</h2><p>一台服务器搭建多个web站点。</p>\n<ul>\n<li>此时多个web站点域名由DNS解析后对应同一个IP，所以在发送HTTP请求时，须在Host首部完整指定主机名或URI。</li>\n</ul>\n<h2 id=\"通信数据转发\"><a href=\"#通信数据转发\" class=\"headerlink\" title=\"通信数据转发\"></a>通信数据转发</h2><h3 id=\"代理\"><a href=\"#代理\" class=\"headerlink\" title=\"代理\"></a>代理</h3><p>位于Server与Client之间，接收Client的请求转发给Server，同时接收Server的响应转发给Client。</p>\n<center>\n    <img src=\"./代理.jpg\" >\n</center>\n\n<ul>\n<li><strong>缓存代理</strong>：代理转发服务器响应时保存缓存，再次收到对相同资源的请求时直接从代理缓存返回响应。<ul>\n<li>缓存服务器是代理服务器的一种。</li>\n<li>即使存在缓存，也会因为Client要求、缓存有效期等因素向源服务器确认资源有效性。若缓存过期则重新从源服务器获取资源。</li>\n<li>另一种缓存是<strong>客户端浏览器缓存</strong>，若过期则重新请求资源。</li>\n</ul>\n</li>\n<li><strong>透明代理</strong>：转发请求或响应时，不对报文加工处理。反之，非透明代理。</li>\n</ul>\n<h3 id=\"网关\"><a href=\"#网关\" class=\"headerlink\" title=\"网关\"></a>网关</h3><p>网关是转发其他服务器通信数据的服务器。</p>\n<ul>\n<li>网关能使服务器提供非HTTP协议服务。</li>\n<li>利用网关能提高通信的安全性。（在Client与网关之间加密来确保连接安全）</li>\n</ul>\n<h3 id=\"隧道\"><a href=\"#隧道\" class=\"headerlink\" title=\"隧道\"></a>隧道</h3><p>隧道可按要求建立一条Client到Server的通信线路，并使用SSL等手段进行加密。</p>\n<ul>\n<li>确保Client与Server之间安全通信。</li>\n</ul>\n<h1 id=\"第六章-HTTP首部\"><a href=\"#第六章-HTTP首部\" class=\"headerlink\" title=\"第六章 HTTP首部\"></a>第六章 HTTP首部</h1><h2 id=\"HTTP-1-1-首部字段-47种\"><a href=\"#HTTP-1-1-首部字段-47种\" class=\"headerlink\" title=\"HTTP/1.1 首部字段 47种\"></a>HTTP/1.1 首部字段 47种</h2><h3 id=\"通用首部字段\"><a href=\"#通用首部字段\" class=\"headerlink\" title=\"通用首部字段\"></a>通用首部字段</h3><center>\n    <img src=\"./通用首部字段.jpg\" >\n</center>\n\n<h4 id=\"Cache-Control\"><a href=\"#Cache-Control\" class=\"headerlink\" title=\"Cache-Control\"></a>Cache-Control</h4><p>用于控制缓存行为。</p>\n<center>\n    <img src=\"./缓存请求指令.jpg\" >\n</center>\n\n<center>\n    <img src=\"./缓存响应指令.jpg\" >\n</center>\n\n<h4 id=\"Connection\"><a href=\"#Connection\" class=\"headerlink\" title=\"Connection\"></a>Connection</h4><ul>\n<li>控制不再转发给代理的首部字段</li>\n</ul>\n<pre><code class=\"java\">Connection: 不再转发的首部字段名</code></pre>\n<ul>\n<li>管理持久连接: HTTP/1.1默认连接为持久连接，当Server想断开连接时，则指定Connection字段为close。</li>\n</ul>\n<h4 id=\"Date\"><a href=\"#Date\" class=\"headerlink\" title=\"Date\"></a>Date</h4><p>表明创建HTTP报文的日期和时间。</p>\n<h4 id=\"Pragma\"><a href=\"#Pragma\" class=\"headerlink\" title=\"Pragma\"></a>Pragma</h4><p>为与HTTP/1.0兼容而保留。</p>\n<pre><code class=\"java\">Cache-Control: no-cache\nPragma: no-cache        // 兼容HTTP/1.1之前的版本</code></pre>\n<h4 id=\"Upgrade\"><a href=\"#Upgrade\" class=\"headerlink\" title=\"Upgrade\"></a>Upgrade</h4><p>检测HTTP协议或其他协议是否可用更高版本进行通信。</p>\n<h4 id=\"Transfer-Encoding\"><a href=\"#Transfer-Encoding\" class=\"headerlink\" title=\"Transfer-Encoding\"></a>Transfer-Encoding</h4><p>规定传输报文主体时采用的编码方式，HTTP/1.1的传输编码方式只对分块传输编码有效。</p>\n<pre><code class=\"java\">Upgrade: TLS/1.0        // Upgrade字段仅限于Client与邻接服务器之间\nConnection: Upgrade     // 所以使用Upgrade时需要额外指定这句话</code></pre>\n<h4 id=\"Via\"><a href=\"#Via\" class=\"headerlink\" title=\"Via\"></a>Via</h4><ul>\n<li>追踪报文的传输路径，每经过代理或网关，现在Via字段中附加该服务器信息，然后再转发</li>\n<li>避免请求回环的发生</li>\n</ul>\n<h3 id=\"请求首部字段\"><a href=\"#请求首部字段\" class=\"headerlink\" title=\"请求首部字段\"></a>请求首部字段</h3><center>\n    <img src=\"./请求首部字段.jpg\" >\n</center>\n\n<h4 id=\"Accept\"><a href=\"#Accept\" class=\"headerlink\" title=\"Accept\"></a>Accept</h4><p>通知Server用户代理能够处理的媒体类型、及优先级。</p>\n<ul>\n<li>用q=xx来指定优先级权重。</li>\n<li>优先返回权重高的媒体类型。</li>\n</ul>\n<h4 id=\"Accept-Charset\"><a href=\"#Accept-Charset\" class=\"headerlink\" title=\"Accept-Charset\"></a>Accept-Charset</h4><p>通知服务器用户代理支持的字符集及字符集的相对优先顺序.</p>\n<h4 id=\"Accept-Encoding\"><a href=\"#Accept-Encoding\" class=\"headerlink\" title=\"Accept-Encoding\"></a>Accept-Encoding</h4><p>用来告知服务器用户代理支持的内容编码及内容编码的优先级顺序。</p>\n<ul>\n<li>可一次性指定多种内容编码。</li>\n</ul>\n<h4 id=\"Accept-Language\"><a href=\"#Accept-Language\" class=\"headerlink\" title=\"Accept-Language\"></a>Accept-Language</h4><p>用来告知服务器用户代理能够处理的自然语言集（指中文或英文等）.</p>\n<h4 id=\"Authorization\"><a href=\"#Authorization\" class=\"headerlink\" title=\"Authorization\"></a>Authorization</h4><p>告知服务器，用户代理的认证信息。</p>\n<ul>\n<li>一般，想要通过Server认证的用户代理会在接收到服务器的401状态码响应后，把Authorization字段加入到请求中。</li>\n</ul>\n<h4 id=\"Host\"><a href=\"#Host\" class=\"headerlink\" title=\"Host\"></a>Host</h4><p>告知服务器，请求的资源所处的互联网主机名和端口号。</p>\n<ul>\n<li>与虚拟主机的工作机制有关。</li>\n</ul>\n<h4 id=\"If-Range\"><a href=\"#If-Range\" class=\"headerlink\" title=\"If-Range\"></a>If-Range</h4><p>若指定的If-Range字段值（ETag或时间）和请求资源的ETag值或时间相一致时，则作为范围请求处理。反之，返回全部资源。</p>\n<h3 id=\"响应首部字段\"><a href=\"#响应首部字段\" class=\"headerlink\" title=\"响应首部字段\"></a>响应首部字段</h3><center>\n    <img src=\"./响应首部字段.jpg\" >\n</center>\n\n<h4 id=\"Age\"><a href=\"#Age\" class=\"headerlink\" title=\"Age\"></a>Age</h4><p>告知Client，源服务器在多久前创建了响应。</p>\n<ul>\n<li>若创建该响应的服务器是缓存服务器，则Age值是指缓存后的响应再次发起认证到认证完成的时间。</li>\n<li>创建代理响应时必须加上首部字段Age。</li>\n</ul>\n<h3 id=\"实体首部字段\"><a href=\"#实体首部字段\" class=\"headerlink\" title=\"实体首部字段\"></a>实体首部字段</h3><center>\n    <img src=\"./实体首部字段.jpg\" >\n</center>\n\n<h4 id=\"Content-Location\"><a href=\"#Content-Location\" class=\"headerlink\" title=\"Content-Location\"></a>Content-Location</h4><p>当返回资源与实际请求的对象内容不同时，Content-Location会注明报文主体返回资源对应的URI。</p>\n<h4 id=\"Content-MD5\"><a href=\"#Content-MD5\" class=\"headerlink\" title=\"Content-MD5\"></a>Content-MD5</h4><p>是一串由MD5算法生成的值，目的在于检查报文主体在传输过程中是否保持完整，以及确认传输到达。</p>\n<ul>\n<li>但其对内容的改变无从查证，也无法检测传输过程中的恶意篡改。</li>\n</ul>\n<h2 id=\"其他高频首部字段\"><a href=\"#其他高频首部字段\" class=\"headerlink\" title=\"其他高频首部字段\"></a>其他高频首部字段</h2><p>Cookie：请求首部字段。Client想获得HTTP状态管理支持时，就会在请求中包含从Server接收到的Cookie。<br>Set-Cookie：响应首部字段。是服务器开始管理Client时，告知Client的Cookie信息。</p>\n<h1 id=\"第七章-HTTPS\"><a href=\"#第七章-HTTPS\" class=\"headerlink\" title=\"第七章 HTTPS\"></a>第七章 HTTPS</h1><p><strong>SSL： Secure Socket Layer， 安全套接层<br>TLS： Transport Layer Security， 安全层传输协议</strong></p>\n<p>SSL是独立于HTTP的协议，是当今世界上应用最为广泛的网络安全技术。</p>\n<p>与SSL组合使用的HTTP称为<strong>HTTPS （HTTP Secure，超文本安全传输协议）</strong>。<br>HTTP over SSL</p>\n<p>SSL提供了证书手段来确认服务器。证书由值得信任的第三方机构颁发，来证明服务器和客户端的身份。</p>\n<h2 id=\"HTTPS-HTTP-加密-认证-完整性保护\"><a href=\"#HTTPS-HTTP-加密-认证-完整性保护\" class=\"headerlink\" title=\"HTTPS=HTTP+加密+认证+完整性保护\"></a>HTTPS=HTTP+加密+认证+完整性保护</h2><p>HTTP直接和TCP通信。<br>HTTPS则使用了SSL，HTTP先和SSL通信，SSL再和TCP通信。</p>\n<center>\n    <img src=\"./HTTPS.jpg\" >\n</center>\n\n<p>共享密钥加密：加密和解密使用同一个密钥。</p>\n<p>SSL采用了<strong>公开密钥加密</strong> （Public-Key cryptography），使用非对称密钥。</p>\n<ul>\n<li>私有密钥 private key</li>\n<li>公开密钥 public key</li>\n<li><strong>发送密文方使用对方的公开密钥进行加密，对方收到密文后，用自己的私有密钥进行解密。</strong></li>\n</ul>\n<h3 id=\"HTTPS采用混合加密机制\"><a href=\"#HTTPS采用混合加密机制\" class=\"headerlink\" title=\"HTTPS采用混合加密机制\"></a>HTTPS采用混合加密机制</h3><p>共享密钥加密 + 公开密钥加密</p>\n<center>\n    <img src=\"./HTTPS混合加密机制.jpg\" >\n</center>\n\n<p>使用<strong>公开密钥证书</strong>来确保公开密钥的正确性。</p>\n<h2 id=\"HTTPS通信步骤\"><a href=\"#HTTPS通信步骤\" class=\"headerlink\" title=\"HTTPS通信步骤\"></a>HTTPS通信步骤</h2><center>\n    <img src=\"./HTTPS通信步骤.jpg\" >\n</center>\n\n<ol>\n<li>Client发送Client Hello报文来开始SSL通信。（报文中包括Client支持的SSL版本、加密组件列表(加密算法、密钥长度等)）</li>\n<li>Server回复Server Hello报文。（内容同样包括SSL版本、<strong>筛选的</strong>加密组件）</li>\n<li>Server发送Certificate报文。（包含<strong>公钥</strong>，之后Client发送的报文会以该公钥进行加密）</li>\n<li>Server发送Server Hello Done报文，代表最初阶段的SSL第一次握手协商结束。</li>\n<li>Client发送Client Key Exchange报文。（包含Pre-master secret随机密码串）</li>\n<li>Client发送Change Cipher Spec报文，提示Server之后的通信采用Pre-master secret加密。</li>\n<li>Client发送Finished报文。（包含从连接开始的全部报文的整体校验值）</li>\n<li>Server发送Change Cipher Spec报文。</li>\n<li>Server发送Finished报文。</li>\n<li>服务器与客户端Finished报文交换完毕，<strong>SSL连接成功建立</strong>。开始在SSL的保护下进行应用层协议通信，发送HTTP请求。</li>\n<li>应用层协议通信，回复HTTP响应。</li>\n<li>HTTP通信结束时由客户端断开连接，通过发送close_notify报文。之后发送TCP FIN报文来关闭与TCP的通信。</li>\n</ol>\n<ul>\n<li>为了保护报文的完整性，在应用层发送数据时附加MAC （Message Authentication Code）的报文摘要来检测报文是否被篡改。</li>\n</ul>\n<center>\n    <img src=\"./HTTPS通信细节.jpg\" >\n</center>\n\n<h2 id=\"TLS和SSL\"><a href=\"#TLS和SSL\" class=\"headerlink\" title=\"TLS和SSL\"></a>TLS和SSL</h2><p>HTTPS通信使用SSL和TLS两个协议。</p>\n<ul>\n<li>TLS是以SSL 3.0为原型开发的协议，可与SSL统称为SSL。</li>\n</ul>\n<h2 id=\"HTTPS比HTTP慢2-100倍\"><a href=\"#HTTPS比HTTP慢2-100倍\" class=\"headerlink\" title=\"HTTPS比HTTP慢2~100倍\"></a>HTTPS比HTTP慢2~100倍</h2><ol>\n<li>通信慢，需要额外进行SSL通信，消耗网络资源大。</li>\n<li>HTTPS需要做服务器、客户端双方加密、解密，消耗CPU、内存等硬件资源。</li>\n</ol>\n<p>所以一般只在包含个人信息等敏感数据时，才进行HTTPS加密通信。</p>\n<h1 id=\"第八章-认证机制\"><a href=\"#第八章-认证机制\" class=\"headerlink\" title=\"第八章 认证机制\"></a>第八章 认证机制</h1><p>HTTP/1.1使用的认证方式：</p>\n<ul>\n<li>BASIC认证<ul>\n<li>采用Base64编码，解码不需要任何附加信息，安全性差。</li>\n</ul>\n</li>\n<li>DIGEST认证</li>\n<li>SSL客户端认证<ul>\n<li>利用HTTPS的客户端证书进行认证客户端，客户端证书要钱</li>\n<li>再利用密码来确定用户本人</li>\n</ul>\n</li>\n<li>FormBase认证（基于表单认证）<ul>\n<li>由Web应用各自实现，没有标准</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"第九章-基于HTTP的功能追加协议\"><a href=\"#第九章-基于HTTP的功能追加协议\" class=\"headerlink\" title=\"第九章 基于HTTP的功能追加协议\"></a>第九章 基于HTTP的功能追加协议</h1><h2 id=\"Ajax-技术\"><a href=\"#Ajax-技术\" class=\"headerlink\" title=\"Ajax 技术\"></a>Ajax 技术</h2><p>Asynchronous JavaScript and XML， 异步JS与XML技术，从已加载完毕的Web页面上发起HTTP请求，只更新局部页面，但可能导致大量请求产生。</p>\n<h2 id=\"Comet-技术\"><a href=\"#Comet-技术\" class=\"headerlink\" title=\"Comet 技术\"></a>Comet 技术</h2><p>客户端发送内容更新请求时，Server先挂起响应，一旦Server有内容更新，直接主动给客户端返回响应，实现实时更新。</p>\n<ul>\n<li>但为了维持TCP连接会消耗更多资源。</li>\n</ul>\n<h2 id=\"SPDY-协议\"><a href=\"#SPDY-协议\" class=\"headerlink\" title=\"SPDY 协议\"></a>SPDY 协议</h2><p>为了在协议级别消除HTTP的瓶颈。<br>没有完全改写HTTP，而是在TCP/IP的应用层与传输层之间新加入会话层，控制数据流动；但还是采用HTTP进行通信连接。</p>\n<center>\n    <img src=\"./SPDY.jpg\" >\n</center>\n\n<ul>\n<li>通过单一TCP连接，可无限制处理多个HTTP请求。</li>\n<li>可给请求逐个分配优先级。</li>\n<li>压缩HTTP请求和响应的首部。</li>\n<li>支持服务器向客户端的推送。</li>\n<li>服务器可主动提示客户端请求所需的资源。</li>\n</ul>\n<h2 id=\"WebSocket：全双工通信标准\"><a href=\"#WebSocket：全双工通信标准\" class=\"headerlink\" title=\"WebSocket：全双工通信标准\"></a>WebSocket：全双工通信标准</h2><ul>\n<li>支持Server到Client的推送。</li>\n<li>建立起WebSocket连接后，一直保持连接状态，通信时开销减少；WebSocket首部信息小，通信量也减少。</li>\n<li>在HTTP连接建立后，进行一次握手来实现WebSocket通信。</li>\n</ul>\n<pre><code class=\"java\">Upgrade: websocket\nConnection: Upgrade</code></pre>\n"},{"title":"进程与线程-转载","date":"2020-03-06T13:19:11.000Z","_content":"\n\n\n> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&mid=2247487913&idx=1&sn=8c3f042c5a73ce9e49b21bc6cce2442e&chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&mpshare=1&scene=1&srcid=&sharer_sharetime=1583500047238&sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&ascene=1&uin=MTIwMTg1OTcwMg%3D%3D&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm\n\n来源：Java 建设者\n\n作者：cxuan\n\n下面是本文的结构图\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJArB4bFRERsiaKqyAZbnJxU3ISIOnRUH908G29Tx2iaCXc5Ps7DTiaD4A/640?wx_fmt=png)\n\n我们平常说的进程和线程更多的是基于编程语言的角度来说的，那么你真的了解什么是线程和进程吗？那么我们就从操作系统的角度来了解一下什么是进程和线程。\n\n进程\n--\n\n操作系统中最核心的概念就是 `进程`，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，它们也支持`（伪）并发`操作。它们会将一个单独的 CPU 抽象为多个虚拟机的 CPU。可以说：没有进程的抽象，现代操作系统将不复存在。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJcVYZew9ryLN0RIu6fwSUliaeSKiaKgoBDSXfaH9Hqvm4Cm73Na86K3Q/640?wx_fmt=png)\n\n所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。\n\n现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。于是一个支持多进程的多道程序系统就会显得很有必要了。\n\n在许多多道程序系统中，CPU 会在`进程`间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生`并行`的错觉。有时候人们说的 `伪并行(pseudoparallelism)` 就是这种情况，以此来区分多处理器系统 (该系统由两个或多个 CPU 来共享同一个物理内存)\n\n> 再来详细解释一下伪并行：`伪并行`是指单核或多核处理器同时执行多个进程，从而使程序更快。通过以非常有限的时间间隔在程序之间快速切换 CPU，因此会产生并行感。缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。\n\n因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析，对该模型的探讨，也是本篇文章的主题。下面我们就来探讨一下进程模型\n\n### 进程模型\n\n在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干`顺序进程(sequential processes)`，简称为 `进程(process)` 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkwicOIsH2wqofqK877AcZEnQwsg3hSibpu2q5ZWrKKOwIUZloGHVEY69w/640?wx_fmt=png)\n\n如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkpSsh1RicmibCiaNmgwq5xMM8NtTl1yW3jXcL2pMIBDUmQk9VRGSMC4wwA/640?wx_fmt=png)\n\n在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。\n\n从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，**但在任何一个给定的瞬间仅有一个进程真正运行**。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkeqicuKAib5xjeLwSEKvmWbnZd9poHkykMIZxKGfryBFwNBCNHghALbQg/640?wx_fmt=png)\n\n因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），**每一个核也只能一次运行一个线程**。\n\n由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原谅：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、而做蛋糕的各种原料都是输入数据。进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系列动作的总和。\n\n现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。\n\n这里的关键思想是`认识到一个进程所需的条件`，进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，如果一个进程运行了两遍，则被认为是两个进程。那么我们了解到进程模型后，那么进程是如何创建的呢？\n\n### 进程的创建\n\n操作系统需要一些方式来创建进程。下面是一些创建进程的方式\n\n*   系统初始化（init）\n    \n*   正在运行的程序执行了创建进程的系统调用（比如 fork）\n    \n*   用户请求创建一个新进程\n    \n*   初始化一个批处理工作\n    \n\n#### 系统初始化\n\n启动操作系统时，通常会创建若干个进程。其中有些是`前台进程(numerous processes)`，也就是同用户进行交互并替他们完成工作的进程。一些运行在后台，并不与特定的用户进行交互，例如，设计一个进程来接收发来的电子邮件，这个进程大部分的时间都在休眠，但是只要邮件到来后这个进程就会被唤醒。还可以设计一个进程来接收对该计算机上网页的传入请求，在请求到达的进程唤醒来处理网页的传入请求。进程运行在后台用来处理一些活动像是 e-mail，web 网页，新闻，打印等等被称为 `守护进程(daemons)`。大型系统会有很多守护进程。在 UNIX 中，`ps` 程序可以列出正在运行的进程， 在 Windows 中，可以使用任务管理器。\n\n#### 系统调用创建\n\n除了在启动阶段创建进程之外，一些新的进程也可以在后面创建。通常，一个正在运行的进程会发出`系统调用`用来创建一个或多个新进程来帮助其完成工作。例如，如果有大量的数据需要经过网络调取并进行顺序处理，那么创建一个进程读数据，并把数据放到共享缓冲区中，而让第二个进程取走并正确处理会比较容易些。在多处理器中，让每个进程运行在不同的 CPU 上也可以使工作做的更快。\n\n#### 用户请求创建\n\n在许多交互式系统中，输入一个命令或者双击图标就可以启动程序，以上任意一种操作都可以选择开启一个新的进程，在基本的 UNIX 系统中运行 X，新进程将接管启动它的窗口。在 Windows 中启动进程时，它一般没有窗口，但是它可以创建一个或多个窗口。每个窗口都可以运行进程。通过鼠标或者命令就可以切换窗口并与进程进行交互。\n\n> 交互式系统是以人与计算机之间大量交互为特征的计算机系统，比如游戏、web 浏览器，IDE 等集成开发环境。\n\n#### 批处理创建\n\n最后一种创建进程的情形会在`大型机的批处理系统`中应用。用户在这种系统中提交批处理作业。当操作系统决定它有资源来运行另一个任务时，它将创建一个新进程并从其中的输入队列中运行下一个作业。\n\n从技术上讲，在所有这些情况下，让现有流程执行流程是通过创建系统调用来创建新流程的。该进程可能是正在运行的用户进程，是从键盘或鼠标调用的系统进程或批处理程序。这些就是系统调用创建新进程的过程。该系统调用告诉操作系统创建一个新进程，并直接或间接指示在其中运行哪个程序。\n\n在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 `fork`。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。通常，子进程会执行 `execve` 或者一个简单的系统调用来改变内存映像并运行一个新的程序。例如，当一个用户在 shell 中输出 sort 命令时，shell 会 fork 一个子进程然后子进程去执行 sort 命令。这两步过程的原因是允许子进程在 fork 之后但在 execve 之前操作其文件描述符，以完成标准输入，标准输出和标准错误的重定向。\n\n在 Windows 中，情况正相反，一个简单的 Win32 功能调用 `CreateProcess`，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 `CreateProcess` Win 32 中大概有 100 个其他的函数用于处理进程的管理，同步以及相关的事务。下面是 UNIX 操作系统和 Windows 操作系统系统调用的对比\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkCg59tia26o7PFqCbmnFhEI6j1qoKbDeLKhUYepPVmZ400sWwtahYrNA/640?wx_fmt=png)\n\n在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个词，这个修改将对另一个进程不可见。在 UNIX 中，子进程的地址空间是父进程的一个拷贝，但是却是两个不同的地址空间；不可写的内存区域是共享的。某些 UNIX 实现是正是在两者之间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但是这种情况下内存通过 `写时复制(copy-on-write)` 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确的复制，以确保修改发生在私有内存区域。再次强调，**可写的内存是不能被共享的**。但是，对于一个新创建的进程来说，确实有可能共享创建者的资源，比如可以共享打开的文件。**在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的**。  \n\n### 进程的终止\n\n进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的\n\n*   `正常退出(自愿的)`\n    \n*   `错误退出(自愿的)`\n    \n*   `严重错误(非自愿的)`\n    \n*   `被其他进程杀死(非自愿的)`\n    \n\n#### 正常退出\n\n多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 `exit` ，在 Windows 中是 `ExitProcess`。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。\n\n#### 错误退出\n\n进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令\n\n```\ncc foo.c    \n```\n\n为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。\n\n#### 严重错误\n\n进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。\n\n#### 被其他进程杀死\n\n第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 `TerminateProcess`（注意不是系统调用）。\n\n### 进程的层次结构\n\n在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。\n\n#### UNIX 进程体系\n\n在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。\n\n这里有另一个例子，可以用来说明层次的作用，考虑 `UNIX` 在启动时如何初始化自己。一个称为 `init` 的特殊进程出现在启动映像中 。当 init 进程开始运行时，它会读取一个文件，文件会告诉它有多少个终端。然后为每个终端创建一个新进程。这些进程等待用户登录。如果登录成功，该登录进程就执行一个 shell 来等待接收用户输入指令，这些命令可能会启动更多的进程，以此类推。因此，整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkfB32mZKNYKtf0P9jW3Qax9iaW3gF4OfXGnBLM7FDBxvAUAHpiazZDRVw/640?wx_fmt=png)\n\n#### Windows 进程体系\n\n相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。而在 UNIX 中，进程不能剥夺其子进程的 `进程权`。（这样看来，还是 Windows 比较`渣`）。\n\n### 进程状态\n\n尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。例如，一个进程的结果可以作为另一个进程的输入，在 shell 命令中\n\n```\ncat chapter1 chapter2 chapter3 | grep tree\n```\n\n第一个进程是 `cat`，将三个文件级联并输出。第二个进程是 `grep`，它从输入中选择具有包含关键字 `tree` 的内容，根据这两个进程的相对速度（这取决于两个程序的相对复杂度和各自所分配到的 CPU 时间片），可能会发生下面这种情况，`grep` 准备就绪开始运行，但是输入进程还没有完成，于是必须阻塞 grep 进程，直到输入完毕。\n\n当一个进程开始运行时，它可能会经历下面这几种状态\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk0nh0PP7ykpeG74eOW5iahBUU5AmxJjnr2Lot6w2dloqoBYgsAibrFg0A/640?wx_fmt=png)\n\n图中会涉及三种状态\n\n1.  `运行态`，运行态指的就是进程实际占用 CPU 时间片运行时\n    \n2.  `就绪态`，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态\n    \n3.  `阻塞态`，除非某种外部事件发生，否则进程不能运行\n    \n\n逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程`可运行`，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。\n\n三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生`状态1`的轮转，在某些系统中进程执行系统调用，例如 `pause`，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。\n\n转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。\n\n> **程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点**。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。\n\n当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。\n\n从上面的观点引入了下面的模型\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPP9Rn6j8AW1uLNLoKOjBtWbYRvyhrQicjjLl8n8GFuibRbuBXQnu27nw/640?wx_fmt=png)\n\n**操作系统最底层的就是调度程序**，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。事实上，调度程序只是一段非常小的程序。\n\n### 进程的实现\n\n操作系统为了执行进程间的切换，会维护着一张表格，这张表就是 `进程表(process table)`。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。\n\n下面展示了一个典型系统中的关键字段\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkC2WWXEkRAKErcia0ib3Hia2DWsLtPRzqQLdt4Mo326QWfF7LfyXfcUApQ/640?wx_fmt=png)\n\n第一列内容与`进程管理`有关，第二列内容与 `存储管理`有关，第三列内容与`文件管理`有关。\n\n存储管理的 text segment 、 data segment、stack segment 更多了解见下面这篇文章\n\n[程序员需要了解的硬核知识之汇编语言 (全)](https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&mid=2247484788&idx=1&sn=8a17224cabe09d3bd564dfdf22e2ff5d&chksm=fc45f887cb3271914f0e688a3cce4d7e3ce9077cdde199648e72aa92ad08fba2047b4483b7e8&token=504034995&lang=zh_CN&scene=21#wechat_redirect)\n\n现在我们应该对进程表有个大致的了解了，就可以在对单个 CPU 上如何运行多个顺序进程的错觉做更多的解释。与每一 I/O 类相关联的是一个称作 `中断向量(interrupt vector)` 的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这就是硬件所做的事情。然后软件就随即接管一切剩余的工作。\n\n当中断结束后，操作系统会调用一个 C 程序来处理中断剩下的工作。在完成剩下的工作后，会使某些进程就绪，接着调用调度程序，决定随后运行哪个进程。然后将控制权转移给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行，下面显示了中断处理和调度的过程。\n\n1.  硬件压入堆栈程序计数器等\n    \n2.  硬件从中断向量装入新的程序计数器\n    \n3.  汇编语言过程保存寄存器的值\n    \n4.  汇编语言过程设置新的堆栈\n    \n5.  C 中断服务器运行（典型的读和缓存写入）\n    \n6.  调度器决定下面哪个程序先运行\n    \n7.  C 过程返回至汇编代码\n    \n8.  汇编语言过程开始运行新的当前进程\n    \n\n一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。\n\n线程\n--\n\n在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。下面我们就着重探讨一下什么是线程\n\n### 线程的使用\n\n或许这个疑问也是你的疑问，为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答\n\n*   多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的\n    \n*   线程要比进程`更轻量级`，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。\n    \n*   第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度\n    \n\n#### 多线程解决方案\n\n现在考虑一个线程使用的例子：一个万维网服务器，对页面的请求发送给服务器，而所请求的页面发送回客户端。在多数 web 站点上，某些页面较其他页面相比有更多的访问。例如，索尼的主页比任何一个照相机详情介绍页面具有更多的访问，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这种页面的集合称为 `高速缓存(cache)`，高速缓存也应用在许多场合中，比如说 CPU 缓存。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiafv8cMyibXVb2KNYiaU7IktbLNOPOeficbw2jRlHzF50BPen1r00FYCag/640?wx_fmt=png)\n\n上面是一个 web 服务器的组织方式，一个叫做 `调度线程(dispatcher thread)` 的线程从网络中读入工作请求，在调度线程检查完请求后，它会选择一个空闲的（阻塞的）工作线程来处理请求，通常是将消息的指针写入到每个线程关联的特殊字中。然后调度线程会唤醒正在睡眠中的工作线程，把工作线程的状态从阻塞态变为就绪态。\n\n当工作线程启动后，它会检查请求是否在 web 页面的高速缓存中存在，这个高速缓存是所有线程都可以访问的。如果高速缓存不存在这个 web 页面的话，它会调用一个 `read` 操作从磁盘中获取页面并且阻塞线程直到磁盘操作完成。当线程阻塞在硬盘操作的期间，为了完成更多的工作，调度线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。\n\n这种模型允许将服务器编写为顺序线程的集合，在分派线程的程序中包含一个死循环，该循环用来获得工作请求并且把请求派给工作线程。每个工作线程的代码包含一个从调度线程接收的请求，并且检查 web 高速缓存中是否存在所需页面，如果有，直接把该页面返回给客户，接着工作线程阻塞，等待一个新请求的到达。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后工作线程阻塞，等待一个新请求。\n\n下面是调度线程和工作线程的代码，这里假设 TRUE 为常数 1 ，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。\n\n**调度线程的大致逻辑**\n\n```\nwhile(TRUE){\n  get_next_request(&buf);\n  handoff_work(&buf);\n}\n```\n\n**工作线程的大致逻辑**\n\n```\nwhile(TRUE){\n  wait_for_work(&buf);\n  look_for_page_in_cache(&buf,&page);\n  if(page_not_in_cache(&page)){\n    read_page_from_disk(&buf,&page);\n  }\n  return _page(&page);\n}\n```\n\n#### 单线程解决方案\n\n现在考虑没有多线程的情况下，如何编写 Web 服务器。我们很容易的就想象为单个线程了，Web 服务器的主循环获取请求并检查请求，并争取在下一个请求之前完成工作。在等待磁盘操作时，服务器空转，并且不处理任何到来的其他请求。结果会导致每秒中只有很少的请求被处理，所以这个例子能够说明多线程提高了程序的并行性并提高了程序的性能。\n\n#### 状态机解决方案\n\n到现在为止，我们已经有了两种解决方案，单线程解决方案和多线程解决方案，其实还有一种解决方案就是 `状态机解决方案`，它的流程如下\n\n如果目前只有一个非阻塞版本的 read 系统调用可以使用，那么当请求到达服务器时，这个唯一的 read 调用的线程会进行检查，如果能够从高速缓存中得到响应，那么直接返回，如果不能，则启动一个非阻塞的磁盘操作\n\n服务器在表中记录当前请求的状态，然后进入并获取下一个事件，紧接着下一个事件可能就是一个新工作的请求或是磁盘对先前操作的回答。如果是新工作的请求，那么就开始处理请求。如果是磁盘的响应，就从表中取出对应的状态信息进行处理。对于非阻塞式磁盘 I/O 而言，这种响应一般都是信号中断响应。\n\n每次服务器从某个请求工作的状态切换到另一个状态时，都必须显示的保存或者重新装入相应的计算状态。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为`有限状态机(finite-state machine)`，有限状态机被广泛的应用在计算机科学中。\n\n这三种解决方案各有各的特性，多线程使得顺序进程的思想得以保留下来，并且实现了并行性，但是顺序进程会阻塞系统调用；单线程服务器保留了阻塞系统的简易性，但是却放弃了性能。有限状态机的处理方法运用了非阻塞调用和中断，通过并行实现了高性能，但是给编程增加了困难。\n\n| 模型 | 特性 |\n| --- | --- |\n| 单线程 | 无并行性，性能较差，阻塞系统调用 |\n| 多线程 | 有并行性，阻塞系统调用 |\n| 有限状态机 | 并行性，非阻塞系统调用、中断 |\n\n### 经典的线程模型\n\n理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。\n\n另一个概念是，进程中拥有一个执行的线程，通常简写为 `线程(thread)`。线程会有程序计数器，用来记录接着要执行哪一条指令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。\n\n线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在一个进程中并行运行多个线程类似于在一台计算机上运行多个进程。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为`轻量的进程(lightweight processes)`。`多线程(multithreading)`一词还用于描述在同一进程中多个线程的情况。\n\n下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2uvgku9q5Vv9GyQkOicZQtYCH52z6BKMGiaeVlQztM3jDeicn1AFOL7dQ/640?wx_fmt=png)\n\n下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknc4JzHybInkL388a2Mib2jq4P8P2JkvgH6RFbsv0QKtOFN6mz0qgQOw/640?wx_fmt=png)\n\n线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，**因此一个线程可以读取、写入甚至擦除另一个线程的堆栈**。线程之间除了共享同一内存空间外，还具有如下不同的内容\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkciaYNEibh4VsBF79p911Fgt7Ca558CpyNyuppk9wt7DrvuN1Tfibysvmg/640?wx_fmt=png)\n\n上图左边的是同一个进程中`每个线程共享`的内容，上图右边是`每个线程`中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。\n\n和进程一样，线程可以处于下面这几种状态：**运行中、阻塞、就绪和终止（进程图中没有画）**。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。**线程之间的状态转换和进程之间的状态转换是一样的**。\n\n每个线程都会有自己的堆栈，如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkSwK4icLBknT5psHj1niac06X161XVudxzlylzibyRPBHhsjHvdqkpDAQ/640?wx_fmt=png)\n\n#### 线程系统调用\n\n进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 `thread_create`）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。\n\n当一个线程完成工作后，可以通过调用一个函数（比如 `thread_exit`）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 `thread_join` ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。\n\n另一个常见的线程是调用 `thread_yield`，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。\n\n### POSIX 线程\n\n为了使编写可移植线程程序成为可能，IEEE 在 IEEE 标准 1003.1c 中定义了线程标准。线程包被定义为 `Pthreads`。大部分的 UNIX 系统支持它。这个标准定义了 60 多种功能调用，一一列举不太现实，下面为你列举了一些常用的系统调用。\n\n> **POSIX 线程**（通常称为 **pthreads**）是一种独立于语言而存在的执行模型，以及并行执行模型。它允许程序控制时间上重叠的多个不同的工作流程。每个工作流程都称为一个线程，可以通过调用 POSIX Threads API 来实现对这些流程的创建和控制。可以把它理解为线程的标准。\n> \n> POSIX Threads 的实现在许多类似且符合 POSIX 的操作系统上可用，例如 **FreeBSD、NetBSD、OpenBSD、Linux、macOS、Android、Solaris**，它在现有 Windows API 之上实现了 **pthread**。\n> \n> IEEE 是世界上最大的技术专业组织，致力于为人类的利益而发展技术。\n\n| 线程调用 | 描述 |\n| --- | --- |\n| pthread_create | 创建一个新线程 |\n| pthread_exit | 结束调用的线程 |\n| pthread_join | 等待一个特定的线程退出 |\n| pthread_yield | 释放 CPU 来运行另外一个线程 |\n| pthread_attr_init | 创建并初始化一个线程的属性结构 |\n| pthread_attr_destory | 删除一个线程的属性结构 |\n\n所有的 Pthreads 都有特定的属性，每一个都含有标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这个属性包括堆栈大小、调度参数以及其他线程需要的项目。\n\n新的线程会通过 `pthread_create` 创建，新创建的线程的标识符会作为函数值返回。这个调用非常像是 UNIX 中的 `fork` 系统调用（除了参数之外），其中线程标识符起着 `PID` 的作用，这么做的目的是为了和其他线程进行区分。\n\n当线程完成指派给他的工作后，会通过 `pthread_exit` 来终止。这个调用会停止线程并释放堆栈。\n\n一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 `pthread_join` 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。\n\n有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长的时间并且希望给另外一个线程机会去运行。这时候可以通过 `pthread_yield` 来完成。\n\n下面两个线程调用是处理属性的。`pthread_attr_init` 建立关联一个线程的属性结构并初始化成默认值，这些值（例如优先级）可以通过修改属性结构的值来改变。\n\n最后，`pthread_attr_destroy` 删除一个线程的结构，释放它占用的内存。它不会影响调用它的线程，这些线程会一直存在。\n\n为了更好的理解 pthread 是如何工作的，考虑下面这个例子\n\n```\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUMBER_OF_THREADS 10\n\nvoid *print_hello_world(vvoid *tid){\n  /* 输出线程的标识符，然后退出 */\n  printf(\"Hello World. Greetings from thread %d\\n\",tid);\n  pthread_exit(NULL);\n}\n\nint main(int argc,char *argv[]){\n  /* 主程序创建 10 个线程，然后退出 */\n  pthread_t threads[NUMBER_OF_THREADS];\n  int status,i;\n\n  for(int i = 0;i < NUMBER_OF_THREADS;i++){\n    printf(\"Main here. Creating thread %d\\n\",i);\n    status = pthread_create(&threads[i], NULL, print_hello_world, (void *)i);\n\n    if(status != 0){\n      printf(\"Oops. pthread_create returned error code %d\\n\",status);\n      exit(-1);\n    }\n  }\n  exit(NULL);\n}\n```\n\n主线程在宣布它的指责之后，循环 `NUMBER_OF_THREADS` 次，每次创建一个新的线程。如果线程创建失败，会打印出一条信息后退出。在创建完成所有的工作后，主程序退出。\n\n### 线程实现\n\n主要有三种实现方式\n\n*   在用户空间中实现线程；\n    \n*   在内核空间中实现线程；\n    \n*   在用户和内核空间中混合实现线程。\n    \n\n下面我们分开讨论一下\n\n#### 在用户空间中实现线程\n\n第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkcq03vztMLnRiaYPTqX0KENPFKPnNr2Ic0qj79V3e0Py9JstIWCI4HibQ/640?wx_fmt=png)\n\n线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程：pthread_create, pthread_exit, pthread_join 和 pthread_yield。\n\n> `运行时系统(Runtime System)` 也叫做运行时环境，该运行时系统提供了程序在其中运行的环境。此环境可能会解决许多问题，包括应用程序内存的布局，程序如何访问变量，在过程之间传递参数的机制，与操作系统的接口等等。编译器根据特定的运行时系统进行假设以生成正确的代码。通常，运行时系统将负责设置和管理堆栈，并且会包含诸如垃圾收集，线程或语言内置的其他动态的功能。\n\n在用户空间管理线程时，每个进程需要有其专用的`线程表(thread table)`，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态。该线程表由运行时系统统一管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程的所有信息，与内核在进程表中存放的信息完全一样。\n\n#### 在用户空间实现线程的优势\n\n在用户空间中实现线程要比在内核空间中实现线程具有这些方面的优势：考虑如果在线程完成时或者是在调用 `pthread_yield` 时，必要时会进程线程切换，然后线程的信息会被保存在运行时环境所提供的线程表中，然后，线程调度程序来选择另外一个需要运行的线程。保存线程的状态和调度程序都是`本地过程`，**所以启动他们比进行内核调用效率更高。因而不需要切换到内核，也就不需要上下文切换，也不需要对内存高速缓存进行刷新，因为线程调度非常便捷，因此效率比较高**。\n\n在用户空间实现线程还有一个优势就是**它允许每个进程有自己定制的调度算法**。例如在某些应用程序中，那些具有垃圾收集线程的应用程序（知道是谁了吧）就不用担心自己线程会不会在不合适的时候停止，这是一个优势。用户线程还具有较好的可扩展性，因为内核空间中的内核线程需要一些表空间和堆栈空间，如果内核线程数量比较大，容易造成问题。\n\n#### 在用户空间实现线程的劣势\n\n尽管在用户空间实现线程会具有一定的性能优势，但是劣势还是很明显的，你如何实现`阻塞系统调用`呢？假设在还没有任何键盘输入之前，一个线程读取键盘，让线程进行系统调用是不可能的，因为这会停止所有的线程。所以，**使用线程的一个目标是能够让线程进行阻塞调用，并且要避免被阻塞的线程影响其他线程**。\n\n与阻塞调用类似的问题是`缺页中断`问题，实际上，计算机并不会把所有的程序都一次性的放入内存中，如果某个程序发生函数调用或者跳转指令到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令，这就称为`缺页故障`。而在对所需的指令进行读入和执行时，相关的进程就会被阻塞。如果只有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。\n\n另外一个问题是，如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。\n\n### 在内核中实现线程\n\n现在我们考虑使用内核来实现线程的情况，此时不再需要运行时环境了。另外，每个进程中也没有线程表。相反，在内核中会有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaPkapIx1EYhPdibEPKuChcIOcClAlhTUicxq554eFbJVWrvyCVUdumBw/640?wx_fmt=png)\n\n内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。\n\n所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。\n\n由于在内核中创建或者销毁线程的开销比较大，所以某些系统会采用可循环利用的方式来回收线程。当某个线程被销毁时，就把它标志为不可运行的状态，但是其内部结构没有受到影响。稍后，在必须创建一个新线程时，就会重新启用旧线程，把它标志为可用状态。\n\n如果某个进程中的线程造成缺页故障后，内核很容易的就能检查出来是否有其他可运行的线程，如果有的话，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止）比较多，就会带来很大的开销。\n\n### 混合实现\n\n结合用户空间和内核空间的优点，设计人员采用了一种`内核级线程`的方式，然后将用户级线程与某些或者全部内核线程多路复用起来\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkKYe6RpSy705bprAxhibKHKkiba32AcKmS0AOAcuCyZuMvyduVgWFwGhQ/640?wx_fmt=png)\n\n在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。\n\n进程间通信\n-----\n\n进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 `进程间通信(Inter Process Communication, IPC)` 的问题。\n\n关于进程间的通信，这里有三个问题\n\n*   上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。\n    \n*   第二个问题是如何确保两个或多个线程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。\n    \n*   第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。\n    \n\n需要注意的是，这三个问题中的后面两个问题同样也适用于线程\n\n第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？\n\n另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。我们后面会慢慢讨论这三个问题，你现在脑子中大致有个印象即可。\n\n### 竞态条件\n\n在一些操作系统中，协作的进程可能共享一些彼此都能读写的公共资源。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的`后台目录(spooler directory)`中。另一个进程 `打印后台进程(printer daemon)` 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。\n\n假设我们的后台目录有非常多的 `槽位(slot)`，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：`out`，指向下一个需要打印的文件；`in`，指向目录中下个空闲的槽位。可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2JljDicfDxXbzlWe7J4KyqznJfd12m6a6BbVaiaMKYxDKU0LpRP9wibibw/640?wx_fmt=png)\n\n`墨菲法则(Murphy)` 中说过，任何可能出错的地方终将出错，这句话生效时，可能发生如下情况。\n\n进程 A 读到 in 的值为 7，将 7 存在一个局部变量 `next_free_slot` 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 `next_free_slot` 中，在这一时刻两个进程都认为下一个可用槽位是 7 。\n\n进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情\n\n现在进程 A 开始恢复运行，由于进程 A 通过检查 `next_free_slot`也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，**即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件 (race condition)**。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象。\n\n### 临界区\n\n不仅共享资源会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：**禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写**。换句话说，我们需要一种 `互斥(mutual exclusion)` 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。上面问题的纠结点在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。在任何操作系统中，为了实现互斥操作而选用适当的原语是一个主要的设计问题，接下来我们会着重探讨一下。\n\n避免竞争问题的条件可以用一种抽象的方式去描述。大部分时间，进程都会忙于内部计算和其他不会导致竞争条件的计算。然而，有时候进程会访问共享内存或文件，或者做一些能够导致竞态条件的操作。我们把对共享内存进行访问的程序片段称作 `临界区域(critical region)` 或 `临界区(critical section)`。如果我们能够正确的操作，使两个不同进程不可能同时处于临界区，就能避免竞争条件，这也是从操作系统设计角度来进行的。\n\n尽管上面这种设计避免了竞争条件，但是不能确保并发线程同时访问共享数据的正确性和高效性。一个好的解决方案，应该包含下面四种条件\n\n1.  任何时候两个进程不能同时处于临界区\n    \n2.  不应对 CPU 的速度和数量做任何假设\n    \n3.  位于临界区外的进程不得阻塞其他进程\n    \n4.  不能使任何进程无限等待进入临界区\n    \n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkrTXZzTqwPTGouHGo3DMXicFwwsRRENeKdia9UicibzOyzGBZ1NA1R8kWCg/640?wx_fmt=png)\n\n从抽象的角度来看，我们通常希望进程的行为如上图所示，在 t1 时刻，进程 A 进入临界区，在 t2 的时刻，进程 B 尝试进入临界区，因为此时进程 A 正在处于临界区中，所以进程 B 会阻塞直到 t3 时刻进程 A 离开临界区，此时进程 B 能够允许进入临界区。最后，在 t4 时刻，进程 B 离开临界区，系统恢复到没有进程的原始状态。\n\n### 忙等互斥\n\n下面我们会继续探讨实现互斥的各种设计，在这些方案中，当一个进程正忙于更新其关键区域的共享内存时，没有其他进程会进入其关键区域，也不会造成影响。\n\n#### 屏蔽中断\n\n在单处理器系统上，最简单的解决方案是让每个进程在进入临界区后立即`屏蔽所有中断`，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。\n\n这个方案可行吗？进程进入临界区域是由谁决定的呢？不是用户进程吗？当进程进入临界区域后，用户进程关闭中断，如果经过一段较长时间后进程没有离开，那么中断不就一直启用不了，结果会如何？可能会造成整个系统的终止。而且如果是多处理器的话，屏蔽中断仅仅对执行 `disable` 指令的 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。\n\n另一方面，对内核来说，当它在执行更新变量或列表的几条指令期间将中断屏蔽是很方便的。例如，如果多个进程处理就绪列表中的时候发生中断，则可能会发生竞态条件的出现。所以，屏蔽中断对于操作系统本身来说是一项很有用的技术，但是对于用户线程来说，屏蔽中断却不是一项通用的互斥机制。\n\n#### 锁变量\n\n作为第二种尝试，可以寻找一种软件层面解决方案。考虑有单个共享的（锁）变量，初始为值为 0 。当一个线程想要进入关键区域时，它首先会查看锁的值是否为 0 ，如果锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。因此，锁变量的值是 0 则意味着没有线程进入关键区域。如果是 1 则意味着有进程在关键区域内。我们对上图修改后，如下所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmcJYsm5uD0kUSRoia4J0KORtZslfTnAnqBca2Ay7KbWibU2a9ywAKwaw/640?wx_fmt=png)\n\n这种设计方式是否正确呢？是否存在纰漏呢？假设一个进程读出锁变量的值并发现它为 0 ，而恰好在它将其设置为 1 之前，另一个进程调度运行，读出锁的变量为 0 ，并将锁的变量设置为 1 。然后第一个线程运行，把锁变量的值再次设置为 1，此时，临界区域就会有两个进程在同时运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVmTDUd4XWEic0EUCtJnWB8yKr5qUJANrZrDYXm0PLF60Zu7sKas4Yibw/640?wx_fmt=png)\n\n也许有的读者可以这么认为，在进入前检查一次，在要离开的关键区域再检查一次不就解决了吗？实际上这种情况也是于事无补，因为在第二次检查期间其他线程仍有可能修改锁变量的值，换句话说，这种 `set-before-check` 不是一种 `原子性` 操作，所以同样还会发生竞争条件。\n\n#### 严格轮询法\n\n第三种互斥的方式先抛出来一段代码，这里的程序是用 C 语言编写，之所以采用 C 是因为操作系统普遍是用 C 来编写的（偶尔会用 C++），而基本不会使用 Java 、Modula3 或 Pascal 这样的语言，Java 中的 native 关键字底层也是 C 或 C++ 编写的源码。对于编写操作系统而言，需要使用 C 语言这种强大、高效、可预知和有特性的语言，而对于 Java ，它是不可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾回收机制回收内存。在 C 语言中，这种情况不会发生，C 语言中不会主动调用垃圾回收回收内存。有关 C 、C++ 、Java 和其他四种语言的比较可以参考 **链接**\n\n**进程 0 的代码**\n\n```\nwhile(TRUE){\n  while(turn != 0){\n    /* 进入关键区域 */\n    critical_region();\n    turn = 1;\n    /* 离开关键区域 */\n    noncritical_region();\n  }\n}\n```\n\n**进程 1 的代码**\n\n```\nwhile(TRUE){\n  while(turn != 1){\n    critical_region();\n    turn = 0;\n    noncritical_region();\n  }\n}\n```\n\n在上面代码中，变量 `turn`，初始值为 0 ，用于记录轮到那个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0 ，于是进入临界区。进程 1 也发现其值为 0 ，所以在一个等待循环中不停的测试 turn，看其值何时变为 1。连续检查一个变量直到某个值出现为止，这种方法称为 `忙等待(busywaiting)`。由于这种方式浪费 CPU 时间，所以这种方式通常应该要避免。只有在有理由认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 `自旋锁(spinlock)`。\n\n进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0 。现在进程 0 很快就执行完了整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。\n\n突然，进程 0 结束了非临界区的操作并返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，此时进程 1 还忙于非临界区的操作，进程 0 只能继续 while 循环，直到进程 1 把 turn 的值改为 0 。这说明，在一个进程比另一个进程执行速度慢了很多的情况下，轮流进入临界区并不是一个好的方法。\n\n这种情况违反了前面的叙述 3 ，即 **位于临界区外的进程不得阻塞其他进程**，进程 0 被一个临界区外的进程阻塞。由于违反了第三条，所以也不能作为一个好的方案。\n\n#### Peterson 解法\n\n荷兰数学家 T.Dekker 通过将锁变量与警告变量相结合，最早提出了一个不需要严格轮换的软件互斥算法，关于 Dekker 的算法，参考 **链接**\n\n后来， G.L.Peterson 发现了一种简单很多的互斥算法，它的算法如下\n\n```\n#define FALSE 0\n#define TRUE  1\n/* 进程数量 */\n#define N     2                                                    \n\n/* 现在轮到谁 */\nint turn;                    \n\n/* 所有值初始化为 0 (FALSE) */\nint interested[N];                                            \n\n/* 进程是 0 或 1 */\nvoid enter_region(int process){                    \n\n  /* 另一个进程号 */\n  int other;                                                        \n\n  /* 另一个进程 */\n  other = 1 - process;                \n\n  /* 表示愿意进入临界区 */\n  interested[process] = TRUE;                        \n  turn = process;\n\n  /* 空循环 */\n  while(turn == process \n        && interested[other] == true){} \n\n}\n\nvoid leave_region(int process){\n\n  /* 表示离开临界区 */\n  interested[process] == FALSE;                 \n}\n```\n\n在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 `enter_region`，这个函数调用在需要时将使进程等待，直到能够安全的临界区。在完成对共享变量的操作之后，进程将调用 `leave_region` 表示操作完成，并且允许其他进程进入。\n\n现在来看看这个办法是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 `enter_region`。它通过设置数组元素和将 turn 置为 0 来表示它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程现在调用 enter_region，进程 1 将在此处挂起直到 `interested[0]` 变为 FALSE，这种情况只有在进程 0 调用 `leave_region` 退出临界区时才会发生。\n\n那么上面讨论的是顺序进入的情况，现在来考虑一种两个进程同时调用 `enter_region` 的情况。它们都将自己的进程存入 turn，但只有最后保存进去的进程号才有效，前一个进程的进程号因为重写而丢失。假如进程 1 是最后存入的，则 turn 为 1 。当两个进程都运行到 `while` 的时候，进程 0 将不会循环并进入临界区，而进程 1 将会无限循环且不会进入临界区，直到进程 0 退出位置。\n\n#### TSL 指令\n\n现在来看一种需要硬件帮助的方案。一些计算机，特别是那些设计为多处理器的计算机，都会有下面这条指令\n\n```\nTSL RX,LOCK    \n```\n\n称为 `测试并加锁(test and set lock)`，它将一个内存字 lock 读到寄存器 `RX` 中，然后在该内存地址上存储一个非零值。读写指令能保证是一体的，不可分割的，一同执行的。在这个指令结束之前其他处理器均不允许访问内存。执行 TSL 指令的 CPU 将会锁住内存总线，用来禁止其他 CPU 在这个指令结束之前访问内存。\n\n很重要的一点是锁住内存总线和禁用中断不一样。禁用中断并不能保证一个处理器在读写操作之间另一个处理器对内存的读写。也就是说，在处理器 1 上屏蔽中断对处理器 2 没有影响。让处理器 2 远离内存直到处理器 1 完成读写的最好的方式就是锁住总线。这需要一个特殊的硬件（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能使用）\n\n为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程使用 `move` 指令将 lock 的值重新设置为 0 。\n\n这条指令如何防止两个进程同时进入临界区呢？下面是解决方案\n\n```\nenter_region:\n            | 复制锁到寄存器并将锁设为1\n            TSL REGISTER,LOCK              \n            | 锁是 0 吗？\n          CMP REGISTER,#0                             \n          | 若不是零，说明锁已被设置，所以循环\n          JNE enter_region                            \n          | 返回调用者，进入临界区\n          RET                                              \n\nleave_region:\n\n            | 在锁中存入 0\n            MOVE LOCK,#0                  \n      | 返回调用者\n          RET                                              \n```\n\n我们可以看到这个解决方案的思想和 Peterson 的思想很相似。假设存在如下共 4 指令的汇编语言程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1 ，随后这个原来的值和 0 做对比。如果它不是零，说明之前已经被加过锁，则程序返回到开始并再次测试。经过一段时间后（可长可短），该值变为 0 （当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁也比较简单，程序只需要将 0 存入 lock 即可，不需要特殊的同步指令。\n\n现在有了一种很明确的做法，那就是进程在进入临界区之前会先调用 `enter_region`，判断是否进行循环，如果 lock 的值是 1 ，进行无限循环，如果 lock 是 0，不进入循环并进入临界区。在进程从临界区返回时它调用 `leave_region`，这会把 lock 设置为 0 。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region ，解法才能奏效。\n\n还有一个可以替换 TSL 的指令是 `XCHG`，它原子性的交换了两个位置的内容，例如，一个寄存器与一个内存字，代码如下\n\n```\nenter_region:\n        | 把 1 放在内存器中\n        MOVE REGISTER,#1    \n    | 交换寄存器和锁变量的内容\n        XCHG REGISTER,LOCK          \n    | 锁是 0 吗？\n        CMP REGISTER,#0     \n    | 若不是 0 ，锁已被设置，进行循环\n        JNE enter_region                    \n    | 返回调用者，进入临界区\n        RET                                                     \n\nleave_region:                \n        | 在锁中存入 0 \n        MOVE LOCK,#0    \n    | 返回调用者\n        RET                                                     \n```\n\nXCHG 的本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在底层同步中使用 XCHG 指令。\n\n### 睡眠与唤醒\n\n上面解法中的 Peterson 、TSL 和 XCHG 解法都是正确的，但是它们都有忙等待的缺点。这些解法的本质上都是一样的，先检查是否能够进入临界区，若不允许，则该进程将原地等待，直到允许为止。\n\n这种方式不但浪费了 CPU 时间，而且还可能引起意想不到的结果。考虑一台计算机上有两个进程，这两个进程具有不同的优先级，`H` 是属于优先级比较高的进程，`L` 是属于优先级比较低的进程。进程调度的规则是不论何时只要 H 进程处于就绪态 H 就开始运行。在某一时刻，L 处于临界区中，此时 H 变为就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 要开始忙等，但由于当 H 就绪时 L 就不会被调度，L 从来不会有机会离开关键区域，所以 H 会变成死循环，有时将这种情况称为`优先级反转问题(priority inversion problem)`。\n\n现在让我们看一下进程间的通信原语，这些原语在不允许它们进入关键区域之前会阻塞而不是浪费 CPU 时间，最简单的是 `sleep` 和 `wakeup`。Sleep 是一个能够造成调用者阻塞的系统调用，也就是说，这个系统调用会暂停直到其他进程唤醒它。wakeup 调用有一个参数，即要唤醒的进程。还有一种方式是 wakeup 和 sleep 都有一个参数，即 sleep 和 wakeup 需要匹配的内存地址。\n\n#### 生产者 - 消费者问题\n\n作为这些私有原语的例子，让我们考虑`生产者-消费者(producer-consumer)` 问题，也称作 `有界缓冲区(bounded-buffer)` 问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是`生产者(producer)`，将信息放入缓冲区， 另一个是`消费者(consumer)`，会从缓冲区中取出。也可以把这个问题一般化为 m 个生产者和 n 个消费者的问题，但是我们这里只讨论一个生产者和一个消费者的情况，这样可以简化实现方案。\n\n如果缓冲队列已满，那么当生产者仍想要将数据写入缓冲区的时候，会出现问题。它的解决办法是让生产者睡眠，也就是阻塞生产者。等到消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样的，当消费者试图从缓冲区中取数据，但是发现缓冲区为空时，消费者也会睡眠，阻塞。直到生产者向其中放入一个新的数据。\n\n这个逻辑听起来比较简单，而且这种方式也需要一种称作 `监听` 的变量，这个变量用于监视缓冲区的数据，我们暂定为 count，如果缓冲区最多存放 N 个数据项，生产者会每次判断 count 是否达到 N，否则生产者向缓冲区放入一个数据项并增量 count 的值。消费者的逻辑也很相似：首先测试 count 的值是否为 0 ，如果为 0 则消费者睡眠、阻塞，否则会从缓冲区取出数据并使 count 数量递减。每个进程也会检查检查是否其他线程是否应该被唤醒，如果应该被唤醒，那么就唤醒该线程。下面是生产者消费者的代码\n\n```\n/* 缓冲区 slot 槽的数量 */\n#define N 100                        \n/* 缓冲区数据的数量 */\nint count = 0                                        \n\n// 生产者\nvoid producer(void){\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){                \n    /* 生成下一项数据 */\n    item = produce_item()                \n    /* 如果缓存区是满的，就会阻塞 */\n    if(count == N){\n      sleep();                                    \n    }\n\n    /* 把当前数据放在缓冲区中 */\n    insert_item(item);\n    /* 增加缓冲区 count 的数量 */\n    count = count + 1;                    \n    if(count == 1){\n      /* 缓冲区是否为空？ */\n      wakeup(consumer);                    \n    }\n  }\n}\n\n// 消费者\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 如果缓冲区是空的，就会进行阻塞 */\n      if(count == 0){                         \n      sleep();\n    }\n    /* 从缓冲区中取出一个数据 */\n       item = remove_item();           \n    /* 将缓冲区的 count 数量减一 */\n    count = count - 1\n    /* 缓冲区满嘛？ */\n    if(count == N - 1){                    \n      wakeup(producer);        \n    }\n    /* 打印数据项 */\n    consumer_item(item);                \n  }\n\n}\n```\n\n为了在 C 语言中描述像是 `sleep` 和 `wakeup` 的系统调用，我们将以库函数调用的形式来表示。它们不是 C 标准库的一部分，但可以在实际具有这些系统调用的任何系统上使用。代码中未实现的 `insert_item` 和 `remove_item` 用来记录将数据项放入缓冲区和从缓冲区取出数据等。\n\n现在让我们回到生产者 - 消费者问题上来，上面代码中会产生竞争条件，因为 count 这个变量是暴露在大众视野下的。有可能出现下面这种情况：缓冲区为空，此时消费者刚好读取 count 的值发现它为 0 。此时调度程序决定暂停消费者并启动运行生产者。生产者生产了一条数据并把它放在缓冲区中，然后增加 count 的值，并注意到它的值是 1 。由于 count 为 0，消费者必须处于睡眠状态，因此生产者调用 `wakeup` 来唤醒消费者。但是，消费者此时在逻辑上并没有睡眠，所以 wakeup 信号会丢失。当消费者下次启动后，它会查看之前读取的 count 值，发现它的值是 0 ，然后在此进行睡眠。不久之后生产者会填满整个缓冲区，在这之后会阻塞，这样一来两个进程将永远睡眠下去。\n\n引起上面问题的本质是 **唤醒尚未进行睡眠状态的进程会导致唤醒丢失**。如果它没有丢失，则一切都很正常。一种快速解决上面问题的方式是增加一个`唤醒等待位(wakeup waiting bit)`。当一个 wakeup 信号发送给仍在清醒的进程后，该位置为 1 。之后，当进程尝试睡眠的时候，如果唤醒等待位为 1 ，则该位清除，而进程仍然保持清醒。\n\n然而，当进程数量有许多的时候，这时你可以说通过增加唤醒等待位的数量来唤醒等待位，于是就有了 2、4、6、8 个唤醒等待位，但是并没有从根本上解决问题。\n\n### 信号量\n\n信号量是 E.W.Dijkstra 在 1965 年提出的一种方法，它使用一个整形变量来累计唤醒次数，以供之后使用。在他的观点中，有一个新的变量类型称作 `信号量(semaphore)`。一个信号量的取值可以是 0 ，或任意正数。0 表示的是不需要任何唤醒，任意的正数表示的就是唤醒次数。\n\nDijkstra 提出了信号量有两个操作，现在通常使用 `down` 和 `up`（分别可以用 sleep 和 wakeup 来表示）。down 这个指令的操作会检查值是否大于 0 。如果大于 0 ，则将其值减 1 ；若该值为 0 ，则进程将睡眠，而且此时 down 操作将会继续执行。检查数值、修改变量值以及可能发生的睡眠操作均为一个单一的、不可分割的 `原子操作(atomic action)` 完成。这会保证一旦信号量操作开始，没有其他的进程能够访问信号量，直到操作完成或者阻塞。这种原子性对于解决同步问题和避免竞争绝对必不可少。\n\n> 原子性操作指的是在计算机科学的许多其他领域中，一组相关操作全部执行而没有中断或根本不执行。\n\nup 操作会使信号量的值 + 1。如果一个或者多个进程在信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个并允许该程完成 down 操作。因此，对一个进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍然是 0 ，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞是一样的道理。\n\n#### 用信号量解决生产者 - 消费者问题\n\n用信号量解决丢失的 wakeup 问题，代码如下\n\n```\n/* 定义缓冲区槽的数量 */\n#define N 100\n/* 信号量是一种特殊的 int */\ntypedef int semaphore;\n/* 控制关键区域的访问 */\nsemaphore mutex = 1;\n/* 统计 buffer 空槽的数量 */\nsemaphore empty = N;\n/* 统计 buffer 满槽的数量 */\nsemaphore full = 0;                                                \n\nvoid producer(void){ \n\n  int item;  \n\n  /* TRUE 的常量是 1 */\n  while(TRUE){            \n    /* 产生放在缓冲区的一些数据 */\n    item = producer_item();        \n    /* 将空槽数量减 1  */\n    down(&empty);    \n    /* 进入关键区域  */\n    down(&mutex);    \n    /* 把数据放入缓冲区中 */\n    insert_item(item);\n    /* 离开临界区 */\n    up(&mutex);    \n    /* 将 buffer 满槽数量 + 1 */\n    up(&full);                                                        \n  }\n}\n\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 缓存区满槽数量 - 1 */\n    down(&full);\n    /* 进入缓冲区 */    \n    down(&mutex);\n    /* 从缓冲区取出数据 */\n    item = remove_item();    \n    /* 离开临界区 */\n    up(&mutex);    \n    /* 将空槽数目 + 1 */\n    up(&empty);    \n    /* 处理数据 */\n    consume_item(item);                                            \n  }\n\n}\n```\n\n为了确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用来实现。而且操作系统只需在执行以下操作时暂时屏蔽全部中断：**检查信号量、更新、必要时使进程睡眠**。由于这些操作仅需要非常少的指令，因此中断不会造成影响。如果使用多个 CPU，那么信号量应该被锁进行保护。使用 TSL 或者 XCHG 指令用来确保同一时刻只有一个 CPU 对信号量进行操作。\n\n使用 TSL 或者 XCHG 来防止几个 CPU 同时访问一个信号量，与生产者或消费者使用忙等待来等待其他腾出或填充缓冲区是完全不一样的。前者的操作仅需要几个毫秒，而生产者或消费者可能需要任意长的时间。\n\n上面这个解决方案使用了三种信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex，用来确保生产者和消费者不会同时进入缓冲区。`Full` 被初始化为 0 ，empty 初始化为缓冲区中插槽数，mutex 初始化为 1。信号量初始化为 1 并且由两个或多个进程使用，以确保它们中同时只有一个可以进入关键区域的信号被称为 `二进制信号量(binary semaphores)`。如果每个进程都在进入关键区域之前执行 down 操作，而在离开关键区域之后执行 up 操作，则可以确保相互互斥。\n\n现在我们有了一个好的进程间原语的保证。然后我们再来看一下中断的顺序保证\n\n1.  硬件压入堆栈程序计数器等\n    \n2.  硬件从中断向量装入新的程序计数器\n    \n3.  汇编语言过程保存寄存器的值\n    \n4.  汇编语言过程设置新的堆栈\n    \n5.  C 中断服务器运行（典型的读和缓存写入）\n    \n6.  调度器决定下面哪个程序先运行\n    \n7.  C 过程返回至汇编代码\n    \n8.  汇编语言过程开始运行新的当前进程\n    \n\n在使用`信号量`的系统中，隐藏中断的自然方法是让每个 I/O 设备都配备一个信号量，该信号量最初设置为 0。在 I/O 设备启动后，中断处理程序立刻对相关联的信号执行一个 `down` 操作，于是进程立即被阻塞。当中断进入时，中断处理程序随后对相关的信号量执行一个 `up`操作，能够使已经阻止的进程恢复运行。在上面的中断处理步骤中，其中的第 5 步 `C 中断服务器运行` 就是中断处理程序在信号量上执行的一个 up 操作，所以在第 6 步中，操作系统能够执行设备驱动程序。当然，如果有几个进程已经处于就绪状态，调度程序可能会选择接下来运行一个更重要的进程，我们会在后面讨论调度的算法。\n\n上面的代码实际上是通过两种不同的方式来使用信号量的，而这两种信号量之间的区别也是很重要的。`mutex` 信号量用于互斥。它用于确保任意时刻只有一个进程能够对缓冲区和相关变量进行读写。互斥是用于避免进程混乱所必须的一种操作。\n\n另外一个信号量是关于`同步(synchronization)`的。`full` 和 `empty` 信号量用于确保事件的发生或者不发生。在这个事例中，它们确保了缓冲区满时生产者停止运行；缓冲区为空时消费者停止运行。这两个信号量的使用与 mutex 不同。\n\n### 互斥量\n\n如果不需要信号量的计数能力时，可以使用信号量的一个简单版本，称为 `mutex(互斥量)`。互斥量的优势就在于在一些共享资源和一段代码中保持互斥。由于互斥的实现既简单又有效，这使得互斥量在实现用户空间线程包时非常有用。\n\n互斥量是一个处于两种状态之一的共享变量：`解锁(unlocked)` 和 `加锁(locked)`。这样，只需要一个二进制位来表示它，不过一般情况下，通常会用一个 `整形(integer)` 来表示。0 表示解锁，其他所有的值表示加锁，比 1 大的值表示加锁的次数。\n\nmutex 使用两个过程，当一个线程（或者进程）需要访问关键区域时，会调用 `mutex_lock` 进行加锁。如果互斥锁当前处于解锁状态（表示关键区域可用），则调用成功，并且调用线程可以自由进入关键区域。\n\n另一方面，如果 mutex 互斥量已经锁定的话，调用线程会阻塞直到关键区域内的线程执行完毕并且调用了 `mutex_unlock` 。如果多个线程在 mutex 互斥量上阻塞，将随机选择一个线程并允许它获得锁。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkXJy2jibeQGLUNaWLCLWibibpIKfM2RLogQ38s0VHMdVqUmfVLcPNdwK3w/640?wx_fmt=png)\n\n由于 mutex 互斥量非常简单，所以只要有 TSL 或者是 XCHG 指令，就可以很容易地在用户空间实现它们。用于用户级线程包的 `mutex_lock` 和 `mutex_unlock` 代码如下，XCHG 的本质也一样。\n\n```\nmutex_lock:\n            | 将互斥信号量复制到寄存器，并将互斥信号量置为1\n            TSL REGISTER,MUTEX\n      | 互斥信号量是 0 吗？\n            CMP REGISTER,#0 \n      | 如果互斥信号量为0，它被解锁，所以返回\n            JZE ok  \n      | 互斥信号正在使用；调度其他线程\n            CALL thread_yield   \n      | 再试一次\n            JMP mutex_lock  \n      | 返回调用者，进入临界区\nok:     RET                                                     \n\nmutex_unlcok:\n            | 将 mutex 置为 0 \n            MOVE MUTEX,#0   \n      | 返回调用者\n            RET                                                     \n```\n\nmutex_lock 的代码和上面 enter_region 的代码很相似，我们可以对比着看一下\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkzgYKTTgzB7hSZvozXicEez3sabKfYzxQcuehvgtiaF4NicljJg2PZJOLg/640?wx_fmt=png)\n\n上面代码最大的区别你看出来了吗？\n\n*   根据上面我们对 TSL 的分析，我们知道，如果 TSL 判断没有进入临界区的进程会进行无限循环获取锁，而在 TSL 的处理中，如果 mutex 正在使用，那么就调度其他线程进行处理。所以上面最大的区别其实就是在判断 mutex/TSL 之后的处理。\n    \n*   在（用户）线程中，情况有所不同，因为没有时钟来停止运行时间过长的线程。结果是通过忙等待的方式来试图获得锁的线程将永远循环下去，决不会得到锁，因为这个运行的线程不会让其他线程运行从而释放锁，其他线程根本没有获得锁的机会。在后者获取锁失败时，它会调用 `thread_yield` 将 CPU 放弃给另外一个线程。结果就不会进行忙等待。在该线程下次运行时，它再一次对锁进行测试。\n    \n\n上面就是 enter_region 和 mutex_lock 的差别所在。由于 thread_yield 仅仅是一个用户空间的线程调度，所以它的运行非常快捷。这样，`mutex_lock` 和 `mutex_unlock` 都不需要任何内核调用。通过使用这些过程，用户线程完全可以实现在用户空间中的同步，这个过程仅仅需要少量的同步。\n\n我们上面描述的互斥量其实是一套调用框架中的指令。从软件角度来说，总是需要更多的特性和同步原语。例如，有时线程包提供一个调用 `mutex_trylock`，这个调用尝试获取锁或者返回错误码，但是不会进行加锁操作。这就给了调用线程一个灵活性，以决定下一步做什么，是使用替代方法还是等候下去。\n\n#### Futexes\n\n随着并行的增加，有效的`同步(synchronization)`和`锁定(locking)` 对于性能来说是非常重要的。如果进程等待时间很短，那么`自旋锁(Spin lock)` 是非常有效；但是如果等待时间比较长，那么这会浪费 CPU 周期。如果进程很多，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞是更有效的方式。不幸的是，这种方式也会导致另外的问题：它可以在进程竞争频繁的时候运行良好，但是在竞争不是很激烈的情况下内核切换的消耗会非常大，而且更困难的是，预测锁的竞争数量更不容易。\n\n有一种有趣的解决方案是把两者的优点结合起来，提出一种新的思想，称为 `futex`，或者是 `快速用户空间互斥(fast user space mutex)`，是不是听起来很有意思？\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkW2sY6sXshsFia7jXlNdhuB5XwTt6cjo1pqLgyvV1gcXnNfMASjiasAFA/640?wx_fmt=png)\n\nfutex 是 `Linux` 中的特性实现了基本的锁定（很像是互斥锁）而且避免了陷入内核中，因为内核的切换的开销非常大，这样做可以大大提高性能。futex 由两部分组成：**内核服务和用户库**。内核服务提供了了一个 `等待队列(wait queue)` 允许多个进程在锁上排队等待。除非内核明确的对他们解除阻塞，否则它们不会运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXksBadzURKQx0t6EagaQBFBZsNcKeXSLCOl01WfJeyIrTU3DCoXz5DbA/640?wx_fmt=png)\n\n对于一个进程来说，把它放到等待队列需要昂贵的系统调用，这种方式应该被避免。在没有竞争的情况下，futex 可以直接在用户空间中工作。这些进程共享一个 32 位`整数(integer)` 作为公共锁变量。假设锁的初始化为 1，我们认为这时锁已经被释放了。线程通过执行原子性的操作`减少并测试(decrement and test)` 来抢占锁。decrement and set 是 Linux 中的原子功能，由包裹在 C 函数中的内联汇编组成，并在头文件中进行定义。下一步，线程会检查结果来查看锁是否已经被释放。如果锁现在不是锁定状态，那么刚好我们的线程可以成功抢占该锁。然而，如果锁被其他线程持有，抢占锁的线程不得不等待。在这种情况下，futex 库不会`自旋`，但是会使用一个系统调用来把线程放在内核中的等待队列中。这样一来，切换到内核的开销已经是合情合理的了，因为线程可以在任何时候阻塞。当线程完成了锁的工作时，它会使用原子性的 `增加并测试(increment and test)` 释放锁，并检查结果以查看内核等待队列上是否仍阻止任何进程。如果有的话，它会通知内核可以对等待队列中的一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与竞争。\n\n#### Pthreads 中的互斥量\n\nPthreads 提供了一些功能用来同步线程。最基本的机制是使用互斥量变量，可以锁定和解锁，用来保护每个关键区域。希望进入关键区域的线程首先要尝试获取 mutex。如果 mutex 没有加锁，线程能够马上进入并且互斥量能够自动锁定，从而阻止其他线程进入。如果 mutex 已经加锁，调用线程会阻塞，直到 mutex 解锁。如果多个线程在相同的互斥量上等待，当互斥量解锁时，只有一个线程能够进入并且重新加锁。这些锁并不是必须的，程序员需要正确使用它们。\n\n下面是与互斥量有关的函数调用\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkjhv2Kpw5NOIUR9iaZqLkRyb8oR34ThPSm8mZJbwfmVYcC2DwiaU6f1w/640?wx_fmt=png)\n\n像我们想象中的一样，mutex 能够被创建和销毁，扮演这两个角色的分别是 `Phread_mutex_init` 和 `Pthread_mutex_destroy`。mutex 也可以通过 `Pthread_mutex_lock` 来进行加锁，如果互斥量已经加锁，则会阻塞调用者。还有一个调用`Pthread_mutex_trylock` 用来尝试对线程加锁，当 mutex 已经被加锁时，会返回一个错误代码而不是阻塞调用者。这个调用允许线程有效的进行忙等。最后，`Pthread_mutex_unlock` 会对 mutex 解锁并且释放一个正在等待的线程。\n\n除了互斥量以外，`Pthreads` 还提供了第二种同步机制： `条件变量(condition variables)` 。mutex 可以很好的允许或阻止对关键区域的访问。条件变量允许线程由于未满足某些条件而阻塞。绝大多数情况下这两种方法是一起使用的。下面我们进一步来研究线程、互斥量、条件变量之间的关联。\n\n下面再来重新认识一下生产者和消费者问题：一个线程将东西放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区没有空槽可以使用了，生产者线程会阻塞起来直到有一个线程可以使用。生产者使用 mutex 来进行原子性检查从而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自己并在以后被唤醒。这便是条件变量做的工作。\n\n下面是一些与条件变量有关的最重要的 pthread 调用\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk839icYzflFsfMELQx6wusdDtK5VibFSBT3icKPIKBXpkO0jNshBocXZmA/640?wx_fmt=png)\n\n上表中给出了一些调用用来创建和销毁条件变量。条件变量上的主要属性是 `Pthread_cond_wait` 和 `Pthread_cond_signal`。前者阻塞调用线程，直到其他线程发出信号为止（使用后者调用）。阻塞的线程通常需要等待唤醒的信号以此来释放资源或者执行某些其他活动。只有这样阻塞的线程才能继续工作。条件变量允许等待与阻塞原子性的进程。`Pthread_cond_broadcast` 用来唤醒多个阻塞的、需要等待信号唤醒的线程。\n\n> 需要注意的是，条件变量（不像是信号量）不会存在于内存中。如果将一个信号量传递给一个没有线程等待的条件变量，那么这个信号就会丢失，这个需要注意\n\n下面是一个使用互斥量和条件变量的例子\n\n```\n#include <stdio.h>\n#include <pthread.h>\n\n/* 需要生产的数量 */\n#define MAX 1000000000                                        \npthread_mutex_t the_mutex;\n/* 使用信号量 */\npthread_cond_t condc,condp;                                \nint buffer = 0;\n\n/* 生产数据 */\nvoid *producer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i <= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&the_mutex);                \n    while(buffer != 0){\n      pthread_cond_wait(&condp,&the_mutex);\n    }\n    /* 把他们放在缓冲区中 */\n    buffer = i;            \n    /* 唤醒消费者 */\n    pthread_cond_signal(&condc);    \n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&the_mutex);            \n  }\n  pthread_exit(0);\n\n}\n\n/* 消费数据 */\nvoid *consumer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i <= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&the_mutex);                \n    while(buffer == 0){\n      pthread_cond_wait(&condc,&the_mutex);\n    }\n    /* 把他们从缓冲区中取出 */\n    buffer = 0;    \n    /* 唤醒生产者 */\n    pthread_cond_signal(&condp);\n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&the_mutex);            \n  }\n  pthread_exit(0);\n\n}                              \n```\n\n### 管程\n\n为了能够编写更加准确无误的程序，Brinch Hansen 和 Hoare 提出了一个更高级的同步原语叫做 `管程(monitor)`。他们两个人的提案略有不同，通过下面的描述你就可以知道。管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。下面展示了一种抽象的，类似 Pascal 语言展示的简洁的管程。不能用 C 语言进行描述，因为管程是语言概念而 C 语言并不支持管程。\n\n```\nmonitor example\n    integer i;\n    condition c;\n\n    procedure producer();\n  ...\n    end;    \n\n    procedure consumer();\n    .\n    end;\nend monitor;\n```\n\n管程有一个很重要的特性，即在任何时候管程中只能有一个活跃的进程，这一特性使管程能够很方便的实现互斥操作。管程是编程语言的特性，所以编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。通常情况下，当进程调用管程中的程序时，该程序的前几条指令会检查管程中是否有其他活跃的进程。如果有的话，调用进程将被挂起，直到另一个进程离开管程才将其唤醒。如果没有活跃进程在使用管程，那么该调用进程才可以进入。\n\n进入管程中的互斥由编译器负责，但是一种通用做法是使用 `互斥量(mutex)` 和 `二进制信号量(binary semaphore)`。由于编译器而不是程序员在操作，因此出错的几率会大大降低。在任何时候，编写管程的程序员都无需关心编译器是如何处理的。他只需要知道将所有的临界区转换成为管程过程即可。绝不会有两个进程同时执行临界区中的代码。\n\n即使管程提供了一种简单的方式来实现互斥，但在我们看来，这还不够。因为我们还需要一种在进程无法执行被阻塞。在生产者 - 消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放在管程程序中，但是生产者在发现缓冲区满的时候该如何阻塞呢？\n\n解决的办法是引入`条件变量(condition variables)` 以及相关的两个操作 `wait` 和 `signal`。当一个管程程序发现它不能运行时（例如，生产者发现缓冲区已满），它会在某个条件变量（如 full）上执行 `wait` 操作。这个操作造成调用进程阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面的 pthread 中我们已经探讨过条件变量的实现细节了。另一个进程，比如消费者可以通过执行 `signal` 来唤醒阻塞的调用进程。\n\n> Brinch Hansen 和 Hoare 在对进程唤醒上有所不同，Hoare 建议让新唤醒的进程继续运行；而挂起另外的进程。而 Brinch Hansen 建议让执行 signal 的进程必须退出管程，这里我们采用 Brinch Hansen 的建议，因为它在概念上更简单，并且更容易实现。\n\n如果在一个条件变量上有若干进程都在等待，则在对该条件执行 signal 操作后，系统调度程序只能选择其中一个进程恢复运行。\n\n顺便提一下，这里还有上面两位教授没有提出的第三种方式，它的理论是让执行 signal 的进程继续运行，等待这个进程退出管程时，其他进程才能进入管程。\n\n条件变量不是计数器。条件变量也不能像信号量那样积累信号以便以后使用。所以，如果向一个条件变量发送信号，但是该条件变量上没有等待进程，那么信号将会丢失。也就是说，**wait 操作必须在 signal 之前执行**。\n\n下面是一个使用 `Pascal` 语言通过管程实现的生产者 - 消费者问题的解法\n\n```\nmonitor ProducerConsumer\n        condition full,empty;\n        integer count;\n\n        procedure insert(item:integer);\n        begin\n                if count = N then wait(full);\n                insert_item(item);\n                count := count + 1;\n                if count = 1 then signal(empty);\n        end;\n\n        function remove:integer;\n        begin\n                if count = 0 then wait(empty);\n                remove = remove_item;\n                count := count - 1;\n                if count = N - 1 then signal(full);\n        end;\n\n        count := 0;\nend monitor;\n\nprocedure producer;\nbegin\n            while true do\n      begin \n                  item = produce_item;\n                  ProducerConsumer.insert(item);\n      end\nend;\n\nprocedure consumer;\nbegin \n            while true do\n            begin\n                        item = ProducerConsumer.remove;\n                        consume_item(item);\n            end\nend;\n```\n\n读者可能觉得 wait 和 signal 操作看起来像是前面提到的 sleep 和 wakeup ，而且后者存在严重的竞争条件。它们确实很像，但是有个关键的区别：sleep 和 wakeup 之所以会失败是因为当一个进程想睡眠时，另一个进程试图去唤醒它。使用管程则不会发生这种情况。管程程序的自动互斥保证了这一点，如果管程过程中的生产者发现缓冲区已满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成并且把生产者标志为不可运行之前，是不会允许消费者进入管程的。\n\n尽管类 Pascal 是一种想象的语言，但还是有一些真正的编程语言支持，比如 Java （终于轮到大 Java 出场了），Java 是能够支持管程的，它是一种 `面向对象`的语言，支持用户级线程，还允许将方法划分为类。只要将关键字 `synchronized` 关键字加到方法中即可。Java 能够保证一旦某个线程执行该方法，就不允许其他线程执行该对象中的任何 synchronized 方法。没有关键字 synchronized ，就不能保证没有交叉执行。\n\n下面是 Java 使用管程解决的生产者 - 消费者问题\n\n```\npublic class ProducerConsumer {\n  // 定义缓冲区大小的长度\n  static final int N = 100;\n  // 初始化一个新的生产者线程\n  static Producer p = new Producer();\n  // 初始化一个新的消费者线程\n  static Consumer c = new Consumer();        \n  // 初始化一个管程\n  static Our_monitor mon = new Our_monitor(); \n\n  // run 包含了线程代码\n  static class Producer extends Thread{\n    public void run(){                                                \n      int item;\n      // 生产者循环\n      while(true){                                                        \n        item = produce_item();\n        mon.insert(item);\n      }\n    }\n    // 生产代码\n    private int produce_item(){...}                        \n  }\n\n  // run 包含了线程代码\n  static class consumer extends Thread {\n    public void run( ) {                                            \n           int item;\n      while(true){\n        item = mon.remove();\n                consume_item(item);\n      }\n    }\n    // 消费代码\n    private int produce_item(){...}                        \n  }\n\n  // 这是管程\n  static class Our_monitor {                                    \n    private int buffer[] = new int[N];\n    // 计数器和索引\n    private int count = 0,lo = 0,hi = 0;            \n\n    private synchronized void insert(int val){\n      if(count == N){\n        // 如果缓冲区是满的，则进入休眠\n        go_to_sleep();                                                \n      }\n      // 向缓冲区插入内容\n            buffer[hi] = val;                   \n      // 找到下一个槽的为止\n      hi = (hi + 1) % N;                 \n      // 缓冲区中的数目自增 1 \n      count = count + 1;                                            \n      if(count == 1){\n        // 如果消费者睡眠，则唤醒\n        notify();                                                            \n      }\n    }\n\n    private synchronized void remove(int val){\n      int val;\n      if(count == 0){\n        // 缓冲区是空的，进入休眠\n        go_to_sleep();                                                \n      }\n      // 从缓冲区取出数据\n      val = buffer[lo];                \n      // 设置待取出数据项的槽\n      lo = (lo + 1) % N;                    \n      // 缓冲区中的数据项数目减 1 \n      count = count - 1;                                            \n      if(count = N - 1){\n        // 如果生产者睡眠，唤醒它\n        notify();                                                            \n      }\n      return val;\n    }\n\n    private void go_to_sleep() {\n      try{\n        wait( );\n      }catch(Interr uptedExceptionexc) {};\n    }\n  }\n\n}\n```\n\n上面的代码中主要设计四个类，`外部类(outer class)` ProducerConsumer 创建并启动两个线程，p 和 c。第二个类和第三个类 `Producer` 和 `Consumer` 分别包含生产者和消费者代码。最后，`Our_monitor` 是管程，它有两个同步线程，用于在共享缓冲区中插入和取出数据。\n\n在前面的所有例子中，生产者和消费者线程在功能上与它们是相同的。生产者有一个无限循环，该无限循环产生数据并将数据放入公共缓冲区中；消费者也有一个等价的无限循环，该无限循环用于从缓冲区取出数据并完成一系列工作。\n\n程序中比较耐人寻味的就是 `Our_monitor` 了，它包含缓冲区、管理变量以及两个同步方法。当生产者在 insert 内活动时，它保证消费者不能在 remove 方法中运行，从而保证更新变量以及缓冲区的安全性，并且不用担心竞争条件。变量 count 记录在缓冲区中数据的数量。变量 `lo` 是缓冲区槽的序号，指出将要取出的下一个数据项。类似地，`hi` 是缓冲区中下一个要放入的数据项序号。允许 lo = hi，含义是在缓冲区中有 0 个或 N 个数据。\n\nJava 中的同步方法与其他经典管程有本质差别：Java 没有内嵌的条件变量。然而，Java 提供了 wait 和 notify 分别与 sleep 和 wakeup 等价。\n\n**通过临界区自动的互斥，管程比信号量更容易保证并行编程的正确性**。但是管程也有缺点，我们前面说到过管程是一个编程语言的概念，编译器必须要识别管程并用某种方式对其互斥作出保证。**C、Pascal 以及大多数其他编程语言都没有管程**，所以不能依靠编译器来遵守互斥规则。\n\n与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问共享内存的一个或多个 CPU 上的互斥问题的。通过将信号量放在共享内存中并用 `TSL` 或 `XCHG` 指令来保护它们，可以避免竞争。但是如果是在分布式系统中，可能同时具有多个 CPU 的情况，并且每个 CPU 都有自己的私有内存呢，它们通过网络相连，那么这些原语将会失效。因为信号量太低级了，而管程在少数几种编程语言之外无法使用，所以还需要其他方法。\n\n### 消息传递\n\n上面提到的其他方法就是 `消息传递(messaage passing)`。这种进程间通信的方法使用两个原语 `send` 和 `receive` ，它们像信号量而不像管程，是系统调用而不是语言级别。示例如下\n\n```\nsend(destination, &message);\n\nreceive(source, &message);\n```\n\nsend 方法用于向一个给定的目标发送一条消息，receive 从一个给定的源接受一条消息。如果没有消息，接受者可能被阻塞，直到接受一条消息或者带着错误码返回。\n\n#### 消息传递系统的设计要点\n\n消息传递系统现在面临着许多信号量和管程所未涉及的问题和设计难点，尤其对那些在网络中不同机器上的通信状况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接收方可以达成一致：一旦接受到消息后，接收方马上回送一条特殊的 `确认(acknowledgement)` 消息。如果发送方在一段时间间隔内未收到确认，则重发消息。\n\n现在考虑消息本身被正确接收，而返回给发送着的确认消息丢失的情况。发送者将重发消息，这样接受者将收到两次相同的消息。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaWMs2vSqjpXtVDia8zUVjIPup5ZQHWgGQT55NgvLs2OgkaCuw2TSdEA/640?wx_fmt=png)\n\n对于接收者来说，如何区分新的消息和一条重发的老消息是非常重要的。通常采用在每条原始消息中嵌入一个连续的序号来解决此问题。如果接受者收到一条消息，它具有与前面某一条消息一样的序号，就知道这条消息是重复的，可以忽略。\n\n消息系统还必须处理如何命名进程的问题，以便在发送或接收调用中清晰的指明进程。`身份验证(authentication)` 也是一个问题，比如客户端怎么知道它是在与一个真正的文件服务器通信，从发送方到接收方的信息有可能被中间人所篡改。\n\n#### 用消息传递解决生产者 - 消费者问题\n\n现在我们考虑如何使用消息传递来解决生产者 - 消费者问题，而不是共享缓存。下面是一种解决方式\n\n```\n/* buffer 中槽的数量 */\n#define N 100                                                    \n\nvoid producer(void){\n\n  int item;\n  /* buffer 中槽的数量 */\n  message m;                                                    \n\n  while(TRUE){\n    /* 生成放入缓冲区的数据 */\n    item = produce_item();                        \n    /* 等待消费者发送空缓冲区 */\n    receive(consumer,&m);                            \n    /* 建立一个待发送的消息 */\n    build_message(&m,item);                        \n    /* 发送给消费者 */\n    send(consumer,&m);                                \n  }\n\n}\n\nvoid consumer(void){\n\n  int item,i;\n  message m;\n\n  /* 循环N次 */\n  for(int i = 0;i < N;i++){                        \n    /* 发送N个缓冲区 */\n    send(producer,&m);                                \n  }\n  while(TRUE){\n    /* 接受包含数据的消息 */\n    receive(producer,&m);                            \n    /* 将数据从消息中提取出来 */\n      item = extract_item(&m);                    \n    /* 将空缓冲区发送回生产者 */\n    send(producer,&m);                                \n    /* 处理数据 */\n    consume_item(item);                                \n  }\n\n}\n```\n\n假设所有的消息都有相同的大小，并且在尚未接受到发出的消息时，由操作系统自动进行缓冲。在该解决方案中共使用 N 条消息，这就类似于一块共享内存缓冲区的 N 个槽。消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并返回一条填充了内容的消息。通过这种方式，系统中总的消息数量保持不变，所以消息都可以存放在事先确定数量的内存中。\n\n如果生产者的速度要比消费者快，则所有的消息最终都将被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度快，那么情况将正相反：所有的消息均为空，等待生产者来填充，消费者将被阻塞，以等待一条填充过的消息。\n\n消息传递的方式有许多变体，下面先介绍如何对消息进行 `编址`。\n\n*   一种方法是为每个进程分配一个唯一的地址，让消息按进程的地址编址。\n    \n*   另一种方式是引入一个新的数据结构，称为 `信箱(mailbox)`，信箱是一个用来对一定的数据进行缓冲的数据结构，信箱中消息的设置方法也有多种，典型的方法是在信箱创建时确定消息的数量。在使用信箱时，在 send 和 receive 调用的地址参数就是信箱的地址，而不是进程的地址。当一个进程试图向一个满的信箱发送消息时，它将被挂起，直到信箱中有消息被取走，从而为新的消息腾出地址空间。\n    \n\n### 屏障\n\n最后一个同步机制是准备用于进程组而不是进程间的生产者 - 消费者情况的。在某些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段，可以通过在每个阶段的结尾安装一个 `屏障(barrier)` 来实现这种行为。当一个进程到达屏障时，它会被屏障所拦截，直到所有的屏障都到达为止。屏障可用于一组进程同步，如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXktobEIdqeRzlib8Q2NE2hBvwcInsibDwCw80fyuPwWZ9GBugIdpLYMbeA/640?wx_fmt=png)\n\n在上图中我们可以看到，有四个进程接近屏障，这意味着每个进程都在进行运算，但是还没有到达每个阶段的结尾。过了一段时间后，A、B、D 三个进程都到达了屏障，各自的进程被挂起，但此时还不能进入下一个阶段呢，因为进程 B 还没有执行完毕。结果，当最后一个 C 到达屏障后，这个进程组才能够进入下一个阶段。\n\n### 避免锁：读 - 复制 - 更新\n\n最快的锁是根本没有锁。问题在于没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。答案当然是不可以。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其平均值，而此时你进行 A 的移动，会导致 B 会多次读到重复值，而某些值根本没有遇到过。\n\n然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用。窍门在于确保每个读操作要么读取旧的版本，要么读取新的版本，例如下面的树\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknibrKqGWqGZ6HbicKos4iaxdvNsfKaP6DtfTCnjYrjOeIibXzsd0mLcYlw/640?wx_fmt=png)\n\n上面的树中，读操作从根部到叶子遍历整个树。加入一个新节点 X 后，为了实现这一操作，我们要让这个节点在树中可见之前使它 \"恰好正确\"：我们对节点 X 中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使 X 称为 A 的子节点。所有的读操作都不会读到前后不一致的版本\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPU9vEZ58PLRxKcEUQIcCw118ayGmvjv9FyXrkr6XuSDxZe161dsBGA/640?wx_fmt=png)\n\n在上面的图中，我们接着移除 B 和 D。首先，将 A 的左子节点指针指向 C 。所有原本在 A 中的读操作将会后续读到节点 C ，而永远不会读到 B 和 D。也就是说，它们将只会读取到新版数据。同样，所有当前在 B 和 D 中的读操作将继续按照原始的数据结构指针并且读取旧版数据。所有操作均能正确运行，我们不需要锁住任何东西。而不需要锁住数据就能够移除 B 和 D 的主要原因就是 `读-复制-更新(Ready-Copy-Update,RCU)`，将更新过程中的移除和再分配过程分离开。\n\n调度\n--\n\n当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程 / 线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程 / 线程可以运行。操作系统中有一个叫做 `调度程序(scheduler)` 的角色存在，它就是做这件事儿的，该程序使用的算法叫做 `调度算法(scheduling algorithm)` 。\n\n尽管有一些不同，但许多适用于进程调度的处理方法同样也适用于线程调度。当内核管理线程的时候，调度通常会以线程级别发生，很少或者根本不会考虑线程属于哪个进程。下面我们会首先专注于进程和线程的调度问题，然后会明确的介绍线程调度以及它产生的问题。\n\n### 调度介绍\n\n让我们回到早期以磁带上的卡片作为输入的批处理系统的时代，那时候的调度算法非常简单：依次运行磁带上的每一个作业。对于多道程序设计系统，会复杂一些，因为通常会有多个用户在等待服务。一些大型机仍然将 `批处理`和 `分时服务`结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的用户。由于在这些机器中 CPU 是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。\n\n#### 进程行为\n\n几乎所有的进程（磁盘或网络）I/O 请求和计算都是交替运行的\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkhOIjeY0ia73Pm3dJCSLuhRl058IKIxx7RyI1LN1PYfthYvLHmJyicm1A/640?wx_fmt=png)\n\n如上图所示，CPU 不停顿的运行一段时间，然后发出一个系统调用等待 I/O 读写文件。完成系统调用后，CPU 又开始计算，直到它需要读更多的数据或者写入更多的数据为止。当一个进程等待外部设备完成工作而被阻塞时，才是 I/O 活动。  \n\n上面 a 是 CPU 密集型进程；b 是 I/O 密集型进程进程，a 因为在计算的时间上花费时间更长，因此称为`计算密集型(compute-bound)` 或者 `CPU 密集型(CPU-bound)`，b 因为 I/O 发生频率比较快因此称为 `I/O 密集型(I/O-bound)`。计算密集型进程有较长的 CPU 集中使用和较小频度的 I/O 等待。I/O 密集型进程有较短的 CPU 使用时间和较频繁的 I/O 等待。注意到上面两种进程的区分关键在于 CPU 的时间占用而不是 I/O 的时间占用。I/O 密集型的原因是因为它们没有在 I/O 之间花费更多的计算、而不是 I/O 请求时间特别长。无论数据到达后需要花费多少时间，它们都需要花费相同的时间来发出读取磁盘块的硬件请求。\n\n值得注意的是，随着 CPU 的速度越来越快，更多的进程倾向于 I/O 密集型。这种情况出现的原因是 CPU 速度的提升要远远高于硬盘。这种情况导致的结果是，未来对 I/O 密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。\n\n#### 何时调度\n\n第一个和调度有关的问题是`何时进行调度决策`。存在着需要调度处理的各种情形。首先，在创建一个新进程后，需要决定是运行父进程还是子进程。因为二者的进程都处于就绪态下，这是正常的调度决策，可以任意选择，也就是说，调度程序可以任意的选择子进程或父进程开始运行。\n\n第二，在进程退出时需要作出调度决定。因为此进程不再运行（因为它将不再存在），因此必须从就绪进程中选择其他进程运行。如果没有进程处于就绪态，系统提供的`空闲进程`通常会运行\n\n**什么是空闲进程**\n\n`空闲进程(system-supplied idle process)` 是 Microsoft 公司 windows 操作系统带有的系统进程，该进程是在各个处理器上运行的单个线程，它唯一的任务是在系统没有处理其他线程时占用处理器时间。System Idle Process 并不是一个真正的进程，它是`核心虚拟`出来的，多任务操作系统都存在。在没有可用的进程时，系统处于空运行状态，此时就是 System Idle Process 在正在运行。你可以简单的理解成，它代表的是 CPU 的空闲状态，数值越大代表处理器越空闲，可以通过 Windows 任务管理器查看 Windows 中的 CPU 利用率\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmC8dicWibXiabibrgW3hOqJ4xzMFwjPvSuicicpIKiaU711OUIUwOZO6T7pVw/640?wx_fmt=png)\n\n第三种情况是，当进程阻塞在 I/O 、信号量或其他原因时，必须选择另外一个进程来运行。有时，阻塞的原因会成为选择进程运行的关键因素。例如，如果 A 是一个重要进程，并且它正在等待 B 退出关键区域，让 B 退出关键区域从而使 A 得以运行。但是调度程序一般不会对这种情况进行考量。\n\n第四点，当 I/O 中断发生时，可以做出调度决策。如果中断来自 I/O 设备，而 I/O 设备已经完成了其工作，那么那些等待 I/O 的进程现在可以继续运行。由调度程序来决定是否准备运行新的进程还是重新运行已经中断的进程。\n\n如果硬件时钟以 50 或 60 Hz 或其他频率提供周期性中断，可以在每个时钟中断或第 k 个时钟中断处做出调度决策。根据如何处理时钟中断可以把调度算法可以分为两类。`非抢占式(nonpreemptive)` 调度算法挑选一个进程，让该进程运行直到被阻塞（阻塞在 I/O 上或等待另一个进程），或者直到该进程自动释放 CPU。即使该进程运行了若干个小时后，它也不会被强制挂起。这样会在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。\n\n另外一种情况是 `抢占式` 调度算法，它会选择一个进程，并使其在最大固定时间内运行。如果在时间间隔结束后仍在运行，这个进程会被挂起，调度程序会选择其他进程来运行（前提是存在就绪进程）。进行抢占式调度需要在时间间隔结束时发生时钟中断，以将 CPU 的控制权交还给调度程序。如果没有可用的时钟，那么非抢占式就是唯一的选择。\n\n#### 调度算法的分类\n\n毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境\n\n*   `批处理(Batch)`\n    \n*   `交互式(Interactive)`\n    \n*   `实时(Real time)`\n    \n\n批处理系统广泛应用于商业领域，比如用来处理工资单、存货清单、账目收入、账目支出、利息计算、索赔处理和其他周期性作业。在批处理系统中，一般会选择使用非抢占式算法或者周期性比较长的抢占式算法。这种方法可以减少线程切换因此能够提升性能。\n\n在交互式用户环境中，为了避免一个进程霸占 CPU 拒绝为其他进程服务，所以需要抢占式算法。即使没有进程有意要一直运行下去，但是，由于某个进程出现错误也有可能无限期的排斥其他所有进程。为了避免这种情况，抢占式也是必须的。服务器也属于此类别，因为它们通常为多个（远程）用户提供服务，而这些用户都非常着急。计算机用户总是很忙。\n\n在实时系统中，抢占有时是不需要的，因为进程知道自己可能运行不了很长时间，通常很快的做完自己的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。\n\n#### 调度算法的目标\n\n为了设计调度算法，有必要考虑一下什么是好的调度算法。有一些目标取决于环境（批处理、交互式或者实时）蛋大部分是适用于所有情况的，下面是一些需要考量的因素，我们会在下面一起讨论。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkxvibibMFgiaPvgs6ltWepp136jFYSAUMsXGOYRAiaT7l4wCDy4fuKZ95Bw/640?wx_fmt=png)\n\n**所有系统**\n\n在所有的情况中，`公平`是很重要的。对一个进程给予相较于其他等价的进程更多的 CPU 时间片对其他进程来说是不公平的。当然，不同类型的进程可以采用不同的处理方式。\n\n与公平有关的是系统的`强制执行`，什么意思呢？如果某公司的薪资发放系统计划在本月的 15 号，那么碰上了疫情大家生活都很拮据，此时老板说要在 14 号晚上发放薪资，那么调度程序必须强制使进程执行 14 号晚上发放薪资的策略。\n\n另一个共同的目标是保持系统的`所有部分尽可能的忙碌`。如果 CPU 和所有的 I/O 设备能够一直运行，那么相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调入内存运行。在内存中既有一些 CPU 密集型进程又有一些 I/O 密集型进程是一个比较好的想法，好于先调入和运行所有的 CPU 密集型作业，然后在它们完成之后再调入和运行所有 I/O 密集型作业的做法。使用后者这种方式会在 CPU 密集型进程启动后，争夺 CPU ，而磁盘却在空转，而当 I/O 密集型进程启动后，它们又要为磁盘而竞争，CPU 却又在空转。。。。。。显然，通过结合 I/O 密集型和 CPU 密集型，能够使整个系统运行更流畅，效率更高。\n\n**批处理系统**\n\n通常有三个指标来衡量系统工作状态：**吞吐量、周转时间和 CPU 利用率**，`吞吐量(throughout)` 是系统每小时完成的作业数量。综合考虑，每小时完成 50 个工作要比每小时完成 40 个工作好。`周转时间(Turnaround time)` 是一种平均时间，它指的是从一个批处理提交开始直到作业完成时刻为止平均时间。该数据度量了用户要得到输出所需的平均等待时间。周转时间越小越好。\n\n`CPU 利用率(CPU utilization)` 通常作为批处理系统上的指标。即使如此， CPU 利用率也不是一个好的度量指标，真正有价值的衡量指标是系统每小时可以完成多少作业（吞吐量），以及完成作业需要多长时间（周转时间）。把 CPU 利用率作为度量指标，就像是引擎每小时转动了多少次来比较汽车的性能一样。而且知道 CPU 的利用率什么时候接近 100% 要比什么什么时候要求得到更多的计算能力要有用。\n\n**交互式系统**\n\n对于交互式系统，则有不同的指标。最重要的是尽量`减少响应时间`。这个时间说的是从执行指令开始到得到结果的时间。再有后台进程运行（例如，从网络上读取和保存 E-mail 文件）的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的就是一个好的服务。\n\n一个相关的问题是 `均衡性(proportionality)`，用户对做一件事情需要多长时间总是有一种固定（不过通常不正确）的看法。当认为一个请求很复杂需要较多时间时，用户会认为很正常并且可以接受，但是一个很简单的程序却花费了很长的运行时间，用户就会很恼怒。可以拿彩印和复印来举出一个简单的例子，彩印可能需要 1 分钟的时间，但是用户觉得复杂并且愿意等待一分钟，相反，复印很简单只需要 5 秒钟，但是复印机花费 1 分钟却没有完成复印操作，用户就会很焦躁。\n\n**实时系统**\n\n实时系统则有着和交互式系统不同的考量因素，因此也就有不同的调度目标。实时系统的特点是`必须满足最后的截止时间`。例如，如果计算机控制着以固定速率产生数据的设备，未能按时运行的话可能会导致数据丢失。因此，实时系统中最重要的需求是满足所有（或大多数）时间期限。\n\n在一些实事系统中，特别是涉及到多媒体的，`可预测性很重要`。偶尔不能满足最后的截止时间不重要，但是如果音频多媒体运行不稳定，声音质量会持续恶化。视频也会造成问题，但是耳朵要比眼睛敏感很多。为了避免这些问题，进程调度必须能够高度可预测的而且是有规律的。\n\n### 批处理中的调度\n\n现在让我们把目光从一般性的调度转换为特定的调度算法。下面我们会探讨在批处理中的调度。\n\n#### 先来先服务\n\n很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 `先来先服务(first-come,first-serverd)`。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkqPMbFJfGBd9toxDvJn0M90Yc7fIfwm8sYaqk2GkvFWFGWqV0upj7mA/640?wx_fmt=png)\n\n这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。\n\n不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。\n\n#### 最短作业优先\n\n批处理中，第二种调度算法是 `最短作业优先(Shortest Job First)`，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkWytiaXxLwkZ2fQ1nGYZKsZsXtRcNaRjXicn01BsqHwSjk0szP48f1qyQ/640?wx_fmt=png)\n\n如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。  \n\n现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。\n\n> 需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。\n\n#### 最短剩余时间优先\n\n最短作业优先的抢占式版本被称作为 `最短剩余时间优先(Shortest Remaining Time Next)` 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。\n\n### 交互式系统中的调度\n\n交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度\n\n#### 轮询调度\n\n一种最古老、最简单、最公平并且最广泛使用的算法就是 `轮询算法(round-robin)`。每个进程都会被分配一个时间段，称为`时间片(quantum)`，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkOxzKshMcCgeCOxI9IFypGhFvaQNgrmef5xtBTlAN8ozyHPfnQk09Kw/640?wx_fmt=png)\n\n时间片轮询调度中唯一有意思的一点就是时间片的长度。从一个进程切换到另一个进程需要一定的时间进行管理处理，包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作 `进程间切换(process switch)` 和 `上下文切换(context switch)`。如果进程间的切换时间需要 1ms，其中包括内存映射、清除和重新调入高速缓存等，再假设时间片设为 4 ms，那么 CPU 在做完 4 ms 有用的工作之后，CPU 将花费 1 ms 来进行进程间的切换。因此，CPU 的时间片会浪费 20% 的时间在管理开销上。耗费巨大。\n\n为了提高 CPU 的效率，我们把时间片设置为 100 ms。现在时间的浪费只有 1%。但是考虑会发现下面的情况，如果在一个非常短的时间内到达 50 个请求，并且对 CPU 有不同的需求，此时会发生什么？50 个进程都被放在可运行进程列表中。如果 CP 画 U 是空闲的，第一个进程会立即开始执行，第二个直到 100 ms 以后才会启动，以此类推。不幸的是最后一个进程需要等待 5 秒才能获得执行机会。大部分用户都会觉得对于一个简短的指令运行 5 秒中是很慢的。如果队列末尾的某些请求只需要几号秒钟的运行时间的话，这种设计就非常糟糕了。\n\n另外一个因素是如果时间片设置长度要大于 CPU 使用长度，那么抢占就不会经常发生。相反，在时间片用完之前，大多数进程都已经阻塞了，那么就会引起进程间的切换。消除抢占可提高性能，因为进程切换仅在逻辑上必要时才发生，即流程阻塞且无法继续时才发生。\n\n结论可以表述如下：将上下文切换时间设置得太短会导致过多的进程切换并降低 CPU 效率，但设置时间太长会导致一个短请求很长时间得不到响应。最好的切换时间是在 20 - 50 毫秒之间设置。\n\n#### 优先级调度\n\n轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了`优先级调度(priority scheduling)`\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibKKcmqw7wHNaRyic2qWfZQ5mxASpo0qqPtC1M6SCloLc5QvN5rsnib3A/640?wx_fmt=png)\n\n它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。\n\n但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。\n\n可以静态或者动态的为进程分配优先级。在一台军用计算机上，可以把将军所启动的进程设为优先级 100，上校为 90 ，少校为 80，上尉为 70，中尉为 60，以此类推。UNIX 中有一条命令为 `nice` ，它允许用户为了照顾他人而自愿降低自己进程的优先级，但是一般没人用。\n\n优先级也可以由系统动态分配，用于实现某种目的。例如，有些进程为 I/O 密集型，其多数时间用来等待 I/O 结束。当这样的进程需要 CPU 时，应立即分配 CPU，用来启动下一个 I/O 请求，这样就可以在另一个进程进行计算的同时执行 I/O 操作。这类 I/O 密集型进程长时间的等待 CPU 只会造成它长时间占用内存。使 I/O 密集型进程获得较好的服务的一种简单算法是，将其优先级设为 `1/f`，f 为该进程在上一时间片中所占的部分。一个在 50 ms 的时间片中只使用 1 ms 的进程将获得优先级 50 ，而在阻塞之前用掉 25 ms 的进程将具有优先级 2，而使用掉全部时间片的进程将得到优先级 1。\n\n可以很方便的将一组进程按优先级分成若干类，并且在各个类之间采用优先级调度，而在各类进程的内部采用轮转调度。下面展示了一个四个优先级类的系统\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkh7icJrRFORxCKsSnD2DEvfhTIZKYn9o5SYaCl1mvebyx6EnsweGSjnw/640?wx_fmt=png)\n\n它的调度算法主要描述如下：上面存在优先级为 4 类的可运行进程，首先会按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第 4 类进程为空，则按照轮询的方式运行第三类进程。若第 4 类和第 3 类进程都为空，则按照轮转法运行第 2 类进程。如果不对优先级进行调整，则低优先级的进程很容易产生饥饿现象。\n\n#### 多级队列\n\n最早使用优先级调度的系统是 `CTSS(Compatible TimeSharing System)`。CTSS 是一种兼容分时系统，它有一个问题就是进程切换太慢，其原因是 IBM 7094 内存只能放进一个进程。\n\n> IBM 是哥伦比亚大学计算机中心在 1964 - 1968 年的计算机\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkHqGI0SaIpjW7unPiasYQV0ekRmSB3EjbVNJ8jvhic6gL8VbFvicUWOW0w/640?wx_fmt=png)\n\nCTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS 的设计者很快就认识到，为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。\n\n#### 最短进程优先\n\n对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互式进程，那将是非常好的。在某种程度上，的确可以做到这一点。交互式进程通常遵循下列模式：等待命令、执行命令、等待命令、执行命令。。。如果我们把每个命令的执行都看作一个分离的作业，那么我们可以通过首先运行最短的作业来使响应时间最短。这里唯一的问题是如何从当前可运行进程中找出最短的那一个进程。\n\n一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 `T0`，现在假设测量到其下一次运行时间为 `T1`，可以用两个值的加权来改进估计时间，即`aT0+ (1- 1)T1`。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVar1KhzuffcYqXhyRyOL7b8KQiciaUYCpmR2e9iaiaMF6qh60jPk4FCrgA/640?wx_fmt=png)\n\n可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。  \n\n有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 `老化(aging)`。这种方法会使用很多预测值基于当前值的情况。\n\n#### 保证调度\n\n一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。\n\n#### 彩票调度\n\n对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 `彩票调度(lottery scheduling)`算法。\n\n其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。\n\n`George Orwell` 关于 **所有的进程是平等的，但是某些进程能够更平等一些**。一些重要的进程可以给它们额外的彩票，以便增加他们赢得的机会。如果出售了 100 张彩票，而且有一个进程持有了它们中的 20 张，它就会有 20% 的机会去赢得彩票中奖。在长时间的运行中，它就会获得 20% 的 CPU。相反，对于优先级调度程序，很难说明拥有优先级 40 究竟是什么意思，这里的规则很清楚，拥有彩票 f 份额的进程大约得到系统资源的 f 份额。\n\n如果希望进程之间协作的话可以交换它们之间的票据。例如，客户端进程给服务器进程发送了一条消息后阻塞，客户端进程可能会把自己所有的票据都交给服务器，来增加下一次服务器运行的机会。当服务完成后，它会把彩票还给客户端让其有机会再次运行。事实上，如果没有客户机，服务器也根本不需要彩票。\n\n> 可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 `速度之靴` 的效果。\n\n#### 公平分享调度\n\n到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。\n\n为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些 CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkp2JUKicTTic4Mh3owkYeABOicg6zXAkfFSmoTZs7W6UtRN5Rsc3VcTqPA/640?wx_fmt=png)\n\n### 实时系统中的调度\n\n`实时系统(real-time)` 是一个时间扮演了重要作用的系统。典型的，一种或多种外部物理设备发给计算机一个服务请求，而计算机必须在一个确定的时间范围内恰当的做出反应。例如，在 CD 播放器中的计算机会获得从驱动器过来的位流，然后必须在非常短的时间内将位流转换为音乐播放出来。如果计算时间过长，那么音乐就会听起来有异常。再比如说医院特别护理部门的病人监护装置、飞机中的自动驾驶系统、列车中的烟雾警告装置等，在这些例子中，正确但是却缓慢的响应要比没有响应甚至还糟糕。\n\n实时系统可以分为两类，`硬实时(hard real time)` 和 `软实时(soft real time)` 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。在这两种情形中，实时都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前可知的。这些进程一般寿命较短，并且极快的运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。\n\n实时系统中的事件可以按照响应方式进一步分类为`周期性(以规则的时间间隔发生)`事件或 `非周期性(发生时间不可预知)`事件。一个系统可能要响应多个周期性事件流，根据每个事件处理所需的时间，可能甚至无法处理所有事件。例如，如果有 m 个周期事件，事件 i 以周期 Pi 发生，并需要 Ci 秒 CPU 时间处理一个事件，那么可以处理负载的条件是\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkicxWrh9f5BDPIHJU9PDzKE0HR42WWlTyA1P9rDLSVhtibSQ7VVeymJibA/640?wx_fmt=png)\n\n只有满足这个条件的实时系统称为`可调度的`，这意味着它实际上能够被实现。一个不满足此检验标准的进程不能被调度，因为这些进程共同需要的 CPU 时间总和大于 CPU 能提供的时间。\n\n举一个例子，考虑一个有三个周期性事件的软实时系统，其周期分别是 100 ms、200 m 和 500 ms。如果这些事件分别需要 50 ms、30 ms 和 100 ms 的 CPU 时间，那么该系统时可调度的，因为 0.5 + 0.15 + 0.2 < 1。如果此时有第四个事件加入，其周期为 1 秒，那么此时这个事件如果不超过 150 ms，那么仍然是可以调度的。忽略上下文切换的时间。\n\n实时系统的调度算法可以是静态的或动态的。前者在系统开始运行之前做出调度决策；后者在运行过程中进行调度决策。只有在可以提前掌握所完成的工作以及必须满足的截止时间等信息时，静态调度才能工作，而动态调度不需要这些限制。\n\n### 调度策略和机制\n\n到目前为止，我们隐含的假设系统中所有进程属于不同的分组用户并且进程间存在相互竞争 CPU 的情况。通常情况下确实如此，但有时也会发生一个进程会有很多子进程并在其控制下运行的情况。例如，一个数据库管理系统进程会有很多子进程。每一个子进程可能处理不同的请求，或者每个子进程实现不同的功能（如请求分析、磁盘访问等）。主进程完全可能掌握哪一个子进程最重要（或最紧迫），而哪一个最不重要。但是，以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。\n\n解决问题的办法是将 `调度机制(scheduling mechanism)` 和 `调度策略(scheduling policy)` 分开，这是长期一贯的原则。这也就意味着调度算法在某种方式下被参数化了，但是参数可以被用户进程填写。让我们首先考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。调度机制位于内核，而调度策略由用户进程决定，调度策略和机制分离是一种关键性思路。\n\n### 线程调度\n\n当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本质的差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。\n\n首先考虑用户级线程，由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为 A，并给予 A 以时间片控制。A 中的线程调度程序决定哪个线程运行。假设为 A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程继续运行。\n\n在进程 A 终于又一次运行时，线程 A1 会接着运行。该线程会继续耗费 A 进程的所有时间，直到它完成工作。不过，线程运行不会影响到其他进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程 A 内部发生的事情。\n\n现在考虑 A 线程每次 CPU 计算的工作比较少的情况，例如：在 50 ms 的时间片中有 5 ms 的计算工作。于是，每个线程运行一会儿，然后把 CPU 交回给线程调度程序。这样在内核切换到进程 B 之前，就会有序列 A1,A2,A3,A1,A2,A3,A1,A2,A3,A1 。如下所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibIqnCiaYicYscwr55u59URicaa9iaIgcMA3zmicGaJKFtoByUkUAClg9YUA/640?wx_fmt=png)\n\n运行时系统使用的调度算法可以是上面介绍算法的任意一种。从实用方面考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程。但由于线程之间的合作关系，这通常也不是问题。\n\n现在考虑使用内核线程的情况，内核选择一个特定的线程运行。它不用考虑线程属于哪个进程，不过如果有必要的话，也可以这么做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在 50 ms 的时间片内，5 ms 之后被阻塞，在 30 ms 的时间片中，线程的顺序会是 A1,B1,A2,B2,A3,B3。如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaejGGnPoyhnwOUWNVdDCQpicVrhQwUibbMtZRKOUEOOJGvgBh5tPMiavg/640?wx_fmt=png)\n\n用户级线程和内核级线程之间的主要差别在于`性能`。用户级线程的切换需要少量的机器指令（想象一下 Java 程序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程挂起。  \n\n从进程 A 的一个线程切换到进程 B 的一个线程，其消耗要远高于运行进程 A 的两个线程（涉及修改内存映像，修改高速缓存），内核对这种切换的消耗是了解到，可以通过这些信息作出决定。\n\n文章参考：\n\n《现代操作系统》\n\n《Modern Operating System》forth edition\n\nhttps://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems\n\nhttps://j00ru.vexillium.org/syscalls/nt/32/\n\nhttps://www.bottomupcs.com/process_hierarchy.xhtml\n\nhttps://en.wikipedia.org/wiki/Runtime_system\n\nhttps://en.wikipedia.org/wiki/Execution_model\n\nhttps://zhidao.baidu.com/question/113227654.html\n\nhttps://baike.baidu.com/item/ 等待队列 / 9223804?fr=aladdin\n\nhttp://www.columbia.edu/cu/computinghistory/7094.html\n\nhttps://baike.baidu.com/item/ 中断向量 / 4947039?fr=aladdin\n\n```\n推荐阅读：\n\n\n\n\n完全整理 | 365篇高质技术文章目录整理\n\n算法之美 : 栈和队列\n\n\n主宰这个世界的10大算法\n\n\n彻底理解cookie、session、token\n\n\n浅谈什么是递归算法\n\n专注服务器后台技术栈知识总结分享\n\n欢迎关注交流共同进步\n\n码农有道 coding\n\n\n\n\n码农有道，为您提供通俗易懂的技术文章，让技术变的更简单！\n\n好文章，我 在看 \n```","source":"_posts/进程与线程-转载.md","raw":"---\ntitle: 进程与线程-转载\ndate: 2020-03-06 21:19:11\ntags: 操作系统\ncategories: 专业课\n---\n\n\n\n> 本文由 [简悦 SimpRead](http://ksria.com/simpread/) 转码， 原文地址 https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&mid=2247487913&idx=1&sn=8c3f042c5a73ce9e49b21bc6cce2442e&chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&mpshare=1&scene=1&srcid=&sharer_sharetime=1583500047238&sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&ascene=1&uin=MTIwMTg1OTcwMg%3D%3D&devicetype=Windows+10&version=62080079&lang=zh_CN&exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm\n\n来源：Java 建设者\n\n作者：cxuan\n\n下面是本文的结构图\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJArB4bFRERsiaKqyAZbnJxU3ISIOnRUH908G29Tx2iaCXc5Ps7DTiaD4A/640?wx_fmt=png)\n\n我们平常说的进程和线程更多的是基于编程语言的角度来说的，那么你真的了解什么是线程和进程吗？那么我们就从操作系统的角度来了解一下什么是进程和线程。\n\n进程\n--\n\n操作系统中最核心的概念就是 `进程`，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，它们也支持`（伪）并发`操作。它们会将一个单独的 CPU 抽象为多个虚拟机的 CPU。可以说：没有进程的抽象，现代操作系统将不复存在。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJcVYZew9ryLN0RIu6fwSUliaeSKiaKgoBDSXfaH9Hqvm4Cm73Na86K3Q/640?wx_fmt=png)\n\n所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。\n\n现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。于是一个支持多进程的多道程序系统就会显得很有必要了。\n\n在许多多道程序系统中，CPU 会在`进程`间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生`并行`的错觉。有时候人们说的 `伪并行(pseudoparallelism)` 就是这种情况，以此来区分多处理器系统 (该系统由两个或多个 CPU 来共享同一个物理内存)\n\n> 再来详细解释一下伪并行：`伪并行`是指单核或多核处理器同时执行多个进程，从而使程序更快。通过以非常有限的时间间隔在程序之间快速切换 CPU，因此会产生并行感。缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。\n\n因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析，对该模型的探讨，也是本篇文章的主题。下面我们就来探讨一下进程模型\n\n### 进程模型\n\n在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干`顺序进程(sequential processes)`，简称为 `进程(process)` 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkwicOIsH2wqofqK877AcZEnQwsg3hSibpu2q5ZWrKKOwIUZloGHVEY69w/640?wx_fmt=png)\n\n如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkpSsh1RicmibCiaNmgwq5xMM8NtTl1yW3jXcL2pMIBDUmQk9VRGSMC4wwA/640?wx_fmt=png)\n\n在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。\n\n从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，**但在任何一个给定的瞬间仅有一个进程真正运行**。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkeqicuKAib5xjeLwSEKvmWbnZd9poHkykMIZxKGfryBFwNBCNHghALbQg/640?wx_fmt=png)\n\n因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），**每一个核也只能一次运行一个线程**。\n\n由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原谅：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、而做蛋糕的各种原料都是输入数据。进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系列动作的总和。\n\n现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。\n\n这里的关键思想是`认识到一个进程所需的条件`，进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，如果一个进程运行了两遍，则被认为是两个进程。那么我们了解到进程模型后，那么进程是如何创建的呢？\n\n### 进程的创建\n\n操作系统需要一些方式来创建进程。下面是一些创建进程的方式\n\n*   系统初始化（init）\n    \n*   正在运行的程序执行了创建进程的系统调用（比如 fork）\n    \n*   用户请求创建一个新进程\n    \n*   初始化一个批处理工作\n    \n\n#### 系统初始化\n\n启动操作系统时，通常会创建若干个进程。其中有些是`前台进程(numerous processes)`，也就是同用户进行交互并替他们完成工作的进程。一些运行在后台，并不与特定的用户进行交互，例如，设计一个进程来接收发来的电子邮件，这个进程大部分的时间都在休眠，但是只要邮件到来后这个进程就会被唤醒。还可以设计一个进程来接收对该计算机上网页的传入请求，在请求到达的进程唤醒来处理网页的传入请求。进程运行在后台用来处理一些活动像是 e-mail，web 网页，新闻，打印等等被称为 `守护进程(daemons)`。大型系统会有很多守护进程。在 UNIX 中，`ps` 程序可以列出正在运行的进程， 在 Windows 中，可以使用任务管理器。\n\n#### 系统调用创建\n\n除了在启动阶段创建进程之外，一些新的进程也可以在后面创建。通常，一个正在运行的进程会发出`系统调用`用来创建一个或多个新进程来帮助其完成工作。例如，如果有大量的数据需要经过网络调取并进行顺序处理，那么创建一个进程读数据，并把数据放到共享缓冲区中，而让第二个进程取走并正确处理会比较容易些。在多处理器中，让每个进程运行在不同的 CPU 上也可以使工作做的更快。\n\n#### 用户请求创建\n\n在许多交互式系统中，输入一个命令或者双击图标就可以启动程序，以上任意一种操作都可以选择开启一个新的进程，在基本的 UNIX 系统中运行 X，新进程将接管启动它的窗口。在 Windows 中启动进程时，它一般没有窗口，但是它可以创建一个或多个窗口。每个窗口都可以运行进程。通过鼠标或者命令就可以切换窗口并与进程进行交互。\n\n> 交互式系统是以人与计算机之间大量交互为特征的计算机系统，比如游戏、web 浏览器，IDE 等集成开发环境。\n\n#### 批处理创建\n\n最后一种创建进程的情形会在`大型机的批处理系统`中应用。用户在这种系统中提交批处理作业。当操作系统决定它有资源来运行另一个任务时，它将创建一个新进程并从其中的输入队列中运行下一个作业。\n\n从技术上讲，在所有这些情况下，让现有流程执行流程是通过创建系统调用来创建新流程的。该进程可能是正在运行的用户进程，是从键盘或鼠标调用的系统进程或批处理程序。这些就是系统调用创建新进程的过程。该系统调用告诉操作系统创建一个新进程，并直接或间接指示在其中运行哪个程序。\n\n在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 `fork`。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。通常，子进程会执行 `execve` 或者一个简单的系统调用来改变内存映像并运行一个新的程序。例如，当一个用户在 shell 中输出 sort 命令时，shell 会 fork 一个子进程然后子进程去执行 sort 命令。这两步过程的原因是允许子进程在 fork 之后但在 execve 之前操作其文件描述符，以完成标准输入，标准输出和标准错误的重定向。\n\n在 Windows 中，情况正相反，一个简单的 Win32 功能调用 `CreateProcess`，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 `CreateProcess` Win 32 中大概有 100 个其他的函数用于处理进程的管理，同步以及相关的事务。下面是 UNIX 操作系统和 Windows 操作系统系统调用的对比\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkCg59tia26o7PFqCbmnFhEI6j1qoKbDeLKhUYepPVmZ400sWwtahYrNA/640?wx_fmt=png)\n\n在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个词，这个修改将对另一个进程不可见。在 UNIX 中，子进程的地址空间是父进程的一个拷贝，但是却是两个不同的地址空间；不可写的内存区域是共享的。某些 UNIX 实现是正是在两者之间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但是这种情况下内存通过 `写时复制(copy-on-write)` 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确的复制，以确保修改发生在私有内存区域。再次强调，**可写的内存是不能被共享的**。但是，对于一个新创建的进程来说，确实有可能共享创建者的资源，比如可以共享打开的文件。**在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的**。  \n\n### 进程的终止\n\n进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的\n\n*   `正常退出(自愿的)`\n    \n*   `错误退出(自愿的)`\n    \n*   `严重错误(非自愿的)`\n    \n*   `被其他进程杀死(非自愿的)`\n    \n\n#### 正常退出\n\n多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 `exit` ，在 Windows 中是 `ExitProcess`。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。\n\n#### 错误退出\n\n进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令\n\n```\ncc foo.c    \n```\n\n为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。\n\n#### 严重错误\n\n进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。\n\n#### 被其他进程杀死\n\n第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 `TerminateProcess`（注意不是系统调用）。\n\n### 进程的层次结构\n\n在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。\n\n#### UNIX 进程体系\n\n在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。\n\n这里有另一个例子，可以用来说明层次的作用，考虑 `UNIX` 在启动时如何初始化自己。一个称为 `init` 的特殊进程出现在启动映像中 。当 init 进程开始运行时，它会读取一个文件，文件会告诉它有多少个终端。然后为每个终端创建一个新进程。这些进程等待用户登录。如果登录成功，该登录进程就执行一个 shell 来等待接收用户输入指令，这些命令可能会启动更多的进程，以此类推。因此，整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkfB32mZKNYKtf0P9jW3Qax9iaW3gF4OfXGnBLM7FDBxvAUAHpiazZDRVw/640?wx_fmt=png)\n\n#### Windows 进程体系\n\n相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。而在 UNIX 中，进程不能剥夺其子进程的 `进程权`。（这样看来，还是 Windows 比较`渣`）。\n\n### 进程状态\n\n尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。例如，一个进程的结果可以作为另一个进程的输入，在 shell 命令中\n\n```\ncat chapter1 chapter2 chapter3 | grep tree\n```\n\n第一个进程是 `cat`，将三个文件级联并输出。第二个进程是 `grep`，它从输入中选择具有包含关键字 `tree` 的内容，根据这两个进程的相对速度（这取决于两个程序的相对复杂度和各自所分配到的 CPU 时间片），可能会发生下面这种情况，`grep` 准备就绪开始运行，但是输入进程还没有完成，于是必须阻塞 grep 进程，直到输入完毕。\n\n当一个进程开始运行时，它可能会经历下面这几种状态\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk0nh0PP7ykpeG74eOW5iahBUU5AmxJjnr2Lot6w2dloqoBYgsAibrFg0A/640?wx_fmt=png)\n\n图中会涉及三种状态\n\n1.  `运行态`，运行态指的就是进程实际占用 CPU 时间片运行时\n    \n2.  `就绪态`，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态\n    \n3.  `阻塞态`，除非某种外部事件发生，否则进程不能运行\n    \n\n逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程`可运行`，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。\n\n三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生`状态1`的轮转，在某些系统中进程执行系统调用，例如 `pause`，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。\n\n转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。\n\n> **程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点**。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。\n\n当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。\n\n从上面的观点引入了下面的模型\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPP9Rn6j8AW1uLNLoKOjBtWbYRvyhrQicjjLl8n8GFuibRbuBXQnu27nw/640?wx_fmt=png)\n\n**操作系统最底层的就是调度程序**，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。事实上，调度程序只是一段非常小的程序。\n\n### 进程的实现\n\n操作系统为了执行进程间的切换，会维护着一张表格，这张表就是 `进程表(process table)`。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。\n\n下面展示了一个典型系统中的关键字段\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkC2WWXEkRAKErcia0ib3Hia2DWsLtPRzqQLdt4Mo326QWfF7LfyXfcUApQ/640?wx_fmt=png)\n\n第一列内容与`进程管理`有关，第二列内容与 `存储管理`有关，第三列内容与`文件管理`有关。\n\n存储管理的 text segment 、 data segment、stack segment 更多了解见下面这篇文章\n\n[程序员需要了解的硬核知识之汇编语言 (全)](https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&mid=2247484788&idx=1&sn=8a17224cabe09d3bd564dfdf22e2ff5d&chksm=fc45f887cb3271914f0e688a3cce4d7e3ce9077cdde199648e72aa92ad08fba2047b4483b7e8&token=504034995&lang=zh_CN&scene=21#wechat_redirect)\n\n现在我们应该对进程表有个大致的了解了，就可以在对单个 CPU 上如何运行多个顺序进程的错觉做更多的解释。与每一 I/O 类相关联的是一个称作 `中断向量(interrupt vector)` 的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这就是硬件所做的事情。然后软件就随即接管一切剩余的工作。\n\n当中断结束后，操作系统会调用一个 C 程序来处理中断剩下的工作。在完成剩下的工作后，会使某些进程就绪，接着调用调度程序，决定随后运行哪个进程。然后将控制权转移给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行，下面显示了中断处理和调度的过程。\n\n1.  硬件压入堆栈程序计数器等\n    \n2.  硬件从中断向量装入新的程序计数器\n    \n3.  汇编语言过程保存寄存器的值\n    \n4.  汇编语言过程设置新的堆栈\n    \n5.  C 中断服务器运行（典型的读和缓存写入）\n    \n6.  调度器决定下面哪个程序先运行\n    \n7.  C 过程返回至汇编代码\n    \n8.  汇编语言过程开始运行新的当前进程\n    \n\n一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。\n\n线程\n--\n\n在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。下面我们就着重探讨一下什么是线程\n\n### 线程的使用\n\n或许这个疑问也是你的疑问，为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答\n\n*   多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的\n    \n*   线程要比进程`更轻量级`，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。\n    \n*   第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度\n    \n\n#### 多线程解决方案\n\n现在考虑一个线程使用的例子：一个万维网服务器，对页面的请求发送给服务器，而所请求的页面发送回客户端。在多数 web 站点上，某些页面较其他页面相比有更多的访问。例如，索尼的主页比任何一个照相机详情介绍页面具有更多的访问，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这种页面的集合称为 `高速缓存(cache)`，高速缓存也应用在许多场合中，比如说 CPU 缓存。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiafv8cMyibXVb2KNYiaU7IktbLNOPOeficbw2jRlHzF50BPen1r00FYCag/640?wx_fmt=png)\n\n上面是一个 web 服务器的组织方式，一个叫做 `调度线程(dispatcher thread)` 的线程从网络中读入工作请求，在调度线程检查完请求后，它会选择一个空闲的（阻塞的）工作线程来处理请求，通常是将消息的指针写入到每个线程关联的特殊字中。然后调度线程会唤醒正在睡眠中的工作线程，把工作线程的状态从阻塞态变为就绪态。\n\n当工作线程启动后，它会检查请求是否在 web 页面的高速缓存中存在，这个高速缓存是所有线程都可以访问的。如果高速缓存不存在这个 web 页面的话，它会调用一个 `read` 操作从磁盘中获取页面并且阻塞线程直到磁盘操作完成。当线程阻塞在硬盘操作的期间，为了完成更多的工作，调度线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。\n\n这种模型允许将服务器编写为顺序线程的集合，在分派线程的程序中包含一个死循环，该循环用来获得工作请求并且把请求派给工作线程。每个工作线程的代码包含一个从调度线程接收的请求，并且检查 web 高速缓存中是否存在所需页面，如果有，直接把该页面返回给客户，接着工作线程阻塞，等待一个新请求的到达。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后工作线程阻塞，等待一个新请求。\n\n下面是调度线程和工作线程的代码，这里假设 TRUE 为常数 1 ，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。\n\n**调度线程的大致逻辑**\n\n```\nwhile(TRUE){\n  get_next_request(&buf);\n  handoff_work(&buf);\n}\n```\n\n**工作线程的大致逻辑**\n\n```\nwhile(TRUE){\n  wait_for_work(&buf);\n  look_for_page_in_cache(&buf,&page);\n  if(page_not_in_cache(&page)){\n    read_page_from_disk(&buf,&page);\n  }\n  return _page(&page);\n}\n```\n\n#### 单线程解决方案\n\n现在考虑没有多线程的情况下，如何编写 Web 服务器。我们很容易的就想象为单个线程了，Web 服务器的主循环获取请求并检查请求，并争取在下一个请求之前完成工作。在等待磁盘操作时，服务器空转，并且不处理任何到来的其他请求。结果会导致每秒中只有很少的请求被处理，所以这个例子能够说明多线程提高了程序的并行性并提高了程序的性能。\n\n#### 状态机解决方案\n\n到现在为止，我们已经有了两种解决方案，单线程解决方案和多线程解决方案，其实还有一种解决方案就是 `状态机解决方案`，它的流程如下\n\n如果目前只有一个非阻塞版本的 read 系统调用可以使用，那么当请求到达服务器时，这个唯一的 read 调用的线程会进行检查，如果能够从高速缓存中得到响应，那么直接返回，如果不能，则启动一个非阻塞的磁盘操作\n\n服务器在表中记录当前请求的状态，然后进入并获取下一个事件，紧接着下一个事件可能就是一个新工作的请求或是磁盘对先前操作的回答。如果是新工作的请求，那么就开始处理请求。如果是磁盘的响应，就从表中取出对应的状态信息进行处理。对于非阻塞式磁盘 I/O 而言，这种响应一般都是信号中断响应。\n\n每次服务器从某个请求工作的状态切换到另一个状态时，都必须显示的保存或者重新装入相应的计算状态。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为`有限状态机(finite-state machine)`，有限状态机被广泛的应用在计算机科学中。\n\n这三种解决方案各有各的特性，多线程使得顺序进程的思想得以保留下来，并且实现了并行性，但是顺序进程会阻塞系统调用；单线程服务器保留了阻塞系统的简易性，但是却放弃了性能。有限状态机的处理方法运用了非阻塞调用和中断，通过并行实现了高性能，但是给编程增加了困难。\n\n| 模型 | 特性 |\n| --- | --- |\n| 单线程 | 无并行性，性能较差，阻塞系统调用 |\n| 多线程 | 有并行性，阻塞系统调用 |\n| 有限状态机 | 并行性，非阻塞系统调用、中断 |\n\n### 经典的线程模型\n\n理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。\n\n另一个概念是，进程中拥有一个执行的线程，通常简写为 `线程(thread)`。线程会有程序计数器，用来记录接着要执行哪一条指令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。\n\n线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在一个进程中并行运行多个线程类似于在一台计算机上运行多个进程。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为`轻量的进程(lightweight processes)`。`多线程(multithreading)`一词还用于描述在同一进程中多个线程的情况。\n\n下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2uvgku9q5Vv9GyQkOicZQtYCH52z6BKMGiaeVlQztM3jDeicn1AFOL7dQ/640?wx_fmt=png)\n\n下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknc4JzHybInkL388a2Mib2jq4P8P2JkvgH6RFbsv0QKtOFN6mz0qgQOw/640?wx_fmt=png)\n\n线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，**因此一个线程可以读取、写入甚至擦除另一个线程的堆栈**。线程之间除了共享同一内存空间外，还具有如下不同的内容\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkciaYNEibh4VsBF79p911Fgt7Ca558CpyNyuppk9wt7DrvuN1Tfibysvmg/640?wx_fmt=png)\n\n上图左边的是同一个进程中`每个线程共享`的内容，上图右边是`每个线程`中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。\n\n和进程一样，线程可以处于下面这几种状态：**运行中、阻塞、就绪和终止（进程图中没有画）**。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。**线程之间的状态转换和进程之间的状态转换是一样的**。\n\n每个线程都会有自己的堆栈，如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkSwK4icLBknT5psHj1niac06X161XVudxzlylzibyRPBHhsjHvdqkpDAQ/640?wx_fmt=png)\n\n#### 线程系统调用\n\n进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 `thread_create`）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。\n\n当一个线程完成工作后，可以通过调用一个函数（比如 `thread_exit`）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 `thread_join` ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。\n\n另一个常见的线程是调用 `thread_yield`，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。\n\n### POSIX 线程\n\n为了使编写可移植线程程序成为可能，IEEE 在 IEEE 标准 1003.1c 中定义了线程标准。线程包被定义为 `Pthreads`。大部分的 UNIX 系统支持它。这个标准定义了 60 多种功能调用，一一列举不太现实，下面为你列举了一些常用的系统调用。\n\n> **POSIX 线程**（通常称为 **pthreads**）是一种独立于语言而存在的执行模型，以及并行执行模型。它允许程序控制时间上重叠的多个不同的工作流程。每个工作流程都称为一个线程，可以通过调用 POSIX Threads API 来实现对这些流程的创建和控制。可以把它理解为线程的标准。\n> \n> POSIX Threads 的实现在许多类似且符合 POSIX 的操作系统上可用，例如 **FreeBSD、NetBSD、OpenBSD、Linux、macOS、Android、Solaris**，它在现有 Windows API 之上实现了 **pthread**。\n> \n> IEEE 是世界上最大的技术专业组织，致力于为人类的利益而发展技术。\n\n| 线程调用 | 描述 |\n| --- | --- |\n| pthread_create | 创建一个新线程 |\n| pthread_exit | 结束调用的线程 |\n| pthread_join | 等待一个特定的线程退出 |\n| pthread_yield | 释放 CPU 来运行另外一个线程 |\n| pthread_attr_init | 创建并初始化一个线程的属性结构 |\n| pthread_attr_destory | 删除一个线程的属性结构 |\n\n所有的 Pthreads 都有特定的属性，每一个都含有标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这个属性包括堆栈大小、调度参数以及其他线程需要的项目。\n\n新的线程会通过 `pthread_create` 创建，新创建的线程的标识符会作为函数值返回。这个调用非常像是 UNIX 中的 `fork` 系统调用（除了参数之外），其中线程标识符起着 `PID` 的作用，这么做的目的是为了和其他线程进行区分。\n\n当线程完成指派给他的工作后，会通过 `pthread_exit` 来终止。这个调用会停止线程并释放堆栈。\n\n一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 `pthread_join` 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。\n\n有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长的时间并且希望给另外一个线程机会去运行。这时候可以通过 `pthread_yield` 来完成。\n\n下面两个线程调用是处理属性的。`pthread_attr_init` 建立关联一个线程的属性结构并初始化成默认值，这些值（例如优先级）可以通过修改属性结构的值来改变。\n\n最后，`pthread_attr_destroy` 删除一个线程的结构，释放它占用的内存。它不会影响调用它的线程，这些线程会一直存在。\n\n为了更好的理解 pthread 是如何工作的，考虑下面这个例子\n\n```\n#include <pthread.h>\n#include <stdio.h>\n#include <stdlib.h>\n\n#define NUMBER_OF_THREADS 10\n\nvoid *print_hello_world(vvoid *tid){\n  /* 输出线程的标识符，然后退出 */\n  printf(\"Hello World. Greetings from thread %d\\n\",tid);\n  pthread_exit(NULL);\n}\n\nint main(int argc,char *argv[]){\n  /* 主程序创建 10 个线程，然后退出 */\n  pthread_t threads[NUMBER_OF_THREADS];\n  int status,i;\n\n  for(int i = 0;i < NUMBER_OF_THREADS;i++){\n    printf(\"Main here. Creating thread %d\\n\",i);\n    status = pthread_create(&threads[i], NULL, print_hello_world, (void *)i);\n\n    if(status != 0){\n      printf(\"Oops. pthread_create returned error code %d\\n\",status);\n      exit(-1);\n    }\n  }\n  exit(NULL);\n}\n```\n\n主线程在宣布它的指责之后，循环 `NUMBER_OF_THREADS` 次，每次创建一个新的线程。如果线程创建失败，会打印出一条信息后退出。在创建完成所有的工作后，主程序退出。\n\n### 线程实现\n\n主要有三种实现方式\n\n*   在用户空间中实现线程；\n    \n*   在内核空间中实现线程；\n    \n*   在用户和内核空间中混合实现线程。\n    \n\n下面我们分开讨论一下\n\n#### 在用户空间中实现线程\n\n第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkcq03vztMLnRiaYPTqX0KENPFKPnNr2Ic0qj79V3e0Py9JstIWCI4HibQ/640?wx_fmt=png)\n\n线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程：pthread_create, pthread_exit, pthread_join 和 pthread_yield。\n\n> `运行时系统(Runtime System)` 也叫做运行时环境，该运行时系统提供了程序在其中运行的环境。此环境可能会解决许多问题，包括应用程序内存的布局，程序如何访问变量，在过程之间传递参数的机制，与操作系统的接口等等。编译器根据特定的运行时系统进行假设以生成正确的代码。通常，运行时系统将负责设置和管理堆栈，并且会包含诸如垃圾收集，线程或语言内置的其他动态的功能。\n\n在用户空间管理线程时，每个进程需要有其专用的`线程表(thread table)`，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态。该线程表由运行时系统统一管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程的所有信息，与内核在进程表中存放的信息完全一样。\n\n#### 在用户空间实现线程的优势\n\n在用户空间中实现线程要比在内核空间中实现线程具有这些方面的优势：考虑如果在线程完成时或者是在调用 `pthread_yield` 时，必要时会进程线程切换，然后线程的信息会被保存在运行时环境所提供的线程表中，然后，线程调度程序来选择另外一个需要运行的线程。保存线程的状态和调度程序都是`本地过程`，**所以启动他们比进行内核调用效率更高。因而不需要切换到内核，也就不需要上下文切换，也不需要对内存高速缓存进行刷新，因为线程调度非常便捷，因此效率比较高**。\n\n在用户空间实现线程还有一个优势就是**它允许每个进程有自己定制的调度算法**。例如在某些应用程序中，那些具有垃圾收集线程的应用程序（知道是谁了吧）就不用担心自己线程会不会在不合适的时候停止，这是一个优势。用户线程还具有较好的可扩展性，因为内核空间中的内核线程需要一些表空间和堆栈空间，如果内核线程数量比较大，容易造成问题。\n\n#### 在用户空间实现线程的劣势\n\n尽管在用户空间实现线程会具有一定的性能优势，但是劣势还是很明显的，你如何实现`阻塞系统调用`呢？假设在还没有任何键盘输入之前，一个线程读取键盘，让线程进行系统调用是不可能的，因为这会停止所有的线程。所以，**使用线程的一个目标是能够让线程进行阻塞调用，并且要避免被阻塞的线程影响其他线程**。\n\n与阻塞调用类似的问题是`缺页中断`问题，实际上，计算机并不会把所有的程序都一次性的放入内存中，如果某个程序发生函数调用或者跳转指令到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令，这就称为`缺页故障`。而在对所需的指令进行读入和执行时，相关的进程就会被阻塞。如果只有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。\n\n另外一个问题是，如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。\n\n### 在内核中实现线程\n\n现在我们考虑使用内核来实现线程的情况，此时不再需要运行时环境了。另外，每个进程中也没有线程表。相反，在内核中会有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaPkapIx1EYhPdibEPKuChcIOcClAlhTUicxq554eFbJVWrvyCVUdumBw/640?wx_fmt=png)\n\n内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。\n\n所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。\n\n由于在内核中创建或者销毁线程的开销比较大，所以某些系统会采用可循环利用的方式来回收线程。当某个线程被销毁时，就把它标志为不可运行的状态，但是其内部结构没有受到影响。稍后，在必须创建一个新线程时，就会重新启用旧线程，把它标志为可用状态。\n\n如果某个进程中的线程造成缺页故障后，内核很容易的就能检查出来是否有其他可运行的线程，如果有的话，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止）比较多，就会带来很大的开销。\n\n### 混合实现\n\n结合用户空间和内核空间的优点，设计人员采用了一种`内核级线程`的方式，然后将用户级线程与某些或者全部内核线程多路复用起来\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkKYe6RpSy705bprAxhibKHKkiba32AcKmS0AOAcuCyZuMvyduVgWFwGhQ/640?wx_fmt=png)\n\n在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。\n\n进程间通信\n-----\n\n进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 `进程间通信(Inter Process Communication, IPC)` 的问题。\n\n关于进程间的通信，这里有三个问题\n\n*   上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。\n    \n*   第二个问题是如何确保两个或多个线程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。\n    \n*   第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。\n    \n\n需要注意的是，这三个问题中的后面两个问题同样也适用于线程\n\n第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？\n\n另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。我们后面会慢慢讨论这三个问题，你现在脑子中大致有个印象即可。\n\n### 竞态条件\n\n在一些操作系统中，协作的进程可能共享一些彼此都能读写的公共资源。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的`后台目录(spooler directory)`中。另一个进程 `打印后台进程(printer daemon)` 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。\n\n假设我们的后台目录有非常多的 `槽位(slot)`，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：`out`，指向下一个需要打印的文件；`in`，指向目录中下个空闲的槽位。可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2JljDicfDxXbzlWe7J4KyqznJfd12m6a6BbVaiaMKYxDKU0LpRP9wibibw/640?wx_fmt=png)\n\n`墨菲法则(Murphy)` 中说过，任何可能出错的地方终将出错，这句话生效时，可能发生如下情况。\n\n进程 A 读到 in 的值为 7，将 7 存在一个局部变量 `next_free_slot` 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 `next_free_slot` 中，在这一时刻两个进程都认为下一个可用槽位是 7 。\n\n进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情\n\n现在进程 A 开始恢复运行，由于进程 A 通过检查 `next_free_slot`也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，**即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件 (race condition)**。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象。\n\n### 临界区\n\n不仅共享资源会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：**禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写**。换句话说，我们需要一种 `互斥(mutual exclusion)` 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。上面问题的纠结点在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。在任何操作系统中，为了实现互斥操作而选用适当的原语是一个主要的设计问题，接下来我们会着重探讨一下。\n\n避免竞争问题的条件可以用一种抽象的方式去描述。大部分时间，进程都会忙于内部计算和其他不会导致竞争条件的计算。然而，有时候进程会访问共享内存或文件，或者做一些能够导致竞态条件的操作。我们把对共享内存进行访问的程序片段称作 `临界区域(critical region)` 或 `临界区(critical section)`。如果我们能够正确的操作，使两个不同进程不可能同时处于临界区，就能避免竞争条件，这也是从操作系统设计角度来进行的。\n\n尽管上面这种设计避免了竞争条件，但是不能确保并发线程同时访问共享数据的正确性和高效性。一个好的解决方案，应该包含下面四种条件\n\n1.  任何时候两个进程不能同时处于临界区\n    \n2.  不应对 CPU 的速度和数量做任何假设\n    \n3.  位于临界区外的进程不得阻塞其他进程\n    \n4.  不能使任何进程无限等待进入临界区\n    \n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkrTXZzTqwPTGouHGo3DMXicFwwsRRENeKdia9UicibzOyzGBZ1NA1R8kWCg/640?wx_fmt=png)\n\n从抽象的角度来看，我们通常希望进程的行为如上图所示，在 t1 时刻，进程 A 进入临界区，在 t2 的时刻，进程 B 尝试进入临界区，因为此时进程 A 正在处于临界区中，所以进程 B 会阻塞直到 t3 时刻进程 A 离开临界区，此时进程 B 能够允许进入临界区。最后，在 t4 时刻，进程 B 离开临界区，系统恢复到没有进程的原始状态。\n\n### 忙等互斥\n\n下面我们会继续探讨实现互斥的各种设计，在这些方案中，当一个进程正忙于更新其关键区域的共享内存时，没有其他进程会进入其关键区域，也不会造成影响。\n\n#### 屏蔽中断\n\n在单处理器系统上，最简单的解决方案是让每个进程在进入临界区后立即`屏蔽所有中断`，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。\n\n这个方案可行吗？进程进入临界区域是由谁决定的呢？不是用户进程吗？当进程进入临界区域后，用户进程关闭中断，如果经过一段较长时间后进程没有离开，那么中断不就一直启用不了，结果会如何？可能会造成整个系统的终止。而且如果是多处理器的话，屏蔽中断仅仅对执行 `disable` 指令的 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。\n\n另一方面，对内核来说，当它在执行更新变量或列表的几条指令期间将中断屏蔽是很方便的。例如，如果多个进程处理就绪列表中的时候发生中断，则可能会发生竞态条件的出现。所以，屏蔽中断对于操作系统本身来说是一项很有用的技术，但是对于用户线程来说，屏蔽中断却不是一项通用的互斥机制。\n\n#### 锁变量\n\n作为第二种尝试，可以寻找一种软件层面解决方案。考虑有单个共享的（锁）变量，初始为值为 0 。当一个线程想要进入关键区域时，它首先会查看锁的值是否为 0 ，如果锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。因此，锁变量的值是 0 则意味着没有线程进入关键区域。如果是 1 则意味着有进程在关键区域内。我们对上图修改后，如下所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmcJYsm5uD0kUSRoia4J0KORtZslfTnAnqBca2Ay7KbWibU2a9ywAKwaw/640?wx_fmt=png)\n\n这种设计方式是否正确呢？是否存在纰漏呢？假设一个进程读出锁变量的值并发现它为 0 ，而恰好在它将其设置为 1 之前，另一个进程调度运行，读出锁的变量为 0 ，并将锁的变量设置为 1 。然后第一个线程运行，把锁变量的值再次设置为 1，此时，临界区域就会有两个进程在同时运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVmTDUd4XWEic0EUCtJnWB8yKr5qUJANrZrDYXm0PLF60Zu7sKas4Yibw/640?wx_fmt=png)\n\n也许有的读者可以这么认为，在进入前检查一次，在要离开的关键区域再检查一次不就解决了吗？实际上这种情况也是于事无补，因为在第二次检查期间其他线程仍有可能修改锁变量的值，换句话说，这种 `set-before-check` 不是一种 `原子性` 操作，所以同样还会发生竞争条件。\n\n#### 严格轮询法\n\n第三种互斥的方式先抛出来一段代码，这里的程序是用 C 语言编写，之所以采用 C 是因为操作系统普遍是用 C 来编写的（偶尔会用 C++），而基本不会使用 Java 、Modula3 或 Pascal 这样的语言，Java 中的 native 关键字底层也是 C 或 C++ 编写的源码。对于编写操作系统而言，需要使用 C 语言这种强大、高效、可预知和有特性的语言，而对于 Java ，它是不可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾回收机制回收内存。在 C 语言中，这种情况不会发生，C 语言中不会主动调用垃圾回收回收内存。有关 C 、C++ 、Java 和其他四种语言的比较可以参考 **链接**\n\n**进程 0 的代码**\n\n```\nwhile(TRUE){\n  while(turn != 0){\n    /* 进入关键区域 */\n    critical_region();\n    turn = 1;\n    /* 离开关键区域 */\n    noncritical_region();\n  }\n}\n```\n\n**进程 1 的代码**\n\n```\nwhile(TRUE){\n  while(turn != 1){\n    critical_region();\n    turn = 0;\n    noncritical_region();\n  }\n}\n```\n\n在上面代码中，变量 `turn`，初始值为 0 ，用于记录轮到那个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0 ，于是进入临界区。进程 1 也发现其值为 0 ，所以在一个等待循环中不停的测试 turn，看其值何时变为 1。连续检查一个变量直到某个值出现为止，这种方法称为 `忙等待(busywaiting)`。由于这种方式浪费 CPU 时间，所以这种方式通常应该要避免。只有在有理由认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 `自旋锁(spinlock)`。\n\n进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0 。现在进程 0 很快就执行完了整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。\n\n突然，进程 0 结束了非临界区的操作并返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，此时进程 1 还忙于非临界区的操作，进程 0 只能继续 while 循环，直到进程 1 把 turn 的值改为 0 。这说明，在一个进程比另一个进程执行速度慢了很多的情况下，轮流进入临界区并不是一个好的方法。\n\n这种情况违反了前面的叙述 3 ，即 **位于临界区外的进程不得阻塞其他进程**，进程 0 被一个临界区外的进程阻塞。由于违反了第三条，所以也不能作为一个好的方案。\n\n#### Peterson 解法\n\n荷兰数学家 T.Dekker 通过将锁变量与警告变量相结合，最早提出了一个不需要严格轮换的软件互斥算法，关于 Dekker 的算法，参考 **链接**\n\n后来， G.L.Peterson 发现了一种简单很多的互斥算法，它的算法如下\n\n```\n#define FALSE 0\n#define TRUE  1\n/* 进程数量 */\n#define N     2                                                    \n\n/* 现在轮到谁 */\nint turn;                    \n\n/* 所有值初始化为 0 (FALSE) */\nint interested[N];                                            \n\n/* 进程是 0 或 1 */\nvoid enter_region(int process){                    \n\n  /* 另一个进程号 */\n  int other;                                                        \n\n  /* 另一个进程 */\n  other = 1 - process;                \n\n  /* 表示愿意进入临界区 */\n  interested[process] = TRUE;                        \n  turn = process;\n\n  /* 空循环 */\n  while(turn == process \n        && interested[other] == true){} \n\n}\n\nvoid leave_region(int process){\n\n  /* 表示离开临界区 */\n  interested[process] == FALSE;                 \n}\n```\n\n在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 `enter_region`，这个函数调用在需要时将使进程等待，直到能够安全的临界区。在完成对共享变量的操作之后，进程将调用 `leave_region` 表示操作完成，并且允许其他进程进入。\n\n现在来看看这个办法是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 `enter_region`。它通过设置数组元素和将 turn 置为 0 来表示它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程现在调用 enter_region，进程 1 将在此处挂起直到 `interested[0]` 变为 FALSE，这种情况只有在进程 0 调用 `leave_region` 退出临界区时才会发生。\n\n那么上面讨论的是顺序进入的情况，现在来考虑一种两个进程同时调用 `enter_region` 的情况。它们都将自己的进程存入 turn，但只有最后保存进去的进程号才有效，前一个进程的进程号因为重写而丢失。假如进程 1 是最后存入的，则 turn 为 1 。当两个进程都运行到 `while` 的时候，进程 0 将不会循环并进入临界区，而进程 1 将会无限循环且不会进入临界区，直到进程 0 退出位置。\n\n#### TSL 指令\n\n现在来看一种需要硬件帮助的方案。一些计算机，特别是那些设计为多处理器的计算机，都会有下面这条指令\n\n```\nTSL RX,LOCK    \n```\n\n称为 `测试并加锁(test and set lock)`，它将一个内存字 lock 读到寄存器 `RX` 中，然后在该内存地址上存储一个非零值。读写指令能保证是一体的，不可分割的，一同执行的。在这个指令结束之前其他处理器均不允许访问内存。执行 TSL 指令的 CPU 将会锁住内存总线，用来禁止其他 CPU 在这个指令结束之前访问内存。\n\n很重要的一点是锁住内存总线和禁用中断不一样。禁用中断并不能保证一个处理器在读写操作之间另一个处理器对内存的读写。也就是说，在处理器 1 上屏蔽中断对处理器 2 没有影响。让处理器 2 远离内存直到处理器 1 完成读写的最好的方式就是锁住总线。这需要一个特殊的硬件（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能使用）\n\n为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程使用 `move` 指令将 lock 的值重新设置为 0 。\n\n这条指令如何防止两个进程同时进入临界区呢？下面是解决方案\n\n```\nenter_region:\n            | 复制锁到寄存器并将锁设为1\n            TSL REGISTER,LOCK              \n            | 锁是 0 吗？\n          CMP REGISTER,#0                             \n          | 若不是零，说明锁已被设置，所以循环\n          JNE enter_region                            \n          | 返回调用者，进入临界区\n          RET                                              \n\nleave_region:\n\n            | 在锁中存入 0\n            MOVE LOCK,#0                  \n      | 返回调用者\n          RET                                              \n```\n\n我们可以看到这个解决方案的思想和 Peterson 的思想很相似。假设存在如下共 4 指令的汇编语言程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1 ，随后这个原来的值和 0 做对比。如果它不是零，说明之前已经被加过锁，则程序返回到开始并再次测试。经过一段时间后（可长可短），该值变为 0 （当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁也比较简单，程序只需要将 0 存入 lock 即可，不需要特殊的同步指令。\n\n现在有了一种很明确的做法，那就是进程在进入临界区之前会先调用 `enter_region`，判断是否进行循环，如果 lock 的值是 1 ，进行无限循环，如果 lock 是 0，不进入循环并进入临界区。在进程从临界区返回时它调用 `leave_region`，这会把 lock 设置为 0 。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region ，解法才能奏效。\n\n还有一个可以替换 TSL 的指令是 `XCHG`，它原子性的交换了两个位置的内容，例如，一个寄存器与一个内存字，代码如下\n\n```\nenter_region:\n        | 把 1 放在内存器中\n        MOVE REGISTER,#1    \n    | 交换寄存器和锁变量的内容\n        XCHG REGISTER,LOCK          \n    | 锁是 0 吗？\n        CMP REGISTER,#0     \n    | 若不是 0 ，锁已被设置，进行循环\n        JNE enter_region                    \n    | 返回调用者，进入临界区\n        RET                                                     \n\nleave_region:                \n        | 在锁中存入 0 \n        MOVE LOCK,#0    \n    | 返回调用者\n        RET                                                     \n```\n\nXCHG 的本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在底层同步中使用 XCHG 指令。\n\n### 睡眠与唤醒\n\n上面解法中的 Peterson 、TSL 和 XCHG 解法都是正确的，但是它们都有忙等待的缺点。这些解法的本质上都是一样的，先检查是否能够进入临界区，若不允许，则该进程将原地等待，直到允许为止。\n\n这种方式不但浪费了 CPU 时间，而且还可能引起意想不到的结果。考虑一台计算机上有两个进程，这两个进程具有不同的优先级，`H` 是属于优先级比较高的进程，`L` 是属于优先级比较低的进程。进程调度的规则是不论何时只要 H 进程处于就绪态 H 就开始运行。在某一时刻，L 处于临界区中，此时 H 变为就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 要开始忙等，但由于当 H 就绪时 L 就不会被调度，L 从来不会有机会离开关键区域，所以 H 会变成死循环，有时将这种情况称为`优先级反转问题(priority inversion problem)`。\n\n现在让我们看一下进程间的通信原语，这些原语在不允许它们进入关键区域之前会阻塞而不是浪费 CPU 时间，最简单的是 `sleep` 和 `wakeup`。Sleep 是一个能够造成调用者阻塞的系统调用，也就是说，这个系统调用会暂停直到其他进程唤醒它。wakeup 调用有一个参数，即要唤醒的进程。还有一种方式是 wakeup 和 sleep 都有一个参数，即 sleep 和 wakeup 需要匹配的内存地址。\n\n#### 生产者 - 消费者问题\n\n作为这些私有原语的例子，让我们考虑`生产者-消费者(producer-consumer)` 问题，也称作 `有界缓冲区(bounded-buffer)` 问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是`生产者(producer)`，将信息放入缓冲区， 另一个是`消费者(consumer)`，会从缓冲区中取出。也可以把这个问题一般化为 m 个生产者和 n 个消费者的问题，但是我们这里只讨论一个生产者和一个消费者的情况，这样可以简化实现方案。\n\n如果缓冲队列已满，那么当生产者仍想要将数据写入缓冲区的时候，会出现问题。它的解决办法是让生产者睡眠，也就是阻塞生产者。等到消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样的，当消费者试图从缓冲区中取数据，但是发现缓冲区为空时，消费者也会睡眠，阻塞。直到生产者向其中放入一个新的数据。\n\n这个逻辑听起来比较简单，而且这种方式也需要一种称作 `监听` 的变量，这个变量用于监视缓冲区的数据，我们暂定为 count，如果缓冲区最多存放 N 个数据项，生产者会每次判断 count 是否达到 N，否则生产者向缓冲区放入一个数据项并增量 count 的值。消费者的逻辑也很相似：首先测试 count 的值是否为 0 ，如果为 0 则消费者睡眠、阻塞，否则会从缓冲区取出数据并使 count 数量递减。每个进程也会检查检查是否其他线程是否应该被唤醒，如果应该被唤醒，那么就唤醒该线程。下面是生产者消费者的代码\n\n```\n/* 缓冲区 slot 槽的数量 */\n#define N 100                        \n/* 缓冲区数据的数量 */\nint count = 0                                        \n\n// 生产者\nvoid producer(void){\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){                \n    /* 生成下一项数据 */\n    item = produce_item()                \n    /* 如果缓存区是满的，就会阻塞 */\n    if(count == N){\n      sleep();                                    \n    }\n\n    /* 把当前数据放在缓冲区中 */\n    insert_item(item);\n    /* 增加缓冲区 count 的数量 */\n    count = count + 1;                    \n    if(count == 1){\n      /* 缓冲区是否为空？ */\n      wakeup(consumer);                    \n    }\n  }\n}\n\n// 消费者\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 如果缓冲区是空的，就会进行阻塞 */\n      if(count == 0){                         \n      sleep();\n    }\n    /* 从缓冲区中取出一个数据 */\n       item = remove_item();           \n    /* 将缓冲区的 count 数量减一 */\n    count = count - 1\n    /* 缓冲区满嘛？ */\n    if(count == N - 1){                    \n      wakeup(producer);        \n    }\n    /* 打印数据项 */\n    consumer_item(item);                \n  }\n\n}\n```\n\n为了在 C 语言中描述像是 `sleep` 和 `wakeup` 的系统调用，我们将以库函数调用的形式来表示。它们不是 C 标准库的一部分，但可以在实际具有这些系统调用的任何系统上使用。代码中未实现的 `insert_item` 和 `remove_item` 用来记录将数据项放入缓冲区和从缓冲区取出数据等。\n\n现在让我们回到生产者 - 消费者问题上来，上面代码中会产生竞争条件，因为 count 这个变量是暴露在大众视野下的。有可能出现下面这种情况：缓冲区为空，此时消费者刚好读取 count 的值发现它为 0 。此时调度程序决定暂停消费者并启动运行生产者。生产者生产了一条数据并把它放在缓冲区中，然后增加 count 的值，并注意到它的值是 1 。由于 count 为 0，消费者必须处于睡眠状态，因此生产者调用 `wakeup` 来唤醒消费者。但是，消费者此时在逻辑上并没有睡眠，所以 wakeup 信号会丢失。当消费者下次启动后，它会查看之前读取的 count 值，发现它的值是 0 ，然后在此进行睡眠。不久之后生产者会填满整个缓冲区，在这之后会阻塞，这样一来两个进程将永远睡眠下去。\n\n引起上面问题的本质是 **唤醒尚未进行睡眠状态的进程会导致唤醒丢失**。如果它没有丢失，则一切都很正常。一种快速解决上面问题的方式是增加一个`唤醒等待位(wakeup waiting bit)`。当一个 wakeup 信号发送给仍在清醒的进程后，该位置为 1 。之后，当进程尝试睡眠的时候，如果唤醒等待位为 1 ，则该位清除，而进程仍然保持清醒。\n\n然而，当进程数量有许多的时候，这时你可以说通过增加唤醒等待位的数量来唤醒等待位，于是就有了 2、4、6、8 个唤醒等待位，但是并没有从根本上解决问题。\n\n### 信号量\n\n信号量是 E.W.Dijkstra 在 1965 年提出的一种方法，它使用一个整形变量来累计唤醒次数，以供之后使用。在他的观点中，有一个新的变量类型称作 `信号量(semaphore)`。一个信号量的取值可以是 0 ，或任意正数。0 表示的是不需要任何唤醒，任意的正数表示的就是唤醒次数。\n\nDijkstra 提出了信号量有两个操作，现在通常使用 `down` 和 `up`（分别可以用 sleep 和 wakeup 来表示）。down 这个指令的操作会检查值是否大于 0 。如果大于 0 ，则将其值减 1 ；若该值为 0 ，则进程将睡眠，而且此时 down 操作将会继续执行。检查数值、修改变量值以及可能发生的睡眠操作均为一个单一的、不可分割的 `原子操作(atomic action)` 完成。这会保证一旦信号量操作开始，没有其他的进程能够访问信号量，直到操作完成或者阻塞。这种原子性对于解决同步问题和避免竞争绝对必不可少。\n\n> 原子性操作指的是在计算机科学的许多其他领域中，一组相关操作全部执行而没有中断或根本不执行。\n\nup 操作会使信号量的值 + 1。如果一个或者多个进程在信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个并允许该程完成 down 操作。因此，对一个进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍然是 0 ，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞是一样的道理。\n\n#### 用信号量解决生产者 - 消费者问题\n\n用信号量解决丢失的 wakeup 问题，代码如下\n\n```\n/* 定义缓冲区槽的数量 */\n#define N 100\n/* 信号量是一种特殊的 int */\ntypedef int semaphore;\n/* 控制关键区域的访问 */\nsemaphore mutex = 1;\n/* 统计 buffer 空槽的数量 */\nsemaphore empty = N;\n/* 统计 buffer 满槽的数量 */\nsemaphore full = 0;                                                \n\nvoid producer(void){ \n\n  int item;  \n\n  /* TRUE 的常量是 1 */\n  while(TRUE){            \n    /* 产生放在缓冲区的一些数据 */\n    item = producer_item();        \n    /* 将空槽数量减 1  */\n    down(&empty);    \n    /* 进入关键区域  */\n    down(&mutex);    \n    /* 把数据放入缓冲区中 */\n    insert_item(item);\n    /* 离开临界区 */\n    up(&mutex);    \n    /* 将 buffer 满槽数量 + 1 */\n    up(&full);                                                        \n  }\n}\n\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 缓存区满槽数量 - 1 */\n    down(&full);\n    /* 进入缓冲区 */    \n    down(&mutex);\n    /* 从缓冲区取出数据 */\n    item = remove_item();    \n    /* 离开临界区 */\n    up(&mutex);    \n    /* 将空槽数目 + 1 */\n    up(&empty);    \n    /* 处理数据 */\n    consume_item(item);                                            \n  }\n\n}\n```\n\n为了确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用来实现。而且操作系统只需在执行以下操作时暂时屏蔽全部中断：**检查信号量、更新、必要时使进程睡眠**。由于这些操作仅需要非常少的指令，因此中断不会造成影响。如果使用多个 CPU，那么信号量应该被锁进行保护。使用 TSL 或者 XCHG 指令用来确保同一时刻只有一个 CPU 对信号量进行操作。\n\n使用 TSL 或者 XCHG 来防止几个 CPU 同时访问一个信号量，与生产者或消费者使用忙等待来等待其他腾出或填充缓冲区是完全不一样的。前者的操作仅需要几个毫秒，而生产者或消费者可能需要任意长的时间。\n\n上面这个解决方案使用了三种信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex，用来确保生产者和消费者不会同时进入缓冲区。`Full` 被初始化为 0 ，empty 初始化为缓冲区中插槽数，mutex 初始化为 1。信号量初始化为 1 并且由两个或多个进程使用，以确保它们中同时只有一个可以进入关键区域的信号被称为 `二进制信号量(binary semaphores)`。如果每个进程都在进入关键区域之前执行 down 操作，而在离开关键区域之后执行 up 操作，则可以确保相互互斥。\n\n现在我们有了一个好的进程间原语的保证。然后我们再来看一下中断的顺序保证\n\n1.  硬件压入堆栈程序计数器等\n    \n2.  硬件从中断向量装入新的程序计数器\n    \n3.  汇编语言过程保存寄存器的值\n    \n4.  汇编语言过程设置新的堆栈\n    \n5.  C 中断服务器运行（典型的读和缓存写入）\n    \n6.  调度器决定下面哪个程序先运行\n    \n7.  C 过程返回至汇编代码\n    \n8.  汇编语言过程开始运行新的当前进程\n    \n\n在使用`信号量`的系统中，隐藏中断的自然方法是让每个 I/O 设备都配备一个信号量，该信号量最初设置为 0。在 I/O 设备启动后，中断处理程序立刻对相关联的信号执行一个 `down` 操作，于是进程立即被阻塞。当中断进入时，中断处理程序随后对相关的信号量执行一个 `up`操作，能够使已经阻止的进程恢复运行。在上面的中断处理步骤中，其中的第 5 步 `C 中断服务器运行` 就是中断处理程序在信号量上执行的一个 up 操作，所以在第 6 步中，操作系统能够执行设备驱动程序。当然，如果有几个进程已经处于就绪状态，调度程序可能会选择接下来运行一个更重要的进程，我们会在后面讨论调度的算法。\n\n上面的代码实际上是通过两种不同的方式来使用信号量的，而这两种信号量之间的区别也是很重要的。`mutex` 信号量用于互斥。它用于确保任意时刻只有一个进程能够对缓冲区和相关变量进行读写。互斥是用于避免进程混乱所必须的一种操作。\n\n另外一个信号量是关于`同步(synchronization)`的。`full` 和 `empty` 信号量用于确保事件的发生或者不发生。在这个事例中，它们确保了缓冲区满时生产者停止运行；缓冲区为空时消费者停止运行。这两个信号量的使用与 mutex 不同。\n\n### 互斥量\n\n如果不需要信号量的计数能力时，可以使用信号量的一个简单版本，称为 `mutex(互斥量)`。互斥量的优势就在于在一些共享资源和一段代码中保持互斥。由于互斥的实现既简单又有效，这使得互斥量在实现用户空间线程包时非常有用。\n\n互斥量是一个处于两种状态之一的共享变量：`解锁(unlocked)` 和 `加锁(locked)`。这样，只需要一个二进制位来表示它，不过一般情况下，通常会用一个 `整形(integer)` 来表示。0 表示解锁，其他所有的值表示加锁，比 1 大的值表示加锁的次数。\n\nmutex 使用两个过程，当一个线程（或者进程）需要访问关键区域时，会调用 `mutex_lock` 进行加锁。如果互斥锁当前处于解锁状态（表示关键区域可用），则调用成功，并且调用线程可以自由进入关键区域。\n\n另一方面，如果 mutex 互斥量已经锁定的话，调用线程会阻塞直到关键区域内的线程执行完毕并且调用了 `mutex_unlock` 。如果多个线程在 mutex 互斥量上阻塞，将随机选择一个线程并允许它获得锁。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkXJy2jibeQGLUNaWLCLWibibpIKfM2RLogQ38s0VHMdVqUmfVLcPNdwK3w/640?wx_fmt=png)\n\n由于 mutex 互斥量非常简单，所以只要有 TSL 或者是 XCHG 指令，就可以很容易地在用户空间实现它们。用于用户级线程包的 `mutex_lock` 和 `mutex_unlock` 代码如下，XCHG 的本质也一样。\n\n```\nmutex_lock:\n            | 将互斥信号量复制到寄存器，并将互斥信号量置为1\n            TSL REGISTER,MUTEX\n      | 互斥信号量是 0 吗？\n            CMP REGISTER,#0 \n      | 如果互斥信号量为0，它被解锁，所以返回\n            JZE ok  \n      | 互斥信号正在使用；调度其他线程\n            CALL thread_yield   \n      | 再试一次\n            JMP mutex_lock  \n      | 返回调用者，进入临界区\nok:     RET                                                     \n\nmutex_unlcok:\n            | 将 mutex 置为 0 \n            MOVE MUTEX,#0   \n      | 返回调用者\n            RET                                                     \n```\n\nmutex_lock 的代码和上面 enter_region 的代码很相似，我们可以对比着看一下\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkzgYKTTgzB7hSZvozXicEez3sabKfYzxQcuehvgtiaF4NicljJg2PZJOLg/640?wx_fmt=png)\n\n上面代码最大的区别你看出来了吗？\n\n*   根据上面我们对 TSL 的分析，我们知道，如果 TSL 判断没有进入临界区的进程会进行无限循环获取锁，而在 TSL 的处理中，如果 mutex 正在使用，那么就调度其他线程进行处理。所以上面最大的区别其实就是在判断 mutex/TSL 之后的处理。\n    \n*   在（用户）线程中，情况有所不同，因为没有时钟来停止运行时间过长的线程。结果是通过忙等待的方式来试图获得锁的线程将永远循环下去，决不会得到锁，因为这个运行的线程不会让其他线程运行从而释放锁，其他线程根本没有获得锁的机会。在后者获取锁失败时，它会调用 `thread_yield` 将 CPU 放弃给另外一个线程。结果就不会进行忙等待。在该线程下次运行时，它再一次对锁进行测试。\n    \n\n上面就是 enter_region 和 mutex_lock 的差别所在。由于 thread_yield 仅仅是一个用户空间的线程调度，所以它的运行非常快捷。这样，`mutex_lock` 和 `mutex_unlock` 都不需要任何内核调用。通过使用这些过程，用户线程完全可以实现在用户空间中的同步，这个过程仅仅需要少量的同步。\n\n我们上面描述的互斥量其实是一套调用框架中的指令。从软件角度来说，总是需要更多的特性和同步原语。例如，有时线程包提供一个调用 `mutex_trylock`，这个调用尝试获取锁或者返回错误码，但是不会进行加锁操作。这就给了调用线程一个灵活性，以决定下一步做什么，是使用替代方法还是等候下去。\n\n#### Futexes\n\n随着并行的增加，有效的`同步(synchronization)`和`锁定(locking)` 对于性能来说是非常重要的。如果进程等待时间很短，那么`自旋锁(Spin lock)` 是非常有效；但是如果等待时间比较长，那么这会浪费 CPU 周期。如果进程很多，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞是更有效的方式。不幸的是，这种方式也会导致另外的问题：它可以在进程竞争频繁的时候运行良好，但是在竞争不是很激烈的情况下内核切换的消耗会非常大，而且更困难的是，预测锁的竞争数量更不容易。\n\n有一种有趣的解决方案是把两者的优点结合起来，提出一种新的思想，称为 `futex`，或者是 `快速用户空间互斥(fast user space mutex)`，是不是听起来很有意思？\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkW2sY6sXshsFia7jXlNdhuB5XwTt6cjo1pqLgyvV1gcXnNfMASjiasAFA/640?wx_fmt=png)\n\nfutex 是 `Linux` 中的特性实现了基本的锁定（很像是互斥锁）而且避免了陷入内核中，因为内核的切换的开销非常大，这样做可以大大提高性能。futex 由两部分组成：**内核服务和用户库**。内核服务提供了了一个 `等待队列(wait queue)` 允许多个进程在锁上排队等待。除非内核明确的对他们解除阻塞，否则它们不会运行。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXksBadzURKQx0t6EagaQBFBZsNcKeXSLCOl01WfJeyIrTU3DCoXz5DbA/640?wx_fmt=png)\n\n对于一个进程来说，把它放到等待队列需要昂贵的系统调用，这种方式应该被避免。在没有竞争的情况下，futex 可以直接在用户空间中工作。这些进程共享一个 32 位`整数(integer)` 作为公共锁变量。假设锁的初始化为 1，我们认为这时锁已经被释放了。线程通过执行原子性的操作`减少并测试(decrement and test)` 来抢占锁。decrement and set 是 Linux 中的原子功能，由包裹在 C 函数中的内联汇编组成，并在头文件中进行定义。下一步，线程会检查结果来查看锁是否已经被释放。如果锁现在不是锁定状态，那么刚好我们的线程可以成功抢占该锁。然而，如果锁被其他线程持有，抢占锁的线程不得不等待。在这种情况下，futex 库不会`自旋`，但是会使用一个系统调用来把线程放在内核中的等待队列中。这样一来，切换到内核的开销已经是合情合理的了，因为线程可以在任何时候阻塞。当线程完成了锁的工作时，它会使用原子性的 `增加并测试(increment and test)` 释放锁，并检查结果以查看内核等待队列上是否仍阻止任何进程。如果有的话，它会通知内核可以对等待队列中的一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与竞争。\n\n#### Pthreads 中的互斥量\n\nPthreads 提供了一些功能用来同步线程。最基本的机制是使用互斥量变量，可以锁定和解锁，用来保护每个关键区域。希望进入关键区域的线程首先要尝试获取 mutex。如果 mutex 没有加锁，线程能够马上进入并且互斥量能够自动锁定，从而阻止其他线程进入。如果 mutex 已经加锁，调用线程会阻塞，直到 mutex 解锁。如果多个线程在相同的互斥量上等待，当互斥量解锁时，只有一个线程能够进入并且重新加锁。这些锁并不是必须的，程序员需要正确使用它们。\n\n下面是与互斥量有关的函数调用\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkjhv2Kpw5NOIUR9iaZqLkRyb8oR34ThPSm8mZJbwfmVYcC2DwiaU6f1w/640?wx_fmt=png)\n\n像我们想象中的一样，mutex 能够被创建和销毁，扮演这两个角色的分别是 `Phread_mutex_init` 和 `Pthread_mutex_destroy`。mutex 也可以通过 `Pthread_mutex_lock` 来进行加锁，如果互斥量已经加锁，则会阻塞调用者。还有一个调用`Pthread_mutex_trylock` 用来尝试对线程加锁，当 mutex 已经被加锁时，会返回一个错误代码而不是阻塞调用者。这个调用允许线程有效的进行忙等。最后，`Pthread_mutex_unlock` 会对 mutex 解锁并且释放一个正在等待的线程。\n\n除了互斥量以外，`Pthreads` 还提供了第二种同步机制： `条件变量(condition variables)` 。mutex 可以很好的允许或阻止对关键区域的访问。条件变量允许线程由于未满足某些条件而阻塞。绝大多数情况下这两种方法是一起使用的。下面我们进一步来研究线程、互斥量、条件变量之间的关联。\n\n下面再来重新认识一下生产者和消费者问题：一个线程将东西放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区没有空槽可以使用了，生产者线程会阻塞起来直到有一个线程可以使用。生产者使用 mutex 来进行原子性检查从而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自己并在以后被唤醒。这便是条件变量做的工作。\n\n下面是一些与条件变量有关的最重要的 pthread 调用\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk839icYzflFsfMELQx6wusdDtK5VibFSBT3icKPIKBXpkO0jNshBocXZmA/640?wx_fmt=png)\n\n上表中给出了一些调用用来创建和销毁条件变量。条件变量上的主要属性是 `Pthread_cond_wait` 和 `Pthread_cond_signal`。前者阻塞调用线程，直到其他线程发出信号为止（使用后者调用）。阻塞的线程通常需要等待唤醒的信号以此来释放资源或者执行某些其他活动。只有这样阻塞的线程才能继续工作。条件变量允许等待与阻塞原子性的进程。`Pthread_cond_broadcast` 用来唤醒多个阻塞的、需要等待信号唤醒的线程。\n\n> 需要注意的是，条件变量（不像是信号量）不会存在于内存中。如果将一个信号量传递给一个没有线程等待的条件变量，那么这个信号就会丢失，这个需要注意\n\n下面是一个使用互斥量和条件变量的例子\n\n```\n#include <stdio.h>\n#include <pthread.h>\n\n/* 需要生产的数量 */\n#define MAX 1000000000                                        \npthread_mutex_t the_mutex;\n/* 使用信号量 */\npthread_cond_t condc,condp;                                \nint buffer = 0;\n\n/* 生产数据 */\nvoid *producer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i <= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&the_mutex);                \n    while(buffer != 0){\n      pthread_cond_wait(&condp,&the_mutex);\n    }\n    /* 把他们放在缓冲区中 */\n    buffer = i;            \n    /* 唤醒消费者 */\n    pthread_cond_signal(&condc);    \n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&the_mutex);            \n  }\n  pthread_exit(0);\n\n}\n\n/* 消费数据 */\nvoid *consumer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i <= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&the_mutex);                \n    while(buffer == 0){\n      pthread_cond_wait(&condc,&the_mutex);\n    }\n    /* 把他们从缓冲区中取出 */\n    buffer = 0;    \n    /* 唤醒生产者 */\n    pthread_cond_signal(&condp);\n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&the_mutex);            \n  }\n  pthread_exit(0);\n\n}                              \n```\n\n### 管程\n\n为了能够编写更加准确无误的程序，Brinch Hansen 和 Hoare 提出了一个更高级的同步原语叫做 `管程(monitor)`。他们两个人的提案略有不同，通过下面的描述你就可以知道。管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。下面展示了一种抽象的，类似 Pascal 语言展示的简洁的管程。不能用 C 语言进行描述，因为管程是语言概念而 C 语言并不支持管程。\n\n```\nmonitor example\n    integer i;\n    condition c;\n\n    procedure producer();\n  ...\n    end;    \n\n    procedure consumer();\n    .\n    end;\nend monitor;\n```\n\n管程有一个很重要的特性，即在任何时候管程中只能有一个活跃的进程，这一特性使管程能够很方便的实现互斥操作。管程是编程语言的特性，所以编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。通常情况下，当进程调用管程中的程序时，该程序的前几条指令会检查管程中是否有其他活跃的进程。如果有的话，调用进程将被挂起，直到另一个进程离开管程才将其唤醒。如果没有活跃进程在使用管程，那么该调用进程才可以进入。\n\n进入管程中的互斥由编译器负责，但是一种通用做法是使用 `互斥量(mutex)` 和 `二进制信号量(binary semaphore)`。由于编译器而不是程序员在操作，因此出错的几率会大大降低。在任何时候，编写管程的程序员都无需关心编译器是如何处理的。他只需要知道将所有的临界区转换成为管程过程即可。绝不会有两个进程同时执行临界区中的代码。\n\n即使管程提供了一种简单的方式来实现互斥，但在我们看来，这还不够。因为我们还需要一种在进程无法执行被阻塞。在生产者 - 消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放在管程程序中，但是生产者在发现缓冲区满的时候该如何阻塞呢？\n\n解决的办法是引入`条件变量(condition variables)` 以及相关的两个操作 `wait` 和 `signal`。当一个管程程序发现它不能运行时（例如，生产者发现缓冲区已满），它会在某个条件变量（如 full）上执行 `wait` 操作。这个操作造成调用进程阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面的 pthread 中我们已经探讨过条件变量的实现细节了。另一个进程，比如消费者可以通过执行 `signal` 来唤醒阻塞的调用进程。\n\n> Brinch Hansen 和 Hoare 在对进程唤醒上有所不同，Hoare 建议让新唤醒的进程继续运行；而挂起另外的进程。而 Brinch Hansen 建议让执行 signal 的进程必须退出管程，这里我们采用 Brinch Hansen 的建议，因为它在概念上更简单，并且更容易实现。\n\n如果在一个条件变量上有若干进程都在等待，则在对该条件执行 signal 操作后，系统调度程序只能选择其中一个进程恢复运行。\n\n顺便提一下，这里还有上面两位教授没有提出的第三种方式，它的理论是让执行 signal 的进程继续运行，等待这个进程退出管程时，其他进程才能进入管程。\n\n条件变量不是计数器。条件变量也不能像信号量那样积累信号以便以后使用。所以，如果向一个条件变量发送信号，但是该条件变量上没有等待进程，那么信号将会丢失。也就是说，**wait 操作必须在 signal 之前执行**。\n\n下面是一个使用 `Pascal` 语言通过管程实现的生产者 - 消费者问题的解法\n\n```\nmonitor ProducerConsumer\n        condition full,empty;\n        integer count;\n\n        procedure insert(item:integer);\n        begin\n                if count = N then wait(full);\n                insert_item(item);\n                count := count + 1;\n                if count = 1 then signal(empty);\n        end;\n\n        function remove:integer;\n        begin\n                if count = 0 then wait(empty);\n                remove = remove_item;\n                count := count - 1;\n                if count = N - 1 then signal(full);\n        end;\n\n        count := 0;\nend monitor;\n\nprocedure producer;\nbegin\n            while true do\n      begin \n                  item = produce_item;\n                  ProducerConsumer.insert(item);\n      end\nend;\n\nprocedure consumer;\nbegin \n            while true do\n            begin\n                        item = ProducerConsumer.remove;\n                        consume_item(item);\n            end\nend;\n```\n\n读者可能觉得 wait 和 signal 操作看起来像是前面提到的 sleep 和 wakeup ，而且后者存在严重的竞争条件。它们确实很像，但是有个关键的区别：sleep 和 wakeup 之所以会失败是因为当一个进程想睡眠时，另一个进程试图去唤醒它。使用管程则不会发生这种情况。管程程序的自动互斥保证了这一点，如果管程过程中的生产者发现缓冲区已满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成并且把生产者标志为不可运行之前，是不会允许消费者进入管程的。\n\n尽管类 Pascal 是一种想象的语言，但还是有一些真正的编程语言支持，比如 Java （终于轮到大 Java 出场了），Java 是能够支持管程的，它是一种 `面向对象`的语言，支持用户级线程，还允许将方法划分为类。只要将关键字 `synchronized` 关键字加到方法中即可。Java 能够保证一旦某个线程执行该方法，就不允许其他线程执行该对象中的任何 synchronized 方法。没有关键字 synchronized ，就不能保证没有交叉执行。\n\n下面是 Java 使用管程解决的生产者 - 消费者问题\n\n```\npublic class ProducerConsumer {\n  // 定义缓冲区大小的长度\n  static final int N = 100;\n  // 初始化一个新的生产者线程\n  static Producer p = new Producer();\n  // 初始化一个新的消费者线程\n  static Consumer c = new Consumer();        \n  // 初始化一个管程\n  static Our_monitor mon = new Our_monitor(); \n\n  // run 包含了线程代码\n  static class Producer extends Thread{\n    public void run(){                                                \n      int item;\n      // 生产者循环\n      while(true){                                                        \n        item = produce_item();\n        mon.insert(item);\n      }\n    }\n    // 生产代码\n    private int produce_item(){...}                        \n  }\n\n  // run 包含了线程代码\n  static class consumer extends Thread {\n    public void run( ) {                                            \n           int item;\n      while(true){\n        item = mon.remove();\n                consume_item(item);\n      }\n    }\n    // 消费代码\n    private int produce_item(){...}                        \n  }\n\n  // 这是管程\n  static class Our_monitor {                                    \n    private int buffer[] = new int[N];\n    // 计数器和索引\n    private int count = 0,lo = 0,hi = 0;            \n\n    private synchronized void insert(int val){\n      if(count == N){\n        // 如果缓冲区是满的，则进入休眠\n        go_to_sleep();                                                \n      }\n      // 向缓冲区插入内容\n            buffer[hi] = val;                   \n      // 找到下一个槽的为止\n      hi = (hi + 1) % N;                 \n      // 缓冲区中的数目自增 1 \n      count = count + 1;                                            \n      if(count == 1){\n        // 如果消费者睡眠，则唤醒\n        notify();                                                            \n      }\n    }\n\n    private synchronized void remove(int val){\n      int val;\n      if(count == 0){\n        // 缓冲区是空的，进入休眠\n        go_to_sleep();                                                \n      }\n      // 从缓冲区取出数据\n      val = buffer[lo];                \n      // 设置待取出数据项的槽\n      lo = (lo + 1) % N;                    \n      // 缓冲区中的数据项数目减 1 \n      count = count - 1;                                            \n      if(count = N - 1){\n        // 如果生产者睡眠，唤醒它\n        notify();                                                            \n      }\n      return val;\n    }\n\n    private void go_to_sleep() {\n      try{\n        wait( );\n      }catch(Interr uptedExceptionexc) {};\n    }\n  }\n\n}\n```\n\n上面的代码中主要设计四个类，`外部类(outer class)` ProducerConsumer 创建并启动两个线程，p 和 c。第二个类和第三个类 `Producer` 和 `Consumer` 分别包含生产者和消费者代码。最后，`Our_monitor` 是管程，它有两个同步线程，用于在共享缓冲区中插入和取出数据。\n\n在前面的所有例子中，生产者和消费者线程在功能上与它们是相同的。生产者有一个无限循环，该无限循环产生数据并将数据放入公共缓冲区中；消费者也有一个等价的无限循环，该无限循环用于从缓冲区取出数据并完成一系列工作。\n\n程序中比较耐人寻味的就是 `Our_monitor` 了，它包含缓冲区、管理变量以及两个同步方法。当生产者在 insert 内活动时，它保证消费者不能在 remove 方法中运行，从而保证更新变量以及缓冲区的安全性，并且不用担心竞争条件。变量 count 记录在缓冲区中数据的数量。变量 `lo` 是缓冲区槽的序号，指出将要取出的下一个数据项。类似地，`hi` 是缓冲区中下一个要放入的数据项序号。允许 lo = hi，含义是在缓冲区中有 0 个或 N 个数据。\n\nJava 中的同步方法与其他经典管程有本质差别：Java 没有内嵌的条件变量。然而，Java 提供了 wait 和 notify 分别与 sleep 和 wakeup 等价。\n\n**通过临界区自动的互斥，管程比信号量更容易保证并行编程的正确性**。但是管程也有缺点，我们前面说到过管程是一个编程语言的概念，编译器必须要识别管程并用某种方式对其互斥作出保证。**C、Pascal 以及大多数其他编程语言都没有管程**，所以不能依靠编译器来遵守互斥规则。\n\n与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问共享内存的一个或多个 CPU 上的互斥问题的。通过将信号量放在共享内存中并用 `TSL` 或 `XCHG` 指令来保护它们，可以避免竞争。但是如果是在分布式系统中，可能同时具有多个 CPU 的情况，并且每个 CPU 都有自己的私有内存呢，它们通过网络相连，那么这些原语将会失效。因为信号量太低级了，而管程在少数几种编程语言之外无法使用，所以还需要其他方法。\n\n### 消息传递\n\n上面提到的其他方法就是 `消息传递(messaage passing)`。这种进程间通信的方法使用两个原语 `send` 和 `receive` ，它们像信号量而不像管程，是系统调用而不是语言级别。示例如下\n\n```\nsend(destination, &message);\n\nreceive(source, &message);\n```\n\nsend 方法用于向一个给定的目标发送一条消息，receive 从一个给定的源接受一条消息。如果没有消息，接受者可能被阻塞，直到接受一条消息或者带着错误码返回。\n\n#### 消息传递系统的设计要点\n\n消息传递系统现在面临着许多信号量和管程所未涉及的问题和设计难点，尤其对那些在网络中不同机器上的通信状况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接收方可以达成一致：一旦接受到消息后，接收方马上回送一条特殊的 `确认(acknowledgement)` 消息。如果发送方在一段时间间隔内未收到确认，则重发消息。\n\n现在考虑消息本身被正确接收，而返回给发送着的确认消息丢失的情况。发送者将重发消息，这样接受者将收到两次相同的消息。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaWMs2vSqjpXtVDia8zUVjIPup5ZQHWgGQT55NgvLs2OgkaCuw2TSdEA/640?wx_fmt=png)\n\n对于接收者来说，如何区分新的消息和一条重发的老消息是非常重要的。通常采用在每条原始消息中嵌入一个连续的序号来解决此问题。如果接受者收到一条消息，它具有与前面某一条消息一样的序号，就知道这条消息是重复的，可以忽略。\n\n消息系统还必须处理如何命名进程的问题，以便在发送或接收调用中清晰的指明进程。`身份验证(authentication)` 也是一个问题，比如客户端怎么知道它是在与一个真正的文件服务器通信，从发送方到接收方的信息有可能被中间人所篡改。\n\n#### 用消息传递解决生产者 - 消费者问题\n\n现在我们考虑如何使用消息传递来解决生产者 - 消费者问题，而不是共享缓存。下面是一种解决方式\n\n```\n/* buffer 中槽的数量 */\n#define N 100                                                    \n\nvoid producer(void){\n\n  int item;\n  /* buffer 中槽的数量 */\n  message m;                                                    \n\n  while(TRUE){\n    /* 生成放入缓冲区的数据 */\n    item = produce_item();                        \n    /* 等待消费者发送空缓冲区 */\n    receive(consumer,&m);                            \n    /* 建立一个待发送的消息 */\n    build_message(&m,item);                        \n    /* 发送给消费者 */\n    send(consumer,&m);                                \n  }\n\n}\n\nvoid consumer(void){\n\n  int item,i;\n  message m;\n\n  /* 循环N次 */\n  for(int i = 0;i < N;i++){                        \n    /* 发送N个缓冲区 */\n    send(producer,&m);                                \n  }\n  while(TRUE){\n    /* 接受包含数据的消息 */\n    receive(producer,&m);                            \n    /* 将数据从消息中提取出来 */\n      item = extract_item(&m);                    \n    /* 将空缓冲区发送回生产者 */\n    send(producer,&m);                                \n    /* 处理数据 */\n    consume_item(item);                                \n  }\n\n}\n```\n\n假设所有的消息都有相同的大小，并且在尚未接受到发出的消息时，由操作系统自动进行缓冲。在该解决方案中共使用 N 条消息，这就类似于一块共享内存缓冲区的 N 个槽。消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并返回一条填充了内容的消息。通过这种方式，系统中总的消息数量保持不变，所以消息都可以存放在事先确定数量的内存中。\n\n如果生产者的速度要比消费者快，则所有的消息最终都将被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度快，那么情况将正相反：所有的消息均为空，等待生产者来填充，消费者将被阻塞，以等待一条填充过的消息。\n\n消息传递的方式有许多变体，下面先介绍如何对消息进行 `编址`。\n\n*   一种方法是为每个进程分配一个唯一的地址，让消息按进程的地址编址。\n    \n*   另一种方式是引入一个新的数据结构，称为 `信箱(mailbox)`，信箱是一个用来对一定的数据进行缓冲的数据结构，信箱中消息的设置方法也有多种，典型的方法是在信箱创建时确定消息的数量。在使用信箱时，在 send 和 receive 调用的地址参数就是信箱的地址，而不是进程的地址。当一个进程试图向一个满的信箱发送消息时，它将被挂起，直到信箱中有消息被取走，从而为新的消息腾出地址空间。\n    \n\n### 屏障\n\n最后一个同步机制是准备用于进程组而不是进程间的生产者 - 消费者情况的。在某些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段，可以通过在每个阶段的结尾安装一个 `屏障(barrier)` 来实现这种行为。当一个进程到达屏障时，它会被屏障所拦截，直到所有的屏障都到达为止。屏障可用于一组进程同步，如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXktobEIdqeRzlib8Q2NE2hBvwcInsibDwCw80fyuPwWZ9GBugIdpLYMbeA/640?wx_fmt=png)\n\n在上图中我们可以看到，有四个进程接近屏障，这意味着每个进程都在进行运算，但是还没有到达每个阶段的结尾。过了一段时间后，A、B、D 三个进程都到达了屏障，各自的进程被挂起，但此时还不能进入下一个阶段呢，因为进程 B 还没有执行完毕。结果，当最后一个 C 到达屏障后，这个进程组才能够进入下一个阶段。\n\n### 避免锁：读 - 复制 - 更新\n\n最快的锁是根本没有锁。问题在于没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。答案当然是不可以。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其平均值，而此时你进行 A 的移动，会导致 B 会多次读到重复值，而某些值根本没有遇到过。\n\n然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用。窍门在于确保每个读操作要么读取旧的版本，要么读取新的版本，例如下面的树\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknibrKqGWqGZ6HbicKos4iaxdvNsfKaP6DtfTCnjYrjOeIibXzsd0mLcYlw/640?wx_fmt=png)\n\n上面的树中，读操作从根部到叶子遍历整个树。加入一个新节点 X 后，为了实现这一操作，我们要让这个节点在树中可见之前使它 \"恰好正确\"：我们对节点 X 中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使 X 称为 A 的子节点。所有的读操作都不会读到前后不一致的版本\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPU9vEZ58PLRxKcEUQIcCw118ayGmvjv9FyXrkr6XuSDxZe161dsBGA/640?wx_fmt=png)\n\n在上面的图中，我们接着移除 B 和 D。首先，将 A 的左子节点指针指向 C 。所有原本在 A 中的读操作将会后续读到节点 C ，而永远不会读到 B 和 D。也就是说，它们将只会读取到新版数据。同样，所有当前在 B 和 D 中的读操作将继续按照原始的数据结构指针并且读取旧版数据。所有操作均能正确运行，我们不需要锁住任何东西。而不需要锁住数据就能够移除 B 和 D 的主要原因就是 `读-复制-更新(Ready-Copy-Update,RCU)`，将更新过程中的移除和再分配过程分离开。\n\n调度\n--\n\n当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程 / 线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程 / 线程可以运行。操作系统中有一个叫做 `调度程序(scheduler)` 的角色存在，它就是做这件事儿的，该程序使用的算法叫做 `调度算法(scheduling algorithm)` 。\n\n尽管有一些不同，但许多适用于进程调度的处理方法同样也适用于线程调度。当内核管理线程的时候，调度通常会以线程级别发生，很少或者根本不会考虑线程属于哪个进程。下面我们会首先专注于进程和线程的调度问题，然后会明确的介绍线程调度以及它产生的问题。\n\n### 调度介绍\n\n让我们回到早期以磁带上的卡片作为输入的批处理系统的时代，那时候的调度算法非常简单：依次运行磁带上的每一个作业。对于多道程序设计系统，会复杂一些，因为通常会有多个用户在等待服务。一些大型机仍然将 `批处理`和 `分时服务`结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的用户。由于在这些机器中 CPU 是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。\n\n#### 进程行为\n\n几乎所有的进程（磁盘或网络）I/O 请求和计算都是交替运行的\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkhOIjeY0ia73Pm3dJCSLuhRl058IKIxx7RyI1LN1PYfthYvLHmJyicm1A/640?wx_fmt=png)\n\n如上图所示，CPU 不停顿的运行一段时间，然后发出一个系统调用等待 I/O 读写文件。完成系统调用后，CPU 又开始计算，直到它需要读更多的数据或者写入更多的数据为止。当一个进程等待外部设备完成工作而被阻塞时，才是 I/O 活动。  \n\n上面 a 是 CPU 密集型进程；b 是 I/O 密集型进程进程，a 因为在计算的时间上花费时间更长，因此称为`计算密集型(compute-bound)` 或者 `CPU 密集型(CPU-bound)`，b 因为 I/O 发生频率比较快因此称为 `I/O 密集型(I/O-bound)`。计算密集型进程有较长的 CPU 集中使用和较小频度的 I/O 等待。I/O 密集型进程有较短的 CPU 使用时间和较频繁的 I/O 等待。注意到上面两种进程的区分关键在于 CPU 的时间占用而不是 I/O 的时间占用。I/O 密集型的原因是因为它们没有在 I/O 之间花费更多的计算、而不是 I/O 请求时间特别长。无论数据到达后需要花费多少时间，它们都需要花费相同的时间来发出读取磁盘块的硬件请求。\n\n值得注意的是，随着 CPU 的速度越来越快，更多的进程倾向于 I/O 密集型。这种情况出现的原因是 CPU 速度的提升要远远高于硬盘。这种情况导致的结果是，未来对 I/O 密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。\n\n#### 何时调度\n\n第一个和调度有关的问题是`何时进行调度决策`。存在着需要调度处理的各种情形。首先，在创建一个新进程后，需要决定是运行父进程还是子进程。因为二者的进程都处于就绪态下，这是正常的调度决策，可以任意选择，也就是说，调度程序可以任意的选择子进程或父进程开始运行。\n\n第二，在进程退出时需要作出调度决定。因为此进程不再运行（因为它将不再存在），因此必须从就绪进程中选择其他进程运行。如果没有进程处于就绪态，系统提供的`空闲进程`通常会运行\n\n**什么是空闲进程**\n\n`空闲进程(system-supplied idle process)` 是 Microsoft 公司 windows 操作系统带有的系统进程，该进程是在各个处理器上运行的单个线程，它唯一的任务是在系统没有处理其他线程时占用处理器时间。System Idle Process 并不是一个真正的进程，它是`核心虚拟`出来的，多任务操作系统都存在。在没有可用的进程时，系统处于空运行状态，此时就是 System Idle Process 在正在运行。你可以简单的理解成，它代表的是 CPU 的空闲状态，数值越大代表处理器越空闲，可以通过 Windows 任务管理器查看 Windows 中的 CPU 利用率\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmC8dicWibXiabibrgW3hOqJ4xzMFwjPvSuicicpIKiaU711OUIUwOZO6T7pVw/640?wx_fmt=png)\n\n第三种情况是，当进程阻塞在 I/O 、信号量或其他原因时，必须选择另外一个进程来运行。有时，阻塞的原因会成为选择进程运行的关键因素。例如，如果 A 是一个重要进程，并且它正在等待 B 退出关键区域，让 B 退出关键区域从而使 A 得以运行。但是调度程序一般不会对这种情况进行考量。\n\n第四点，当 I/O 中断发生时，可以做出调度决策。如果中断来自 I/O 设备，而 I/O 设备已经完成了其工作，那么那些等待 I/O 的进程现在可以继续运行。由调度程序来决定是否准备运行新的进程还是重新运行已经中断的进程。\n\n如果硬件时钟以 50 或 60 Hz 或其他频率提供周期性中断，可以在每个时钟中断或第 k 个时钟中断处做出调度决策。根据如何处理时钟中断可以把调度算法可以分为两类。`非抢占式(nonpreemptive)` 调度算法挑选一个进程，让该进程运行直到被阻塞（阻塞在 I/O 上或等待另一个进程），或者直到该进程自动释放 CPU。即使该进程运行了若干个小时后，它也不会被强制挂起。这样会在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。\n\n另外一种情况是 `抢占式` 调度算法，它会选择一个进程，并使其在最大固定时间内运行。如果在时间间隔结束后仍在运行，这个进程会被挂起，调度程序会选择其他进程来运行（前提是存在就绪进程）。进行抢占式调度需要在时间间隔结束时发生时钟中断，以将 CPU 的控制权交还给调度程序。如果没有可用的时钟，那么非抢占式就是唯一的选择。\n\n#### 调度算法的分类\n\n毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境\n\n*   `批处理(Batch)`\n    \n*   `交互式(Interactive)`\n    \n*   `实时(Real time)`\n    \n\n批处理系统广泛应用于商业领域，比如用来处理工资单、存货清单、账目收入、账目支出、利息计算、索赔处理和其他周期性作业。在批处理系统中，一般会选择使用非抢占式算法或者周期性比较长的抢占式算法。这种方法可以减少线程切换因此能够提升性能。\n\n在交互式用户环境中，为了避免一个进程霸占 CPU 拒绝为其他进程服务，所以需要抢占式算法。即使没有进程有意要一直运行下去，但是，由于某个进程出现错误也有可能无限期的排斥其他所有进程。为了避免这种情况，抢占式也是必须的。服务器也属于此类别，因为它们通常为多个（远程）用户提供服务，而这些用户都非常着急。计算机用户总是很忙。\n\n在实时系统中，抢占有时是不需要的，因为进程知道自己可能运行不了很长时间，通常很快的做完自己的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。\n\n#### 调度算法的目标\n\n为了设计调度算法，有必要考虑一下什么是好的调度算法。有一些目标取决于环境（批处理、交互式或者实时）蛋大部分是适用于所有情况的，下面是一些需要考量的因素，我们会在下面一起讨论。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkxvibibMFgiaPvgs6ltWepp136jFYSAUMsXGOYRAiaT7l4wCDy4fuKZ95Bw/640?wx_fmt=png)\n\n**所有系统**\n\n在所有的情况中，`公平`是很重要的。对一个进程给予相较于其他等价的进程更多的 CPU 时间片对其他进程来说是不公平的。当然，不同类型的进程可以采用不同的处理方式。\n\n与公平有关的是系统的`强制执行`，什么意思呢？如果某公司的薪资发放系统计划在本月的 15 号，那么碰上了疫情大家生活都很拮据，此时老板说要在 14 号晚上发放薪资，那么调度程序必须强制使进程执行 14 号晚上发放薪资的策略。\n\n另一个共同的目标是保持系统的`所有部分尽可能的忙碌`。如果 CPU 和所有的 I/O 设备能够一直运行，那么相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调入内存运行。在内存中既有一些 CPU 密集型进程又有一些 I/O 密集型进程是一个比较好的想法，好于先调入和运行所有的 CPU 密集型作业，然后在它们完成之后再调入和运行所有 I/O 密集型作业的做法。使用后者这种方式会在 CPU 密集型进程启动后，争夺 CPU ，而磁盘却在空转，而当 I/O 密集型进程启动后，它们又要为磁盘而竞争，CPU 却又在空转。。。。。。显然，通过结合 I/O 密集型和 CPU 密集型，能够使整个系统运行更流畅，效率更高。\n\n**批处理系统**\n\n通常有三个指标来衡量系统工作状态：**吞吐量、周转时间和 CPU 利用率**，`吞吐量(throughout)` 是系统每小时完成的作业数量。综合考虑，每小时完成 50 个工作要比每小时完成 40 个工作好。`周转时间(Turnaround time)` 是一种平均时间，它指的是从一个批处理提交开始直到作业完成时刻为止平均时间。该数据度量了用户要得到输出所需的平均等待时间。周转时间越小越好。\n\n`CPU 利用率(CPU utilization)` 通常作为批处理系统上的指标。即使如此， CPU 利用率也不是一个好的度量指标，真正有价值的衡量指标是系统每小时可以完成多少作业（吞吐量），以及完成作业需要多长时间（周转时间）。把 CPU 利用率作为度量指标，就像是引擎每小时转动了多少次来比较汽车的性能一样。而且知道 CPU 的利用率什么时候接近 100% 要比什么什么时候要求得到更多的计算能力要有用。\n\n**交互式系统**\n\n对于交互式系统，则有不同的指标。最重要的是尽量`减少响应时间`。这个时间说的是从执行指令开始到得到结果的时间。再有后台进程运行（例如，从网络上读取和保存 E-mail 文件）的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的就是一个好的服务。\n\n一个相关的问题是 `均衡性(proportionality)`，用户对做一件事情需要多长时间总是有一种固定（不过通常不正确）的看法。当认为一个请求很复杂需要较多时间时，用户会认为很正常并且可以接受，但是一个很简单的程序却花费了很长的运行时间，用户就会很恼怒。可以拿彩印和复印来举出一个简单的例子，彩印可能需要 1 分钟的时间，但是用户觉得复杂并且愿意等待一分钟，相反，复印很简单只需要 5 秒钟，但是复印机花费 1 分钟却没有完成复印操作，用户就会很焦躁。\n\n**实时系统**\n\n实时系统则有着和交互式系统不同的考量因素，因此也就有不同的调度目标。实时系统的特点是`必须满足最后的截止时间`。例如，如果计算机控制着以固定速率产生数据的设备，未能按时运行的话可能会导致数据丢失。因此，实时系统中最重要的需求是满足所有（或大多数）时间期限。\n\n在一些实事系统中，特别是涉及到多媒体的，`可预测性很重要`。偶尔不能满足最后的截止时间不重要，但是如果音频多媒体运行不稳定，声音质量会持续恶化。视频也会造成问题，但是耳朵要比眼睛敏感很多。为了避免这些问题，进程调度必须能够高度可预测的而且是有规律的。\n\n### 批处理中的调度\n\n现在让我们把目光从一般性的调度转换为特定的调度算法。下面我们会探讨在批处理中的调度。\n\n#### 先来先服务\n\n很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 `先来先服务(first-come,first-serverd)`。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkqPMbFJfGBd9toxDvJn0M90Yc7fIfwm8sYaqk2GkvFWFGWqV0upj7mA/640?wx_fmt=png)\n\n这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。\n\n不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。\n\n#### 最短作业优先\n\n批处理中，第二种调度算法是 `最短作业优先(Shortest Job First)`，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkWytiaXxLwkZ2fQ1nGYZKsZsXtRcNaRjXicn01BsqHwSjk0szP48f1qyQ/640?wx_fmt=png)\n\n如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。  \n\n现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。\n\n> 需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。\n\n#### 最短剩余时间优先\n\n最短作业优先的抢占式版本被称作为 `最短剩余时间优先(Shortest Remaining Time Next)` 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。\n\n### 交互式系统中的调度\n\n交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度\n\n#### 轮询调度\n\n一种最古老、最简单、最公平并且最广泛使用的算法就是 `轮询算法(round-robin)`。每个进程都会被分配一个时间段，称为`时间片(quantum)`，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkOxzKshMcCgeCOxI9IFypGhFvaQNgrmef5xtBTlAN8ozyHPfnQk09Kw/640?wx_fmt=png)\n\n时间片轮询调度中唯一有意思的一点就是时间片的长度。从一个进程切换到另一个进程需要一定的时间进行管理处理，包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作 `进程间切换(process switch)` 和 `上下文切换(context switch)`。如果进程间的切换时间需要 1ms，其中包括内存映射、清除和重新调入高速缓存等，再假设时间片设为 4 ms，那么 CPU 在做完 4 ms 有用的工作之后，CPU 将花费 1 ms 来进行进程间的切换。因此，CPU 的时间片会浪费 20% 的时间在管理开销上。耗费巨大。\n\n为了提高 CPU 的效率，我们把时间片设置为 100 ms。现在时间的浪费只有 1%。但是考虑会发现下面的情况，如果在一个非常短的时间内到达 50 个请求，并且对 CPU 有不同的需求，此时会发生什么？50 个进程都被放在可运行进程列表中。如果 CP 画 U 是空闲的，第一个进程会立即开始执行，第二个直到 100 ms 以后才会启动，以此类推。不幸的是最后一个进程需要等待 5 秒才能获得执行机会。大部分用户都会觉得对于一个简短的指令运行 5 秒中是很慢的。如果队列末尾的某些请求只需要几号秒钟的运行时间的话，这种设计就非常糟糕了。\n\n另外一个因素是如果时间片设置长度要大于 CPU 使用长度，那么抢占就不会经常发生。相反，在时间片用完之前，大多数进程都已经阻塞了，那么就会引起进程间的切换。消除抢占可提高性能，因为进程切换仅在逻辑上必要时才发生，即流程阻塞且无法继续时才发生。\n\n结论可以表述如下：将上下文切换时间设置得太短会导致过多的进程切换并降低 CPU 效率，但设置时间太长会导致一个短请求很长时间得不到响应。最好的切换时间是在 20 - 50 毫秒之间设置。\n\n#### 优先级调度\n\n轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了`优先级调度(priority scheduling)`\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibKKcmqw7wHNaRyic2qWfZQ5mxASpo0qqPtC1M6SCloLc5QvN5rsnib3A/640?wx_fmt=png)\n\n它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。\n\n但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。\n\n可以静态或者动态的为进程分配优先级。在一台军用计算机上，可以把将军所启动的进程设为优先级 100，上校为 90 ，少校为 80，上尉为 70，中尉为 60，以此类推。UNIX 中有一条命令为 `nice` ，它允许用户为了照顾他人而自愿降低自己进程的优先级，但是一般没人用。\n\n优先级也可以由系统动态分配，用于实现某种目的。例如，有些进程为 I/O 密集型，其多数时间用来等待 I/O 结束。当这样的进程需要 CPU 时，应立即分配 CPU，用来启动下一个 I/O 请求，这样就可以在另一个进程进行计算的同时执行 I/O 操作。这类 I/O 密集型进程长时间的等待 CPU 只会造成它长时间占用内存。使 I/O 密集型进程获得较好的服务的一种简单算法是，将其优先级设为 `1/f`，f 为该进程在上一时间片中所占的部分。一个在 50 ms 的时间片中只使用 1 ms 的进程将获得优先级 50 ，而在阻塞之前用掉 25 ms 的进程将具有优先级 2，而使用掉全部时间片的进程将得到优先级 1。\n\n可以很方便的将一组进程按优先级分成若干类，并且在各个类之间采用优先级调度，而在各类进程的内部采用轮转调度。下面展示了一个四个优先级类的系统\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkh7icJrRFORxCKsSnD2DEvfhTIZKYn9o5SYaCl1mvebyx6EnsweGSjnw/640?wx_fmt=png)\n\n它的调度算法主要描述如下：上面存在优先级为 4 类的可运行进程，首先会按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第 4 类进程为空，则按照轮询的方式运行第三类进程。若第 4 类和第 3 类进程都为空，则按照轮转法运行第 2 类进程。如果不对优先级进行调整，则低优先级的进程很容易产生饥饿现象。\n\n#### 多级队列\n\n最早使用优先级调度的系统是 `CTSS(Compatible TimeSharing System)`。CTSS 是一种兼容分时系统，它有一个问题就是进程切换太慢，其原因是 IBM 7094 内存只能放进一个进程。\n\n> IBM 是哥伦比亚大学计算机中心在 1964 - 1968 年的计算机\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkHqGI0SaIpjW7unPiasYQV0ekRmSB3EjbVNJ8jvhic6gL8VbFvicUWOW0w/640?wx_fmt=png)\n\nCTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS 的设计者很快就认识到，为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。\n\n#### 最短进程优先\n\n对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互式进程，那将是非常好的。在某种程度上，的确可以做到这一点。交互式进程通常遵循下列模式：等待命令、执行命令、等待命令、执行命令。。。如果我们把每个命令的执行都看作一个分离的作业，那么我们可以通过首先运行最短的作业来使响应时间最短。这里唯一的问题是如何从当前可运行进程中找出最短的那一个进程。\n\n一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 `T0`，现在假设测量到其下一次运行时间为 `T1`，可以用两个值的加权来改进估计时间，即`aT0+ (1- 1)T1`。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVar1KhzuffcYqXhyRyOL7b8KQiciaUYCpmR2e9iaiaMF6qh60jPk4FCrgA/640?wx_fmt=png)\n\n可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。  \n\n有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 `老化(aging)`。这种方法会使用很多预测值基于当前值的情况。\n\n#### 保证调度\n\n一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。\n\n#### 彩票调度\n\n对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 `彩票调度(lottery scheduling)`算法。\n\n其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。\n\n`George Orwell` 关于 **所有的进程是平等的，但是某些进程能够更平等一些**。一些重要的进程可以给它们额外的彩票，以便增加他们赢得的机会。如果出售了 100 张彩票，而且有一个进程持有了它们中的 20 张，它就会有 20% 的机会去赢得彩票中奖。在长时间的运行中，它就会获得 20% 的 CPU。相反，对于优先级调度程序，很难说明拥有优先级 40 究竟是什么意思，这里的规则很清楚，拥有彩票 f 份额的进程大约得到系统资源的 f 份额。\n\n如果希望进程之间协作的话可以交换它们之间的票据。例如，客户端进程给服务器进程发送了一条消息后阻塞，客户端进程可能会把自己所有的票据都交给服务器，来增加下一次服务器运行的机会。当服务完成后，它会把彩票还给客户端让其有机会再次运行。事实上，如果没有客户机，服务器也根本不需要彩票。\n\n> 可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 `速度之靴` 的效果。\n\n#### 公平分享调度\n\n到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。\n\n为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些 CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkp2JUKicTTic4Mh3owkYeABOicg6zXAkfFSmoTZs7W6UtRN5Rsc3VcTqPA/640?wx_fmt=png)\n\n### 实时系统中的调度\n\n`实时系统(real-time)` 是一个时间扮演了重要作用的系统。典型的，一种或多种外部物理设备发给计算机一个服务请求，而计算机必须在一个确定的时间范围内恰当的做出反应。例如，在 CD 播放器中的计算机会获得从驱动器过来的位流，然后必须在非常短的时间内将位流转换为音乐播放出来。如果计算时间过长，那么音乐就会听起来有异常。再比如说医院特别护理部门的病人监护装置、飞机中的自动驾驶系统、列车中的烟雾警告装置等，在这些例子中，正确但是却缓慢的响应要比没有响应甚至还糟糕。\n\n实时系统可以分为两类，`硬实时(hard real time)` 和 `软实时(soft real time)` 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。在这两种情形中，实时都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前可知的。这些进程一般寿命较短，并且极快的运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。\n\n实时系统中的事件可以按照响应方式进一步分类为`周期性(以规则的时间间隔发生)`事件或 `非周期性(发生时间不可预知)`事件。一个系统可能要响应多个周期性事件流，根据每个事件处理所需的时间，可能甚至无法处理所有事件。例如，如果有 m 个周期事件，事件 i 以周期 Pi 发生，并需要 Ci 秒 CPU 时间处理一个事件，那么可以处理负载的条件是\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkicxWrh9f5BDPIHJU9PDzKE0HR42WWlTyA1P9rDLSVhtibSQ7VVeymJibA/640?wx_fmt=png)\n\n只有满足这个条件的实时系统称为`可调度的`，这意味着它实际上能够被实现。一个不满足此检验标准的进程不能被调度，因为这些进程共同需要的 CPU 时间总和大于 CPU 能提供的时间。\n\n举一个例子，考虑一个有三个周期性事件的软实时系统，其周期分别是 100 ms、200 m 和 500 ms。如果这些事件分别需要 50 ms、30 ms 和 100 ms 的 CPU 时间，那么该系统时可调度的，因为 0.5 + 0.15 + 0.2 < 1。如果此时有第四个事件加入，其周期为 1 秒，那么此时这个事件如果不超过 150 ms，那么仍然是可以调度的。忽略上下文切换的时间。\n\n实时系统的调度算法可以是静态的或动态的。前者在系统开始运行之前做出调度决策；后者在运行过程中进行调度决策。只有在可以提前掌握所完成的工作以及必须满足的截止时间等信息时，静态调度才能工作，而动态调度不需要这些限制。\n\n### 调度策略和机制\n\n到目前为止，我们隐含的假设系统中所有进程属于不同的分组用户并且进程间存在相互竞争 CPU 的情况。通常情况下确实如此，但有时也会发生一个进程会有很多子进程并在其控制下运行的情况。例如，一个数据库管理系统进程会有很多子进程。每一个子进程可能处理不同的请求，或者每个子进程实现不同的功能（如请求分析、磁盘访问等）。主进程完全可能掌握哪一个子进程最重要（或最紧迫），而哪一个最不重要。但是，以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。\n\n解决问题的办法是将 `调度机制(scheduling mechanism)` 和 `调度策略(scheduling policy)` 分开，这是长期一贯的原则。这也就意味着调度算法在某种方式下被参数化了，但是参数可以被用户进程填写。让我们首先考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。调度机制位于内核，而调度策略由用户进程决定，调度策略和机制分离是一种关键性思路。\n\n### 线程调度\n\n当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本质的差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。\n\n首先考虑用户级线程，由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为 A，并给予 A 以时间片控制。A 中的线程调度程序决定哪个线程运行。假设为 A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程继续运行。\n\n在进程 A 终于又一次运行时，线程 A1 会接着运行。该线程会继续耗费 A 进程的所有时间，直到它完成工作。不过，线程运行不会影响到其他进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程 A 内部发生的事情。\n\n现在考虑 A 线程每次 CPU 计算的工作比较少的情况，例如：在 50 ms 的时间片中有 5 ms 的计算工作。于是，每个线程运行一会儿，然后把 CPU 交回给线程调度程序。这样在内核切换到进程 B 之前，就会有序列 A1,A2,A3,A1,A2,A3,A1,A2,A3,A1 。如下所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibIqnCiaYicYscwr55u59URicaa9iaIgcMA3zmicGaJKFtoByUkUAClg9YUA/640?wx_fmt=png)\n\n运行时系统使用的调度算法可以是上面介绍算法的任意一种。从实用方面考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程。但由于线程之间的合作关系，这通常也不是问题。\n\n现在考虑使用内核线程的情况，内核选择一个特定的线程运行。它不用考虑线程属于哪个进程，不过如果有必要的话，也可以这么做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在 50 ms 的时间片内，5 ms 之后被阻塞，在 30 ms 的时间片中，线程的顺序会是 A1,B1,A2,B2,A3,B3。如下图所示\n\n![](https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaejGGnPoyhnwOUWNVdDCQpicVrhQwUibbMtZRKOUEOOJGvgBh5tPMiavg/640?wx_fmt=png)\n\n用户级线程和内核级线程之间的主要差别在于`性能`。用户级线程的切换需要少量的机器指令（想象一下 Java 程序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程挂起。  \n\n从进程 A 的一个线程切换到进程 B 的一个线程，其消耗要远高于运行进程 A 的两个线程（涉及修改内存映像，修改高速缓存），内核对这种切换的消耗是了解到，可以通过这些信息作出决定。\n\n文章参考：\n\n《现代操作系统》\n\n《Modern Operating System》forth edition\n\nhttps://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems\n\nhttps://j00ru.vexillium.org/syscalls/nt/32/\n\nhttps://www.bottomupcs.com/process_hierarchy.xhtml\n\nhttps://en.wikipedia.org/wiki/Runtime_system\n\nhttps://en.wikipedia.org/wiki/Execution_model\n\nhttps://zhidao.baidu.com/question/113227654.html\n\nhttps://baike.baidu.com/item/ 等待队列 / 9223804?fr=aladdin\n\nhttp://www.columbia.edu/cu/computinghistory/7094.html\n\nhttps://baike.baidu.com/item/ 中断向量 / 4947039?fr=aladdin\n\n```\n推荐阅读：\n\n\n\n\n完全整理 | 365篇高质技术文章目录整理\n\n算法之美 : 栈和队列\n\n\n主宰这个世界的10大算法\n\n\n彻底理解cookie、session、token\n\n\n浅谈什么是递归算法\n\n专注服务器后台技术栈知识总结分享\n\n欢迎关注交流共同进步\n\n码农有道 coding\n\n\n\n\n码农有道，为您提供通俗易懂的技术文章，让技术变的更简单！\n\n好文章，我 在看 \n```","slug":"进程与线程-转载","published":1,"updated":"2020-06-08T06:05:04.751Z","_id":"ck7hczcxk0000bwym2xsyab17","comments":1,"layout":"post","photos":[],"link":"","content":"<blockquote>\n<p>本文由 <a href=\"http://ksria.com/simpread/\" target=\"_blank\" rel=\"noopener\">简悦 SimpRead</a> 转码， 原文地址 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&amp;mid=2247487913&amp;idx=1&amp;sn=8c3f042c5a73ce9e49b21bc6cce2442e&amp;chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1583500047238&amp;sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&amp;key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&amp;ascene=1&amp;uin=MTIwMTg1OTcwMg%3D%3D&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&amp;pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&amp;mid=2247487913&amp;idx=1&amp;sn=8c3f042c5a73ce9e49b21bc6cce2442e&amp;chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1583500047238&amp;sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&amp;key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&amp;ascene=1&amp;uin=MTIwMTg1OTcwMg%3D%3D&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&amp;pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm</a></p>\n</blockquote>\n<p>来源：Java 建设者</p>\n<p>作者：cxuan</p>\n<p>下面是本文的结构图</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJArB4bFRERsiaKqyAZbnJxU3ISIOnRUH908G29Tx2iaCXc5Ps7DTiaD4A/640?wx_fmt=png\" alt=\"\"></p>\n<p>我们平常说的进程和线程更多的是基于编程语言的角度来说的，那么你真的了解什么是线程和进程吗？那么我们就从操作系统的角度来了解一下什么是进程和线程。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>操作系统中最核心的概念就是 <code>进程</code>，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，它们也支持<code>（伪）并发</code>操作。它们会将一个单独的 CPU 抽象为多个虚拟机的 CPU。可以说：没有进程的抽象，现代操作系统将不复存在。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJcVYZew9ryLN0RIu6fwSUliaeSKiaKgoBDSXfaH9Hqvm4Cm73Na86K3Q/640?wx_fmt=png\" alt=\"\"></p>\n<p>所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。</p>\n<p>现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。于是一个支持多进程的多道程序系统就会显得很有必要了。</p>\n<p>在许多多道程序系统中，CPU 会在<code>进程</code>间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生<code>并行</code>的错觉。有时候人们说的 <code>伪并行(pseudoparallelism)</code> 就是这种情况，以此来区分多处理器系统 (该系统由两个或多个 CPU 来共享同一个物理内存)</p>\n<blockquote>\n<p>再来详细解释一下伪并行：<code>伪并行</code>是指单核或多核处理器同时执行多个进程，从而使程序更快。通过以非常有限的时间间隔在程序之间快速切换 CPU，因此会产生并行感。缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。</p>\n</blockquote>\n<p>因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析，对该模型的探讨，也是本篇文章的主题。下面我们就来探讨一下进程模型</p>\n<h3 id=\"进程模型\"><a href=\"#进程模型\" class=\"headerlink\" title=\"进程模型\"></a>进程模型</h3><p>在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干<code>顺序进程(sequential processes)</code>，简称为 <code>进程(process)</code> 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkwicOIsH2wqofqK877AcZEnQwsg3hSibpu2q5ZWrKKOwIUZloGHVEY69w/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkpSsh1RicmibCiaNmgwq5xMM8NtTl1yW3jXcL2pMIBDUmQk9VRGSMC4wwA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。</p>\n<p>从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，<strong>但在任何一个给定的瞬间仅有一个进程真正运行</strong>。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkeqicuKAib5xjeLwSEKvmWbnZd9poHkykMIZxKGfryBFwNBCNHghALbQg/640?wx_fmt=png\" alt=\"\"></p>\n<p>因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），<strong>每一个核也只能一次运行一个线程</strong>。</p>\n<p>由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原谅：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、而做蛋糕的各种原料都是输入数据。进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系列动作的总和。</p>\n<p>现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。</p>\n<p>这里的关键思想是<code>认识到一个进程所需的条件</code>，进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，如果一个进程运行了两遍，则被认为是两个进程。那么我们了解到进程模型后，那么进程是如何创建的呢？</p>\n<h3 id=\"进程的创建\"><a href=\"#进程的创建\" class=\"headerlink\" title=\"进程的创建\"></a>进程的创建</h3><p>操作系统需要一些方式来创建进程。下面是一些创建进程的方式</p>\n<ul>\n<li><p>系统初始化（init）</p>\n</li>\n<li><p>正在运行的程序执行了创建进程的系统调用（比如 fork）</p>\n</li>\n<li><p>用户请求创建一个新进程</p>\n</li>\n<li><p>初始化一个批处理工作</p>\n</li>\n</ul>\n<h4 id=\"系统初始化\"><a href=\"#系统初始化\" class=\"headerlink\" title=\"系统初始化\"></a>系统初始化</h4><p>启动操作系统时，通常会创建若干个进程。其中有些是<code>前台进程(numerous processes)</code>，也就是同用户进行交互并替他们完成工作的进程。一些运行在后台，并不与特定的用户进行交互，例如，设计一个进程来接收发来的电子邮件，这个进程大部分的时间都在休眠，但是只要邮件到来后这个进程就会被唤醒。还可以设计一个进程来接收对该计算机上网页的传入请求，在请求到达的进程唤醒来处理网页的传入请求。进程运行在后台用来处理一些活动像是 e-mail，web 网页，新闻，打印等等被称为 <code>守护进程(daemons)</code>。大型系统会有很多守护进程。在 UNIX 中，<code>ps</code> 程序可以列出正在运行的进程， 在 Windows 中，可以使用任务管理器。</p>\n<h4 id=\"系统调用创建\"><a href=\"#系统调用创建\" class=\"headerlink\" title=\"系统调用创建\"></a>系统调用创建</h4><p>除了在启动阶段创建进程之外，一些新的进程也可以在后面创建。通常，一个正在运行的进程会发出<code>系统调用</code>用来创建一个或多个新进程来帮助其完成工作。例如，如果有大量的数据需要经过网络调取并进行顺序处理，那么创建一个进程读数据，并把数据放到共享缓冲区中，而让第二个进程取走并正确处理会比较容易些。在多处理器中，让每个进程运行在不同的 CPU 上也可以使工作做的更快。</p>\n<h4 id=\"用户请求创建\"><a href=\"#用户请求创建\" class=\"headerlink\" title=\"用户请求创建\"></a>用户请求创建</h4><p>在许多交互式系统中，输入一个命令或者双击图标就可以启动程序，以上任意一种操作都可以选择开启一个新的进程，在基本的 UNIX 系统中运行 X，新进程将接管启动它的窗口。在 Windows 中启动进程时，它一般没有窗口，但是它可以创建一个或多个窗口。每个窗口都可以运行进程。通过鼠标或者命令就可以切换窗口并与进程进行交互。</p>\n<blockquote>\n<p>交互式系统是以人与计算机之间大量交互为特征的计算机系统，比如游戏、web 浏览器，IDE 等集成开发环境。</p>\n</blockquote>\n<h4 id=\"批处理创建\"><a href=\"#批处理创建\" class=\"headerlink\" title=\"批处理创建\"></a>批处理创建</h4><p>最后一种创建进程的情形会在<code>大型机的批处理系统</code>中应用。用户在这种系统中提交批处理作业。当操作系统决定它有资源来运行另一个任务时，它将创建一个新进程并从其中的输入队列中运行下一个作业。</p>\n<p>从技术上讲，在所有这些情况下，让现有流程执行流程是通过创建系统调用来创建新流程的。该进程可能是正在运行的用户进程，是从键盘或鼠标调用的系统进程或批处理程序。这些就是系统调用创建新进程的过程。该系统调用告诉操作系统创建一个新进程，并直接或间接指示在其中运行哪个程序。</p>\n<p>在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 <code>fork</code>。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。通常，子进程会执行 <code>execve</code> 或者一个简单的系统调用来改变内存映像并运行一个新的程序。例如，当一个用户在 shell 中输出 sort 命令时，shell 会 fork 一个子进程然后子进程去执行 sort 命令。这两步过程的原因是允许子进程在 fork 之后但在 execve 之前操作其文件描述符，以完成标准输入，标准输出和标准错误的重定向。</p>\n<p>在 Windows 中，情况正相反，一个简单的 Win32 功能调用 <code>CreateProcess</code>，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 <code>CreateProcess</code> Win 32 中大概有 100 个其他的函数用于处理进程的管理，同步以及相关的事务。下面是 UNIX 操作系统和 Windows 操作系统系统调用的对比</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkCg59tia26o7PFqCbmnFhEI6j1qoKbDeLKhUYepPVmZ400sWwtahYrNA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个词，这个修改将对另一个进程不可见。在 UNIX 中，子进程的地址空间是父进程的一个拷贝，但是却是两个不同的地址空间；不可写的内存区域是共享的。某些 UNIX 实现是正是在两者之间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但是这种情况下内存通过 <code>写时复制(copy-on-write)</code> 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确的复制，以确保修改发生在私有内存区域。再次强调，<strong>可写的内存是不能被共享的</strong>。但是，对于一个新创建的进程来说，确实有可能共享创建者的资源，比如可以共享打开的文件。<strong>在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的</strong>。  </p>\n<h3 id=\"进程的终止\"><a href=\"#进程的终止\" class=\"headerlink\" title=\"进程的终止\"></a>进程的终止</h3><p>进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的</p>\n<ul>\n<li><p><code>正常退出(自愿的)</code></p>\n</li>\n<li><p><code>错误退出(自愿的)</code></p>\n</li>\n<li><p><code>严重错误(非自愿的)</code></p>\n</li>\n<li><p><code>被其他进程杀死(非自愿的)</code></p>\n</li>\n</ul>\n<h4 id=\"正常退出\"><a href=\"#正常退出\" class=\"headerlink\" title=\"正常退出\"></a>正常退出</h4><p>多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 <code>exit</code> ，在 Windows 中是 <code>ExitProcess</code>。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。</p>\n<h4 id=\"错误退出\"><a href=\"#错误退出\" class=\"headerlink\" title=\"错误退出\"></a>错误退出</h4><p>进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令</p>\n<pre><code>cc foo.c    </code></pre><p>为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。</p>\n<h4 id=\"严重错误\"><a href=\"#严重错误\" class=\"headerlink\" title=\"严重错误\"></a>严重错误</h4><p>进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。</p>\n<h4 id=\"被其他进程杀死\"><a href=\"#被其他进程杀死\" class=\"headerlink\" title=\"被其他进程杀死\"></a>被其他进程杀死</h4><p>第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 <code>TerminateProcess</code>（注意不是系统调用）。</p>\n<h3 id=\"进程的层次结构\"><a href=\"#进程的层次结构\" class=\"headerlink\" title=\"进程的层次结构\"></a>进程的层次结构</h3><p>在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。</p>\n<h4 id=\"UNIX-进程体系\"><a href=\"#UNIX-进程体系\" class=\"headerlink\" title=\"UNIX 进程体系\"></a>UNIX 进程体系</h4><p>在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。</p>\n<p>这里有另一个例子，可以用来说明层次的作用，考虑 <code>UNIX</code> 在启动时如何初始化自己。一个称为 <code>init</code> 的特殊进程出现在启动映像中 。当 init 进程开始运行时，它会读取一个文件，文件会告诉它有多少个终端。然后为每个终端创建一个新进程。这些进程等待用户登录。如果登录成功，该登录进程就执行一个 shell 来等待接收用户输入指令，这些命令可能会启动更多的进程，以此类推。因此，整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkfB32mZKNYKtf0P9jW3Qax9iaW3gF4OfXGnBLM7FDBxvAUAHpiazZDRVw/640?wx_fmt=png\" alt=\"\"></p>\n<h4 id=\"Windows-进程体系\"><a href=\"#Windows-进程体系\" class=\"headerlink\" title=\"Windows 进程体系\"></a>Windows 进程体系</h4><p>相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。而在 UNIX 中，进程不能剥夺其子进程的 <code>进程权</code>。（这样看来，还是 Windows 比较<code>渣</code>）。</p>\n<h3 id=\"进程状态\"><a href=\"#进程状态\" class=\"headerlink\" title=\"进程状态\"></a>进程状态</h3><p>尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。例如，一个进程的结果可以作为另一个进程的输入，在 shell 命令中</p>\n<pre><code>cat chapter1 chapter2 chapter3 | grep tree</code></pre><p>第一个进程是 <code>cat</code>，将三个文件级联并输出。第二个进程是 <code>grep</code>，它从输入中选择具有包含关键字 <code>tree</code> 的内容，根据这两个进程的相对速度（这取决于两个程序的相对复杂度和各自所分配到的 CPU 时间片），可能会发生下面这种情况，<code>grep</code> 准备就绪开始运行，但是输入进程还没有完成，于是必须阻塞 grep 进程，直到输入完毕。</p>\n<p>当一个进程开始运行时，它可能会经历下面这几种状态</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk0nh0PP7ykpeG74eOW5iahBUU5AmxJjnr2Lot6w2dloqoBYgsAibrFg0A/640?wx_fmt=png\" alt=\"\"></p>\n<p>图中会涉及三种状态</p>\n<ol>\n<li><p><code>运行态</code>，运行态指的就是进程实际占用 CPU 时间片运行时</p>\n</li>\n<li><p><code>就绪态</code>，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态</p>\n</li>\n<li><p><code>阻塞态</code>，除非某种外部事件发生，否则进程不能运行</p>\n</li>\n</ol>\n<p>逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程<code>可运行</code>，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。</p>\n<p>三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生<code>状态1</code>的轮转，在某些系统中进程执行系统调用，例如 <code>pause</code>，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。</p>\n<p>转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。</p>\n<blockquote>\n<p><strong>程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点</strong>。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。</p>\n</blockquote>\n<p>当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。</p>\n<p>从上面的观点引入了下面的模型</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPP9Rn6j8AW1uLNLoKOjBtWbYRvyhrQicjjLl8n8GFuibRbuBXQnu27nw/640?wx_fmt=png\" alt=\"\"></p>\n<p><strong>操作系统最底层的就是调度程序</strong>，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。事实上，调度程序只是一段非常小的程序。</p>\n<h3 id=\"进程的实现\"><a href=\"#进程的实现\" class=\"headerlink\" title=\"进程的实现\"></a>进程的实现</h3><p>操作系统为了执行进程间的切换，会维护着一张表格，这张表就是 <code>进程表(process table)</code>。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。</p>\n<p>下面展示了一个典型系统中的关键字段</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkC2WWXEkRAKErcia0ib3Hia2DWsLtPRzqQLdt4Mo326QWfF7LfyXfcUApQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>第一列内容与<code>进程管理</code>有关，第二列内容与 <code>存储管理</code>有关，第三列内容与<code>文件管理</code>有关。</p>\n<p>存储管理的 text segment 、 data segment、stack segment 更多了解见下面这篇文章</p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&mid=2247484788&idx=1&sn=8a17224cabe09d3bd564dfdf22e2ff5d&chksm=fc45f887cb3271914f0e688a3cce4d7e3ce9077cdde199648e72aa92ad08fba2047b4483b7e8&token=504034995&lang=zh_CN&scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">程序员需要了解的硬核知识之汇编语言 (全)</a></p>\n<p>现在我们应该对进程表有个大致的了解了，就可以在对单个 CPU 上如何运行多个顺序进程的错觉做更多的解释。与每一 I/O 类相关联的是一个称作 <code>中断向量(interrupt vector)</code> 的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这就是硬件所做的事情。然后软件就随即接管一切剩余的工作。</p>\n<p>当中断结束后，操作系统会调用一个 C 程序来处理中断剩下的工作。在完成剩下的工作后，会使某些进程就绪，接着调用调度程序，决定随后运行哪个进程。然后将控制权转移给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行，下面显示了中断处理和调度的过程。</p>\n<ol>\n<li><p>硬件压入堆栈程序计数器等</p>\n</li>\n<li><p>硬件从中断向量装入新的程序计数器</p>\n</li>\n<li><p>汇编语言过程保存寄存器的值</p>\n</li>\n<li><p>汇编语言过程设置新的堆栈</p>\n</li>\n<li><p>C 中断服务器运行（典型的读和缓存写入）</p>\n</li>\n<li><p>调度器决定下面哪个程序先运行</p>\n</li>\n<li><p>C 过程返回至汇编代码</p>\n</li>\n<li><p>汇编语言过程开始运行新的当前进程</p>\n</li>\n</ol>\n<p>一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。</p>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><p>在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。下面我们就着重探讨一下什么是线程</p>\n<h3 id=\"线程的使用\"><a href=\"#线程的使用\" class=\"headerlink\" title=\"线程的使用\"></a>线程的使用</h3><p>或许这个疑问也是你的疑问，为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答</p>\n<ul>\n<li><p>多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的</p>\n</li>\n<li><p>线程要比进程<code>更轻量级</code>，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。</p>\n</li>\n<li><p>第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度</p>\n</li>\n</ul>\n<h4 id=\"多线程解决方案\"><a href=\"#多线程解决方案\" class=\"headerlink\" title=\"多线程解决方案\"></a>多线程解决方案</h4><p>现在考虑一个线程使用的例子：一个万维网服务器，对页面的请求发送给服务器，而所请求的页面发送回客户端。在多数 web 站点上，某些页面较其他页面相比有更多的访问。例如，索尼的主页比任何一个照相机详情介绍页面具有更多的访问，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这种页面的集合称为 <code>高速缓存(cache)</code>，高速缓存也应用在许多场合中，比如说 CPU 缓存。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiafv8cMyibXVb2KNYiaU7IktbLNOPOeficbw2jRlHzF50BPen1r00FYCag/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面是一个 web 服务器的组织方式，一个叫做 <code>调度线程(dispatcher thread)</code> 的线程从网络中读入工作请求，在调度线程检查完请求后，它会选择一个空闲的（阻塞的）工作线程来处理请求，通常是将消息的指针写入到每个线程关联的特殊字中。然后调度线程会唤醒正在睡眠中的工作线程，把工作线程的状态从阻塞态变为就绪态。</p>\n<p>当工作线程启动后，它会检查请求是否在 web 页面的高速缓存中存在，这个高速缓存是所有线程都可以访问的。如果高速缓存不存在这个 web 页面的话，它会调用一个 <code>read</code> 操作从磁盘中获取页面并且阻塞线程直到磁盘操作完成。当线程阻塞在硬盘操作的期间，为了完成更多的工作，调度线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。</p>\n<p>这种模型允许将服务器编写为顺序线程的集合，在分派线程的程序中包含一个死循环，该循环用来获得工作请求并且把请求派给工作线程。每个工作线程的代码包含一个从调度线程接收的请求，并且检查 web 高速缓存中是否存在所需页面，如果有，直接把该页面返回给客户，接着工作线程阻塞，等待一个新请求的到达。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后工作线程阻塞，等待一个新请求。</p>\n<p>下面是调度线程和工作线程的代码，这里假设 TRUE 为常数 1 ，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。</p>\n<p><strong>调度线程的大致逻辑</strong></p>\n<pre><code>while(TRUE){\n  get_next_request(&amp;buf);\n  handoff_work(&amp;buf);\n}</code></pre><p><strong>工作线程的大致逻辑</strong></p>\n<pre><code>while(TRUE){\n  wait_for_work(&amp;buf);\n  look_for_page_in_cache(&amp;buf,&amp;page);\n  if(page_not_in_cache(&amp;page)){\n    read_page_from_disk(&amp;buf,&amp;page);\n  }\n  return _page(&amp;page);\n}</code></pre><h4 id=\"单线程解决方案\"><a href=\"#单线程解决方案\" class=\"headerlink\" title=\"单线程解决方案\"></a>单线程解决方案</h4><p>现在考虑没有多线程的情况下，如何编写 Web 服务器。我们很容易的就想象为单个线程了，Web 服务器的主循环获取请求并检查请求，并争取在下一个请求之前完成工作。在等待磁盘操作时，服务器空转，并且不处理任何到来的其他请求。结果会导致每秒中只有很少的请求被处理，所以这个例子能够说明多线程提高了程序的并行性并提高了程序的性能。</p>\n<h4 id=\"状态机解决方案\"><a href=\"#状态机解决方案\" class=\"headerlink\" title=\"状态机解决方案\"></a>状态机解决方案</h4><p>到现在为止，我们已经有了两种解决方案，单线程解决方案和多线程解决方案，其实还有一种解决方案就是 <code>状态机解决方案</code>，它的流程如下</p>\n<p>如果目前只有一个非阻塞版本的 read 系统调用可以使用，那么当请求到达服务器时，这个唯一的 read 调用的线程会进行检查，如果能够从高速缓存中得到响应，那么直接返回，如果不能，则启动一个非阻塞的磁盘操作</p>\n<p>服务器在表中记录当前请求的状态，然后进入并获取下一个事件，紧接着下一个事件可能就是一个新工作的请求或是磁盘对先前操作的回答。如果是新工作的请求，那么就开始处理请求。如果是磁盘的响应，就从表中取出对应的状态信息进行处理。对于非阻塞式磁盘 I/O 而言，这种响应一般都是信号中断响应。</p>\n<p>每次服务器从某个请求工作的状态切换到另一个状态时，都必须显示的保存或者重新装入相应的计算状态。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为<code>有限状态机(finite-state machine)</code>，有限状态机被广泛的应用在计算机科学中。</p>\n<p>这三种解决方案各有各的特性，多线程使得顺序进程的思想得以保留下来，并且实现了并行性，但是顺序进程会阻塞系统调用；单线程服务器保留了阻塞系统的简易性，但是却放弃了性能。有限状态机的处理方法运用了非阻塞调用和中断，通过并行实现了高性能，但是给编程增加了困难。</p>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>特性</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单线程</td>\n<td>无并行性，性能较差，阻塞系统调用</td>\n</tr>\n<tr>\n<td>多线程</td>\n<td>有并行性，阻塞系统调用</td>\n</tr>\n<tr>\n<td>有限状态机</td>\n<td>并行性，非阻塞系统调用、中断</td>\n</tr>\n</tbody></table>\n<h3 id=\"经典的线程模型\"><a href=\"#经典的线程模型\" class=\"headerlink\" title=\"经典的线程模型\"></a>经典的线程模型</h3><p>理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。</p>\n<p>另一个概念是，进程中拥有一个执行的线程，通常简写为 <code>线程(thread)</code>。线程会有程序计数器，用来记录接着要执行哪一条指令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。</p>\n<p>线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在一个进程中并行运行多个线程类似于在一台计算机上运行多个进程。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为<code>轻量的进程(lightweight processes)</code>。<code>多线程(multithreading)</code>一词还用于描述在同一进程中多个线程的情况。</p>\n<p>下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2uvgku9q5Vv9GyQkOicZQtYCH52z6BKMGiaeVlQztM3jDeicn1AFOL7dQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknc4JzHybInkL388a2Mib2jq4P8P2JkvgH6RFbsv0QKtOFN6mz0qgQOw/640?wx_fmt=png\" alt=\"\"></p>\n<p>线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，<strong>因此一个线程可以读取、写入甚至擦除另一个线程的堆栈</strong>。线程之间除了共享同一内存空间外，还具有如下不同的内容</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkciaYNEibh4VsBF79p911Fgt7Ca558CpyNyuppk9wt7DrvuN1Tfibysvmg/640?wx_fmt=png\" alt=\"\"></p>\n<p>上图左边的是同一个进程中<code>每个线程共享</code>的内容，上图右边是<code>每个线程</code>中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。</p>\n<p>和进程一样，线程可以处于下面这几种状态：<strong>运行中、阻塞、就绪和终止（进程图中没有画）</strong>。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。<strong>线程之间的状态转换和进程之间的状态转换是一样的</strong>。</p>\n<p>每个线程都会有自己的堆栈，如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkSwK4icLBknT5psHj1niac06X161XVudxzlylzibyRPBHhsjHvdqkpDAQ/640?wx_fmt=png\" alt=\"\"></p>\n<h4 id=\"线程系统调用\"><a href=\"#线程系统调用\" class=\"headerlink\" title=\"线程系统调用\"></a>线程系统调用</h4><p>进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 <code>thread_create</code>）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。</p>\n<p>当一个线程完成工作后，可以通过调用一个函数（比如 <code>thread_exit</code>）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 <code>thread_join</code> ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。</p>\n<p>另一个常见的线程是调用 <code>thread_yield</code>，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。</p>\n<h3 id=\"POSIX-线程\"><a href=\"#POSIX-线程\" class=\"headerlink\" title=\"POSIX 线程\"></a>POSIX 线程</h3><p>为了使编写可移植线程程序成为可能，IEEE 在 IEEE 标准 1003.1c 中定义了线程标准。线程包被定义为 <code>Pthreads</code>。大部分的 UNIX 系统支持它。这个标准定义了 60 多种功能调用，一一列举不太现实，下面为你列举了一些常用的系统调用。</p>\n<blockquote>\n<p><strong>POSIX 线程</strong>（通常称为 <strong>pthreads</strong>）是一种独立于语言而存在的执行模型，以及并行执行模型。它允许程序控制时间上重叠的多个不同的工作流程。每个工作流程都称为一个线程，可以通过调用 POSIX Threads API 来实现对这些流程的创建和控制。可以把它理解为线程的标准。</p>\n<p>POSIX Threads 的实现在许多类似且符合 POSIX 的操作系统上可用，例如 <strong>FreeBSD、NetBSD、OpenBSD、Linux、macOS、Android、Solaris</strong>，它在现有 Windows API 之上实现了 <strong>pthread</strong>。</p>\n<p>IEEE 是世界上最大的技术专业组织，致力于为人类的利益而发展技术。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>线程调用</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pthread_create</td>\n<td>创建一个新线程</td>\n</tr>\n<tr>\n<td>pthread_exit</td>\n<td>结束调用的线程</td>\n</tr>\n<tr>\n<td>pthread_join</td>\n<td>等待一个特定的线程退出</td>\n</tr>\n<tr>\n<td>pthread_yield</td>\n<td>释放 CPU 来运行另外一个线程</td>\n</tr>\n<tr>\n<td>pthread_attr_init</td>\n<td>创建并初始化一个线程的属性结构</td>\n</tr>\n<tr>\n<td>pthread_attr_destory</td>\n<td>删除一个线程的属性结构</td>\n</tr>\n</tbody></table>\n<p>所有的 Pthreads 都有特定的属性，每一个都含有标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这个属性包括堆栈大小、调度参数以及其他线程需要的项目。</p>\n<p>新的线程会通过 <code>pthread_create</code> 创建，新创建的线程的标识符会作为函数值返回。这个调用非常像是 UNIX 中的 <code>fork</code> 系统调用（除了参数之外），其中线程标识符起着 <code>PID</code> 的作用，这么做的目的是为了和其他线程进行区分。</p>\n<p>当线程完成指派给他的工作后，会通过 <code>pthread_exit</code> 来终止。这个调用会停止线程并释放堆栈。</p>\n<p>一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 <code>pthread_join</code> 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。</p>\n<p>有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长的时间并且希望给另外一个线程机会去运行。这时候可以通过 <code>pthread_yield</code> 来完成。</p>\n<p>下面两个线程调用是处理属性的。<code>pthread_attr_init</code> 建立关联一个线程的属性结构并初始化成默认值，这些值（例如优先级）可以通过修改属性结构的值来改变。</p>\n<p>最后，<code>pthread_attr_destroy</code> 删除一个线程的结构，释放它占用的内存。它不会影响调用它的线程，这些线程会一直存在。</p>\n<p>为了更好的理解 pthread 是如何工作的，考虑下面这个例子</p>\n<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\n#define NUMBER_OF_THREADS 10\n\nvoid *print_hello_world(vvoid *tid){\n  /* 输出线程的标识符，然后退出 */\n  printf(&quot;Hello World. Greetings from thread %d\\n&quot;,tid);\n  pthread_exit(NULL);\n}\n\nint main(int argc,char *argv[]){\n  /* 主程序创建 10 个线程，然后退出 */\n  pthread_t threads[NUMBER_OF_THREADS];\n  int status,i;\n\n  for(int i = 0;i &lt; NUMBER_OF_THREADS;i++){\n    printf(&quot;Main here. Creating thread %d\\n&quot;,i);\n    status = pthread_create(&amp;threads[i], NULL, print_hello_world, (void *)i);\n\n    if(status != 0){\n      printf(&quot;Oops. pthread_create returned error code %d\\n&quot;,status);\n      exit(-1);\n    }\n  }\n  exit(NULL);\n}</code></pre><p>主线程在宣布它的指责之后，循环 <code>NUMBER_OF_THREADS</code> 次，每次创建一个新的线程。如果线程创建失败，会打印出一条信息后退出。在创建完成所有的工作后，主程序退出。</p>\n<h3 id=\"线程实现\"><a href=\"#线程实现\" class=\"headerlink\" title=\"线程实现\"></a>线程实现</h3><p>主要有三种实现方式</p>\n<ul>\n<li><p>在用户空间中实现线程；</p>\n</li>\n<li><p>在内核空间中实现线程；</p>\n</li>\n<li><p>在用户和内核空间中混合实现线程。</p>\n</li>\n</ul>\n<p>下面我们分开讨论一下</p>\n<h4 id=\"在用户空间中实现线程\"><a href=\"#在用户空间中实现线程\" class=\"headerlink\" title=\"在用户空间中实现线程\"></a>在用户空间中实现线程</h4><p>第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkcq03vztMLnRiaYPTqX0KENPFKPnNr2Ic0qj79V3e0Py9JstIWCI4HibQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程：pthread_create, pthread_exit, pthread_join 和 pthread_yield。</p>\n<blockquote>\n<p><code>运行时系统(Runtime System)</code> 也叫做运行时环境，该运行时系统提供了程序在其中运行的环境。此环境可能会解决许多问题，包括应用程序内存的布局，程序如何访问变量，在过程之间传递参数的机制，与操作系统的接口等等。编译器根据特定的运行时系统进行假设以生成正确的代码。通常，运行时系统将负责设置和管理堆栈，并且会包含诸如垃圾收集，线程或语言内置的其他动态的功能。</p>\n</blockquote>\n<p>在用户空间管理线程时，每个进程需要有其专用的<code>线程表(thread table)</code>，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态。该线程表由运行时系统统一管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程的所有信息，与内核在进程表中存放的信息完全一样。</p>\n<h4 id=\"在用户空间实现线程的优势\"><a href=\"#在用户空间实现线程的优势\" class=\"headerlink\" title=\"在用户空间实现线程的优势\"></a>在用户空间实现线程的优势</h4><p>在用户空间中实现线程要比在内核空间中实现线程具有这些方面的优势：考虑如果在线程完成时或者是在调用 <code>pthread_yield</code> 时，必要时会进程线程切换，然后线程的信息会被保存在运行时环境所提供的线程表中，然后，线程调度程序来选择另外一个需要运行的线程。保存线程的状态和调度程序都是<code>本地过程</code>，<strong>所以启动他们比进行内核调用效率更高。因而不需要切换到内核，也就不需要上下文切换，也不需要对内存高速缓存进行刷新，因为线程调度非常便捷，因此效率比较高</strong>。</p>\n<p>在用户空间实现线程还有一个优势就是<strong>它允许每个进程有自己定制的调度算法</strong>。例如在某些应用程序中，那些具有垃圾收集线程的应用程序（知道是谁了吧）就不用担心自己线程会不会在不合适的时候停止，这是一个优势。用户线程还具有较好的可扩展性，因为内核空间中的内核线程需要一些表空间和堆栈空间，如果内核线程数量比较大，容易造成问题。</p>\n<h4 id=\"在用户空间实现线程的劣势\"><a href=\"#在用户空间实现线程的劣势\" class=\"headerlink\" title=\"在用户空间实现线程的劣势\"></a>在用户空间实现线程的劣势</h4><p>尽管在用户空间实现线程会具有一定的性能优势，但是劣势还是很明显的，你如何实现<code>阻塞系统调用</code>呢？假设在还没有任何键盘输入之前，一个线程读取键盘，让线程进行系统调用是不可能的，因为这会停止所有的线程。所以，<strong>使用线程的一个目标是能够让线程进行阻塞调用，并且要避免被阻塞的线程影响其他线程</strong>。</p>\n<p>与阻塞调用类似的问题是<code>缺页中断</code>问题，实际上，计算机并不会把所有的程序都一次性的放入内存中，如果某个程序发生函数调用或者跳转指令到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令，这就称为<code>缺页故障</code>。而在对所需的指令进行读入和执行时，相关的进程就会被阻塞。如果只有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。</p>\n<p>另外一个问题是，如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。</p>\n<h3 id=\"在内核中实现线程\"><a href=\"#在内核中实现线程\" class=\"headerlink\" title=\"在内核中实现线程\"></a>在内核中实现线程</h3><p>现在我们考虑使用内核来实现线程的情况，此时不再需要运行时环境了。另外，每个进程中也没有线程表。相反，在内核中会有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaPkapIx1EYhPdibEPKuChcIOcClAlhTUicxq554eFbJVWrvyCVUdumBw/640?wx_fmt=png\" alt=\"\"></p>\n<p>内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。</p>\n<p>所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。</p>\n<p>由于在内核中创建或者销毁线程的开销比较大，所以某些系统会采用可循环利用的方式来回收线程。当某个线程被销毁时，就把它标志为不可运行的状态，但是其内部结构没有受到影响。稍后，在必须创建一个新线程时，就会重新启用旧线程，把它标志为可用状态。</p>\n<p>如果某个进程中的线程造成缺页故障后，内核很容易的就能检查出来是否有其他可运行的线程，如果有的话，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止）比较多，就会带来很大的开销。</p>\n<h3 id=\"混合实现\"><a href=\"#混合实现\" class=\"headerlink\" title=\"混合实现\"></a>混合实现</h3><p>结合用户空间和内核空间的优点，设计人员采用了一种<code>内核级线程</code>的方式，然后将用户级线程与某些或者全部内核线程多路复用起来</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkKYe6RpSy705bprAxhibKHKkiba32AcKmS0AOAcuCyZuMvyduVgWFwGhQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。</p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><p>进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 <code>进程间通信(Inter Process Communication, IPC)</code> 的问题。</p>\n<p>关于进程间的通信，这里有三个问题</p>\n<ul>\n<li><p>上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。</p>\n</li>\n<li><p>第二个问题是如何确保两个或多个线程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。</p>\n</li>\n<li><p>第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。</p>\n</li>\n</ul>\n<p>需要注意的是，这三个问题中的后面两个问题同样也适用于线程</p>\n<p>第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？</p>\n<p>另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。我们后面会慢慢讨论这三个问题，你现在脑子中大致有个印象即可。</p>\n<h3 id=\"竞态条件\"><a href=\"#竞态条件\" class=\"headerlink\" title=\"竞态条件\"></a>竞态条件</h3><p>在一些操作系统中，协作的进程可能共享一些彼此都能读写的公共资源。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的<code>后台目录(spooler directory)</code>中。另一个进程 <code>打印后台进程(printer daemon)</code> 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。</p>\n<p>假设我们的后台目录有非常多的 <code>槽位(slot)</code>，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：<code>out</code>，指向下一个需要打印的文件；<code>in</code>，指向目录中下个空闲的槽位。可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2JljDicfDxXbzlWe7J4KyqznJfd12m6a6BbVaiaMKYxDKU0LpRP9wibibw/640?wx_fmt=png\" alt=\"\"></p>\n<p><code>墨菲法则(Murphy)</code> 中说过，任何可能出错的地方终将出错，这句话生效时，可能发生如下情况。</p>\n<p>进程 A 读到 in 的值为 7，将 7 存在一个局部变量 <code>next_free_slot</code> 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 <code>next_free_slot</code> 中，在这一时刻两个进程都认为下一个可用槽位是 7 。</p>\n<p>进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情</p>\n<p>现在进程 A 开始恢复运行，由于进程 A 通过检查 <code>next_free_slot</code>也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，<strong>即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件 (race condition)</strong>。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象。</p>\n<h3 id=\"临界区\"><a href=\"#临界区\" class=\"headerlink\" title=\"临界区\"></a>临界区</h3><p>不仅共享资源会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：<strong>禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写</strong>。换句话说，我们需要一种 <code>互斥(mutual exclusion)</code> 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。上面问题的纠结点在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。在任何操作系统中，为了实现互斥操作而选用适当的原语是一个主要的设计问题，接下来我们会着重探讨一下。</p>\n<p>避免竞争问题的条件可以用一种抽象的方式去描述。大部分时间，进程都会忙于内部计算和其他不会导致竞争条件的计算。然而，有时候进程会访问共享内存或文件，或者做一些能够导致竞态条件的操作。我们把对共享内存进行访问的程序片段称作 <code>临界区域(critical region)</code> 或 <code>临界区(critical section)</code>。如果我们能够正确的操作，使两个不同进程不可能同时处于临界区，就能避免竞争条件，这也是从操作系统设计角度来进行的。</p>\n<p>尽管上面这种设计避免了竞争条件，但是不能确保并发线程同时访问共享数据的正确性和高效性。一个好的解决方案，应该包含下面四种条件</p>\n<ol>\n<li><p>任何时候两个进程不能同时处于临界区</p>\n</li>\n<li><p>不应对 CPU 的速度和数量做任何假设</p>\n</li>\n<li><p>位于临界区外的进程不得阻塞其他进程</p>\n</li>\n<li><p>不能使任何进程无限等待进入临界区</p>\n</li>\n</ol>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkrTXZzTqwPTGouHGo3DMXicFwwsRRENeKdia9UicibzOyzGBZ1NA1R8kWCg/640?wx_fmt=png\" alt=\"\"></p>\n<p>从抽象的角度来看，我们通常希望进程的行为如上图所示，在 t1 时刻，进程 A 进入临界区，在 t2 的时刻，进程 B 尝试进入临界区，因为此时进程 A 正在处于临界区中，所以进程 B 会阻塞直到 t3 时刻进程 A 离开临界区，此时进程 B 能够允许进入临界区。最后，在 t4 时刻，进程 B 离开临界区，系统恢复到没有进程的原始状态。</p>\n<h3 id=\"忙等互斥\"><a href=\"#忙等互斥\" class=\"headerlink\" title=\"忙等互斥\"></a>忙等互斥</h3><p>下面我们会继续探讨实现互斥的各种设计，在这些方案中，当一个进程正忙于更新其关键区域的共享内存时，没有其他进程会进入其关键区域，也不会造成影响。</p>\n<h4 id=\"屏蔽中断\"><a href=\"#屏蔽中断\" class=\"headerlink\" title=\"屏蔽中断\"></a>屏蔽中断</h4><p>在单处理器系统上，最简单的解决方案是让每个进程在进入临界区后立即<code>屏蔽所有中断</code>，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。</p>\n<p>这个方案可行吗？进程进入临界区域是由谁决定的呢？不是用户进程吗？当进程进入临界区域后，用户进程关闭中断，如果经过一段较长时间后进程没有离开，那么中断不就一直启用不了，结果会如何？可能会造成整个系统的终止。而且如果是多处理器的话，屏蔽中断仅仅对执行 <code>disable</code> 指令的 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。</p>\n<p>另一方面，对内核来说，当它在执行更新变量或列表的几条指令期间将中断屏蔽是很方便的。例如，如果多个进程处理就绪列表中的时候发生中断，则可能会发生竞态条件的出现。所以，屏蔽中断对于操作系统本身来说是一项很有用的技术，但是对于用户线程来说，屏蔽中断却不是一项通用的互斥机制。</p>\n<h4 id=\"锁变量\"><a href=\"#锁变量\" class=\"headerlink\" title=\"锁变量\"></a>锁变量</h4><p>作为第二种尝试，可以寻找一种软件层面解决方案。考虑有单个共享的（锁）变量，初始为值为 0 。当一个线程想要进入关键区域时，它首先会查看锁的值是否为 0 ，如果锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。因此，锁变量的值是 0 则意味着没有线程进入关键区域。如果是 1 则意味着有进程在关键区域内。我们对上图修改后，如下所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmcJYsm5uD0kUSRoia4J0KORtZslfTnAnqBca2Ay7KbWibU2a9ywAKwaw/640?wx_fmt=png\" alt=\"\"></p>\n<p>这种设计方式是否正确呢？是否存在纰漏呢？假设一个进程读出锁变量的值并发现它为 0 ，而恰好在它将其设置为 1 之前，另一个进程调度运行，读出锁的变量为 0 ，并将锁的变量设置为 1 。然后第一个线程运行，把锁变量的值再次设置为 1，此时，临界区域就会有两个进程在同时运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVmTDUd4XWEic0EUCtJnWB8yKr5qUJANrZrDYXm0PLF60Zu7sKas4Yibw/640?wx_fmt=png\" alt=\"\"></p>\n<p>也许有的读者可以这么认为，在进入前检查一次，在要离开的关键区域再检查一次不就解决了吗？实际上这种情况也是于事无补，因为在第二次检查期间其他线程仍有可能修改锁变量的值，换句话说，这种 <code>set-before-check</code> 不是一种 <code>原子性</code> 操作，所以同样还会发生竞争条件。</p>\n<h4 id=\"严格轮询法\"><a href=\"#严格轮询法\" class=\"headerlink\" title=\"严格轮询法\"></a>严格轮询法</h4><p>第三种互斥的方式先抛出来一段代码，这里的程序是用 C 语言编写，之所以采用 C 是因为操作系统普遍是用 C 来编写的（偶尔会用 C++），而基本不会使用 Java 、Modula3 或 Pascal 这样的语言，Java 中的 native 关键字底层也是 C 或 C++ 编写的源码。对于编写操作系统而言，需要使用 C 语言这种强大、高效、可预知和有特性的语言，而对于 Java ，它是不可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾回收机制回收内存。在 C 语言中，这种情况不会发生，C 语言中不会主动调用垃圾回收回收内存。有关 C 、C++ 、Java 和其他四种语言的比较可以参考 <strong>链接</strong></p>\n<p><strong>进程 0 的代码</strong></p>\n<pre><code>while(TRUE){\n  while(turn != 0){\n    /* 进入关键区域 */\n    critical_region();\n    turn = 1;\n    /* 离开关键区域 */\n    noncritical_region();\n  }\n}</code></pre><p><strong>进程 1 的代码</strong></p>\n<pre><code>while(TRUE){\n  while(turn != 1){\n    critical_region();\n    turn = 0;\n    noncritical_region();\n  }\n}</code></pre><p>在上面代码中，变量 <code>turn</code>，初始值为 0 ，用于记录轮到那个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0 ，于是进入临界区。进程 1 也发现其值为 0 ，所以在一个等待循环中不停的测试 turn，看其值何时变为 1。连续检查一个变量直到某个值出现为止，这种方法称为 <code>忙等待(busywaiting)</code>。由于这种方式浪费 CPU 时间，所以这种方式通常应该要避免。只有在有理由认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 <code>自旋锁(spinlock)</code>。</p>\n<p>进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0 。现在进程 0 很快就执行完了整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。</p>\n<p>突然，进程 0 结束了非临界区的操作并返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，此时进程 1 还忙于非临界区的操作，进程 0 只能继续 while 循环，直到进程 1 把 turn 的值改为 0 。这说明，在一个进程比另一个进程执行速度慢了很多的情况下，轮流进入临界区并不是一个好的方法。</p>\n<p>这种情况违反了前面的叙述 3 ，即 <strong>位于临界区外的进程不得阻塞其他进程</strong>，进程 0 被一个临界区外的进程阻塞。由于违反了第三条，所以也不能作为一个好的方案。</p>\n<h4 id=\"Peterson-解法\"><a href=\"#Peterson-解法\" class=\"headerlink\" title=\"Peterson 解法\"></a>Peterson 解法</h4><p>荷兰数学家 T.Dekker 通过将锁变量与警告变量相结合，最早提出了一个不需要严格轮换的软件互斥算法，关于 Dekker 的算法，参考 <strong>链接</strong></p>\n<p>后来， G.L.Peterson 发现了一种简单很多的互斥算法，它的算法如下</p>\n<pre><code>#define FALSE 0\n#define TRUE  1\n/* 进程数量 */\n#define N     2                                                    \n\n/* 现在轮到谁 */\nint turn;                    \n\n/* 所有值初始化为 0 (FALSE) */\nint interested[N];                                            \n\n/* 进程是 0 或 1 */\nvoid enter_region(int process){                    \n\n  /* 另一个进程号 */\n  int other;                                                        \n\n  /* 另一个进程 */\n  other = 1 - process;                \n\n  /* 表示愿意进入临界区 */\n  interested[process] = TRUE;                        \n  turn = process;\n\n  /* 空循环 */\n  while(turn == process \n        &amp;&amp; interested[other] == true){} \n\n}\n\nvoid leave_region(int process){\n\n  /* 表示离开临界区 */\n  interested[process] == FALSE;                 \n}</code></pre><p>在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 <code>enter_region</code>，这个函数调用在需要时将使进程等待，直到能够安全的临界区。在完成对共享变量的操作之后，进程将调用 <code>leave_region</code> 表示操作完成，并且允许其他进程进入。</p>\n<p>现在来看看这个办法是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 <code>enter_region</code>。它通过设置数组元素和将 turn 置为 0 来表示它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程现在调用 enter_region，进程 1 将在此处挂起直到 <code>interested[0]</code> 变为 FALSE，这种情况只有在进程 0 调用 <code>leave_region</code> 退出临界区时才会发生。</p>\n<p>那么上面讨论的是顺序进入的情况，现在来考虑一种两个进程同时调用 <code>enter_region</code> 的情况。它们都将自己的进程存入 turn，但只有最后保存进去的进程号才有效，前一个进程的进程号因为重写而丢失。假如进程 1 是最后存入的，则 turn 为 1 。当两个进程都运行到 <code>while</code> 的时候，进程 0 将不会循环并进入临界区，而进程 1 将会无限循环且不会进入临界区，直到进程 0 退出位置。</p>\n<h4 id=\"TSL-指令\"><a href=\"#TSL-指令\" class=\"headerlink\" title=\"TSL 指令\"></a>TSL 指令</h4><p>现在来看一种需要硬件帮助的方案。一些计算机，特别是那些设计为多处理器的计算机，都会有下面这条指令</p>\n<pre><code>TSL RX,LOCK    </code></pre><p>称为 <code>测试并加锁(test and set lock)</code>，它将一个内存字 lock 读到寄存器 <code>RX</code> 中，然后在该内存地址上存储一个非零值。读写指令能保证是一体的，不可分割的，一同执行的。在这个指令结束之前其他处理器均不允许访问内存。执行 TSL 指令的 CPU 将会锁住内存总线，用来禁止其他 CPU 在这个指令结束之前访问内存。</p>\n<p>很重要的一点是锁住内存总线和禁用中断不一样。禁用中断并不能保证一个处理器在读写操作之间另一个处理器对内存的读写。也就是说，在处理器 1 上屏蔽中断对处理器 2 没有影响。让处理器 2 远离内存直到处理器 1 完成读写的最好的方式就是锁住总线。这需要一个特殊的硬件（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能使用）</p>\n<p>为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程使用 <code>move</code> 指令将 lock 的值重新设置为 0 。</p>\n<p>这条指令如何防止两个进程同时进入临界区呢？下面是解决方案</p>\n<pre><code>enter_region:\n            | 复制锁到寄存器并将锁设为1\n            TSL REGISTER,LOCK              \n            | 锁是 0 吗？\n          CMP REGISTER,#0                             \n          | 若不是零，说明锁已被设置，所以循环\n          JNE enter_region                            \n          | 返回调用者，进入临界区\n          RET                                              \n\nleave_region:\n\n            | 在锁中存入 0\n            MOVE LOCK,#0                  \n      | 返回调用者\n          RET                                              </code></pre><p>我们可以看到这个解决方案的思想和 Peterson 的思想很相似。假设存在如下共 4 指令的汇编语言程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1 ，随后这个原来的值和 0 做对比。如果它不是零，说明之前已经被加过锁，则程序返回到开始并再次测试。经过一段时间后（可长可短），该值变为 0 （当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁也比较简单，程序只需要将 0 存入 lock 即可，不需要特殊的同步指令。</p>\n<p>现在有了一种很明确的做法，那就是进程在进入临界区之前会先调用 <code>enter_region</code>，判断是否进行循环，如果 lock 的值是 1 ，进行无限循环，如果 lock 是 0，不进入循环并进入临界区。在进程从临界区返回时它调用 <code>leave_region</code>，这会把 lock 设置为 0 。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region ，解法才能奏效。</p>\n<p>还有一个可以替换 TSL 的指令是 <code>XCHG</code>，它原子性的交换了两个位置的内容，例如，一个寄存器与一个内存字，代码如下</p>\n<pre><code>enter_region:\n        | 把 1 放在内存器中\n        MOVE REGISTER,#1    \n    | 交换寄存器和锁变量的内容\n        XCHG REGISTER,LOCK          \n    | 锁是 0 吗？\n        CMP REGISTER,#0     \n    | 若不是 0 ，锁已被设置，进行循环\n        JNE enter_region                    \n    | 返回调用者，进入临界区\n        RET                                                     \n\nleave_region:                \n        | 在锁中存入 0 \n        MOVE LOCK,#0    \n    | 返回调用者\n        RET                                                     </code></pre><p>XCHG 的本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在底层同步中使用 XCHG 指令。</p>\n<h3 id=\"睡眠与唤醒\"><a href=\"#睡眠与唤醒\" class=\"headerlink\" title=\"睡眠与唤醒\"></a>睡眠与唤醒</h3><p>上面解法中的 Peterson 、TSL 和 XCHG 解法都是正确的，但是它们都有忙等待的缺点。这些解法的本质上都是一样的，先检查是否能够进入临界区，若不允许，则该进程将原地等待，直到允许为止。</p>\n<p>这种方式不但浪费了 CPU 时间，而且还可能引起意想不到的结果。考虑一台计算机上有两个进程，这两个进程具有不同的优先级，<code>H</code> 是属于优先级比较高的进程，<code>L</code> 是属于优先级比较低的进程。进程调度的规则是不论何时只要 H 进程处于就绪态 H 就开始运行。在某一时刻，L 处于临界区中，此时 H 变为就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 要开始忙等，但由于当 H 就绪时 L 就不会被调度，L 从来不会有机会离开关键区域，所以 H 会变成死循环，有时将这种情况称为<code>优先级反转问题(priority inversion problem)</code>。</p>\n<p>现在让我们看一下进程间的通信原语，这些原语在不允许它们进入关键区域之前会阻塞而不是浪费 CPU 时间，最简单的是 <code>sleep</code> 和 <code>wakeup</code>。Sleep 是一个能够造成调用者阻塞的系统调用，也就是说，这个系统调用会暂停直到其他进程唤醒它。wakeup 调用有一个参数，即要唤醒的进程。还有一种方式是 wakeup 和 sleep 都有一个参数，即 sleep 和 wakeup 需要匹配的内存地址。</p>\n<h4 id=\"生产者-消费者问题\"><a href=\"#生产者-消费者问题\" class=\"headerlink\" title=\"生产者 - 消费者问题\"></a>生产者 - 消费者问题</h4><p>作为这些私有原语的例子，让我们考虑<code>生产者-消费者(producer-consumer)</code> 问题，也称作 <code>有界缓冲区(bounded-buffer)</code> 问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是<code>生产者(producer)</code>，将信息放入缓冲区， 另一个是<code>消费者(consumer)</code>，会从缓冲区中取出。也可以把这个问题一般化为 m 个生产者和 n 个消费者的问题，但是我们这里只讨论一个生产者和一个消费者的情况，这样可以简化实现方案。</p>\n<p>如果缓冲队列已满，那么当生产者仍想要将数据写入缓冲区的时候，会出现问题。它的解决办法是让生产者睡眠，也就是阻塞生产者。等到消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样的，当消费者试图从缓冲区中取数据，但是发现缓冲区为空时，消费者也会睡眠，阻塞。直到生产者向其中放入一个新的数据。</p>\n<p>这个逻辑听起来比较简单，而且这种方式也需要一种称作 <code>监听</code> 的变量，这个变量用于监视缓冲区的数据，我们暂定为 count，如果缓冲区最多存放 N 个数据项，生产者会每次判断 count 是否达到 N，否则生产者向缓冲区放入一个数据项并增量 count 的值。消费者的逻辑也很相似：首先测试 count 的值是否为 0 ，如果为 0 则消费者睡眠、阻塞，否则会从缓冲区取出数据并使 count 数量递减。每个进程也会检查检查是否其他线程是否应该被唤醒，如果应该被唤醒，那么就唤醒该线程。下面是生产者消费者的代码</p>\n<pre><code>/* 缓冲区 slot 槽的数量 */\n#define N 100                        \n/* 缓冲区数据的数量 */\nint count = 0                                        \n\n// 生产者\nvoid producer(void){\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){                \n    /* 生成下一项数据 */\n    item = produce_item()                \n    /* 如果缓存区是满的，就会阻塞 */\n    if(count == N){\n      sleep();                                    \n    }\n\n    /* 把当前数据放在缓冲区中 */\n    insert_item(item);\n    /* 增加缓冲区 count 的数量 */\n    count = count + 1;                    \n    if(count == 1){\n      /* 缓冲区是否为空？ */\n      wakeup(consumer);                    \n    }\n  }\n}\n\n// 消费者\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 如果缓冲区是空的，就会进行阻塞 */\n      if(count == 0){                         \n      sleep();\n    }\n    /* 从缓冲区中取出一个数据 */\n       item = remove_item();           \n    /* 将缓冲区的 count 数量减一 */\n    count = count - 1\n    /* 缓冲区满嘛？ */\n    if(count == N - 1){                    \n      wakeup(producer);        \n    }\n    /* 打印数据项 */\n    consumer_item(item);                \n  }\n\n}</code></pre><p>为了在 C 语言中描述像是 <code>sleep</code> 和 <code>wakeup</code> 的系统调用，我们将以库函数调用的形式来表示。它们不是 C 标准库的一部分，但可以在实际具有这些系统调用的任何系统上使用。代码中未实现的 <code>insert_item</code> 和 <code>remove_item</code> 用来记录将数据项放入缓冲区和从缓冲区取出数据等。</p>\n<p>现在让我们回到生产者 - 消费者问题上来，上面代码中会产生竞争条件，因为 count 这个变量是暴露在大众视野下的。有可能出现下面这种情况：缓冲区为空，此时消费者刚好读取 count 的值发现它为 0 。此时调度程序决定暂停消费者并启动运行生产者。生产者生产了一条数据并把它放在缓冲区中，然后增加 count 的值，并注意到它的值是 1 。由于 count 为 0，消费者必须处于睡眠状态，因此生产者调用 <code>wakeup</code> 来唤醒消费者。但是，消费者此时在逻辑上并没有睡眠，所以 wakeup 信号会丢失。当消费者下次启动后，它会查看之前读取的 count 值，发现它的值是 0 ，然后在此进行睡眠。不久之后生产者会填满整个缓冲区，在这之后会阻塞，这样一来两个进程将永远睡眠下去。</p>\n<p>引起上面问题的本质是 <strong>唤醒尚未进行睡眠状态的进程会导致唤醒丢失</strong>。如果它没有丢失，则一切都很正常。一种快速解决上面问题的方式是增加一个<code>唤醒等待位(wakeup waiting bit)</code>。当一个 wakeup 信号发送给仍在清醒的进程后，该位置为 1 。之后，当进程尝试睡眠的时候，如果唤醒等待位为 1 ，则该位清除，而进程仍然保持清醒。</p>\n<p>然而，当进程数量有许多的时候，这时你可以说通过增加唤醒等待位的数量来唤醒等待位，于是就有了 2、4、6、8 个唤醒等待位，但是并没有从根本上解决问题。</p>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>信号量是 E.W.Dijkstra 在 1965 年提出的一种方法，它使用一个整形变量来累计唤醒次数，以供之后使用。在他的观点中，有一个新的变量类型称作 <code>信号量(semaphore)</code>。一个信号量的取值可以是 0 ，或任意正数。0 表示的是不需要任何唤醒，任意的正数表示的就是唤醒次数。</p>\n<p>Dijkstra 提出了信号量有两个操作，现在通常使用 <code>down</code> 和 <code>up</code>（分别可以用 sleep 和 wakeup 来表示）。down 这个指令的操作会检查值是否大于 0 。如果大于 0 ，则将其值减 1 ；若该值为 0 ，则进程将睡眠，而且此时 down 操作将会继续执行。检查数值、修改变量值以及可能发生的睡眠操作均为一个单一的、不可分割的 <code>原子操作(atomic action)</code> 完成。这会保证一旦信号量操作开始，没有其他的进程能够访问信号量，直到操作完成或者阻塞。这种原子性对于解决同步问题和避免竞争绝对必不可少。</p>\n<blockquote>\n<p>原子性操作指的是在计算机科学的许多其他领域中，一组相关操作全部执行而没有中断或根本不执行。</p>\n</blockquote>\n<p>up 操作会使信号量的值 + 1。如果一个或者多个进程在信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个并允许该程完成 down 操作。因此，对一个进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍然是 0 ，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞是一样的道理。</p>\n<h4 id=\"用信号量解决生产者-消费者问题\"><a href=\"#用信号量解决生产者-消费者问题\" class=\"headerlink\" title=\"用信号量解决生产者 - 消费者问题\"></a>用信号量解决生产者 - 消费者问题</h4><p>用信号量解决丢失的 wakeup 问题，代码如下</p>\n<pre><code>/* 定义缓冲区槽的数量 */\n#define N 100\n/* 信号量是一种特殊的 int */\ntypedef int semaphore;\n/* 控制关键区域的访问 */\nsemaphore mutex = 1;\n/* 统计 buffer 空槽的数量 */\nsemaphore empty = N;\n/* 统计 buffer 满槽的数量 */\nsemaphore full = 0;                                                \n\nvoid producer(void){ \n\n  int item;  \n\n  /* TRUE 的常量是 1 */\n  while(TRUE){            \n    /* 产生放在缓冲区的一些数据 */\n    item = producer_item();        \n    /* 将空槽数量减 1  */\n    down(&amp;empty);    \n    /* 进入关键区域  */\n    down(&amp;mutex);    \n    /* 把数据放入缓冲区中 */\n    insert_item(item);\n    /* 离开临界区 */\n    up(&amp;mutex);    \n    /* 将 buffer 满槽数量 + 1 */\n    up(&amp;full);                                                        \n  }\n}\n\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 缓存区满槽数量 - 1 */\n    down(&amp;full);\n    /* 进入缓冲区 */    \n    down(&amp;mutex);\n    /* 从缓冲区取出数据 */\n    item = remove_item();    \n    /* 离开临界区 */\n    up(&amp;mutex);    \n    /* 将空槽数目 + 1 */\n    up(&amp;empty);    \n    /* 处理数据 */\n    consume_item(item);                                            \n  }\n\n}</code></pre><p>为了确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用来实现。而且操作系统只需在执行以下操作时暂时屏蔽全部中断：<strong>检查信号量、更新、必要时使进程睡眠</strong>。由于这些操作仅需要非常少的指令，因此中断不会造成影响。如果使用多个 CPU，那么信号量应该被锁进行保护。使用 TSL 或者 XCHG 指令用来确保同一时刻只有一个 CPU 对信号量进行操作。</p>\n<p>使用 TSL 或者 XCHG 来防止几个 CPU 同时访问一个信号量，与生产者或消费者使用忙等待来等待其他腾出或填充缓冲区是完全不一样的。前者的操作仅需要几个毫秒，而生产者或消费者可能需要任意长的时间。</p>\n<p>上面这个解决方案使用了三种信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex，用来确保生产者和消费者不会同时进入缓冲区。<code>Full</code> 被初始化为 0 ，empty 初始化为缓冲区中插槽数，mutex 初始化为 1。信号量初始化为 1 并且由两个或多个进程使用，以确保它们中同时只有一个可以进入关键区域的信号被称为 <code>二进制信号量(binary semaphores)</code>。如果每个进程都在进入关键区域之前执行 down 操作，而在离开关键区域之后执行 up 操作，则可以确保相互互斥。</p>\n<p>现在我们有了一个好的进程间原语的保证。然后我们再来看一下中断的顺序保证</p>\n<ol>\n<li><p>硬件压入堆栈程序计数器等</p>\n</li>\n<li><p>硬件从中断向量装入新的程序计数器</p>\n</li>\n<li><p>汇编语言过程保存寄存器的值</p>\n</li>\n<li><p>汇编语言过程设置新的堆栈</p>\n</li>\n<li><p>C 中断服务器运行（典型的读和缓存写入）</p>\n</li>\n<li><p>调度器决定下面哪个程序先运行</p>\n</li>\n<li><p>C 过程返回至汇编代码</p>\n</li>\n<li><p>汇编语言过程开始运行新的当前进程</p>\n</li>\n</ol>\n<p>在使用<code>信号量</code>的系统中，隐藏中断的自然方法是让每个 I/O 设备都配备一个信号量，该信号量最初设置为 0。在 I/O 设备启动后，中断处理程序立刻对相关联的信号执行一个 <code>down</code> 操作，于是进程立即被阻塞。当中断进入时，中断处理程序随后对相关的信号量执行一个 <code>up</code>操作，能够使已经阻止的进程恢复运行。在上面的中断处理步骤中，其中的第 5 步 <code>C 中断服务器运行</code> 就是中断处理程序在信号量上执行的一个 up 操作，所以在第 6 步中，操作系统能够执行设备驱动程序。当然，如果有几个进程已经处于就绪状态，调度程序可能会选择接下来运行一个更重要的进程，我们会在后面讨论调度的算法。</p>\n<p>上面的代码实际上是通过两种不同的方式来使用信号量的，而这两种信号量之间的区别也是很重要的。<code>mutex</code> 信号量用于互斥。它用于确保任意时刻只有一个进程能够对缓冲区和相关变量进行读写。互斥是用于避免进程混乱所必须的一种操作。</p>\n<p>另外一个信号量是关于<code>同步(synchronization)</code>的。<code>full</code> 和 <code>empty</code> 信号量用于确保事件的发生或者不发生。在这个事例中，它们确保了缓冲区满时生产者停止运行；缓冲区为空时消费者停止运行。这两个信号量的使用与 mutex 不同。</p>\n<h3 id=\"互斥量\"><a href=\"#互斥量\" class=\"headerlink\" title=\"互斥量\"></a>互斥量</h3><p>如果不需要信号量的计数能力时，可以使用信号量的一个简单版本，称为 <code>mutex(互斥量)</code>。互斥量的优势就在于在一些共享资源和一段代码中保持互斥。由于互斥的实现既简单又有效，这使得互斥量在实现用户空间线程包时非常有用。</p>\n<p>互斥量是一个处于两种状态之一的共享变量：<code>解锁(unlocked)</code> 和 <code>加锁(locked)</code>。这样，只需要一个二进制位来表示它，不过一般情况下，通常会用一个 <code>整形(integer)</code> 来表示。0 表示解锁，其他所有的值表示加锁，比 1 大的值表示加锁的次数。</p>\n<p>mutex 使用两个过程，当一个线程（或者进程）需要访问关键区域时，会调用 <code>mutex_lock</code> 进行加锁。如果互斥锁当前处于解锁状态（表示关键区域可用），则调用成功，并且调用线程可以自由进入关键区域。</p>\n<p>另一方面，如果 mutex 互斥量已经锁定的话，调用线程会阻塞直到关键区域内的线程执行完毕并且调用了 <code>mutex_unlock</code> 。如果多个线程在 mutex 互斥量上阻塞，将随机选择一个线程并允许它获得锁。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkXJy2jibeQGLUNaWLCLWibibpIKfM2RLogQ38s0VHMdVqUmfVLcPNdwK3w/640?wx_fmt=png\" alt=\"\"></p>\n<p>由于 mutex 互斥量非常简单，所以只要有 TSL 或者是 XCHG 指令，就可以很容易地在用户空间实现它们。用于用户级线程包的 <code>mutex_lock</code> 和 <code>mutex_unlock</code> 代码如下，XCHG 的本质也一样。</p>\n<pre><code>mutex_lock:\n            | 将互斥信号量复制到寄存器，并将互斥信号量置为1\n            TSL REGISTER,MUTEX\n      | 互斥信号量是 0 吗？\n            CMP REGISTER,#0 \n      | 如果互斥信号量为0，它被解锁，所以返回\n            JZE ok  \n      | 互斥信号正在使用；调度其他线程\n            CALL thread_yield   \n      | 再试一次\n            JMP mutex_lock  \n      | 返回调用者，进入临界区\nok:     RET                                                     \n\nmutex_unlcok:\n            | 将 mutex 置为 0 \n            MOVE MUTEX,#0   \n      | 返回调用者\n            RET                                                     </code></pre><p>mutex_lock 的代码和上面 enter_region 的代码很相似，我们可以对比着看一下</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkzgYKTTgzB7hSZvozXicEez3sabKfYzxQcuehvgtiaF4NicljJg2PZJOLg/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面代码最大的区别你看出来了吗？</p>\n<ul>\n<li><p>根据上面我们对 TSL 的分析，我们知道，如果 TSL 判断没有进入临界区的进程会进行无限循环获取锁，而在 TSL 的处理中，如果 mutex 正在使用，那么就调度其他线程进行处理。所以上面最大的区别其实就是在判断 mutex/TSL 之后的处理。</p>\n</li>\n<li><p>在（用户）线程中，情况有所不同，因为没有时钟来停止运行时间过长的线程。结果是通过忙等待的方式来试图获得锁的线程将永远循环下去，决不会得到锁，因为这个运行的线程不会让其他线程运行从而释放锁，其他线程根本没有获得锁的机会。在后者获取锁失败时，它会调用 <code>thread_yield</code> 将 CPU 放弃给另外一个线程。结果就不会进行忙等待。在该线程下次运行时，它再一次对锁进行测试。</p>\n</li>\n</ul>\n<p>上面就是 enter_region 和 mutex_lock 的差别所在。由于 thread_yield 仅仅是一个用户空间的线程调度，所以它的运行非常快捷。这样，<code>mutex_lock</code> 和 <code>mutex_unlock</code> 都不需要任何内核调用。通过使用这些过程，用户线程完全可以实现在用户空间中的同步，这个过程仅仅需要少量的同步。</p>\n<p>我们上面描述的互斥量其实是一套调用框架中的指令。从软件角度来说，总是需要更多的特性和同步原语。例如，有时线程包提供一个调用 <code>mutex_trylock</code>，这个调用尝试获取锁或者返回错误码，但是不会进行加锁操作。这就给了调用线程一个灵活性，以决定下一步做什么，是使用替代方法还是等候下去。</p>\n<h4 id=\"Futexes\"><a href=\"#Futexes\" class=\"headerlink\" title=\"Futexes\"></a>Futexes</h4><p>随着并行的增加，有效的<code>同步(synchronization)</code>和<code>锁定(locking)</code> 对于性能来说是非常重要的。如果进程等待时间很短，那么<code>自旋锁(Spin lock)</code> 是非常有效；但是如果等待时间比较长，那么这会浪费 CPU 周期。如果进程很多，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞是更有效的方式。不幸的是，这种方式也会导致另外的问题：它可以在进程竞争频繁的时候运行良好，但是在竞争不是很激烈的情况下内核切换的消耗会非常大，而且更困难的是，预测锁的竞争数量更不容易。</p>\n<p>有一种有趣的解决方案是把两者的优点结合起来，提出一种新的思想，称为 <code>futex</code>，或者是 <code>快速用户空间互斥(fast user space mutex)</code>，是不是听起来很有意思？</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkW2sY6sXshsFia7jXlNdhuB5XwTt6cjo1pqLgyvV1gcXnNfMASjiasAFA/640?wx_fmt=png\" alt=\"\"></p>\n<p>futex 是 <code>Linux</code> 中的特性实现了基本的锁定（很像是互斥锁）而且避免了陷入内核中，因为内核的切换的开销非常大，这样做可以大大提高性能。futex 由两部分组成：<strong>内核服务和用户库</strong>。内核服务提供了了一个 <code>等待队列(wait queue)</code> 允许多个进程在锁上排队等待。除非内核明确的对他们解除阻塞，否则它们不会运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXksBadzURKQx0t6EagaQBFBZsNcKeXSLCOl01WfJeyIrTU3DCoXz5DbA/640?wx_fmt=png\" alt=\"\"></p>\n<p>对于一个进程来说，把它放到等待队列需要昂贵的系统调用，这种方式应该被避免。在没有竞争的情况下，futex 可以直接在用户空间中工作。这些进程共享一个 32 位<code>整数(integer)</code> 作为公共锁变量。假设锁的初始化为 1，我们认为这时锁已经被释放了。线程通过执行原子性的操作<code>减少并测试(decrement and test)</code> 来抢占锁。decrement and set 是 Linux 中的原子功能，由包裹在 C 函数中的内联汇编组成，并在头文件中进行定义。下一步，线程会检查结果来查看锁是否已经被释放。如果锁现在不是锁定状态，那么刚好我们的线程可以成功抢占该锁。然而，如果锁被其他线程持有，抢占锁的线程不得不等待。在这种情况下，futex 库不会<code>自旋</code>，但是会使用一个系统调用来把线程放在内核中的等待队列中。这样一来，切换到内核的开销已经是合情合理的了，因为线程可以在任何时候阻塞。当线程完成了锁的工作时，它会使用原子性的 <code>增加并测试(increment and test)</code> 释放锁，并检查结果以查看内核等待队列上是否仍阻止任何进程。如果有的话，它会通知内核可以对等待队列中的一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与竞争。</p>\n<h4 id=\"Pthreads-中的互斥量\"><a href=\"#Pthreads-中的互斥量\" class=\"headerlink\" title=\"Pthreads 中的互斥量\"></a>Pthreads 中的互斥量</h4><p>Pthreads 提供了一些功能用来同步线程。最基本的机制是使用互斥量变量，可以锁定和解锁，用来保护每个关键区域。希望进入关键区域的线程首先要尝试获取 mutex。如果 mutex 没有加锁，线程能够马上进入并且互斥量能够自动锁定，从而阻止其他线程进入。如果 mutex 已经加锁，调用线程会阻塞，直到 mutex 解锁。如果多个线程在相同的互斥量上等待，当互斥量解锁时，只有一个线程能够进入并且重新加锁。这些锁并不是必须的，程序员需要正确使用它们。</p>\n<p>下面是与互斥量有关的函数调用</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkjhv2Kpw5NOIUR9iaZqLkRyb8oR34ThPSm8mZJbwfmVYcC2DwiaU6f1w/640?wx_fmt=png\" alt=\"\"></p>\n<p>像我们想象中的一样，mutex 能够被创建和销毁，扮演这两个角色的分别是 <code>Phread_mutex_init</code> 和 <code>Pthread_mutex_destroy</code>。mutex 也可以通过 <code>Pthread_mutex_lock</code> 来进行加锁，如果互斥量已经加锁，则会阻塞调用者。还有一个调用<code>Pthread_mutex_trylock</code> 用来尝试对线程加锁，当 mutex 已经被加锁时，会返回一个错误代码而不是阻塞调用者。这个调用允许线程有效的进行忙等。最后，<code>Pthread_mutex_unlock</code> 会对 mutex 解锁并且释放一个正在等待的线程。</p>\n<p>除了互斥量以外，<code>Pthreads</code> 还提供了第二种同步机制： <code>条件变量(condition variables)</code> 。mutex 可以很好的允许或阻止对关键区域的访问。条件变量允许线程由于未满足某些条件而阻塞。绝大多数情况下这两种方法是一起使用的。下面我们进一步来研究线程、互斥量、条件变量之间的关联。</p>\n<p>下面再来重新认识一下生产者和消费者问题：一个线程将东西放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区没有空槽可以使用了，生产者线程会阻塞起来直到有一个线程可以使用。生产者使用 mutex 来进行原子性检查从而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自己并在以后被唤醒。这便是条件变量做的工作。</p>\n<p>下面是一些与条件变量有关的最重要的 pthread 调用</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk839icYzflFsfMELQx6wusdDtK5VibFSBT3icKPIKBXpkO0jNshBocXZmA/640?wx_fmt=png\" alt=\"\"></p>\n<p>上表中给出了一些调用用来创建和销毁条件变量。条件变量上的主要属性是 <code>Pthread_cond_wait</code> 和 <code>Pthread_cond_signal</code>。前者阻塞调用线程，直到其他线程发出信号为止（使用后者调用）。阻塞的线程通常需要等待唤醒的信号以此来释放资源或者执行某些其他活动。只有这样阻塞的线程才能继续工作。条件变量允许等待与阻塞原子性的进程。<code>Pthread_cond_broadcast</code> 用来唤醒多个阻塞的、需要等待信号唤醒的线程。</p>\n<blockquote>\n<p>需要注意的是，条件变量（不像是信号量）不会存在于内存中。如果将一个信号量传递给一个没有线程等待的条件变量，那么这个信号就会丢失，这个需要注意</p>\n</blockquote>\n<p>下面是一个使用互斥量和条件变量的例子</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;pthread.h&gt;\n\n/* 需要生产的数量 */\n#define MAX 1000000000                                        \npthread_mutex_t the_mutex;\n/* 使用信号量 */\npthread_cond_t condc,condp;                                \nint buffer = 0;\n\n/* 生产数据 */\nvoid *producer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i &lt;= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&amp;the_mutex);                \n    while(buffer != 0){\n      pthread_cond_wait(&amp;condp,&amp;the_mutex);\n    }\n    /* 把他们放在缓冲区中 */\n    buffer = i;            \n    /* 唤醒消费者 */\n    pthread_cond_signal(&amp;condc);    \n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&amp;the_mutex);            \n  }\n  pthread_exit(0);\n\n}\n\n/* 消费数据 */\nvoid *consumer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i &lt;= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&amp;the_mutex);                \n    while(buffer == 0){\n      pthread_cond_wait(&amp;condc,&amp;the_mutex);\n    }\n    /* 把他们从缓冲区中取出 */\n    buffer = 0;    \n    /* 唤醒生产者 */\n    pthread_cond_signal(&amp;condp);\n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&amp;the_mutex);            \n  }\n  pthread_exit(0);\n\n}                              </code></pre><h3 id=\"管程\"><a href=\"#管程\" class=\"headerlink\" title=\"管程\"></a>管程</h3><p>为了能够编写更加准确无误的程序，Brinch Hansen 和 Hoare 提出了一个更高级的同步原语叫做 <code>管程(monitor)</code>。他们两个人的提案略有不同，通过下面的描述你就可以知道。管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。下面展示了一种抽象的，类似 Pascal 语言展示的简洁的管程。不能用 C 语言进行描述，因为管程是语言概念而 C 语言并不支持管程。</p>\n<pre><code>monitor example\n    integer i;\n    condition c;\n\n    procedure producer();\n  ...\n    end;    \n\n    procedure consumer();\n    .\n    end;\nend monitor;</code></pre><p>管程有一个很重要的特性，即在任何时候管程中只能有一个活跃的进程，这一特性使管程能够很方便的实现互斥操作。管程是编程语言的特性，所以编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。通常情况下，当进程调用管程中的程序时，该程序的前几条指令会检查管程中是否有其他活跃的进程。如果有的话，调用进程将被挂起，直到另一个进程离开管程才将其唤醒。如果没有活跃进程在使用管程，那么该调用进程才可以进入。</p>\n<p>进入管程中的互斥由编译器负责，但是一种通用做法是使用 <code>互斥量(mutex)</code> 和 <code>二进制信号量(binary semaphore)</code>。由于编译器而不是程序员在操作，因此出错的几率会大大降低。在任何时候，编写管程的程序员都无需关心编译器是如何处理的。他只需要知道将所有的临界区转换成为管程过程即可。绝不会有两个进程同时执行临界区中的代码。</p>\n<p>即使管程提供了一种简单的方式来实现互斥，但在我们看来，这还不够。因为我们还需要一种在进程无法执行被阻塞。在生产者 - 消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放在管程程序中，但是生产者在发现缓冲区满的时候该如何阻塞呢？</p>\n<p>解决的办法是引入<code>条件变量(condition variables)</code> 以及相关的两个操作 <code>wait</code> 和 <code>signal</code>。当一个管程程序发现它不能运行时（例如，生产者发现缓冲区已满），它会在某个条件变量（如 full）上执行 <code>wait</code> 操作。这个操作造成调用进程阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面的 pthread 中我们已经探讨过条件变量的实现细节了。另一个进程，比如消费者可以通过执行 <code>signal</code> 来唤醒阻塞的调用进程。</p>\n<blockquote>\n<p>Brinch Hansen 和 Hoare 在对进程唤醒上有所不同，Hoare 建议让新唤醒的进程继续运行；而挂起另外的进程。而 Brinch Hansen 建议让执行 signal 的进程必须退出管程，这里我们采用 Brinch Hansen 的建议，因为它在概念上更简单，并且更容易实现。</p>\n</blockquote>\n<p>如果在一个条件变量上有若干进程都在等待，则在对该条件执行 signal 操作后，系统调度程序只能选择其中一个进程恢复运行。</p>\n<p>顺便提一下，这里还有上面两位教授没有提出的第三种方式，它的理论是让执行 signal 的进程继续运行，等待这个进程退出管程时，其他进程才能进入管程。</p>\n<p>条件变量不是计数器。条件变量也不能像信号量那样积累信号以便以后使用。所以，如果向一个条件变量发送信号，但是该条件变量上没有等待进程，那么信号将会丢失。也就是说，<strong>wait 操作必须在 signal 之前执行</strong>。</p>\n<p>下面是一个使用 <code>Pascal</code> 语言通过管程实现的生产者 - 消费者问题的解法</p>\n<pre><code>monitor ProducerConsumer\n        condition full,empty;\n        integer count;\n\n        procedure insert(item:integer);\n        begin\n                if count = N then wait(full);\n                insert_item(item);\n                count := count + 1;\n                if count = 1 then signal(empty);\n        end;\n\n        function remove:integer;\n        begin\n                if count = 0 then wait(empty);\n                remove = remove_item;\n                count := count - 1;\n                if count = N - 1 then signal(full);\n        end;\n\n        count := 0;\nend monitor;\n\nprocedure producer;\nbegin\n            while true do\n      begin \n                  item = produce_item;\n                  ProducerConsumer.insert(item);\n      end\nend;\n\nprocedure consumer;\nbegin \n            while true do\n            begin\n                        item = ProducerConsumer.remove;\n                        consume_item(item);\n            end\nend;</code></pre><p>读者可能觉得 wait 和 signal 操作看起来像是前面提到的 sleep 和 wakeup ，而且后者存在严重的竞争条件。它们确实很像，但是有个关键的区别：sleep 和 wakeup 之所以会失败是因为当一个进程想睡眠时，另一个进程试图去唤醒它。使用管程则不会发生这种情况。管程程序的自动互斥保证了这一点，如果管程过程中的生产者发现缓冲区已满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成并且把生产者标志为不可运行之前，是不会允许消费者进入管程的。</p>\n<p>尽管类 Pascal 是一种想象的语言，但还是有一些真正的编程语言支持，比如 Java （终于轮到大 Java 出场了），Java 是能够支持管程的，它是一种 <code>面向对象</code>的语言，支持用户级线程，还允许将方法划分为类。只要将关键字 <code>synchronized</code> 关键字加到方法中即可。Java 能够保证一旦某个线程执行该方法，就不允许其他线程执行该对象中的任何 synchronized 方法。没有关键字 synchronized ，就不能保证没有交叉执行。</p>\n<p>下面是 Java 使用管程解决的生产者 - 消费者问题</p>\n<pre><code>public class ProducerConsumer {\n  // 定义缓冲区大小的长度\n  static final int N = 100;\n  // 初始化一个新的生产者线程\n  static Producer p = new Producer();\n  // 初始化一个新的消费者线程\n  static Consumer c = new Consumer();        \n  // 初始化一个管程\n  static Our_monitor mon = new Our_monitor(); \n\n  // run 包含了线程代码\n  static class Producer extends Thread{\n    public void run(){                                                \n      int item;\n      // 生产者循环\n      while(true){                                                        \n        item = produce_item();\n        mon.insert(item);\n      }\n    }\n    // 生产代码\n    private int produce_item(){...}                        \n  }\n\n  // run 包含了线程代码\n  static class consumer extends Thread {\n    public void run( ) {                                            \n           int item;\n      while(true){\n        item = mon.remove();\n                consume_item(item);\n      }\n    }\n    // 消费代码\n    private int produce_item(){...}                        \n  }\n\n  // 这是管程\n  static class Our_monitor {                                    \n    private int buffer[] = new int[N];\n    // 计数器和索引\n    private int count = 0,lo = 0,hi = 0;            \n\n    private synchronized void insert(int val){\n      if(count == N){\n        // 如果缓冲区是满的，则进入休眠\n        go_to_sleep();                                                \n      }\n      // 向缓冲区插入内容\n            buffer[hi] = val;                   \n      // 找到下一个槽的为止\n      hi = (hi + 1) % N;                 \n      // 缓冲区中的数目自增 1 \n      count = count + 1;                                            \n      if(count == 1){\n        // 如果消费者睡眠，则唤醒\n        notify();                                                            \n      }\n    }\n\n    private synchronized void remove(int val){\n      int val;\n      if(count == 0){\n        // 缓冲区是空的，进入休眠\n        go_to_sleep();                                                \n      }\n      // 从缓冲区取出数据\n      val = buffer[lo];                \n      // 设置待取出数据项的槽\n      lo = (lo + 1) % N;                    \n      // 缓冲区中的数据项数目减 1 \n      count = count - 1;                                            \n      if(count = N - 1){\n        // 如果生产者睡眠，唤醒它\n        notify();                                                            \n      }\n      return val;\n    }\n\n    private void go_to_sleep() {\n      try{\n        wait( );\n      }catch(Interr uptedExceptionexc) {};\n    }\n  }\n\n}</code></pre><p>上面的代码中主要设计四个类，<code>外部类(outer class)</code> ProducerConsumer 创建并启动两个线程，p 和 c。第二个类和第三个类 <code>Producer</code> 和 <code>Consumer</code> 分别包含生产者和消费者代码。最后，<code>Our_monitor</code> 是管程，它有两个同步线程，用于在共享缓冲区中插入和取出数据。</p>\n<p>在前面的所有例子中，生产者和消费者线程在功能上与它们是相同的。生产者有一个无限循环，该无限循环产生数据并将数据放入公共缓冲区中；消费者也有一个等价的无限循环，该无限循环用于从缓冲区取出数据并完成一系列工作。</p>\n<p>程序中比较耐人寻味的就是 <code>Our_monitor</code> 了，它包含缓冲区、管理变量以及两个同步方法。当生产者在 insert 内活动时，它保证消费者不能在 remove 方法中运行，从而保证更新变量以及缓冲区的安全性，并且不用担心竞争条件。变量 count 记录在缓冲区中数据的数量。变量 <code>lo</code> 是缓冲区槽的序号，指出将要取出的下一个数据项。类似地，<code>hi</code> 是缓冲区中下一个要放入的数据项序号。允许 lo = hi，含义是在缓冲区中有 0 个或 N 个数据。</p>\n<p>Java 中的同步方法与其他经典管程有本质差别：Java 没有内嵌的条件变量。然而，Java 提供了 wait 和 notify 分别与 sleep 和 wakeup 等价。</p>\n<p><strong>通过临界区自动的互斥，管程比信号量更容易保证并行编程的正确性</strong>。但是管程也有缺点，我们前面说到过管程是一个编程语言的概念，编译器必须要识别管程并用某种方式对其互斥作出保证。<strong>C、Pascal 以及大多数其他编程语言都没有管程</strong>，所以不能依靠编译器来遵守互斥规则。</p>\n<p>与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问共享内存的一个或多个 CPU 上的互斥问题的。通过将信号量放在共享内存中并用 <code>TSL</code> 或 <code>XCHG</code> 指令来保护它们，可以避免竞争。但是如果是在分布式系统中，可能同时具有多个 CPU 的情况，并且每个 CPU 都有自己的私有内存呢，它们通过网络相连，那么这些原语将会失效。因为信号量太低级了，而管程在少数几种编程语言之外无法使用，所以还需要其他方法。</p>\n<h3 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h3><p>上面提到的其他方法就是 <code>消息传递(messaage passing)</code>。这种进程间通信的方法使用两个原语 <code>send</code> 和 <code>receive</code> ，它们像信号量而不像管程，是系统调用而不是语言级别。示例如下</p>\n<pre><code>send(destination, &amp;message);\n\nreceive(source, &amp;message);</code></pre><p>send 方法用于向一个给定的目标发送一条消息，receive 从一个给定的源接受一条消息。如果没有消息，接受者可能被阻塞，直到接受一条消息或者带着错误码返回。</p>\n<h4 id=\"消息传递系统的设计要点\"><a href=\"#消息传递系统的设计要点\" class=\"headerlink\" title=\"消息传递系统的设计要点\"></a>消息传递系统的设计要点</h4><p>消息传递系统现在面临着许多信号量和管程所未涉及的问题和设计难点，尤其对那些在网络中不同机器上的通信状况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接收方可以达成一致：一旦接受到消息后，接收方马上回送一条特殊的 <code>确认(acknowledgement)</code> 消息。如果发送方在一段时间间隔内未收到确认，则重发消息。</p>\n<p>现在考虑消息本身被正确接收，而返回给发送着的确认消息丢失的情况。发送者将重发消息，这样接受者将收到两次相同的消息。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaWMs2vSqjpXtVDia8zUVjIPup5ZQHWgGQT55NgvLs2OgkaCuw2TSdEA/640?wx_fmt=png\" alt=\"\"></p>\n<p>对于接收者来说，如何区分新的消息和一条重发的老消息是非常重要的。通常采用在每条原始消息中嵌入一个连续的序号来解决此问题。如果接受者收到一条消息，它具有与前面某一条消息一样的序号，就知道这条消息是重复的，可以忽略。</p>\n<p>消息系统还必须处理如何命名进程的问题，以便在发送或接收调用中清晰的指明进程。<code>身份验证(authentication)</code> 也是一个问题，比如客户端怎么知道它是在与一个真正的文件服务器通信，从发送方到接收方的信息有可能被中间人所篡改。</p>\n<h4 id=\"用消息传递解决生产者-消费者问题\"><a href=\"#用消息传递解决生产者-消费者问题\" class=\"headerlink\" title=\"用消息传递解决生产者 - 消费者问题\"></a>用消息传递解决生产者 - 消费者问题</h4><p>现在我们考虑如何使用消息传递来解决生产者 - 消费者问题，而不是共享缓存。下面是一种解决方式</p>\n<pre><code>/* buffer 中槽的数量 */\n#define N 100                                                    \n\nvoid producer(void){\n\n  int item;\n  /* buffer 中槽的数量 */\n  message m;                                                    \n\n  while(TRUE){\n    /* 生成放入缓冲区的数据 */\n    item = produce_item();                        \n    /* 等待消费者发送空缓冲区 */\n    receive(consumer,&amp;m);                            \n    /* 建立一个待发送的消息 */\n    build_message(&amp;m,item);                        \n    /* 发送给消费者 */\n    send(consumer,&amp;m);                                \n  }\n\n}\n\nvoid consumer(void){\n\n  int item,i;\n  message m;\n\n  /* 循环N次 */\n  for(int i = 0;i &lt; N;i++){                        \n    /* 发送N个缓冲区 */\n    send(producer,&amp;m);                                \n  }\n  while(TRUE){\n    /* 接受包含数据的消息 */\n    receive(producer,&amp;m);                            \n    /* 将数据从消息中提取出来 */\n      item = extract_item(&amp;m);                    \n    /* 将空缓冲区发送回生产者 */\n    send(producer,&amp;m);                                \n    /* 处理数据 */\n    consume_item(item);                                \n  }\n\n}</code></pre><p>假设所有的消息都有相同的大小，并且在尚未接受到发出的消息时，由操作系统自动进行缓冲。在该解决方案中共使用 N 条消息，这就类似于一块共享内存缓冲区的 N 个槽。消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并返回一条填充了内容的消息。通过这种方式，系统中总的消息数量保持不变，所以消息都可以存放在事先确定数量的内存中。</p>\n<p>如果生产者的速度要比消费者快，则所有的消息最终都将被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度快，那么情况将正相反：所有的消息均为空，等待生产者来填充，消费者将被阻塞，以等待一条填充过的消息。</p>\n<p>消息传递的方式有许多变体，下面先介绍如何对消息进行 <code>编址</code>。</p>\n<ul>\n<li><p>一种方法是为每个进程分配一个唯一的地址，让消息按进程的地址编址。</p>\n</li>\n<li><p>另一种方式是引入一个新的数据结构，称为 <code>信箱(mailbox)</code>，信箱是一个用来对一定的数据进行缓冲的数据结构，信箱中消息的设置方法也有多种，典型的方法是在信箱创建时确定消息的数量。在使用信箱时，在 send 和 receive 调用的地址参数就是信箱的地址，而不是进程的地址。当一个进程试图向一个满的信箱发送消息时，它将被挂起，直到信箱中有消息被取走，从而为新的消息腾出地址空间。</p>\n</li>\n</ul>\n<h3 id=\"屏障\"><a href=\"#屏障\" class=\"headerlink\" title=\"屏障\"></a>屏障</h3><p>最后一个同步机制是准备用于进程组而不是进程间的生产者 - 消费者情况的。在某些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段，可以通过在每个阶段的结尾安装一个 <code>屏障(barrier)</code> 来实现这种行为。当一个进程到达屏障时，它会被屏障所拦截，直到所有的屏障都到达为止。屏障可用于一组进程同步，如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXktobEIdqeRzlib8Q2NE2hBvwcInsibDwCw80fyuPwWZ9GBugIdpLYMbeA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上图中我们可以看到，有四个进程接近屏障，这意味着每个进程都在进行运算，但是还没有到达每个阶段的结尾。过了一段时间后，A、B、D 三个进程都到达了屏障，各自的进程被挂起，但此时还不能进入下一个阶段呢，因为进程 B 还没有执行完毕。结果，当最后一个 C 到达屏障后，这个进程组才能够进入下一个阶段。</p>\n<h3 id=\"避免锁：读-复制-更新\"><a href=\"#避免锁：读-复制-更新\" class=\"headerlink\" title=\"避免锁：读 - 复制 - 更新\"></a>避免锁：读 - 复制 - 更新</h3><p>最快的锁是根本没有锁。问题在于没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。答案当然是不可以。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其平均值，而此时你进行 A 的移动，会导致 B 会多次读到重复值，而某些值根本没有遇到过。</p>\n<p>然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用。窍门在于确保每个读操作要么读取旧的版本，要么读取新的版本，例如下面的树</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknibrKqGWqGZ6HbicKos4iaxdvNsfKaP6DtfTCnjYrjOeIibXzsd0mLcYlw/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面的树中，读操作从根部到叶子遍历整个树。加入一个新节点 X 后，为了实现这一操作，我们要让这个节点在树中可见之前使它 “恰好正确”：我们对节点 X 中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使 X 称为 A 的子节点。所有的读操作都不会读到前后不一致的版本</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPU9vEZ58PLRxKcEUQIcCw118ayGmvjv9FyXrkr6XuSDxZe161dsBGA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上面的图中，我们接着移除 B 和 D。首先，将 A 的左子节点指针指向 C 。所有原本在 A 中的读操作将会后续读到节点 C ，而永远不会读到 B 和 D。也就是说，它们将只会读取到新版数据。同样，所有当前在 B 和 D 中的读操作将继续按照原始的数据结构指针并且读取旧版数据。所有操作均能正确运行，我们不需要锁住任何东西。而不需要锁住数据就能够移除 B 和 D 的主要原因就是 <code>读-复制-更新(Ready-Copy-Update,RCU)</code>，将更新过程中的移除和再分配过程分离开。</p>\n<h2 id=\"调度\"><a href=\"#调度\" class=\"headerlink\" title=\"调度\"></a>调度</h2><p>当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程 / 线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程 / 线程可以运行。操作系统中有一个叫做 <code>调度程序(scheduler)</code> 的角色存在，它就是做这件事儿的，该程序使用的算法叫做 <code>调度算法(scheduling algorithm)</code> 。</p>\n<p>尽管有一些不同，但许多适用于进程调度的处理方法同样也适用于线程调度。当内核管理线程的时候，调度通常会以线程级别发生，很少或者根本不会考虑线程属于哪个进程。下面我们会首先专注于进程和线程的调度问题，然后会明确的介绍线程调度以及它产生的问题。</p>\n<h3 id=\"调度介绍\"><a href=\"#调度介绍\" class=\"headerlink\" title=\"调度介绍\"></a>调度介绍</h3><p>让我们回到早期以磁带上的卡片作为输入的批处理系统的时代，那时候的调度算法非常简单：依次运行磁带上的每一个作业。对于多道程序设计系统，会复杂一些，因为通常会有多个用户在等待服务。一些大型机仍然将 <code>批处理</code>和 <code>分时服务</code>结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的用户。由于在这些机器中 CPU 是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。</p>\n<h4 id=\"进程行为\"><a href=\"#进程行为\" class=\"headerlink\" title=\"进程行为\"></a>进程行为</h4><p>几乎所有的进程（磁盘或网络）I/O 请求和计算都是交替运行的</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkhOIjeY0ia73Pm3dJCSLuhRl058IKIxx7RyI1LN1PYfthYvLHmJyicm1A/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图所示，CPU 不停顿的运行一段时间，然后发出一个系统调用等待 I/O 读写文件。完成系统调用后，CPU 又开始计算，直到它需要读更多的数据或者写入更多的数据为止。当一个进程等待外部设备完成工作而被阻塞时，才是 I/O 活动。  </p>\n<p>上面 a 是 CPU 密集型进程；b 是 I/O 密集型进程进程，a 因为在计算的时间上花费时间更长，因此称为<code>计算密集型(compute-bound)</code> 或者 <code>CPU 密集型(CPU-bound)</code>，b 因为 I/O 发生频率比较快因此称为 <code>I/O 密集型(I/O-bound)</code>。计算密集型进程有较长的 CPU 集中使用和较小频度的 I/O 等待。I/O 密集型进程有较短的 CPU 使用时间和较频繁的 I/O 等待。注意到上面两种进程的区分关键在于 CPU 的时间占用而不是 I/O 的时间占用。I/O 密集型的原因是因为它们没有在 I/O 之间花费更多的计算、而不是 I/O 请求时间特别长。无论数据到达后需要花费多少时间，它们都需要花费相同的时间来发出读取磁盘块的硬件请求。</p>\n<p>值得注意的是，随着 CPU 的速度越来越快，更多的进程倾向于 I/O 密集型。这种情况出现的原因是 CPU 速度的提升要远远高于硬盘。这种情况导致的结果是，未来对 I/O 密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。</p>\n<h4 id=\"何时调度\"><a href=\"#何时调度\" class=\"headerlink\" title=\"何时调度\"></a>何时调度</h4><p>第一个和调度有关的问题是<code>何时进行调度决策</code>。存在着需要调度处理的各种情形。首先，在创建一个新进程后，需要决定是运行父进程还是子进程。因为二者的进程都处于就绪态下，这是正常的调度决策，可以任意选择，也就是说，调度程序可以任意的选择子进程或父进程开始运行。</p>\n<p>第二，在进程退出时需要作出调度决定。因为此进程不再运行（因为它将不再存在），因此必须从就绪进程中选择其他进程运行。如果没有进程处于就绪态，系统提供的<code>空闲进程</code>通常会运行</p>\n<p><strong>什么是空闲进程</strong></p>\n<p><code>空闲进程(system-supplied idle process)</code> 是 Microsoft 公司 windows 操作系统带有的系统进程，该进程是在各个处理器上运行的单个线程，它唯一的任务是在系统没有处理其他线程时占用处理器时间。System Idle Process 并不是一个真正的进程，它是<code>核心虚拟</code>出来的，多任务操作系统都存在。在没有可用的进程时，系统处于空运行状态，此时就是 System Idle Process 在正在运行。你可以简单的理解成，它代表的是 CPU 的空闲状态，数值越大代表处理器越空闲，可以通过 Windows 任务管理器查看 Windows 中的 CPU 利用率</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmC8dicWibXiabibrgW3hOqJ4xzMFwjPvSuicicpIKiaU711OUIUwOZO6T7pVw/640?wx_fmt=png\" alt=\"\"></p>\n<p>第三种情况是，当进程阻塞在 I/O 、信号量或其他原因时，必须选择另外一个进程来运行。有时，阻塞的原因会成为选择进程运行的关键因素。例如，如果 A 是一个重要进程，并且它正在等待 B 退出关键区域，让 B 退出关键区域从而使 A 得以运行。但是调度程序一般不会对这种情况进行考量。</p>\n<p>第四点，当 I/O 中断发生时，可以做出调度决策。如果中断来自 I/O 设备，而 I/O 设备已经完成了其工作，那么那些等待 I/O 的进程现在可以继续运行。由调度程序来决定是否准备运行新的进程还是重新运行已经中断的进程。</p>\n<p>如果硬件时钟以 50 或 60 Hz 或其他频率提供周期性中断，可以在每个时钟中断或第 k 个时钟中断处做出调度决策。根据如何处理时钟中断可以把调度算法可以分为两类。<code>非抢占式(nonpreemptive)</code> 调度算法挑选一个进程，让该进程运行直到被阻塞（阻塞在 I/O 上或等待另一个进程），或者直到该进程自动释放 CPU。即使该进程运行了若干个小时后，它也不会被强制挂起。这样会在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。</p>\n<p>另外一种情况是 <code>抢占式</code> 调度算法，它会选择一个进程，并使其在最大固定时间内运行。如果在时间间隔结束后仍在运行，这个进程会被挂起，调度程序会选择其他进程来运行（前提是存在就绪进程）。进行抢占式调度需要在时间间隔结束时发生时钟中断，以将 CPU 的控制权交还给调度程序。如果没有可用的时钟，那么非抢占式就是唯一的选择。</p>\n<h4 id=\"调度算法的分类\"><a href=\"#调度算法的分类\" class=\"headerlink\" title=\"调度算法的分类\"></a>调度算法的分类</h4><p>毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境</p>\n<ul>\n<li><p><code>批处理(Batch)</code></p>\n</li>\n<li><p><code>交互式(Interactive)</code></p>\n</li>\n<li><p><code>实时(Real time)</code></p>\n</li>\n</ul>\n<p>批处理系统广泛应用于商业领域，比如用来处理工资单、存货清单、账目收入、账目支出、利息计算、索赔处理和其他周期性作业。在批处理系统中，一般会选择使用非抢占式算法或者周期性比较长的抢占式算法。这种方法可以减少线程切换因此能够提升性能。</p>\n<p>在交互式用户环境中，为了避免一个进程霸占 CPU 拒绝为其他进程服务，所以需要抢占式算法。即使没有进程有意要一直运行下去，但是，由于某个进程出现错误也有可能无限期的排斥其他所有进程。为了避免这种情况，抢占式也是必须的。服务器也属于此类别，因为它们通常为多个（远程）用户提供服务，而这些用户都非常着急。计算机用户总是很忙。</p>\n<p>在实时系统中，抢占有时是不需要的，因为进程知道自己可能运行不了很长时间，通常很快的做完自己的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。</p>\n<h4 id=\"调度算法的目标\"><a href=\"#调度算法的目标\" class=\"headerlink\" title=\"调度算法的目标\"></a>调度算法的目标</h4><p>为了设计调度算法，有必要考虑一下什么是好的调度算法。有一些目标取决于环境（批处理、交互式或者实时）蛋大部分是适用于所有情况的，下面是一些需要考量的因素，我们会在下面一起讨论。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkxvibibMFgiaPvgs6ltWepp136jFYSAUMsXGOYRAiaT7l4wCDy4fuKZ95Bw/640?wx_fmt=png\" alt=\"\"></p>\n<p><strong>所有系统</strong></p>\n<p>在所有的情况中，<code>公平</code>是很重要的。对一个进程给予相较于其他等价的进程更多的 CPU 时间片对其他进程来说是不公平的。当然，不同类型的进程可以采用不同的处理方式。</p>\n<p>与公平有关的是系统的<code>强制执行</code>，什么意思呢？如果某公司的薪资发放系统计划在本月的 15 号，那么碰上了疫情大家生活都很拮据，此时老板说要在 14 号晚上发放薪资，那么调度程序必须强制使进程执行 14 号晚上发放薪资的策略。</p>\n<p>另一个共同的目标是保持系统的<code>所有部分尽可能的忙碌</code>。如果 CPU 和所有的 I/O 设备能够一直运行，那么相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调入内存运行。在内存中既有一些 CPU 密集型进程又有一些 I/O 密集型进程是一个比较好的想法，好于先调入和运行所有的 CPU 密集型作业，然后在它们完成之后再调入和运行所有 I/O 密集型作业的做法。使用后者这种方式会在 CPU 密集型进程启动后，争夺 CPU ，而磁盘却在空转，而当 I/O 密集型进程启动后，它们又要为磁盘而竞争，CPU 却又在空转。。。。。。显然，通过结合 I/O 密集型和 CPU 密集型，能够使整个系统运行更流畅，效率更高。</p>\n<p><strong>批处理系统</strong></p>\n<p>通常有三个指标来衡量系统工作状态：<strong>吞吐量、周转时间和 CPU 利用率</strong>，<code>吞吐量(throughout)</code> 是系统每小时完成的作业数量。综合考虑，每小时完成 50 个工作要比每小时完成 40 个工作好。<code>周转时间(Turnaround time)</code> 是一种平均时间，它指的是从一个批处理提交开始直到作业完成时刻为止平均时间。该数据度量了用户要得到输出所需的平均等待时间。周转时间越小越好。</p>\n<p><code>CPU 利用率(CPU utilization)</code> 通常作为批处理系统上的指标。即使如此， CPU 利用率也不是一个好的度量指标，真正有价值的衡量指标是系统每小时可以完成多少作业（吞吐量），以及完成作业需要多长时间（周转时间）。把 CPU 利用率作为度量指标，就像是引擎每小时转动了多少次来比较汽车的性能一样。而且知道 CPU 的利用率什么时候接近 100% 要比什么什么时候要求得到更多的计算能力要有用。</p>\n<p><strong>交互式系统</strong></p>\n<p>对于交互式系统，则有不同的指标。最重要的是尽量<code>减少响应时间</code>。这个时间说的是从执行指令开始到得到结果的时间。再有后台进程运行（例如，从网络上读取和保存 E-mail 文件）的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的就是一个好的服务。</p>\n<p>一个相关的问题是 <code>均衡性(proportionality)</code>，用户对做一件事情需要多长时间总是有一种固定（不过通常不正确）的看法。当认为一个请求很复杂需要较多时间时，用户会认为很正常并且可以接受，但是一个很简单的程序却花费了很长的运行时间，用户就会很恼怒。可以拿彩印和复印来举出一个简单的例子，彩印可能需要 1 分钟的时间，但是用户觉得复杂并且愿意等待一分钟，相反，复印很简单只需要 5 秒钟，但是复印机花费 1 分钟却没有完成复印操作，用户就会很焦躁。</p>\n<p><strong>实时系统</strong></p>\n<p>实时系统则有着和交互式系统不同的考量因素，因此也就有不同的调度目标。实时系统的特点是<code>必须满足最后的截止时间</code>。例如，如果计算机控制着以固定速率产生数据的设备，未能按时运行的话可能会导致数据丢失。因此，实时系统中最重要的需求是满足所有（或大多数）时间期限。</p>\n<p>在一些实事系统中，特别是涉及到多媒体的，<code>可预测性很重要</code>。偶尔不能满足最后的截止时间不重要，但是如果音频多媒体运行不稳定，声音质量会持续恶化。视频也会造成问题，但是耳朵要比眼睛敏感很多。为了避免这些问题，进程调度必须能够高度可预测的而且是有规律的。</p>\n<h3 id=\"批处理中的调度\"><a href=\"#批处理中的调度\" class=\"headerlink\" title=\"批处理中的调度\"></a>批处理中的调度</h3><p>现在让我们把目光从一般性的调度转换为特定的调度算法。下面我们会探讨在批处理中的调度。</p>\n<h4 id=\"先来先服务\"><a href=\"#先来先服务\" class=\"headerlink\" title=\"先来先服务\"></a>先来先服务</h4><p>很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 <code>先来先服务(first-come,first-serverd)</code>。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkqPMbFJfGBd9toxDvJn0M90Yc7fIfwm8sYaqk2GkvFWFGWqV0upj7mA/640?wx_fmt=png\" alt=\"\"></p>\n<p>这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。</p>\n<p>不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。</p>\n<h4 id=\"最短作业优先\"><a href=\"#最短作业优先\" class=\"headerlink\" title=\"最短作业优先\"></a>最短作业优先</h4><p>批处理中，第二种调度算法是 <code>最短作业优先(Shortest Job First)</code>，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkWytiaXxLwkZ2fQ1nGYZKsZsXtRcNaRjXicn01BsqHwSjk0szP48f1qyQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。  </p>\n<p>现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。</p>\n<blockquote>\n<p>需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。</p>\n</blockquote>\n<h4 id=\"最短剩余时间优先\"><a href=\"#最短剩余时间优先\" class=\"headerlink\" title=\"最短剩余时间优先\"></a>最短剩余时间优先</h4><p>最短作业优先的抢占式版本被称作为 <code>最短剩余时间优先(Shortest Remaining Time Next)</code> 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。</p>\n<h3 id=\"交互式系统中的调度\"><a href=\"#交互式系统中的调度\" class=\"headerlink\" title=\"交互式系统中的调度\"></a>交互式系统中的调度</h3><p>交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度</p>\n<h4 id=\"轮询调度\"><a href=\"#轮询调度\" class=\"headerlink\" title=\"轮询调度\"></a>轮询调度</h4><p>一种最古老、最简单、最公平并且最广泛使用的算法就是 <code>轮询算法(round-robin)</code>。每个进程都会被分配一个时间段，称为<code>时间片(quantum)</code>，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkOxzKshMcCgeCOxI9IFypGhFvaQNgrmef5xtBTlAN8ozyHPfnQk09Kw/640?wx_fmt=png\" alt=\"\"></p>\n<p>时间片轮询调度中唯一有意思的一点就是时间片的长度。从一个进程切换到另一个进程需要一定的时间进行管理处理，包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作 <code>进程间切换(process switch)</code> 和 <code>上下文切换(context switch)</code>。如果进程间的切换时间需要 1ms，其中包括内存映射、清除和重新调入高速缓存等，再假设时间片设为 4 ms，那么 CPU 在做完 4 ms 有用的工作之后，CPU 将花费 1 ms 来进行进程间的切换。因此，CPU 的时间片会浪费 20% 的时间在管理开销上。耗费巨大。</p>\n<p>为了提高 CPU 的效率，我们把时间片设置为 100 ms。现在时间的浪费只有 1%。但是考虑会发现下面的情况，如果在一个非常短的时间内到达 50 个请求，并且对 CPU 有不同的需求，此时会发生什么？50 个进程都被放在可运行进程列表中。如果 CP 画 U 是空闲的，第一个进程会立即开始执行，第二个直到 100 ms 以后才会启动，以此类推。不幸的是最后一个进程需要等待 5 秒才能获得执行机会。大部分用户都会觉得对于一个简短的指令运行 5 秒中是很慢的。如果队列末尾的某些请求只需要几号秒钟的运行时间的话，这种设计就非常糟糕了。</p>\n<p>另外一个因素是如果时间片设置长度要大于 CPU 使用长度，那么抢占就不会经常发生。相反，在时间片用完之前，大多数进程都已经阻塞了，那么就会引起进程间的切换。消除抢占可提高性能，因为进程切换仅在逻辑上必要时才发生，即流程阻塞且无法继续时才发生。</p>\n<p>结论可以表述如下：将上下文切换时间设置得太短会导致过多的进程切换并降低 CPU 效率，但设置时间太长会导致一个短请求很长时间得不到响应。最好的切换时间是在 20 - 50 毫秒之间设置。</p>\n<h4 id=\"优先级调度\"><a href=\"#优先级调度\" class=\"headerlink\" title=\"优先级调度\"></a>优先级调度</h4><p>轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了<code>优先级调度(priority scheduling)</code></p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibKKcmqw7wHNaRyic2qWfZQ5mxASpo0qqPtC1M6SCloLc5QvN5rsnib3A/640?wx_fmt=png\" alt=\"\"></p>\n<p>它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。</p>\n<p>但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。</p>\n<p>可以静态或者动态的为进程分配优先级。在一台军用计算机上，可以把将军所启动的进程设为优先级 100，上校为 90 ，少校为 80，上尉为 70，中尉为 60，以此类推。UNIX 中有一条命令为 <code>nice</code> ，它允许用户为了照顾他人而自愿降低自己进程的优先级，但是一般没人用。</p>\n<p>优先级也可以由系统动态分配，用于实现某种目的。例如，有些进程为 I/O 密集型，其多数时间用来等待 I/O 结束。当这样的进程需要 CPU 时，应立即分配 CPU，用来启动下一个 I/O 请求，这样就可以在另一个进程进行计算的同时执行 I/O 操作。这类 I/O 密集型进程长时间的等待 CPU 只会造成它长时间占用内存。使 I/O 密集型进程获得较好的服务的一种简单算法是，将其优先级设为 <code>1/f</code>，f 为该进程在上一时间片中所占的部分。一个在 50 ms 的时间片中只使用 1 ms 的进程将获得优先级 50 ，而在阻塞之前用掉 25 ms 的进程将具有优先级 2，而使用掉全部时间片的进程将得到优先级 1。</p>\n<p>可以很方便的将一组进程按优先级分成若干类，并且在各个类之间采用优先级调度，而在各类进程的内部采用轮转调度。下面展示了一个四个优先级类的系统</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkh7icJrRFORxCKsSnD2DEvfhTIZKYn9o5SYaCl1mvebyx6EnsweGSjnw/640?wx_fmt=png\" alt=\"\"></p>\n<p>它的调度算法主要描述如下：上面存在优先级为 4 类的可运行进程，首先会按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第 4 类进程为空，则按照轮询的方式运行第三类进程。若第 4 类和第 3 类进程都为空，则按照轮转法运行第 2 类进程。如果不对优先级进行调整，则低优先级的进程很容易产生饥饿现象。</p>\n<h4 id=\"多级队列\"><a href=\"#多级队列\" class=\"headerlink\" title=\"多级队列\"></a>多级队列</h4><p>最早使用优先级调度的系统是 <code>CTSS(Compatible TimeSharing System)</code>。CTSS 是一种兼容分时系统，它有一个问题就是进程切换太慢，其原因是 IBM 7094 内存只能放进一个进程。</p>\n<blockquote>\n<p>IBM 是哥伦比亚大学计算机中心在 1964 - 1968 年的计算机</p>\n</blockquote>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkHqGI0SaIpjW7unPiasYQV0ekRmSB3EjbVNJ8jvhic6gL8VbFvicUWOW0w/640?wx_fmt=png\" alt=\"\"></p>\n<p>CTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS 的设计者很快就认识到，为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。</p>\n<h4 id=\"最短进程优先\"><a href=\"#最短进程优先\" class=\"headerlink\" title=\"最短进程优先\"></a>最短进程优先</h4><p>对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互式进程，那将是非常好的。在某种程度上，的确可以做到这一点。交互式进程通常遵循下列模式：等待命令、执行命令、等待命令、执行命令。。。如果我们把每个命令的执行都看作一个分离的作业，那么我们可以通过首先运行最短的作业来使响应时间最短。这里唯一的问题是如何从当前可运行进程中找出最短的那一个进程。</p>\n<p>一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 <code>T0</code>，现在假设测量到其下一次运行时间为 <code>T1</code>，可以用两个值的加权来改进估计时间，即<code>aT0+ (1- 1)T1</code>。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVar1KhzuffcYqXhyRyOL7b8KQiciaUYCpmR2e9iaiaMF6qh60jPk4FCrgA/640?wx_fmt=png\" alt=\"\"></p>\n<p>可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。  </p>\n<p>有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 <code>老化(aging)</code>。这种方法会使用很多预测值基于当前值的情况。</p>\n<h4 id=\"保证调度\"><a href=\"#保证调度\" class=\"headerlink\" title=\"保证调度\"></a>保证调度</h4><p>一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。</p>\n<h4 id=\"彩票调度\"><a href=\"#彩票调度\" class=\"headerlink\" title=\"彩票调度\"></a>彩票调度</h4><p>对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 <code>彩票调度(lottery scheduling)</code>算法。</p>\n<p>其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。</p>\n<p><code>George Orwell</code> 关于 <strong>所有的进程是平等的，但是某些进程能够更平等一些</strong>。一些重要的进程可以给它们额外的彩票，以便增加他们赢得的机会。如果出售了 100 张彩票，而且有一个进程持有了它们中的 20 张，它就会有 20% 的机会去赢得彩票中奖。在长时间的运行中，它就会获得 20% 的 CPU。相反，对于优先级调度程序，很难说明拥有优先级 40 究竟是什么意思，这里的规则很清楚，拥有彩票 f 份额的进程大约得到系统资源的 f 份额。</p>\n<p>如果希望进程之间协作的话可以交换它们之间的票据。例如，客户端进程给服务器进程发送了一条消息后阻塞，客户端进程可能会把自己所有的票据都交给服务器，来增加下一次服务器运行的机会。当服务完成后，它会把彩票还给客户端让其有机会再次运行。事实上，如果没有客户机，服务器也根本不需要彩票。</p>\n<blockquote>\n<p>可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 <code>速度之靴</code> 的效果。</p>\n</blockquote>\n<h4 id=\"公平分享调度\"><a href=\"#公平分享调度\" class=\"headerlink\" title=\"公平分享调度\"></a>公平分享调度</h4><p>到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。</p>\n<p>为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些 CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkp2JUKicTTic4Mh3owkYeABOicg6zXAkfFSmoTZs7W6UtRN5Rsc3VcTqPA/640?wx_fmt=png\" alt=\"\"></p>\n<h3 id=\"实时系统中的调度\"><a href=\"#实时系统中的调度\" class=\"headerlink\" title=\"实时系统中的调度\"></a>实时系统中的调度</h3><p><code>实时系统(real-time)</code> 是一个时间扮演了重要作用的系统。典型的，一种或多种外部物理设备发给计算机一个服务请求，而计算机必须在一个确定的时间范围内恰当的做出反应。例如，在 CD 播放器中的计算机会获得从驱动器过来的位流，然后必须在非常短的时间内将位流转换为音乐播放出来。如果计算时间过长，那么音乐就会听起来有异常。再比如说医院特别护理部门的病人监护装置、飞机中的自动驾驶系统、列车中的烟雾警告装置等，在这些例子中，正确但是却缓慢的响应要比没有响应甚至还糟糕。</p>\n<p>实时系统可以分为两类，<code>硬实时(hard real time)</code> 和 <code>软实时(soft real time)</code> 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。在这两种情形中，实时都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前可知的。这些进程一般寿命较短，并且极快的运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。</p>\n<p>实时系统中的事件可以按照响应方式进一步分类为<code>周期性(以规则的时间间隔发生)</code>事件或 <code>非周期性(发生时间不可预知)</code>事件。一个系统可能要响应多个周期性事件流，根据每个事件处理所需的时间，可能甚至无法处理所有事件。例如，如果有 m 个周期事件，事件 i 以周期 Pi 发生，并需要 Ci 秒 CPU 时间处理一个事件，那么可以处理负载的条件是</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkicxWrh9f5BDPIHJU9PDzKE0HR42WWlTyA1P9rDLSVhtibSQ7VVeymJibA/640?wx_fmt=png\" alt=\"\"></p>\n<p>只有满足这个条件的实时系统称为<code>可调度的</code>，这意味着它实际上能够被实现。一个不满足此检验标准的进程不能被调度，因为这些进程共同需要的 CPU 时间总和大于 CPU 能提供的时间。</p>\n<p>举一个例子，考虑一个有三个周期性事件的软实时系统，其周期分别是 100 ms、200 m 和 500 ms。如果这些事件分别需要 50 ms、30 ms 和 100 ms 的 CPU 时间，那么该系统时可调度的，因为 0.5 + 0.15 + 0.2 &lt; 1。如果此时有第四个事件加入，其周期为 1 秒，那么此时这个事件如果不超过 150 ms，那么仍然是可以调度的。忽略上下文切换的时间。</p>\n<p>实时系统的调度算法可以是静态的或动态的。前者在系统开始运行之前做出调度决策；后者在运行过程中进行调度决策。只有在可以提前掌握所完成的工作以及必须满足的截止时间等信息时，静态调度才能工作，而动态调度不需要这些限制。</p>\n<h3 id=\"调度策略和机制\"><a href=\"#调度策略和机制\" class=\"headerlink\" title=\"调度策略和机制\"></a>调度策略和机制</h3><p>到目前为止，我们隐含的假设系统中所有进程属于不同的分组用户并且进程间存在相互竞争 CPU 的情况。通常情况下确实如此，但有时也会发生一个进程会有很多子进程并在其控制下运行的情况。例如，一个数据库管理系统进程会有很多子进程。每一个子进程可能处理不同的请求，或者每个子进程实现不同的功能（如请求分析、磁盘访问等）。主进程完全可能掌握哪一个子进程最重要（或最紧迫），而哪一个最不重要。但是，以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。</p>\n<p>解决问题的办法是将 <code>调度机制(scheduling mechanism)</code> 和 <code>调度策略(scheduling policy)</code> 分开，这是长期一贯的原则。这也就意味着调度算法在某种方式下被参数化了，但是参数可以被用户进程填写。让我们首先考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。调度机制位于内核，而调度策略由用户进程决定，调度策略和机制分离是一种关键性思路。</p>\n<h3 id=\"线程调度\"><a href=\"#线程调度\" class=\"headerlink\" title=\"线程调度\"></a>线程调度</h3><p>当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本质的差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。</p>\n<p>首先考虑用户级线程，由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为 A，并给予 A 以时间片控制。A 中的线程调度程序决定哪个线程运行。假设为 A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程继续运行。</p>\n<p>在进程 A 终于又一次运行时，线程 A1 会接着运行。该线程会继续耗费 A 进程的所有时间，直到它完成工作。不过，线程运行不会影响到其他进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程 A 内部发生的事情。</p>\n<p>现在考虑 A 线程每次 CPU 计算的工作比较少的情况，例如：在 50 ms 的时间片中有 5 ms 的计算工作。于是，每个线程运行一会儿，然后把 CPU 交回给线程调度程序。这样在内核切换到进程 B 之前，就会有序列 A1,A2,A3,A1,A2,A3,A1,A2,A3,A1 。如下所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibIqnCiaYicYscwr55u59URicaa9iaIgcMA3zmicGaJKFtoByUkUAClg9YUA/640?wx_fmt=png\" alt=\"\"></p>\n<p>运行时系统使用的调度算法可以是上面介绍算法的任意一种。从实用方面考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程。但由于线程之间的合作关系，这通常也不是问题。</p>\n<p>现在考虑使用内核线程的情况，内核选择一个特定的线程运行。它不用考虑线程属于哪个进程，不过如果有必要的话，也可以这么做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在 50 ms 的时间片内，5 ms 之后被阻塞，在 30 ms 的时间片中，线程的顺序会是 A1,B1,A2,B2,A3,B3。如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaejGGnPoyhnwOUWNVdDCQpicVrhQwUibbMtZRKOUEOOJGvgBh5tPMiavg/640?wx_fmt=png\" alt=\"\"></p>\n<p>用户级线程和内核级线程之间的主要差别在于<code>性能</code>。用户级线程的切换需要少量的机器指令（想象一下 Java 程序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程挂起。  </p>\n<p>从进程 A 的一个线程切换到进程 B 的一个线程，其消耗要远高于运行进程 A 的两个线程（涉及修改内存映像，修改高速缓存），内核对这种切换的消耗是了解到，可以通过这些信息作出决定。</p>\n<p>文章参考：</p>\n<p>《现代操作系统》</p>\n<p>《Modern Operating System》forth edition</p>\n<p><a href=\"https://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems\" target=\"_blank\" rel=\"noopener\">https://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems</a></p>\n<p><a href=\"https://j00ru.vexillium.org/syscalls/nt/32/\" target=\"_blank\" rel=\"noopener\">https://j00ru.vexillium.org/syscalls/nt/32/</a></p>\n<p><a href=\"https://www.bottomupcs.com/process_hierarchy.xhtml\" target=\"_blank\" rel=\"noopener\">https://www.bottomupcs.com/process_hierarchy.xhtml</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Runtime_system\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Runtime_system</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Execution_model\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Execution_model</a></p>\n<p><a href=\"https://zhidao.baidu.com/question/113227654.html\" target=\"_blank\" rel=\"noopener\">https://zhidao.baidu.com/question/113227654.html</a></p>\n<p><a href=\"https://baike.baidu.com/item/\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/</a> 等待队列 / 9223804?fr=aladdin</p>\n<p><a href=\"http://www.columbia.edu/cu/computinghistory/7094.html\" target=\"_blank\" rel=\"noopener\">http://www.columbia.edu/cu/computinghistory/7094.html</a></p>\n<p><a href=\"https://baike.baidu.com/item/\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/</a> 中断向量 / 4947039?fr=aladdin</p>\n<pre><code>推荐阅读：\n\n\n\n\n完全整理 | 365篇高质技术文章目录整理\n\n算法之美 : 栈和队列\n\n\n主宰这个世界的10大算法\n\n\n彻底理解cookie、session、token\n\n\n浅谈什么是递归算法\n\n专注服务器后台技术栈知识总结分享\n\n欢迎关注交流共同进步\n\n码农有道 coding\n\n\n\n\n码农有道，为您提供通俗易懂的技术文章，让技术变的更简单！\n\n好文章，我 在看 </code></pre>","site":{"data":{}},"excerpt":"","more":"<blockquote>\n<p>本文由 <a href=\"http://ksria.com/simpread/\" target=\"_blank\" rel=\"noopener\">简悦 SimpRead</a> 转码， 原文地址 <a href=\"https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&amp;mid=2247487913&amp;idx=1&amp;sn=8c3f042c5a73ce9e49b21bc6cce2442e&amp;chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1583500047238&amp;sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&amp;key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&amp;ascene=1&amp;uin=MTIwMTg1OTcwMg%3D%3D&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&amp;pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm\" target=\"_blank\" rel=\"noopener\">https://mp.weixin.qq.com/s?__biz=MzIwNTc4NTEwOQ==&amp;mid=2247487913&amp;idx=1&amp;sn=8c3f042c5a73ce9e49b21bc6cce2442e&amp;chksm=972ac0d3a05d49c5904f8f10156de521b62c526c805b2b6f0c28814b4a09ff5a7c39d5a826dd&amp;mpshare=1&amp;scene=1&amp;srcid=&amp;sharer_sharetime=1583500047238&amp;sharer_shareid=caaf69befadb615e0e42101f0f9f7bc3&amp;key=6931539c47d7ce8cb25b6b557c8957379d56339dce4baef9484d719fbf0c41057553c7db7e9342b0b024f970a8d00f7812e81de38440c42e2e8edd7df9a6000f8d96b46af1f21c4434aa9f15b2af517c&amp;ascene=1&amp;uin=MTIwMTg1OTcwMg%3D%3D&amp;devicetype=Windows+10&amp;version=62080079&amp;lang=zh_CN&amp;exportkey=AQEkArTiG6c9u7QeoIZkSGc%3D&amp;pass_ticket=EnARPTsl5jlgauK6f6q%2BeXfdY%2BDxHTn%2Fr4Q3cvq3lAgcOrM1D4yCRw%2BOIxUm5Spm</a></p>\n</blockquote>\n<p>来源：Java 建设者</p>\n<p>作者：cxuan</p>\n<p>下面是本文的结构图</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJArB4bFRERsiaKqyAZbnJxU3ISIOnRUH908G29Tx2iaCXc5Ps7DTiaD4A/640?wx_fmt=png\" alt=\"\"></p>\n<p>我们平常说的进程和线程更多的是基于编程语言的角度来说的，那么你真的了解什么是线程和进程吗？那么我们就从操作系统的角度来了解一下什么是进程和线程。</p>\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><p>操作系统中最核心的概念就是 <code>进程</code>，进程是对正在运行中的程序的一个抽象。操作系统的其他所有内容都是围绕着进程展开的。进程是操作系统提供的最古老也是最重要的概念之一。即使可以使用的 CPU 只有一个，它们也支持<code>（伪）并发</code>操作。它们会将一个单独的 CPU 抽象为多个虚拟机的 CPU。可以说：没有进程的抽象，现代操作系统将不复存在。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkJcVYZew9ryLN0RIu6fwSUliaeSKiaKgoBDSXfaH9Hqvm4Cm73Na86K3Q/640?wx_fmt=png\" alt=\"\"></p>\n<p>所有现代的计算机会在同一时刻做很多事情，过去使用计算机的人（单 CPU）可能完全无法理解现在这种变化，举个例子更能说明这一点：首先考虑一个 Web 服务器，请求都来自于 Web 网页。当一个请求到达时，服务器会检查当前页是否在缓存中，如果是在缓存中，就直接把缓存中的内容返回。如果缓存中没有的话，那么请求就会交给磁盘来处理。但是，从 CPU 的角度来看，磁盘请求需要更长的时间，因为磁盘请求会很慢。当硬盘请求完成时，更多其他请求才会进入。如果有多个磁盘的话，可以在第一个请求完成前就可以连续的对其他磁盘发出部分或全部请求。很显然，这是一种并发现象，需要有并发控制条件来控制并发现象。</p>\n<p>现在考虑只有一个用户的 PC。当系统启动时，许多进程也在后台启动，用户通常不知道这些进程的启动，试想一下，当你自己的计算机启动的时候，你能知道哪些进程是需要启动的么？这些后台进程可能是一个需要输入电子邮件的电子邮件进程，或者是一个计算机病毒查杀进程来周期性的更新病毒库。某个用户进程可能会在所有用户上网的时候打印文件以及刻录 CD-ROM，这些活动都需要管理。于是一个支持多进程的多道程序系统就会显得很有必要了。</p>\n<p>在许多多道程序系统中，CPU 会在<code>进程</code>间快速切换，使每个程序运行几十或者几百毫秒。然而，严格意义来说，在某一个瞬间，CPU 只能运行一个进程，然而我们如果把时间定位为 1 秒内的话，它可能运行多个进程。这样就会让我们产生<code>并行</code>的错觉。有时候人们说的 <code>伪并行(pseudoparallelism)</code> 就是这种情况，以此来区分多处理器系统 (该系统由两个或多个 CPU 来共享同一个物理内存)</p>\n<blockquote>\n<p>再来详细解释一下伪并行：<code>伪并行</code>是指单核或多核处理器同时执行多个进程，从而使程序更快。通过以非常有限的时间间隔在程序之间快速切换 CPU，因此会产生并行感。缺点是 CPU 时间可能分配给下一个进程，也可能不分配给下一个进程。</p>\n</blockquote>\n<p>因为 CPU 执行速度很快，进程间的换进换出也非常迅速，因此我们很难对多个并行进程进行跟踪，所以，在经过多年的努力后，操作系统的设计者开发了用于描述并行的一种概念模型（顺序进程），使得并行更加容易理解和分析，对该模型的探讨，也是本篇文章的主题。下面我们就来探讨一下进程模型</p>\n<h3 id=\"进程模型\"><a href=\"#进程模型\" class=\"headerlink\" title=\"进程模型\"></a>进程模型</h3><p>在进程模型中，所有计算机上运行的软件，通常也包括操作系统，被组织为若干<code>顺序进程(sequential processes)</code>，简称为 <code>进程(process)</code> 。一个进程就是一个正在执行的程序的实例，进程也包括程序计数器、寄存器和变量的当前值。从概念上来说，每个进程都有各自的虚拟 CPU，但是实际情况是 CPU 会在各个进程之间进行来回切换。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkwicOIsH2wqofqK877AcZEnQwsg3hSibpu2q5ZWrKKOwIUZloGHVEY69w/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图所示，这是一个具有 4 个程序的多道处理程序，在进程不断切换的过程中，程序计数器也在不同的变化。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkpSsh1RicmibCiaNmgwq5xMM8NtTl1yW3jXcL2pMIBDUmQk9VRGSMC4wwA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上图中，这 4 道程序被抽象为 4 个拥有各自控制流程（即每个自己的程序计数器）的进程，并且每个程序都独立的运行。当然，实际上只有一个物理程序计数器，每个程序要运行时，其逻辑程序计数器会装载到物理程序计数器中。当程序运行结束后，其物理程序计数器就会是真正的程序计数器，然后再把它放回进程的逻辑计数器中。</p>\n<p>从下图我们可以看到，在观察足够长的一段时间后，所有的进程都运行了，<strong>但在任何一个给定的瞬间仅有一个进程真正运行</strong>。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkeqicuKAib5xjeLwSEKvmWbnZd9poHkykMIZxKGfryBFwNBCNHghALbQg/640?wx_fmt=png\" alt=\"\"></p>\n<p>因此，当我们说一个 CPU 只能真正一次运行一个进程的时候，即使有 2 个核（或 CPU），<strong>每一个核也只能一次运行一个线程</strong>。</p>\n<p>由于 CPU 会在各个进程之间来回快速切换，所以每个进程在 CPU 中的运行时间是无法确定的。并且当同一个进程再次在 CPU 中运行时，其在 CPU 内部的运行时间往往也是不固定的。进程和程序之间的区别是非常微妙的，但是通过一个例子可以让你加以区分：想想一位会做饭的计算机科学家正在为他的女儿制作生日蛋糕。他有做生日蛋糕的食谱，厨房里有所需的原谅：面粉、鸡蛋、糖、香草汁等。在这个比喻中，做蛋糕的食谱就是程序、计算机科学家就是 CPU、而做蛋糕的各种原料都是输入数据。进程就是科学家阅读食谱、取来各种原料以及烘焙蛋糕等一系列动作的总和。</p>\n<p>现在假设科学家的儿子跑过来告诉他，说他的头被蜜蜂蜇了一下，那么此时科学家会记录出来他做蛋糕这个过程到了哪一步，然后拿出急救手册，按照上面的步骤给他儿子实施救助。这里，会涉及到进程之间的切换，科学家（CPU）会从做蛋糕（进程）切换到实施医疗救助（另一个进程）。等待伤口处理完毕后，科学家会回到刚刚记录做蛋糕的那一步，继续制作。</p>\n<p>这里的关键思想是<code>认识到一个进程所需的条件</code>，进程是某一类特定活动的总和，它有程序、输入输出以及状态。单个处理器可以被若干进程共享，它使用某种调度算法决定何时停止一个进程的工作，并转而为另外一个进程提供服务。另外需要注意的是，如果一个进程运行了两遍，则被认为是两个进程。那么我们了解到进程模型后，那么进程是如何创建的呢？</p>\n<h3 id=\"进程的创建\"><a href=\"#进程的创建\" class=\"headerlink\" title=\"进程的创建\"></a>进程的创建</h3><p>操作系统需要一些方式来创建进程。下面是一些创建进程的方式</p>\n<ul>\n<li><p>系统初始化（init）</p>\n</li>\n<li><p>正在运行的程序执行了创建进程的系统调用（比如 fork）</p>\n</li>\n<li><p>用户请求创建一个新进程</p>\n</li>\n<li><p>初始化一个批处理工作</p>\n</li>\n</ul>\n<h4 id=\"系统初始化\"><a href=\"#系统初始化\" class=\"headerlink\" title=\"系统初始化\"></a>系统初始化</h4><p>启动操作系统时，通常会创建若干个进程。其中有些是<code>前台进程(numerous processes)</code>，也就是同用户进行交互并替他们完成工作的进程。一些运行在后台，并不与特定的用户进行交互，例如，设计一个进程来接收发来的电子邮件，这个进程大部分的时间都在休眠，但是只要邮件到来后这个进程就会被唤醒。还可以设计一个进程来接收对该计算机上网页的传入请求，在请求到达的进程唤醒来处理网页的传入请求。进程运行在后台用来处理一些活动像是 e-mail，web 网页，新闻，打印等等被称为 <code>守护进程(daemons)</code>。大型系统会有很多守护进程。在 UNIX 中，<code>ps</code> 程序可以列出正在运行的进程， 在 Windows 中，可以使用任务管理器。</p>\n<h4 id=\"系统调用创建\"><a href=\"#系统调用创建\" class=\"headerlink\" title=\"系统调用创建\"></a>系统调用创建</h4><p>除了在启动阶段创建进程之外，一些新的进程也可以在后面创建。通常，一个正在运行的进程会发出<code>系统调用</code>用来创建一个或多个新进程来帮助其完成工作。例如，如果有大量的数据需要经过网络调取并进行顺序处理，那么创建一个进程读数据，并把数据放到共享缓冲区中，而让第二个进程取走并正确处理会比较容易些。在多处理器中，让每个进程运行在不同的 CPU 上也可以使工作做的更快。</p>\n<h4 id=\"用户请求创建\"><a href=\"#用户请求创建\" class=\"headerlink\" title=\"用户请求创建\"></a>用户请求创建</h4><p>在许多交互式系统中，输入一个命令或者双击图标就可以启动程序，以上任意一种操作都可以选择开启一个新的进程，在基本的 UNIX 系统中运行 X，新进程将接管启动它的窗口。在 Windows 中启动进程时，它一般没有窗口，但是它可以创建一个或多个窗口。每个窗口都可以运行进程。通过鼠标或者命令就可以切换窗口并与进程进行交互。</p>\n<blockquote>\n<p>交互式系统是以人与计算机之间大量交互为特征的计算机系统，比如游戏、web 浏览器，IDE 等集成开发环境。</p>\n</blockquote>\n<h4 id=\"批处理创建\"><a href=\"#批处理创建\" class=\"headerlink\" title=\"批处理创建\"></a>批处理创建</h4><p>最后一种创建进程的情形会在<code>大型机的批处理系统</code>中应用。用户在这种系统中提交批处理作业。当操作系统决定它有资源来运行另一个任务时，它将创建一个新进程并从其中的输入队列中运行下一个作业。</p>\n<p>从技术上讲，在所有这些情况下，让现有流程执行流程是通过创建系统调用来创建新流程的。该进程可能是正在运行的用户进程，是从键盘或鼠标调用的系统进程或批处理程序。这些就是系统调用创建新进程的过程。该系统调用告诉操作系统创建一个新进程，并直接或间接指示在其中运行哪个程序。</p>\n<p>在 UNIX 中，仅有一个系统调用来创建一个新的进程，这个系统调用就是 <code>fork</code>。这个调用会创建一个与调用进程相关的副本。在 fork 后，一个父进程和子进程会有相同的内存映像，相同的环境字符串和相同的打开文件。通常，子进程会执行 <code>execve</code> 或者一个简单的系统调用来改变内存映像并运行一个新的程序。例如，当一个用户在 shell 中输出 sort 命令时，shell 会 fork 一个子进程然后子进程去执行 sort 命令。这两步过程的原因是允许子进程在 fork 之后但在 execve 之前操作其文件描述符，以完成标准输入，标准输出和标准错误的重定向。</p>\n<p>在 Windows 中，情况正相反，一个简单的 Win32 功能调用 <code>CreateProcess</code>，会处理流程创建并将正确的程序加载到新的进程中。这个调用会有 10 个参数，包括了需要执行的程序、输入给程序的命令行参数、各种安全属性、有关打开的文件是否继承控制位、优先级信息、进程所需要创建的窗口规格以及指向一个结构的指针，在该结构中新创建进程的信息被返回给调用者。除了 <code>CreateProcess</code> Win 32 中大概有 100 个其他的函数用于处理进程的管理，同步以及相关的事务。下面是 UNIX 操作系统和 Windows 操作系统系统调用的对比</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkCg59tia26o7PFqCbmnFhEI6j1qoKbDeLKhUYepPVmZ400sWwtahYrNA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在 UNIX 和 Windows 中，进程创建之后，父进程和子进程有各自不同的地址空间。如果其中某个进程在其地址空间中修改了一个词，这个修改将对另一个进程不可见。在 UNIX 中，子进程的地址空间是父进程的一个拷贝，但是却是两个不同的地址空间；不可写的内存区域是共享的。某些 UNIX 实现是正是在两者之间共享，因为它不能被修改。或者，子进程共享父进程的所有内存，但是这种情况下内存通过 <code>写时复制(copy-on-write)</code> 共享，这意味着一旦两者之一想要修改部分内存，则这块内存首先被明确的复制，以确保修改发生在私有内存区域。再次强调，<strong>可写的内存是不能被共享的</strong>。但是，对于一个新创建的进程来说，确实有可能共享创建者的资源，比如可以共享打开的文件。<strong>在 Windows 中，从一开始父进程的地址空间和子进程的地址空间就是不同的</strong>。  </p>\n<h3 id=\"进程的终止\"><a href=\"#进程的终止\" class=\"headerlink\" title=\"进程的终止\"></a>进程的终止</h3><p>进程在创建之后，它就开始运行并做完成任务。然而，没有什么事儿是永不停歇的，包括进程也一样。进程早晚会发生终止，但是通常是由于以下情况触发的</p>\n<ul>\n<li><p><code>正常退出(自愿的)</code></p>\n</li>\n<li><p><code>错误退出(自愿的)</code></p>\n</li>\n<li><p><code>严重错误(非自愿的)</code></p>\n</li>\n<li><p><code>被其他进程杀死(非自愿的)</code></p>\n</li>\n</ul>\n<h4 id=\"正常退出\"><a href=\"#正常退出\" class=\"headerlink\" title=\"正常退出\"></a>正常退出</h4><p>多数进程是由于完成了工作而终止。当编译器完成了所给定程序的编译之后，编译器会执行一个系统调用告诉操作系统它完成了工作。这个调用在 UNIX 中是 <code>exit</code> ，在 Windows 中是 <code>ExitProcess</code>。面向屏幕中的软件也支持自愿终止操作。字处理软件、Internet 浏览器和类似的程序中总有一个供用户点击的图标或菜单项，用来通知进程删除它所打开的任何临时文件，然后终止。</p>\n<h4 id=\"错误退出\"><a href=\"#错误退出\" class=\"headerlink\" title=\"错误退出\"></a>错误退出</h4><p>进程发生终止的第二个原因是发现严重错误，例如，如果用户执行如下命令</p>\n<pre><code>cc foo.c    </code></pre><p>为了能够编译 foo.c 但是该文件不存在，于是编译器就会发出声明并退出。在给出了错误参数时，面向屏幕的交互式进程通常并不会直接退出，因为这从用户的角度来说并不合理，用户需要知道发生了什么并想要进行重试，所以这时候应用程序通常会弹出一个对话框告知用户发生了系统错误，是需要重试还是退出。</p>\n<h4 id=\"严重错误\"><a href=\"#严重错误\" class=\"headerlink\" title=\"严重错误\"></a>严重错误</h4><p>进程终止的第三个原因是由进程引起的错误，通常是由于程序中的错误所导致的。例如，执行了一条非法指令，引用不存在的内存，或者除数是 0 等。在有些系统比如 UNIX 中，进程可以通知操作系统，它希望自行处理某种类型的错误，在这类错误中，进程会收到信号（中断），而不是在这类错误出现时直接终止进程。</p>\n<h4 id=\"被其他进程杀死\"><a href=\"#被其他进程杀死\" class=\"headerlink\" title=\"被其他进程杀死\"></a>被其他进程杀死</h4><p>第四个终止进程的原因是，某个进程执行系统调用告诉操作系统杀死某个进程。在 UNIX 中，这个系统调用是 kill。在 Win32 中对应的函数是 <code>TerminateProcess</code>（注意不是系统调用）。</p>\n<h3 id=\"进程的层次结构\"><a href=\"#进程的层次结构\" class=\"headerlink\" title=\"进程的层次结构\"></a>进程的层次结构</h3><p>在一些系统中，当一个进程创建了其他进程后，父进程和子进程就会以某种方式进行关联。子进程它自己就会创建更多进程，从而形成一个进程层次结构。</p>\n<h4 id=\"UNIX-进程体系\"><a href=\"#UNIX-进程体系\" class=\"headerlink\" title=\"UNIX 进程体系\"></a>UNIX 进程体系</h4><p>在 UNIX 中，进程和它的所有子进程以及子进程的子进程共同组成一个进程组。当用户从键盘中发出一个信号后，该信号被发送给当前与键盘相关的进程组中的所有成员（它们通常是在当前窗口创建的所有活动进程）。每个进程可以分别捕获该信号、忽略该信号或采取默认的动作，即被信号 kill 掉。</p>\n<p>这里有另一个例子，可以用来说明层次的作用，考虑 <code>UNIX</code> 在启动时如何初始化自己。一个称为 <code>init</code> 的特殊进程出现在启动映像中 。当 init 进程开始运行时，它会读取一个文件，文件会告诉它有多少个终端。然后为每个终端创建一个新进程。这些进程等待用户登录。如果登录成功，该登录进程就执行一个 shell 来等待接收用户输入指令，这些命令可能会启动更多的进程，以此类推。因此，整个操作系统中所有的进程都隶属于一个单个以 init 为根的进程树。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkfB32mZKNYKtf0P9jW3Qax9iaW3gF4OfXGnBLM7FDBxvAUAHpiazZDRVw/640?wx_fmt=png\" alt=\"\"></p>\n<h4 id=\"Windows-进程体系\"><a href=\"#Windows-进程体系\" class=\"headerlink\" title=\"Windows 进程体系\"></a>Windows 进程体系</h4><p>相反，Windows 中没有进程层次的概念，Windows 中所有进程都是平等的，唯一类似于层次结构的是在创建进程的时候，父进程得到一个特别的令牌（称为句柄），该句柄可以用来控制子进程。然而，这个令牌可能也会移交给别的操作系统，这样就不存在层次结构了。而在 UNIX 中，进程不能剥夺其子进程的 <code>进程权</code>。（这样看来，还是 Windows 比较<code>渣</code>）。</p>\n<h3 id=\"进程状态\"><a href=\"#进程状态\" class=\"headerlink\" title=\"进程状态\"></a>进程状态</h3><p>尽管每个进程是一个独立的实体，有其自己的程序计数器和内部状态，但是，进程之间仍然需要相互帮助。例如，一个进程的结果可以作为另一个进程的输入，在 shell 命令中</p>\n<pre><code>cat chapter1 chapter2 chapter3 | grep tree</code></pre><p>第一个进程是 <code>cat</code>，将三个文件级联并输出。第二个进程是 <code>grep</code>，它从输入中选择具有包含关键字 <code>tree</code> 的内容，根据这两个进程的相对速度（这取决于两个程序的相对复杂度和各自所分配到的 CPU 时间片），可能会发生下面这种情况，<code>grep</code> 准备就绪开始运行，但是输入进程还没有完成，于是必须阻塞 grep 进程，直到输入完毕。</p>\n<p>当一个进程开始运行时，它可能会经历下面这几种状态</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk0nh0PP7ykpeG74eOW5iahBUU5AmxJjnr2Lot6w2dloqoBYgsAibrFg0A/640?wx_fmt=png\" alt=\"\"></p>\n<p>图中会涉及三种状态</p>\n<ol>\n<li><p><code>运行态</code>，运行态指的就是进程实际占用 CPU 时间片运行时</p>\n</li>\n<li><p><code>就绪态</code>，就绪态指的是可运行，但因为其他进程正在运行而处于就绪状态</p>\n</li>\n<li><p><code>阻塞态</code>，除非某种外部事件发生，否则进程不能运行</p>\n</li>\n</ol>\n<p>逻辑上来说，运行态和就绪态是很相似的。这两种情况下都表示进程<code>可运行</code>，但是第二种情况没有获得 CPU 时间分片。第三种状态与前两种状态不同的原因是这个进程不能运行，CPU 空闲时也不能运行。</p>\n<p>三种状态会涉及四种状态间的切换，在操作系统发现进程不能继续执行时会发生<code>状态1</code>的轮转，在某些系统中进程执行系统调用，例如 <code>pause</code>，来获取一个阻塞的状态。在其他系统中包括 UNIX，当进程从管道或特殊文件（例如终端）中读取没有可用的输入时，该进程会被自动终止。</p>\n<p>转换 2 和转换 3 都是由进程调度程序（操作系统的一部分）引起的，进程本身不知道调度程序的存在。转换 2 的出现说明进程调度器认定当前进程已经运行了足够长的时间，是时候让其他进程运行 CPU 时间片了。当所有其他进程都运行过后，这时候该是让第一个进程重新获得 CPU 时间片的时候了，就会发生转换 3。</p>\n<blockquote>\n<p><strong>程序调度指的是，决定哪个进程优先被运行和运行多久，这是很重要的一点</strong>。已经设计出许多算法来尝试平衡系统整体效率与各个流程之间的竞争需求。</p>\n</blockquote>\n<p>当进程等待的一个外部事件发生时（如从外部输入一些数据后），则发生转换 4。如果此时没有其他进程在运行，则立刻触发转换 3，该进程便开始运行，否则该进程会处于就绪阶段，等待 CPU 空闲后再轮到它运行。</p>\n<p>从上面的观点引入了下面的模型</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPP9Rn6j8AW1uLNLoKOjBtWbYRvyhrQicjjLl8n8GFuibRbuBXQnu27nw/640?wx_fmt=png\" alt=\"\"></p>\n<p><strong>操作系统最底层的就是调度程序</strong>，在它上面有许多进程。所有关于中断处理、启动进程和停止进程的具体细节都隐藏在调度程序中。事实上，调度程序只是一段非常小的程序。</p>\n<h3 id=\"进程的实现\"><a href=\"#进程的实现\" class=\"headerlink\" title=\"进程的实现\"></a>进程的实现</h3><p>操作系统为了执行进程间的切换，会维护着一张表格，这张表就是 <code>进程表(process table)</code>。每个进程占用一个进程表项。该表项包含了进程状态的重要信息，包括程序计数器、堆栈指针、内存分配状况、所打开文件的状态、账号和调度信息，以及其他在进程由运行态转换到就绪态或阻塞态时所必须保存的信息，从而保证该进程随后能再次启动，就像从未被中断过一样。</p>\n<p>下面展示了一个典型系统中的关键字段</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkC2WWXEkRAKErcia0ib3Hia2DWsLtPRzqQLdt4Mo326QWfF7LfyXfcUApQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>第一列内容与<code>进程管理</code>有关，第二列内容与 <code>存储管理</code>有关，第三列内容与<code>文件管理</code>有关。</p>\n<p>存储管理的 text segment 、 data segment、stack segment 更多了解见下面这篇文章</p>\n<p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU2NDg0OTgyMA==&mid=2247484788&idx=1&sn=8a17224cabe09d3bd564dfdf22e2ff5d&chksm=fc45f887cb3271914f0e688a3cce4d7e3ce9077cdde199648e72aa92ad08fba2047b4483b7e8&token=504034995&lang=zh_CN&scene=21#wechat_redirect\" target=\"_blank\" rel=\"noopener\">程序员需要了解的硬核知识之汇编语言 (全)</a></p>\n<p>现在我们应该对进程表有个大致的了解了，就可以在对单个 CPU 上如何运行多个顺序进程的错觉做更多的解释。与每一 I/O 类相关联的是一个称作 <code>中断向量(interrupt vector)</code> 的位置（靠近内存底部的固定区域）。它包含中断服务程序的入口地址。假设当一个磁盘中断发生时，用户进程 3 正在运行，则中断硬件将程序计数器、程序状态字、有时还有一个或多个寄存器压入堆栈，计算机随即跳转到中断向量所指示的地址。这就是硬件所做的事情。然后软件就随即接管一切剩余的工作。</p>\n<p>当中断结束后，操作系统会调用一个 C 程序来处理中断剩下的工作。在完成剩下的工作后，会使某些进程就绪，接着调用调度程序，决定随后运行哪个进程。然后将控制权转移给一段汇编语言代码，为当前的进程装入寄存器值以及内存映射并启动该进程运行，下面显示了中断处理和调度的过程。</p>\n<ol>\n<li><p>硬件压入堆栈程序计数器等</p>\n</li>\n<li><p>硬件从中断向量装入新的程序计数器</p>\n</li>\n<li><p>汇编语言过程保存寄存器的值</p>\n</li>\n<li><p>汇编语言过程设置新的堆栈</p>\n</li>\n<li><p>C 中断服务器运行（典型的读和缓存写入）</p>\n</li>\n<li><p>调度器决定下面哪个程序先运行</p>\n</li>\n<li><p>C 过程返回至汇编代码</p>\n</li>\n<li><p>汇编语言过程开始运行新的当前进程</p>\n</li>\n</ol>\n<p>一个进程在执行过程中可能被中断数千次，但关键每次中断后，被中断的进程都返回到与中断发生前完全相同的状态。</p>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><p>在传统的操作系统中，每个进程都有一个地址空间和一个控制线程。事实上，这是大部分进程的定义。不过，在许多情况下，经常存在同一地址空间中运行多个控制线程的情形，这些线程就像是分离的进程。下面我们就着重探讨一下什么是线程</p>\n<h3 id=\"线程的使用\"><a href=\"#线程的使用\" class=\"headerlink\" title=\"线程的使用\"></a>线程的使用</h3><p>或许这个疑问也是你的疑问，为什么要在进程的基础上再创建一个线程的概念，准确的说，这其实是进程模型和线程模型的讨论，回答这个问题，可能需要分三步来回答</p>\n<ul>\n<li><p>多线程之间会共享同一块地址空间和所有可用数据的能力，这是进程所不具备的</p>\n</li>\n<li><p>线程要比进程<code>更轻量级</code>，由于线程更轻，所以它比进程更容易创建，也更容易撤销。在许多系统中，创建一个线程要比创建一个进程快 10 - 100 倍。</p>\n</li>\n<li><p>第三个原因可能是性能方面的探讨，如果多个线程都是 CPU 密集型的，那么并不能获得性能上的增强，但是如果存在着大量的计算和大量的 I/O 处理，拥有多个线程能在这些活动中彼此重叠进行，从而会加快应用程序的执行速度</p>\n</li>\n</ul>\n<h4 id=\"多线程解决方案\"><a href=\"#多线程解决方案\" class=\"headerlink\" title=\"多线程解决方案\"></a>多线程解决方案</h4><p>现在考虑一个线程使用的例子：一个万维网服务器，对页面的请求发送给服务器，而所请求的页面发送回客户端。在多数 web 站点上，某些页面较其他页面相比有更多的访问。例如，索尼的主页比任何一个照相机详情介绍页面具有更多的访问，Web 服务器可以把获得大量访问的页面集合保存在内存中，避免到磁盘去调入这些页面，从而改善性能。这种页面的集合称为 <code>高速缓存(cache)</code>，高速缓存也应用在许多场合中，比如说 CPU 缓存。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiafv8cMyibXVb2KNYiaU7IktbLNOPOeficbw2jRlHzF50BPen1r00FYCag/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面是一个 web 服务器的组织方式，一个叫做 <code>调度线程(dispatcher thread)</code> 的线程从网络中读入工作请求，在调度线程检查完请求后，它会选择一个空闲的（阻塞的）工作线程来处理请求，通常是将消息的指针写入到每个线程关联的特殊字中。然后调度线程会唤醒正在睡眠中的工作线程，把工作线程的状态从阻塞态变为就绪态。</p>\n<p>当工作线程启动后，它会检查请求是否在 web 页面的高速缓存中存在，这个高速缓存是所有线程都可以访问的。如果高速缓存不存在这个 web 页面的话，它会调用一个 <code>read</code> 操作从磁盘中获取页面并且阻塞线程直到磁盘操作完成。当线程阻塞在硬盘操作的期间，为了完成更多的工作，调度线程可能挑选另一个线程运行，也可能把另一个当前就绪的工作线程投入运行。</p>\n<p>这种模型允许将服务器编写为顺序线程的集合，在分派线程的程序中包含一个死循环，该循环用来获得工作请求并且把请求派给工作线程。每个工作线程的代码包含一个从调度线程接收的请求，并且检查 web 高速缓存中是否存在所需页面，如果有，直接把该页面返回给客户，接着工作线程阻塞，等待一个新请求的到达。如果没有，工作线程就从磁盘调入该页面，将该页面返回给客户机，然后工作线程阻塞，等待一个新请求。</p>\n<p>下面是调度线程和工作线程的代码，这里假设 TRUE 为常数 1 ，buf 和 page 分别是保存工作请求和 Web 页面的相应结构。</p>\n<p><strong>调度线程的大致逻辑</strong></p>\n<pre><code>while(TRUE){\n  get_next_request(&amp;buf);\n  handoff_work(&amp;buf);\n}</code></pre><p><strong>工作线程的大致逻辑</strong></p>\n<pre><code>while(TRUE){\n  wait_for_work(&amp;buf);\n  look_for_page_in_cache(&amp;buf,&amp;page);\n  if(page_not_in_cache(&amp;page)){\n    read_page_from_disk(&amp;buf,&amp;page);\n  }\n  return _page(&amp;page);\n}</code></pre><h4 id=\"单线程解决方案\"><a href=\"#单线程解决方案\" class=\"headerlink\" title=\"单线程解决方案\"></a>单线程解决方案</h4><p>现在考虑没有多线程的情况下，如何编写 Web 服务器。我们很容易的就想象为单个线程了，Web 服务器的主循环获取请求并检查请求，并争取在下一个请求之前完成工作。在等待磁盘操作时，服务器空转，并且不处理任何到来的其他请求。结果会导致每秒中只有很少的请求被处理，所以这个例子能够说明多线程提高了程序的并行性并提高了程序的性能。</p>\n<h4 id=\"状态机解决方案\"><a href=\"#状态机解决方案\" class=\"headerlink\" title=\"状态机解决方案\"></a>状态机解决方案</h4><p>到现在为止，我们已经有了两种解决方案，单线程解决方案和多线程解决方案，其实还有一种解决方案就是 <code>状态机解决方案</code>，它的流程如下</p>\n<p>如果目前只有一个非阻塞版本的 read 系统调用可以使用，那么当请求到达服务器时，这个唯一的 read 调用的线程会进行检查，如果能够从高速缓存中得到响应，那么直接返回，如果不能，则启动一个非阻塞的磁盘操作</p>\n<p>服务器在表中记录当前请求的状态，然后进入并获取下一个事件，紧接着下一个事件可能就是一个新工作的请求或是磁盘对先前操作的回答。如果是新工作的请求，那么就开始处理请求。如果是磁盘的响应，就从表中取出对应的状态信息进行处理。对于非阻塞式磁盘 I/O 而言，这种响应一般都是信号中断响应。</p>\n<p>每次服务器从某个请求工作的状态切换到另一个状态时，都必须显示的保存或者重新装入相应的计算状态。这里，每个计算都有一个被保存的状态，存在一个会发生且使得相关状态发生改变的事件集合，我们把这类设计称为<code>有限状态机(finite-state machine)</code>，有限状态机被广泛的应用在计算机科学中。</p>\n<p>这三种解决方案各有各的特性，多线程使得顺序进程的思想得以保留下来，并且实现了并行性，但是顺序进程会阻塞系统调用；单线程服务器保留了阻塞系统的简易性，但是却放弃了性能。有限状态机的处理方法运用了非阻塞调用和中断，通过并行实现了高性能，但是给编程增加了困难。</p>\n<table>\n<thead>\n<tr>\n<th>模型</th>\n<th>特性</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>单线程</td>\n<td>无并行性，性能较差，阻塞系统调用</td>\n</tr>\n<tr>\n<td>多线程</td>\n<td>有并行性，阻塞系统调用</td>\n</tr>\n<tr>\n<td>有限状态机</td>\n<td>并行性，非阻塞系统调用、中断</td>\n</tr>\n</tbody></table>\n<h3 id=\"经典的线程模型\"><a href=\"#经典的线程模型\" class=\"headerlink\" title=\"经典的线程模型\"></a>经典的线程模型</h3><p>理解进程的另一个角度是，用某种方法把相关的资源集中在一起。进程有存放程序正文和数据以及其他资源的地址空间。这些资源包括打开的文件、子进程、即将发生的定时器、信号处理程序、账号信息等。把这些信息放在进程中会比较容易管理。</p>\n<p>另一个概念是，进程中拥有一个执行的线程，通常简写为 <code>线程(thread)</code>。线程会有程序计数器，用来记录接着要执行哪一条指令；线程还拥有寄存器，用来保存线程当前正在使用的变量；线程还会有堆栈，用来记录程序的执行路径。尽管线程必须在某个进程中执行，但是进程和线程完完全全是两个不同的概念，并且他们可以分开处理。进程用于把资源集中在一起，而线程则是 CPU 上调度执行的实体。</p>\n<p>线程给进程模型增加了一项内容，即在同一个进程中，允许彼此之间有较大的独立性且互不干扰。在一个进程中并行运行多个线程类似于在一台计算机上运行多个进程。在多个线程中，各个线程共享同一地址空间和其他资源。在多个进程中，进程共享物理内存、磁盘、打印机和其他资源。因为线程会包含有一些进程的属性，所以线程被称为<code>轻量的进程(lightweight processes)</code>。<code>多线程(multithreading)</code>一词还用于描述在同一进程中多个线程的情况。</p>\n<p>下图我们可以看到三个传统的进程，每个进程有自己的地址空间和单个控制线程。每个线程都在不同的地址空间中运行</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2uvgku9q5Vv9GyQkOicZQtYCH52z6BKMGiaeVlQztM3jDeicn1AFOL7dQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>下图中，我们可以看到有一个进程三个线程的情况。每个线程都在相同的地址空间中运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknc4JzHybInkL388a2Mib2jq4P8P2JkvgH6RFbsv0QKtOFN6mz0qgQOw/640?wx_fmt=png\" alt=\"\"></p>\n<p>线程不像是进程那样具备较强的独立性。同一个进程中的所有线程都会有完全一样的地址空间，这意味着它们也共享同样的全局变量。由于每个线程都可以访问进程地址空间内每个内存地址，<strong>因此一个线程可以读取、写入甚至擦除另一个线程的堆栈</strong>。线程之间除了共享同一内存空间外，还具有如下不同的内容</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkciaYNEibh4VsBF79p911Fgt7Ca558CpyNyuppk9wt7DrvuN1Tfibysvmg/640?wx_fmt=png\" alt=\"\"></p>\n<p>上图左边的是同一个进程中<code>每个线程共享</code>的内容，上图右边是<code>每个线程</code>中的内容。也就是说左边的列表是进程的属性，右边的列表是线程的属性。</p>\n<p>和进程一样，线程可以处于下面这几种状态：<strong>运行中、阻塞、就绪和终止（进程图中没有画）</strong>。正在运行的线程拥有 CPU 时间片并且状态是运行中。一个被阻塞的线程会等待某个释放它的事件。例如，当一个线程执行从键盘读入数据的系统调用时，该线程就被阻塞直到有输入为止。线程通常会被阻塞，直到它等待某个外部事件的发生或者有其他线程来释放它。<strong>线程之间的状态转换和进程之间的状态转换是一样的</strong>。</p>\n<p>每个线程都会有自己的堆栈，如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkSwK4icLBknT5psHj1niac06X161XVudxzlylzibyRPBHhsjHvdqkpDAQ/640?wx_fmt=png\" alt=\"\"></p>\n<h4 id=\"线程系统调用\"><a href=\"#线程系统调用\" class=\"headerlink\" title=\"线程系统调用\"></a>线程系统调用</h4><p>进程通常会从当前的某个单线程开始，然后这个线程通过调用一个库函数（比如 <code>thread_create</code>）创建新的线程。线程创建的函数会要求指定新创建线程的名称。创建的线程通常都返回一个线程标识符，该标识符就是新线程的名字。</p>\n<p>当一个线程完成工作后，可以通过调用一个函数（比如 <code>thread_exit</code>）来退出。紧接着线程消失，状态变为终止，不能再进行调度。在某些线程的运行过程中，可以通过调用函数例如 <code>thread_join</code> ，表示一个线程可以等待另一个线程退出。这个过程阻塞调用线程直到等待特定的线程退出。在这种情况下，线程的创建和终止非常类似于进程的创建和终止。</p>\n<p>另一个常见的线程是调用 <code>thread_yield</code>，它允许线程自动放弃 CPU 从而让另一个线程运行。这样一个调用还是很重要的，因为不同于进程，线程是无法利用时钟中断强制让线程让出 CPU 的。</p>\n<h3 id=\"POSIX-线程\"><a href=\"#POSIX-线程\" class=\"headerlink\" title=\"POSIX 线程\"></a>POSIX 线程</h3><p>为了使编写可移植线程程序成为可能，IEEE 在 IEEE 标准 1003.1c 中定义了线程标准。线程包被定义为 <code>Pthreads</code>。大部分的 UNIX 系统支持它。这个标准定义了 60 多种功能调用，一一列举不太现实，下面为你列举了一些常用的系统调用。</p>\n<blockquote>\n<p><strong>POSIX 线程</strong>（通常称为 <strong>pthreads</strong>）是一种独立于语言而存在的执行模型，以及并行执行模型。它允许程序控制时间上重叠的多个不同的工作流程。每个工作流程都称为一个线程，可以通过调用 POSIX Threads API 来实现对这些流程的创建和控制。可以把它理解为线程的标准。</p>\n<p>POSIX Threads 的实现在许多类似且符合 POSIX 的操作系统上可用，例如 <strong>FreeBSD、NetBSD、OpenBSD、Linux、macOS、Android、Solaris</strong>，它在现有 Windows API 之上实现了 <strong>pthread</strong>。</p>\n<p>IEEE 是世界上最大的技术专业组织，致力于为人类的利益而发展技术。</p>\n</blockquote>\n<table>\n<thead>\n<tr>\n<th>线程调用</th>\n<th>描述</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pthread_create</td>\n<td>创建一个新线程</td>\n</tr>\n<tr>\n<td>pthread_exit</td>\n<td>结束调用的线程</td>\n</tr>\n<tr>\n<td>pthread_join</td>\n<td>等待一个特定的线程退出</td>\n</tr>\n<tr>\n<td>pthread_yield</td>\n<td>释放 CPU 来运行另外一个线程</td>\n</tr>\n<tr>\n<td>pthread_attr_init</td>\n<td>创建并初始化一个线程的属性结构</td>\n</tr>\n<tr>\n<td>pthread_attr_destory</td>\n<td>删除一个线程的属性结构</td>\n</tr>\n</tbody></table>\n<p>所有的 Pthreads 都有特定的属性，每一个都含有标识符、一组寄存器（包括程序计数器）和一组存储在结构中的属性。这个属性包括堆栈大小、调度参数以及其他线程需要的项目。</p>\n<p>新的线程会通过 <code>pthread_create</code> 创建，新创建的线程的标识符会作为函数值返回。这个调用非常像是 UNIX 中的 <code>fork</code> 系统调用（除了参数之外），其中线程标识符起着 <code>PID</code> 的作用，这么做的目的是为了和其他线程进行区分。</p>\n<p>当线程完成指派给他的工作后，会通过 <code>pthread_exit</code> 来终止。这个调用会停止线程并释放堆栈。</p>\n<p>一般一个线程在继续运行前需要等待另一个线程完成它的工作并退出。可以通过 <code>pthread_join</code> 线程调用来等待别的特定线程的终止。而要等待线程的线程标识符作为一个参数给出。</p>\n<p>有时会出现这种情况：一个线程逻辑上没有阻塞，但感觉上它已经运行了足够长的时间并且希望给另外一个线程机会去运行。这时候可以通过 <code>pthread_yield</code> 来完成。</p>\n<p>下面两个线程调用是处理属性的。<code>pthread_attr_init</code> 建立关联一个线程的属性结构并初始化成默认值，这些值（例如优先级）可以通过修改属性结构的值来改变。</p>\n<p>最后，<code>pthread_attr_destroy</code> 删除一个线程的结构，释放它占用的内存。它不会影响调用它的线程，这些线程会一直存在。</p>\n<p>为了更好的理解 pthread 是如何工作的，考虑下面这个例子</p>\n<pre><code>#include &lt;pthread.h&gt;\n#include &lt;stdio.h&gt;\n#include &lt;stdlib.h&gt;\n\n#define NUMBER_OF_THREADS 10\n\nvoid *print_hello_world(vvoid *tid){\n  /* 输出线程的标识符，然后退出 */\n  printf(&quot;Hello World. Greetings from thread %d\\n&quot;,tid);\n  pthread_exit(NULL);\n}\n\nint main(int argc,char *argv[]){\n  /* 主程序创建 10 个线程，然后退出 */\n  pthread_t threads[NUMBER_OF_THREADS];\n  int status,i;\n\n  for(int i = 0;i &lt; NUMBER_OF_THREADS;i++){\n    printf(&quot;Main here. Creating thread %d\\n&quot;,i);\n    status = pthread_create(&amp;threads[i], NULL, print_hello_world, (void *)i);\n\n    if(status != 0){\n      printf(&quot;Oops. pthread_create returned error code %d\\n&quot;,status);\n      exit(-1);\n    }\n  }\n  exit(NULL);\n}</code></pre><p>主线程在宣布它的指责之后，循环 <code>NUMBER_OF_THREADS</code> 次，每次创建一个新的线程。如果线程创建失败，会打印出一条信息后退出。在创建完成所有的工作后，主程序退出。</p>\n<h3 id=\"线程实现\"><a href=\"#线程实现\" class=\"headerlink\" title=\"线程实现\"></a>线程实现</h3><p>主要有三种实现方式</p>\n<ul>\n<li><p>在用户空间中实现线程；</p>\n</li>\n<li><p>在内核空间中实现线程；</p>\n</li>\n<li><p>在用户和内核空间中混合实现线程。</p>\n</li>\n</ul>\n<p>下面我们分开讨论一下</p>\n<h4 id=\"在用户空间中实现线程\"><a href=\"#在用户空间中实现线程\" class=\"headerlink\" title=\"在用户空间中实现线程\"></a>在用户空间中实现线程</h4><p>第一种方法是把整个线程包放在用户空间中，内核对线程一无所知，它不知道线程的存在。所有的这类实现都有同样的通用结构</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkcq03vztMLnRiaYPTqX0KENPFKPnNr2Ic0qj79V3e0Py9JstIWCI4HibQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>线程在运行时系统之上运行，运行时系统是管理线程过程的集合，包括前面提到的四个过程：pthread_create, pthread_exit, pthread_join 和 pthread_yield。</p>\n<blockquote>\n<p><code>运行时系统(Runtime System)</code> 也叫做运行时环境，该运行时系统提供了程序在其中运行的环境。此环境可能会解决许多问题，包括应用程序内存的布局，程序如何访问变量，在过程之间传递参数的机制，与操作系统的接口等等。编译器根据特定的运行时系统进行假设以生成正确的代码。通常，运行时系统将负责设置和管理堆栈，并且会包含诸如垃圾收集，线程或语言内置的其他动态的功能。</p>\n</blockquote>\n<p>在用户空间管理线程时，每个进程需要有其专用的<code>线程表(thread table)</code>，用来跟踪该进程中的线程。这些表和内核中的进程表类似，不过它仅仅记录各个线程的属性，如每个线程的程序计数器、堆栈指针、寄存器和状态。该线程表由运行时系统统一管理。当一个线程转换到就绪状态或阻塞状态时，在该线程表中存放重新启动该线程的所有信息，与内核在进程表中存放的信息完全一样。</p>\n<h4 id=\"在用户空间实现线程的优势\"><a href=\"#在用户空间实现线程的优势\" class=\"headerlink\" title=\"在用户空间实现线程的优势\"></a>在用户空间实现线程的优势</h4><p>在用户空间中实现线程要比在内核空间中实现线程具有这些方面的优势：考虑如果在线程完成时或者是在调用 <code>pthread_yield</code> 时，必要时会进程线程切换，然后线程的信息会被保存在运行时环境所提供的线程表中，然后，线程调度程序来选择另外一个需要运行的线程。保存线程的状态和调度程序都是<code>本地过程</code>，<strong>所以启动他们比进行内核调用效率更高。因而不需要切换到内核，也就不需要上下文切换，也不需要对内存高速缓存进行刷新，因为线程调度非常便捷，因此效率比较高</strong>。</p>\n<p>在用户空间实现线程还有一个优势就是<strong>它允许每个进程有自己定制的调度算法</strong>。例如在某些应用程序中，那些具有垃圾收集线程的应用程序（知道是谁了吧）就不用担心自己线程会不会在不合适的时候停止，这是一个优势。用户线程还具有较好的可扩展性，因为内核空间中的内核线程需要一些表空间和堆栈空间，如果内核线程数量比较大，容易造成问题。</p>\n<h4 id=\"在用户空间实现线程的劣势\"><a href=\"#在用户空间实现线程的劣势\" class=\"headerlink\" title=\"在用户空间实现线程的劣势\"></a>在用户空间实现线程的劣势</h4><p>尽管在用户空间实现线程会具有一定的性能优势，但是劣势还是很明显的，你如何实现<code>阻塞系统调用</code>呢？假设在还没有任何键盘输入之前，一个线程读取键盘，让线程进行系统调用是不可能的，因为这会停止所有的线程。所以，<strong>使用线程的一个目标是能够让线程进行阻塞调用，并且要避免被阻塞的线程影响其他线程</strong>。</p>\n<p>与阻塞调用类似的问题是<code>缺页中断</code>问题，实际上，计算机并不会把所有的程序都一次性的放入内存中，如果某个程序发生函数调用或者跳转指令到了一条不在内存的指令上，就会发生页面故障，而操作系统将到磁盘上取回这个丢失的指令，这就称为<code>缺页故障</code>。而在对所需的指令进行读入和执行时，相关的进程就会被阻塞。如果只有一个线程引起页面故障，内核由于甚至不知道有线程存在，通常会把整个进程阻塞直到磁盘 I/O 完成为止，尽管其他的线程是可以运行的。</p>\n<p>另外一个问题是，如果一个线程开始运行，该线程所在进程中的其他线程都不能运行，除非第一个线程自愿的放弃 CPU，在一个单进程内部，没有时钟中断，所以不可能使用轮转调度的方式调度线程。除非其他线程能够以自己的意愿进入运行时环境，否则调度程序没有可以调度线程的机会。</p>\n<h3 id=\"在内核中实现线程\"><a href=\"#在内核中实现线程\" class=\"headerlink\" title=\"在内核中实现线程\"></a>在内核中实现线程</h3><p>现在我们考虑使用内核来实现线程的情况，此时不再需要运行时环境了。另外，每个进程中也没有线程表。相反，在内核中会有用来记录系统中所有线程的线程表。当某个线程希望创建一个新线程或撤销一个已有线程时，它会进行一个系统调用，这个系统调用通过对线程表的更新来完成线程创建或销毁工作。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaPkapIx1EYhPdibEPKuChcIOcClAlhTUicxq554eFbJVWrvyCVUdumBw/640?wx_fmt=png\" alt=\"\"></p>\n<p>内核中的线程表持有每个线程的寄存器、状态和其他信息。这些信息和用户空间中的线程信息相同，但是位置却被放在了内核中而不是用户空间中。另外，内核还维护了一张进程表用来跟踪系统状态。</p>\n<p>所有能够阻塞的调用都会通过系统调用的方式来实现，当一个线程阻塞时，内核可以进行选择，是运行在同一个进程中的另一个线程（如果有就绪线程的话）还是运行一个另一个进程中的线程。但是在用户实现中，运行时系统始终运行自己的线程，直到内核剥夺它的 CPU 时间片（或者没有可运行的线程存在了）为止。</p>\n<p>由于在内核中创建或者销毁线程的开销比较大，所以某些系统会采用可循环利用的方式来回收线程。当某个线程被销毁时，就把它标志为不可运行的状态，但是其内部结构没有受到影响。稍后，在必须创建一个新线程时，就会重新启用旧线程，把它标志为可用状态。</p>\n<p>如果某个进程中的线程造成缺页故障后，内核很容易的就能检查出来是否有其他可运行的线程，如果有的话，在等待所需要的页面从磁盘读入时，就选择一个可运行的线程运行。这样做的缺点是系统调用的代价比较大，所以如果线程的操作（创建、终止）比较多，就会带来很大的开销。</p>\n<h3 id=\"混合实现\"><a href=\"#混合实现\" class=\"headerlink\" title=\"混合实现\"></a>混合实现</h3><p>结合用户空间和内核空间的优点，设计人员采用了一种<code>内核级线程</code>的方式，然后将用户级线程与某些或者全部内核线程多路复用起来</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkKYe6RpSy705bprAxhibKHKkiba32AcKmS0AOAcuCyZuMvyduVgWFwGhQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>在这种模型中，编程人员可以自由控制用户线程和内核线程的数量，具有很大的灵活度。采用这种方法，内核只识别内核级线程，并对其进行调度。其中一些内核级线程会被多个用户级线程多路复用。</p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><p>进程是需要频繁的和其他进程进行交流的。例如，在一个 shell 管道中，第一个进程的输出必须传递给第二个进程，这样沿着管道进行下去。因此，进程之间如果需要通信的话，必须要使用一种良好的数据结构以至于不能被中断。下面我们会一起讨论有关 <code>进程间通信(Inter Process Communication, IPC)</code> 的问题。</p>\n<p>关于进程间的通信，这里有三个问题</p>\n<ul>\n<li><p>上面提到了第一个问题，那就是一个进程如何传递消息给其他进程。</p>\n</li>\n<li><p>第二个问题是如何确保两个或多个线程之间不会相互干扰。例如，两个航空公司都试图为不同的顾客抢购飞机上的最后一个座位。</p>\n</li>\n<li><p>第三个问题是数据的先后顺序的问题，如果进程 A 产生数据并且进程 B 打印数据。则进程 B 打印数据之前需要先等 A 产生数据后才能够进行打印。</p>\n</li>\n</ul>\n<p>需要注意的是，这三个问题中的后面两个问题同样也适用于线程</p>\n<p>第一个问题在线程间比较好解决，因为它们共享一个地址空间，它们具有相同的运行时环境，可以想象你在用高级语言编写多线程代码的过程中，线程通信问题是不是比较容易解决？</p>\n<p>另外两个问题也同样适用于线程，同样的问题可用同样的方法来解决。我们后面会慢慢讨论这三个问题，你现在脑子中大致有个印象即可。</p>\n<h3 id=\"竞态条件\"><a href=\"#竞态条件\" class=\"headerlink\" title=\"竞态条件\"></a>竞态条件</h3><p>在一些操作系统中，协作的进程可能共享一些彼此都能读写的公共资源。公共资源可能在内存中也可能在一个共享文件。为了讲清楚进程间是如何通信的，这里我们举一个例子：一个后台打印程序。当一个进程需要打印某个文件时，它会将文件名放在一个特殊的<code>后台目录(spooler directory)</code>中。另一个进程 <code>打印后台进程(printer daemon)</code> 会定期的检查是否需要文件被打印，如果有的话，就打印并将该文件名从目录下删除。</p>\n<p>假设我们的后台目录有非常多的 <code>槽位(slot)</code>，编号依次为 0，1，2，…，每个槽位存放一个文件名。同时假设有两个共享变量：<code>out</code>，指向下一个需要打印的文件；<code>in</code>，指向目录中下个空闲的槽位。可以把这两个文件保存在一个所有进程都能访问的文件中，该文件的长度为两个字。在某一时刻，0 至 3 号槽位空，4 号至 6 号槽位被占用。在同一时刻，进程 A 和 进程 B 都决定将一个文件排队打印，情况如下</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk2JljDicfDxXbzlWe7J4KyqznJfd12m6a6BbVaiaMKYxDKU0LpRP9wibibw/640?wx_fmt=png\" alt=\"\"></p>\n<p><code>墨菲法则(Murphy)</code> 中说过，任何可能出错的地方终将出错，这句话生效时，可能发生如下情况。</p>\n<p>进程 A 读到 in 的值为 7，将 7 存在一个局部变量 <code>next_free_slot</code> 中。此时发生一次时钟中断，CPU 认为进程 A 已经运行了足够长的时间，决定切换到进程 B 。进程 B 也读取 in 的值，发现是 7，然后进程 B 将 7 写入到自己的局部变量 <code>next_free_slot</code> 中，在这一时刻两个进程都认为下一个可用槽位是 7 。</p>\n<p>进程 B 现在继续运行，它会将打印文件名写入到 slot 7 中，然后把 in 的指针更改为 8 ，然后进程 B 离开去做其他的事情</p>\n<p>现在进程 A 开始恢复运行，由于进程 A 通过检查 <code>next_free_slot</code>也发现 slot 7 的槽位是空的，于是将打印文件名存入 slot 7 中，然后把 in 的值更新为 8 ，由于 slot 7 这个槽位中已经有进程 B 写入的值，所以进程 A 的打印文件名会把进程 B 的文件覆盖，由于打印机内部是无法发现是哪个进程更新的，它的功能比较局限，所以这时候进程 B 永远无法打印输出，类似这种情况，<strong>即两个或多个线程同时对一共享数据进行修改，从而影响程序运行的正确性时，这种就被称为竞态条件 (race condition)</strong>。调试竞态条件是一种非常困难的工作，因为绝大多数情况下程序运行良好，但在极少数的情况下会发生一些无法解释的奇怪现象。</p>\n<h3 id=\"临界区\"><a href=\"#临界区\" class=\"headerlink\" title=\"临界区\"></a>临界区</h3><p>不仅共享资源会造成竞态条件，事实上共享文件、共享内存也会造成竞态条件、那么该如何避免呢？或许一句话可以概括说明：<strong>禁止一个或多个进程在同一时刻对共享资源（包括共享内存、共享文件等）进行读写</strong>。换句话说，我们需要一种 <code>互斥(mutual exclusion)</code> 条件，这也就是说，如果一个进程在某种方式下使用共享变量和文件的话，除该进程之外的其他进程就禁止做这种事（访问统一资源）。上面问题的纠结点在于，在进程 A 对共享变量的使用未结束之前进程 B 就使用它。在任何操作系统中，为了实现互斥操作而选用适当的原语是一个主要的设计问题，接下来我们会着重探讨一下。</p>\n<p>避免竞争问题的条件可以用一种抽象的方式去描述。大部分时间，进程都会忙于内部计算和其他不会导致竞争条件的计算。然而，有时候进程会访问共享内存或文件，或者做一些能够导致竞态条件的操作。我们把对共享内存进行访问的程序片段称作 <code>临界区域(critical region)</code> 或 <code>临界区(critical section)</code>。如果我们能够正确的操作，使两个不同进程不可能同时处于临界区，就能避免竞争条件，这也是从操作系统设计角度来进行的。</p>\n<p>尽管上面这种设计避免了竞争条件，但是不能确保并发线程同时访问共享数据的正确性和高效性。一个好的解决方案，应该包含下面四种条件</p>\n<ol>\n<li><p>任何时候两个进程不能同时处于临界区</p>\n</li>\n<li><p>不应对 CPU 的速度和数量做任何假设</p>\n</li>\n<li><p>位于临界区外的进程不得阻塞其他进程</p>\n</li>\n<li><p>不能使任何进程无限等待进入临界区</p>\n</li>\n</ol>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkrTXZzTqwPTGouHGo3DMXicFwwsRRENeKdia9UicibzOyzGBZ1NA1R8kWCg/640?wx_fmt=png\" alt=\"\"></p>\n<p>从抽象的角度来看，我们通常希望进程的行为如上图所示，在 t1 时刻，进程 A 进入临界区，在 t2 的时刻，进程 B 尝试进入临界区，因为此时进程 A 正在处于临界区中，所以进程 B 会阻塞直到 t3 时刻进程 A 离开临界区，此时进程 B 能够允许进入临界区。最后，在 t4 时刻，进程 B 离开临界区，系统恢复到没有进程的原始状态。</p>\n<h3 id=\"忙等互斥\"><a href=\"#忙等互斥\" class=\"headerlink\" title=\"忙等互斥\"></a>忙等互斥</h3><p>下面我们会继续探讨实现互斥的各种设计，在这些方案中，当一个进程正忙于更新其关键区域的共享内存时，没有其他进程会进入其关键区域，也不会造成影响。</p>\n<h4 id=\"屏蔽中断\"><a href=\"#屏蔽中断\" class=\"headerlink\" title=\"屏蔽中断\"></a>屏蔽中断</h4><p>在单处理器系统上，最简单的解决方案是让每个进程在进入临界区后立即<code>屏蔽所有中断</code>，并在离开临界区之前重新启用它们。屏蔽中断后，时钟中断也会被屏蔽。CPU 只有发生时钟中断或其他中断时才会进行进程切换。这样，在屏蔽中断后 CPU 不会切换到其他进程。所以，一旦某个进程屏蔽中断之后，它就可以检查和修改共享内存，而不用担心其他进程介入访问共享数据。</p>\n<p>这个方案可行吗？进程进入临界区域是由谁决定的呢？不是用户进程吗？当进程进入临界区域后，用户进程关闭中断，如果经过一段较长时间后进程没有离开，那么中断不就一直启用不了，结果会如何？可能会造成整个系统的终止。而且如果是多处理器的话，屏蔽中断仅仅对执行 <code>disable</code> 指令的 CPU 有效。其他 CPU 仍将继续运行，并可以访问共享内存。</p>\n<p>另一方面，对内核来说，当它在执行更新变量或列表的几条指令期间将中断屏蔽是很方便的。例如，如果多个进程处理就绪列表中的时候发生中断，则可能会发生竞态条件的出现。所以，屏蔽中断对于操作系统本身来说是一项很有用的技术，但是对于用户线程来说，屏蔽中断却不是一项通用的互斥机制。</p>\n<h4 id=\"锁变量\"><a href=\"#锁变量\" class=\"headerlink\" title=\"锁变量\"></a>锁变量</h4><p>作为第二种尝试，可以寻找一种软件层面解决方案。考虑有单个共享的（锁）变量，初始为值为 0 。当一个线程想要进入关键区域时，它首先会查看锁的值是否为 0 ，如果锁的值是 0 ，进程会把它设置为 1 并让进程进入关键区域。如果锁的状态是 1，进程会等待直到锁变量的值变为 0 。因此，锁变量的值是 0 则意味着没有线程进入关键区域。如果是 1 则意味着有进程在关键区域内。我们对上图修改后，如下所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmcJYsm5uD0kUSRoia4J0KORtZslfTnAnqBca2Ay7KbWibU2a9ywAKwaw/640?wx_fmt=png\" alt=\"\"></p>\n<p>这种设计方式是否正确呢？是否存在纰漏呢？假设一个进程读出锁变量的值并发现它为 0 ，而恰好在它将其设置为 1 之前，另一个进程调度运行，读出锁的变量为 0 ，并将锁的变量设置为 1 。然后第一个线程运行，把锁变量的值再次设置为 1，此时，临界区域就会有两个进程在同时运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVmTDUd4XWEic0EUCtJnWB8yKr5qUJANrZrDYXm0PLF60Zu7sKas4Yibw/640?wx_fmt=png\" alt=\"\"></p>\n<p>也许有的读者可以这么认为，在进入前检查一次，在要离开的关键区域再检查一次不就解决了吗？实际上这种情况也是于事无补，因为在第二次检查期间其他线程仍有可能修改锁变量的值，换句话说，这种 <code>set-before-check</code> 不是一种 <code>原子性</code> 操作，所以同样还会发生竞争条件。</p>\n<h4 id=\"严格轮询法\"><a href=\"#严格轮询法\" class=\"headerlink\" title=\"严格轮询法\"></a>严格轮询法</h4><p>第三种互斥的方式先抛出来一段代码，这里的程序是用 C 语言编写，之所以采用 C 是因为操作系统普遍是用 C 来编写的（偶尔会用 C++），而基本不会使用 Java 、Modula3 或 Pascal 这样的语言，Java 中的 native 关键字底层也是 C 或 C++ 编写的源码。对于编写操作系统而言，需要使用 C 语言这种强大、高效、可预知和有特性的语言，而对于 Java ，它是不可预知的，因为它在关键时刻会用完存储器，而在不合适的时候会调用垃圾回收机制回收内存。在 C 语言中，这种情况不会发生，C 语言中不会主动调用垃圾回收回收内存。有关 C 、C++ 、Java 和其他四种语言的比较可以参考 <strong>链接</strong></p>\n<p><strong>进程 0 的代码</strong></p>\n<pre><code>while(TRUE){\n  while(turn != 0){\n    /* 进入关键区域 */\n    critical_region();\n    turn = 1;\n    /* 离开关键区域 */\n    noncritical_region();\n  }\n}</code></pre><p><strong>进程 1 的代码</strong></p>\n<pre><code>while(TRUE){\n  while(turn != 1){\n    critical_region();\n    turn = 0;\n    noncritical_region();\n  }\n}</code></pre><p>在上面代码中，变量 <code>turn</code>，初始值为 0 ，用于记录轮到那个进程进入临界区，并检查或更新共享内存。开始时，进程 0 检查 turn，发现其值为 0 ，于是进入临界区。进程 1 也发现其值为 0 ，所以在一个等待循环中不停的测试 turn，看其值何时变为 1。连续检查一个变量直到某个值出现为止，这种方法称为 <code>忙等待(busywaiting)</code>。由于这种方式浪费 CPU 时间，所以这种方式通常应该要避免。只有在有理由认为等待时间是非常短的情况下，才能够使用忙等待。用于忙等待的锁，称为 <code>自旋锁(spinlock)</code>。</p>\n<p>进程 0 离开临界区时，它将 turn 的值设置为 1，以便允许进程 1 进入其临界区。假设进程 1 很快便离开了临界区，则此时两个进程都处于临界区之外，turn 的值又被设置为 0 。现在进程 0 很快就执行完了整个循环，它退出临界区，并将 turn 的值设置为 1。此时，turn 的值为 1，两个进程都在其临界区外执行。</p>\n<p>突然，进程 0 结束了非临界区的操作并返回到循环的开始。但是，这时它不能进入临界区，因为 turn 的当前值为 1，此时进程 1 还忙于非临界区的操作，进程 0 只能继续 while 循环，直到进程 1 把 turn 的值改为 0 。这说明，在一个进程比另一个进程执行速度慢了很多的情况下，轮流进入临界区并不是一个好的方法。</p>\n<p>这种情况违反了前面的叙述 3 ，即 <strong>位于临界区外的进程不得阻塞其他进程</strong>，进程 0 被一个临界区外的进程阻塞。由于违反了第三条，所以也不能作为一个好的方案。</p>\n<h4 id=\"Peterson-解法\"><a href=\"#Peterson-解法\" class=\"headerlink\" title=\"Peterson 解法\"></a>Peterson 解法</h4><p>荷兰数学家 T.Dekker 通过将锁变量与警告变量相结合，最早提出了一个不需要严格轮换的软件互斥算法，关于 Dekker 的算法，参考 <strong>链接</strong></p>\n<p>后来， G.L.Peterson 发现了一种简单很多的互斥算法，它的算法如下</p>\n<pre><code>#define FALSE 0\n#define TRUE  1\n/* 进程数量 */\n#define N     2                                                    \n\n/* 现在轮到谁 */\nint turn;                    \n\n/* 所有值初始化为 0 (FALSE) */\nint interested[N];                                            \n\n/* 进程是 0 或 1 */\nvoid enter_region(int process){                    \n\n  /* 另一个进程号 */\n  int other;                                                        \n\n  /* 另一个进程 */\n  other = 1 - process;                \n\n  /* 表示愿意进入临界区 */\n  interested[process] = TRUE;                        \n  turn = process;\n\n  /* 空循环 */\n  while(turn == process \n        &amp;&amp; interested[other] == true){} \n\n}\n\nvoid leave_region(int process){\n\n  /* 表示离开临界区 */\n  interested[process] == FALSE;                 \n}</code></pre><p>在使用共享变量时（即进入其临界区）之前，各个进程使用各自的进程号 0 或 1 作为参数来调用 <code>enter_region</code>，这个函数调用在需要时将使进程等待，直到能够安全的临界区。在完成对共享变量的操作之后，进程将调用 <code>leave_region</code> 表示操作完成，并且允许其他进程进入。</p>\n<p>现在来看看这个办法是如何工作的。一开始，没有任何进程处于临界区中，现在进程 0 调用 <code>enter_region</code>。它通过设置数组元素和将 turn 置为 0 来表示它希望进入临界区。由于进程 1 并不想进入临界区，所以 enter_region 很快便返回。如果进程现在调用 enter_region，进程 1 将在此处挂起直到 <code>interested[0]</code> 变为 FALSE，这种情况只有在进程 0 调用 <code>leave_region</code> 退出临界区时才会发生。</p>\n<p>那么上面讨论的是顺序进入的情况，现在来考虑一种两个进程同时调用 <code>enter_region</code> 的情况。它们都将自己的进程存入 turn，但只有最后保存进去的进程号才有效，前一个进程的进程号因为重写而丢失。假如进程 1 是最后存入的，则 turn 为 1 。当两个进程都运行到 <code>while</code> 的时候，进程 0 将不会循环并进入临界区，而进程 1 将会无限循环且不会进入临界区，直到进程 0 退出位置。</p>\n<h4 id=\"TSL-指令\"><a href=\"#TSL-指令\" class=\"headerlink\" title=\"TSL 指令\"></a>TSL 指令</h4><p>现在来看一种需要硬件帮助的方案。一些计算机，特别是那些设计为多处理器的计算机，都会有下面这条指令</p>\n<pre><code>TSL RX,LOCK    </code></pre><p>称为 <code>测试并加锁(test and set lock)</code>，它将一个内存字 lock 读到寄存器 <code>RX</code> 中，然后在该内存地址上存储一个非零值。读写指令能保证是一体的，不可分割的，一同执行的。在这个指令结束之前其他处理器均不允许访问内存。执行 TSL 指令的 CPU 将会锁住内存总线，用来禁止其他 CPU 在这个指令结束之前访问内存。</p>\n<p>很重要的一点是锁住内存总线和禁用中断不一样。禁用中断并不能保证一个处理器在读写操作之间另一个处理器对内存的读写。也就是说，在处理器 1 上屏蔽中断对处理器 2 没有影响。让处理器 2 远离内存直到处理器 1 完成读写的最好的方式就是锁住总线。这需要一个特殊的硬件（基本上，一根总线就可以确保总线由锁住它的处理器使用，而其他的处理器不能使用）</p>\n<p>为了使用 TSL 指令，要使用一个共享变量 lock 来协调对共享内存的访问。当 lock 为 0 时，任何进程都可以使用 TSL 指令将其设置为 1，并读写共享内存。当操作结束时，进程使用 <code>move</code> 指令将 lock 的值重新设置为 0 。</p>\n<p>这条指令如何防止两个进程同时进入临界区呢？下面是解决方案</p>\n<pre><code>enter_region:\n            | 复制锁到寄存器并将锁设为1\n            TSL REGISTER,LOCK              \n            | 锁是 0 吗？\n          CMP REGISTER,#0                             \n          | 若不是零，说明锁已被设置，所以循环\n          JNE enter_region                            \n          | 返回调用者，进入临界区\n          RET                                              \n\nleave_region:\n\n            | 在锁中存入 0\n            MOVE LOCK,#0                  \n      | 返回调用者\n          RET                                              </code></pre><p>我们可以看到这个解决方案的思想和 Peterson 的思想很相似。假设存在如下共 4 指令的汇编语言程序。第一条指令将 lock 原来的值复制到寄存器中并将 lock 设置为 1 ，随后这个原来的值和 0 做对比。如果它不是零，说明之前已经被加过锁，则程序返回到开始并再次测试。经过一段时间后（可长可短），该值变为 0 （当前处于临界区中的进程退出临界区时），于是过程返回，此时已加锁。要清除这个锁也比较简单，程序只需要将 0 存入 lock 即可，不需要特殊的同步指令。</p>\n<p>现在有了一种很明确的做法，那就是进程在进入临界区之前会先调用 <code>enter_region</code>，判断是否进行循环，如果 lock 的值是 1 ，进行无限循环，如果 lock 是 0，不进入循环并进入临界区。在进程从临界区返回时它调用 <code>leave_region</code>，这会把 lock 设置为 0 。与基于临界区问题的所有解法一样，进程必须在正确的时间调用 enter_region 和 leave_region ，解法才能奏效。</p>\n<p>还有一个可以替换 TSL 的指令是 <code>XCHG</code>，它原子性的交换了两个位置的内容，例如，一个寄存器与一个内存字，代码如下</p>\n<pre><code>enter_region:\n        | 把 1 放在内存器中\n        MOVE REGISTER,#1    \n    | 交换寄存器和锁变量的内容\n        XCHG REGISTER,LOCK          \n    | 锁是 0 吗？\n        CMP REGISTER,#0     \n    | 若不是 0 ，锁已被设置，进行循环\n        JNE enter_region                    \n    | 返回调用者，进入临界区\n        RET                                                     \n\nleave_region:                \n        | 在锁中存入 0 \n        MOVE LOCK,#0    \n    | 返回调用者\n        RET                                                     </code></pre><p>XCHG 的本质上与 TSL 的解决办法一样。所有的 Intel x86 CPU 在底层同步中使用 XCHG 指令。</p>\n<h3 id=\"睡眠与唤醒\"><a href=\"#睡眠与唤醒\" class=\"headerlink\" title=\"睡眠与唤醒\"></a>睡眠与唤醒</h3><p>上面解法中的 Peterson 、TSL 和 XCHG 解法都是正确的，但是它们都有忙等待的缺点。这些解法的本质上都是一样的，先检查是否能够进入临界区，若不允许，则该进程将原地等待，直到允许为止。</p>\n<p>这种方式不但浪费了 CPU 时间，而且还可能引起意想不到的结果。考虑一台计算机上有两个进程，这两个进程具有不同的优先级，<code>H</code> 是属于优先级比较高的进程，<code>L</code> 是属于优先级比较低的进程。进程调度的规则是不论何时只要 H 进程处于就绪态 H 就开始运行。在某一时刻，L 处于临界区中，此时 H 变为就绪态，准备运行（例如，一条 I/O 操作结束）。现在 H 要开始忙等，但由于当 H 就绪时 L 就不会被调度，L 从来不会有机会离开关键区域，所以 H 会变成死循环，有时将这种情况称为<code>优先级反转问题(priority inversion problem)</code>。</p>\n<p>现在让我们看一下进程间的通信原语，这些原语在不允许它们进入关键区域之前会阻塞而不是浪费 CPU 时间，最简单的是 <code>sleep</code> 和 <code>wakeup</code>。Sleep 是一个能够造成调用者阻塞的系统调用，也就是说，这个系统调用会暂停直到其他进程唤醒它。wakeup 调用有一个参数，即要唤醒的进程。还有一种方式是 wakeup 和 sleep 都有一个参数，即 sleep 和 wakeup 需要匹配的内存地址。</p>\n<h4 id=\"生产者-消费者问题\"><a href=\"#生产者-消费者问题\" class=\"headerlink\" title=\"生产者 - 消费者问题\"></a>生产者 - 消费者问题</h4><p>作为这些私有原语的例子，让我们考虑<code>生产者-消费者(producer-consumer)</code> 问题，也称作 <code>有界缓冲区(bounded-buffer)</code> 问题。两个进程共享一个公共的固定大小的缓冲区。其中一个是<code>生产者(producer)</code>，将信息放入缓冲区， 另一个是<code>消费者(consumer)</code>，会从缓冲区中取出。也可以把这个问题一般化为 m 个生产者和 n 个消费者的问题，但是我们这里只讨论一个生产者和一个消费者的情况，这样可以简化实现方案。</p>\n<p>如果缓冲队列已满，那么当生产者仍想要将数据写入缓冲区的时候，会出现问题。它的解决办法是让生产者睡眠，也就是阻塞生产者。等到消费者从缓冲区中取出一个或多个数据项时再唤醒它。同样的，当消费者试图从缓冲区中取数据，但是发现缓冲区为空时，消费者也会睡眠，阻塞。直到生产者向其中放入一个新的数据。</p>\n<p>这个逻辑听起来比较简单，而且这种方式也需要一种称作 <code>监听</code> 的变量，这个变量用于监视缓冲区的数据，我们暂定为 count，如果缓冲区最多存放 N 个数据项，生产者会每次判断 count 是否达到 N，否则生产者向缓冲区放入一个数据项并增量 count 的值。消费者的逻辑也很相似：首先测试 count 的值是否为 0 ，如果为 0 则消费者睡眠、阻塞，否则会从缓冲区取出数据并使 count 数量递减。每个进程也会检查检查是否其他线程是否应该被唤醒，如果应该被唤醒，那么就唤醒该线程。下面是生产者消费者的代码</p>\n<pre><code>/* 缓冲区 slot 槽的数量 */\n#define N 100                        \n/* 缓冲区数据的数量 */\nint count = 0                                        \n\n// 生产者\nvoid producer(void){\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){                \n    /* 生成下一项数据 */\n    item = produce_item()                \n    /* 如果缓存区是满的，就会阻塞 */\n    if(count == N){\n      sleep();                                    \n    }\n\n    /* 把当前数据放在缓冲区中 */\n    insert_item(item);\n    /* 增加缓冲区 count 的数量 */\n    count = count + 1;                    \n    if(count == 1){\n      /* 缓冲区是否为空？ */\n      wakeup(consumer);                    \n    }\n  }\n}\n\n// 消费者\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 如果缓冲区是空的，就会进行阻塞 */\n      if(count == 0){                         \n      sleep();\n    }\n    /* 从缓冲区中取出一个数据 */\n       item = remove_item();           \n    /* 将缓冲区的 count 数量减一 */\n    count = count - 1\n    /* 缓冲区满嘛？ */\n    if(count == N - 1){                    \n      wakeup(producer);        \n    }\n    /* 打印数据项 */\n    consumer_item(item);                \n  }\n\n}</code></pre><p>为了在 C 语言中描述像是 <code>sleep</code> 和 <code>wakeup</code> 的系统调用，我们将以库函数调用的形式来表示。它们不是 C 标准库的一部分，但可以在实际具有这些系统调用的任何系统上使用。代码中未实现的 <code>insert_item</code> 和 <code>remove_item</code> 用来记录将数据项放入缓冲区和从缓冲区取出数据等。</p>\n<p>现在让我们回到生产者 - 消费者问题上来，上面代码中会产生竞争条件，因为 count 这个变量是暴露在大众视野下的。有可能出现下面这种情况：缓冲区为空，此时消费者刚好读取 count 的值发现它为 0 。此时调度程序决定暂停消费者并启动运行生产者。生产者生产了一条数据并把它放在缓冲区中，然后增加 count 的值，并注意到它的值是 1 。由于 count 为 0，消费者必须处于睡眠状态，因此生产者调用 <code>wakeup</code> 来唤醒消费者。但是，消费者此时在逻辑上并没有睡眠，所以 wakeup 信号会丢失。当消费者下次启动后，它会查看之前读取的 count 值，发现它的值是 0 ，然后在此进行睡眠。不久之后生产者会填满整个缓冲区，在这之后会阻塞，这样一来两个进程将永远睡眠下去。</p>\n<p>引起上面问题的本质是 <strong>唤醒尚未进行睡眠状态的进程会导致唤醒丢失</strong>。如果它没有丢失，则一切都很正常。一种快速解决上面问题的方式是增加一个<code>唤醒等待位(wakeup waiting bit)</code>。当一个 wakeup 信号发送给仍在清醒的进程后，该位置为 1 。之后，当进程尝试睡眠的时候，如果唤醒等待位为 1 ，则该位清除，而进程仍然保持清醒。</p>\n<p>然而，当进程数量有许多的时候，这时你可以说通过增加唤醒等待位的数量来唤醒等待位，于是就有了 2、4、6、8 个唤醒等待位，但是并没有从根本上解决问题。</p>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>信号量是 E.W.Dijkstra 在 1965 年提出的一种方法，它使用一个整形变量来累计唤醒次数，以供之后使用。在他的观点中，有一个新的变量类型称作 <code>信号量(semaphore)</code>。一个信号量的取值可以是 0 ，或任意正数。0 表示的是不需要任何唤醒，任意的正数表示的就是唤醒次数。</p>\n<p>Dijkstra 提出了信号量有两个操作，现在通常使用 <code>down</code> 和 <code>up</code>（分别可以用 sleep 和 wakeup 来表示）。down 这个指令的操作会检查值是否大于 0 。如果大于 0 ，则将其值减 1 ；若该值为 0 ，则进程将睡眠，而且此时 down 操作将会继续执行。检查数值、修改变量值以及可能发生的睡眠操作均为一个单一的、不可分割的 <code>原子操作(atomic action)</code> 完成。这会保证一旦信号量操作开始，没有其他的进程能够访问信号量，直到操作完成或者阻塞。这种原子性对于解决同步问题和避免竞争绝对必不可少。</p>\n<blockquote>\n<p>原子性操作指的是在计算机科学的许多其他领域中，一组相关操作全部执行而没有中断或根本不执行。</p>\n</blockquote>\n<p>up 操作会使信号量的值 + 1。如果一个或者多个进程在信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中一个并允许该程完成 down 操作。因此，对一个进程在其上睡眠的信号量执行一次 up 操作之后，该信号量的值仍然是 0 ，但在其上睡眠的进程却少了一个。信号量的值增 1 和唤醒一个进程同样也是不可分割的。不会有某个进程因执行 up 而阻塞，正如在前面的模型中不会有进程因执行 wakeup 而阻塞是一样的道理。</p>\n<h4 id=\"用信号量解决生产者-消费者问题\"><a href=\"#用信号量解决生产者-消费者问题\" class=\"headerlink\" title=\"用信号量解决生产者 - 消费者问题\"></a>用信号量解决生产者 - 消费者问题</h4><p>用信号量解决丢失的 wakeup 问题，代码如下</p>\n<pre><code>/* 定义缓冲区槽的数量 */\n#define N 100\n/* 信号量是一种特殊的 int */\ntypedef int semaphore;\n/* 控制关键区域的访问 */\nsemaphore mutex = 1;\n/* 统计 buffer 空槽的数量 */\nsemaphore empty = N;\n/* 统计 buffer 满槽的数量 */\nsemaphore full = 0;                                                \n\nvoid producer(void){ \n\n  int item;  \n\n  /* TRUE 的常量是 1 */\n  while(TRUE){            \n    /* 产生放在缓冲区的一些数据 */\n    item = producer_item();        \n    /* 将空槽数量减 1  */\n    down(&amp;empty);    \n    /* 进入关键区域  */\n    down(&amp;mutex);    \n    /* 把数据放入缓冲区中 */\n    insert_item(item);\n    /* 离开临界区 */\n    up(&amp;mutex);    \n    /* 将 buffer 满槽数量 + 1 */\n    up(&amp;full);                                                        \n  }\n}\n\nvoid consumer(void){\n\n  int item;\n\n  /* 无限循环 */\n  while(TRUE){\n    /* 缓存区满槽数量 - 1 */\n    down(&amp;full);\n    /* 进入缓冲区 */    \n    down(&amp;mutex);\n    /* 从缓冲区取出数据 */\n    item = remove_item();    \n    /* 离开临界区 */\n    up(&amp;mutex);    \n    /* 将空槽数目 + 1 */\n    up(&amp;empty);    \n    /* 处理数据 */\n    consume_item(item);                                            \n  }\n\n}</code></pre><p>为了确保信号量能正确工作，最重要的是要采用一种不可分割的方式来实现它。通常是将 up 和 down 作为系统调用来实现。而且操作系统只需在执行以下操作时暂时屏蔽全部中断：<strong>检查信号量、更新、必要时使进程睡眠</strong>。由于这些操作仅需要非常少的指令，因此中断不会造成影响。如果使用多个 CPU，那么信号量应该被锁进行保护。使用 TSL 或者 XCHG 指令用来确保同一时刻只有一个 CPU 对信号量进行操作。</p>\n<p>使用 TSL 或者 XCHG 来防止几个 CPU 同时访问一个信号量，与生产者或消费者使用忙等待来等待其他腾出或填充缓冲区是完全不一样的。前者的操作仅需要几个毫秒，而生产者或消费者可能需要任意长的时间。</p>\n<p>上面这个解决方案使用了三种信号量：一个称为 full，用来记录充满的缓冲槽数目；一个称为 empty，记录空的缓冲槽数目；一个称为 mutex，用来确保生产者和消费者不会同时进入缓冲区。<code>Full</code> 被初始化为 0 ，empty 初始化为缓冲区中插槽数，mutex 初始化为 1。信号量初始化为 1 并且由两个或多个进程使用，以确保它们中同时只有一个可以进入关键区域的信号被称为 <code>二进制信号量(binary semaphores)</code>。如果每个进程都在进入关键区域之前执行 down 操作，而在离开关键区域之后执行 up 操作，则可以确保相互互斥。</p>\n<p>现在我们有了一个好的进程间原语的保证。然后我们再来看一下中断的顺序保证</p>\n<ol>\n<li><p>硬件压入堆栈程序计数器等</p>\n</li>\n<li><p>硬件从中断向量装入新的程序计数器</p>\n</li>\n<li><p>汇编语言过程保存寄存器的值</p>\n</li>\n<li><p>汇编语言过程设置新的堆栈</p>\n</li>\n<li><p>C 中断服务器运行（典型的读和缓存写入）</p>\n</li>\n<li><p>调度器决定下面哪个程序先运行</p>\n</li>\n<li><p>C 过程返回至汇编代码</p>\n</li>\n<li><p>汇编语言过程开始运行新的当前进程</p>\n</li>\n</ol>\n<p>在使用<code>信号量</code>的系统中，隐藏中断的自然方法是让每个 I/O 设备都配备一个信号量，该信号量最初设置为 0。在 I/O 设备启动后，中断处理程序立刻对相关联的信号执行一个 <code>down</code> 操作，于是进程立即被阻塞。当中断进入时，中断处理程序随后对相关的信号量执行一个 <code>up</code>操作，能够使已经阻止的进程恢复运行。在上面的中断处理步骤中，其中的第 5 步 <code>C 中断服务器运行</code> 就是中断处理程序在信号量上执行的一个 up 操作，所以在第 6 步中，操作系统能够执行设备驱动程序。当然，如果有几个进程已经处于就绪状态，调度程序可能会选择接下来运行一个更重要的进程，我们会在后面讨论调度的算法。</p>\n<p>上面的代码实际上是通过两种不同的方式来使用信号量的，而这两种信号量之间的区别也是很重要的。<code>mutex</code> 信号量用于互斥。它用于确保任意时刻只有一个进程能够对缓冲区和相关变量进行读写。互斥是用于避免进程混乱所必须的一种操作。</p>\n<p>另外一个信号量是关于<code>同步(synchronization)</code>的。<code>full</code> 和 <code>empty</code> 信号量用于确保事件的发生或者不发生。在这个事例中，它们确保了缓冲区满时生产者停止运行；缓冲区为空时消费者停止运行。这两个信号量的使用与 mutex 不同。</p>\n<h3 id=\"互斥量\"><a href=\"#互斥量\" class=\"headerlink\" title=\"互斥量\"></a>互斥量</h3><p>如果不需要信号量的计数能力时，可以使用信号量的一个简单版本，称为 <code>mutex(互斥量)</code>。互斥量的优势就在于在一些共享资源和一段代码中保持互斥。由于互斥的实现既简单又有效，这使得互斥量在实现用户空间线程包时非常有用。</p>\n<p>互斥量是一个处于两种状态之一的共享变量：<code>解锁(unlocked)</code> 和 <code>加锁(locked)</code>。这样，只需要一个二进制位来表示它，不过一般情况下，通常会用一个 <code>整形(integer)</code> 来表示。0 表示解锁，其他所有的值表示加锁，比 1 大的值表示加锁的次数。</p>\n<p>mutex 使用两个过程，当一个线程（或者进程）需要访问关键区域时，会调用 <code>mutex_lock</code> 进行加锁。如果互斥锁当前处于解锁状态（表示关键区域可用），则调用成功，并且调用线程可以自由进入关键区域。</p>\n<p>另一方面，如果 mutex 互斥量已经锁定的话，调用线程会阻塞直到关键区域内的线程执行完毕并且调用了 <code>mutex_unlock</code> 。如果多个线程在 mutex 互斥量上阻塞，将随机选择一个线程并允许它获得锁。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkXJy2jibeQGLUNaWLCLWibibpIKfM2RLogQ38s0VHMdVqUmfVLcPNdwK3w/640?wx_fmt=png\" alt=\"\"></p>\n<p>由于 mutex 互斥量非常简单，所以只要有 TSL 或者是 XCHG 指令，就可以很容易地在用户空间实现它们。用于用户级线程包的 <code>mutex_lock</code> 和 <code>mutex_unlock</code> 代码如下，XCHG 的本质也一样。</p>\n<pre><code>mutex_lock:\n            | 将互斥信号量复制到寄存器，并将互斥信号量置为1\n            TSL REGISTER,MUTEX\n      | 互斥信号量是 0 吗？\n            CMP REGISTER,#0 \n      | 如果互斥信号量为0，它被解锁，所以返回\n            JZE ok  \n      | 互斥信号正在使用；调度其他线程\n            CALL thread_yield   \n      | 再试一次\n            JMP mutex_lock  \n      | 返回调用者，进入临界区\nok:     RET                                                     \n\nmutex_unlcok:\n            | 将 mutex 置为 0 \n            MOVE MUTEX,#0   \n      | 返回调用者\n            RET                                                     </code></pre><p>mutex_lock 的代码和上面 enter_region 的代码很相似，我们可以对比着看一下</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkzgYKTTgzB7hSZvozXicEez3sabKfYzxQcuehvgtiaF4NicljJg2PZJOLg/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面代码最大的区别你看出来了吗？</p>\n<ul>\n<li><p>根据上面我们对 TSL 的分析，我们知道，如果 TSL 判断没有进入临界区的进程会进行无限循环获取锁，而在 TSL 的处理中，如果 mutex 正在使用，那么就调度其他线程进行处理。所以上面最大的区别其实就是在判断 mutex/TSL 之后的处理。</p>\n</li>\n<li><p>在（用户）线程中，情况有所不同，因为没有时钟来停止运行时间过长的线程。结果是通过忙等待的方式来试图获得锁的线程将永远循环下去，决不会得到锁，因为这个运行的线程不会让其他线程运行从而释放锁，其他线程根本没有获得锁的机会。在后者获取锁失败时，它会调用 <code>thread_yield</code> 将 CPU 放弃给另外一个线程。结果就不会进行忙等待。在该线程下次运行时，它再一次对锁进行测试。</p>\n</li>\n</ul>\n<p>上面就是 enter_region 和 mutex_lock 的差别所在。由于 thread_yield 仅仅是一个用户空间的线程调度，所以它的运行非常快捷。这样，<code>mutex_lock</code> 和 <code>mutex_unlock</code> 都不需要任何内核调用。通过使用这些过程，用户线程完全可以实现在用户空间中的同步，这个过程仅仅需要少量的同步。</p>\n<p>我们上面描述的互斥量其实是一套调用框架中的指令。从软件角度来说，总是需要更多的特性和同步原语。例如，有时线程包提供一个调用 <code>mutex_trylock</code>，这个调用尝试获取锁或者返回错误码，但是不会进行加锁操作。这就给了调用线程一个灵活性，以决定下一步做什么，是使用替代方法还是等候下去。</p>\n<h4 id=\"Futexes\"><a href=\"#Futexes\" class=\"headerlink\" title=\"Futexes\"></a>Futexes</h4><p>随着并行的增加，有效的<code>同步(synchronization)</code>和<code>锁定(locking)</code> 对于性能来说是非常重要的。如果进程等待时间很短，那么<code>自旋锁(Spin lock)</code> 是非常有效；但是如果等待时间比较长，那么这会浪费 CPU 周期。如果进程很多，那么阻塞此进程，并仅当锁被释放的时候让内核解除阻塞是更有效的方式。不幸的是，这种方式也会导致另外的问题：它可以在进程竞争频繁的时候运行良好，但是在竞争不是很激烈的情况下内核切换的消耗会非常大，而且更困难的是，预测锁的竞争数量更不容易。</p>\n<p>有一种有趣的解决方案是把两者的优点结合起来，提出一种新的思想，称为 <code>futex</code>，或者是 <code>快速用户空间互斥(fast user space mutex)</code>，是不是听起来很有意思？</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkW2sY6sXshsFia7jXlNdhuB5XwTt6cjo1pqLgyvV1gcXnNfMASjiasAFA/640?wx_fmt=png\" alt=\"\"></p>\n<p>futex 是 <code>Linux</code> 中的特性实现了基本的锁定（很像是互斥锁）而且避免了陷入内核中，因为内核的切换的开销非常大，这样做可以大大提高性能。futex 由两部分组成：<strong>内核服务和用户库</strong>。内核服务提供了了一个 <code>等待队列(wait queue)</code> 允许多个进程在锁上排队等待。除非内核明确的对他们解除阻塞，否则它们不会运行。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXksBadzURKQx0t6EagaQBFBZsNcKeXSLCOl01WfJeyIrTU3DCoXz5DbA/640?wx_fmt=png\" alt=\"\"></p>\n<p>对于一个进程来说，把它放到等待队列需要昂贵的系统调用，这种方式应该被避免。在没有竞争的情况下，futex 可以直接在用户空间中工作。这些进程共享一个 32 位<code>整数(integer)</code> 作为公共锁变量。假设锁的初始化为 1，我们认为这时锁已经被释放了。线程通过执行原子性的操作<code>减少并测试(decrement and test)</code> 来抢占锁。decrement and set 是 Linux 中的原子功能，由包裹在 C 函数中的内联汇编组成，并在头文件中进行定义。下一步，线程会检查结果来查看锁是否已经被释放。如果锁现在不是锁定状态，那么刚好我们的线程可以成功抢占该锁。然而，如果锁被其他线程持有，抢占锁的线程不得不等待。在这种情况下，futex 库不会<code>自旋</code>，但是会使用一个系统调用来把线程放在内核中的等待队列中。这样一来，切换到内核的开销已经是合情合理的了，因为线程可以在任何时候阻塞。当线程完成了锁的工作时，它会使用原子性的 <code>增加并测试(increment and test)</code> 释放锁，并检查结果以查看内核等待队列上是否仍阻止任何进程。如果有的话，它会通知内核可以对等待队列中的一个或多个进程解除阻塞。如果没有锁竞争，内核则不需要参与竞争。</p>\n<h4 id=\"Pthreads-中的互斥量\"><a href=\"#Pthreads-中的互斥量\" class=\"headerlink\" title=\"Pthreads 中的互斥量\"></a>Pthreads 中的互斥量</h4><p>Pthreads 提供了一些功能用来同步线程。最基本的机制是使用互斥量变量，可以锁定和解锁，用来保护每个关键区域。希望进入关键区域的线程首先要尝试获取 mutex。如果 mutex 没有加锁，线程能够马上进入并且互斥量能够自动锁定，从而阻止其他线程进入。如果 mutex 已经加锁，调用线程会阻塞，直到 mutex 解锁。如果多个线程在相同的互斥量上等待，当互斥量解锁时，只有一个线程能够进入并且重新加锁。这些锁并不是必须的，程序员需要正确使用它们。</p>\n<p>下面是与互斥量有关的函数调用</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkkjhv2Kpw5NOIUR9iaZqLkRyb8oR34ThPSm8mZJbwfmVYcC2DwiaU6f1w/640?wx_fmt=png\" alt=\"\"></p>\n<p>像我们想象中的一样，mutex 能够被创建和销毁，扮演这两个角色的分别是 <code>Phread_mutex_init</code> 和 <code>Pthread_mutex_destroy</code>。mutex 也可以通过 <code>Pthread_mutex_lock</code> 来进行加锁，如果互斥量已经加锁，则会阻塞调用者。还有一个调用<code>Pthread_mutex_trylock</code> 用来尝试对线程加锁，当 mutex 已经被加锁时，会返回一个错误代码而不是阻塞调用者。这个调用允许线程有效的进行忙等。最后，<code>Pthread_mutex_unlock</code> 会对 mutex 解锁并且释放一个正在等待的线程。</p>\n<p>除了互斥量以外，<code>Pthreads</code> 还提供了第二种同步机制： <code>条件变量(condition variables)</code> 。mutex 可以很好的允许或阻止对关键区域的访问。条件变量允许线程由于未满足某些条件而阻塞。绝大多数情况下这两种方法是一起使用的。下面我们进一步来研究线程、互斥量、条件变量之间的关联。</p>\n<p>下面再来重新认识一下生产者和消费者问题：一个线程将东西放在一个缓冲区内，由另一个线程将它们取出。如果生产者发现缓冲区没有空槽可以使用了，生产者线程会阻塞起来直到有一个线程可以使用。生产者使用 mutex 来进行原子性检查从而不受其他线程干扰。但是当发现缓冲区已经满了以后，生产者需要一种方法来阻塞自己并在以后被唤醒。这便是条件变量做的工作。</p>\n<p>下面是一些与条件变量有关的最重要的 pthread 调用</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXk839icYzflFsfMELQx6wusdDtK5VibFSBT3icKPIKBXpkO0jNshBocXZmA/640?wx_fmt=png\" alt=\"\"></p>\n<p>上表中给出了一些调用用来创建和销毁条件变量。条件变量上的主要属性是 <code>Pthread_cond_wait</code> 和 <code>Pthread_cond_signal</code>。前者阻塞调用线程，直到其他线程发出信号为止（使用后者调用）。阻塞的线程通常需要等待唤醒的信号以此来释放资源或者执行某些其他活动。只有这样阻塞的线程才能继续工作。条件变量允许等待与阻塞原子性的进程。<code>Pthread_cond_broadcast</code> 用来唤醒多个阻塞的、需要等待信号唤醒的线程。</p>\n<blockquote>\n<p>需要注意的是，条件变量（不像是信号量）不会存在于内存中。如果将一个信号量传递给一个没有线程等待的条件变量，那么这个信号就会丢失，这个需要注意</p>\n</blockquote>\n<p>下面是一个使用互斥量和条件变量的例子</p>\n<pre><code>#include &lt;stdio.h&gt;\n#include &lt;pthread.h&gt;\n\n/* 需要生产的数量 */\n#define MAX 1000000000                                        \npthread_mutex_t the_mutex;\n/* 使用信号量 */\npthread_cond_t condc,condp;                                \nint buffer = 0;\n\n/* 生产数据 */\nvoid *producer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i &lt;= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&amp;the_mutex);                \n    while(buffer != 0){\n      pthread_cond_wait(&amp;condp,&amp;the_mutex);\n    }\n    /* 把他们放在缓冲区中 */\n    buffer = i;            \n    /* 唤醒消费者 */\n    pthread_cond_signal(&amp;condc);    \n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&amp;the_mutex);            \n  }\n  pthread_exit(0);\n\n}\n\n/* 消费数据 */\nvoid *consumer(void *ptr){                                \n\n  int i;\n\n  for(int i = 0;i &lt;= MAX;i++){\n    /* 缓冲区独占访问，也就是使用 mutex 获取锁 */\n    pthread_mutex_lock(&amp;the_mutex);                \n    while(buffer == 0){\n      pthread_cond_wait(&amp;condc,&amp;the_mutex);\n    }\n    /* 把他们从缓冲区中取出 */\n    buffer = 0;    \n    /* 唤醒生产者 */\n    pthread_cond_signal(&amp;condp);\n    /* 释放缓冲区 */\n    pthread_mutex_unlock(&amp;the_mutex);            \n  }\n  pthread_exit(0);\n\n}                              </code></pre><h3 id=\"管程\"><a href=\"#管程\" class=\"headerlink\" title=\"管程\"></a>管程</h3><p>为了能够编写更加准确无误的程序，Brinch Hansen 和 Hoare 提出了一个更高级的同步原语叫做 <code>管程(monitor)</code>。他们两个人的提案略有不同，通过下面的描述你就可以知道。管程是程序、变量和数据结构等组成的一个集合，它们组成一个特殊的模块或者包。进程可以在任何需要的时候调用管程中的程序，但是它们不能从管程外部访问数据结构和程序。下面展示了一种抽象的，类似 Pascal 语言展示的简洁的管程。不能用 C 语言进行描述，因为管程是语言概念而 C 语言并不支持管程。</p>\n<pre><code>monitor example\n    integer i;\n    condition c;\n\n    procedure producer();\n  ...\n    end;    \n\n    procedure consumer();\n    .\n    end;\nend monitor;</code></pre><p>管程有一个很重要的特性，即在任何时候管程中只能有一个活跃的进程，这一特性使管程能够很方便的实现互斥操作。管程是编程语言的特性，所以编译器知道它们的特殊性，因此可以采用与其他过程调用不同的方法来处理对管程的调用。通常情况下，当进程调用管程中的程序时，该程序的前几条指令会检查管程中是否有其他活跃的进程。如果有的话，调用进程将被挂起，直到另一个进程离开管程才将其唤醒。如果没有活跃进程在使用管程，那么该调用进程才可以进入。</p>\n<p>进入管程中的互斥由编译器负责，但是一种通用做法是使用 <code>互斥量(mutex)</code> 和 <code>二进制信号量(binary semaphore)</code>。由于编译器而不是程序员在操作，因此出错的几率会大大降低。在任何时候，编写管程的程序员都无需关心编译器是如何处理的。他只需要知道将所有的临界区转换成为管程过程即可。绝不会有两个进程同时执行临界区中的代码。</p>\n<p>即使管程提供了一种简单的方式来实现互斥，但在我们看来，这还不够。因为我们还需要一种在进程无法执行被阻塞。在生产者 - 消费者问题中，很容易将针对缓冲区满和缓冲区空的测试放在管程程序中，但是生产者在发现缓冲区满的时候该如何阻塞呢？</p>\n<p>解决的办法是引入<code>条件变量(condition variables)</code> 以及相关的两个操作 <code>wait</code> 和 <code>signal</code>。当一个管程程序发现它不能运行时（例如，生产者发现缓冲区已满），它会在某个条件变量（如 full）上执行 <code>wait</code> 操作。这个操作造成调用进程阻塞，并且还将另一个以前等在管程之外的进程调入管程。在前面的 pthread 中我们已经探讨过条件变量的实现细节了。另一个进程，比如消费者可以通过执行 <code>signal</code> 来唤醒阻塞的调用进程。</p>\n<blockquote>\n<p>Brinch Hansen 和 Hoare 在对进程唤醒上有所不同，Hoare 建议让新唤醒的进程继续运行；而挂起另外的进程。而 Brinch Hansen 建议让执行 signal 的进程必须退出管程，这里我们采用 Brinch Hansen 的建议，因为它在概念上更简单，并且更容易实现。</p>\n</blockquote>\n<p>如果在一个条件变量上有若干进程都在等待，则在对该条件执行 signal 操作后，系统调度程序只能选择其中一个进程恢复运行。</p>\n<p>顺便提一下，这里还有上面两位教授没有提出的第三种方式，它的理论是让执行 signal 的进程继续运行，等待这个进程退出管程时，其他进程才能进入管程。</p>\n<p>条件变量不是计数器。条件变量也不能像信号量那样积累信号以便以后使用。所以，如果向一个条件变量发送信号，但是该条件变量上没有等待进程，那么信号将会丢失。也就是说，<strong>wait 操作必须在 signal 之前执行</strong>。</p>\n<p>下面是一个使用 <code>Pascal</code> 语言通过管程实现的生产者 - 消费者问题的解法</p>\n<pre><code>monitor ProducerConsumer\n        condition full,empty;\n        integer count;\n\n        procedure insert(item:integer);\n        begin\n                if count = N then wait(full);\n                insert_item(item);\n                count := count + 1;\n                if count = 1 then signal(empty);\n        end;\n\n        function remove:integer;\n        begin\n                if count = 0 then wait(empty);\n                remove = remove_item;\n                count := count - 1;\n                if count = N - 1 then signal(full);\n        end;\n\n        count := 0;\nend monitor;\n\nprocedure producer;\nbegin\n            while true do\n      begin \n                  item = produce_item;\n                  ProducerConsumer.insert(item);\n      end\nend;\n\nprocedure consumer;\nbegin \n            while true do\n            begin\n                        item = ProducerConsumer.remove;\n                        consume_item(item);\n            end\nend;</code></pre><p>读者可能觉得 wait 和 signal 操作看起来像是前面提到的 sleep 和 wakeup ，而且后者存在严重的竞争条件。它们确实很像，但是有个关键的区别：sleep 和 wakeup 之所以会失败是因为当一个进程想睡眠时，另一个进程试图去唤醒它。使用管程则不会发生这种情况。管程程序的自动互斥保证了这一点，如果管程过程中的生产者发现缓冲区已满，它将能够完成 wait 操作而不用担心调度程序可能会在 wait 完成之前切换到消费者。甚至，在 wait 执行完成并且把生产者标志为不可运行之前，是不会允许消费者进入管程的。</p>\n<p>尽管类 Pascal 是一种想象的语言，但还是有一些真正的编程语言支持，比如 Java （终于轮到大 Java 出场了），Java 是能够支持管程的，它是一种 <code>面向对象</code>的语言，支持用户级线程，还允许将方法划分为类。只要将关键字 <code>synchronized</code> 关键字加到方法中即可。Java 能够保证一旦某个线程执行该方法，就不允许其他线程执行该对象中的任何 synchronized 方法。没有关键字 synchronized ，就不能保证没有交叉执行。</p>\n<p>下面是 Java 使用管程解决的生产者 - 消费者问题</p>\n<pre><code>public class ProducerConsumer {\n  // 定义缓冲区大小的长度\n  static final int N = 100;\n  // 初始化一个新的生产者线程\n  static Producer p = new Producer();\n  // 初始化一个新的消费者线程\n  static Consumer c = new Consumer();        \n  // 初始化一个管程\n  static Our_monitor mon = new Our_monitor(); \n\n  // run 包含了线程代码\n  static class Producer extends Thread{\n    public void run(){                                                \n      int item;\n      // 生产者循环\n      while(true){                                                        \n        item = produce_item();\n        mon.insert(item);\n      }\n    }\n    // 生产代码\n    private int produce_item(){...}                        \n  }\n\n  // run 包含了线程代码\n  static class consumer extends Thread {\n    public void run( ) {                                            \n           int item;\n      while(true){\n        item = mon.remove();\n                consume_item(item);\n      }\n    }\n    // 消费代码\n    private int produce_item(){...}                        \n  }\n\n  // 这是管程\n  static class Our_monitor {                                    \n    private int buffer[] = new int[N];\n    // 计数器和索引\n    private int count = 0,lo = 0,hi = 0;            \n\n    private synchronized void insert(int val){\n      if(count == N){\n        // 如果缓冲区是满的，则进入休眠\n        go_to_sleep();                                                \n      }\n      // 向缓冲区插入内容\n            buffer[hi] = val;                   \n      // 找到下一个槽的为止\n      hi = (hi + 1) % N;                 \n      // 缓冲区中的数目自增 1 \n      count = count + 1;                                            \n      if(count == 1){\n        // 如果消费者睡眠，则唤醒\n        notify();                                                            \n      }\n    }\n\n    private synchronized void remove(int val){\n      int val;\n      if(count == 0){\n        // 缓冲区是空的，进入休眠\n        go_to_sleep();                                                \n      }\n      // 从缓冲区取出数据\n      val = buffer[lo];                \n      // 设置待取出数据项的槽\n      lo = (lo + 1) % N;                    \n      // 缓冲区中的数据项数目减 1 \n      count = count - 1;                                            \n      if(count = N - 1){\n        // 如果生产者睡眠，唤醒它\n        notify();                                                            \n      }\n      return val;\n    }\n\n    private void go_to_sleep() {\n      try{\n        wait( );\n      }catch(Interr uptedExceptionexc) {};\n    }\n  }\n\n}</code></pre><p>上面的代码中主要设计四个类，<code>外部类(outer class)</code> ProducerConsumer 创建并启动两个线程，p 和 c。第二个类和第三个类 <code>Producer</code> 和 <code>Consumer</code> 分别包含生产者和消费者代码。最后，<code>Our_monitor</code> 是管程，它有两个同步线程，用于在共享缓冲区中插入和取出数据。</p>\n<p>在前面的所有例子中，生产者和消费者线程在功能上与它们是相同的。生产者有一个无限循环，该无限循环产生数据并将数据放入公共缓冲区中；消费者也有一个等价的无限循环，该无限循环用于从缓冲区取出数据并完成一系列工作。</p>\n<p>程序中比较耐人寻味的就是 <code>Our_monitor</code> 了，它包含缓冲区、管理变量以及两个同步方法。当生产者在 insert 内活动时，它保证消费者不能在 remove 方法中运行，从而保证更新变量以及缓冲区的安全性，并且不用担心竞争条件。变量 count 记录在缓冲区中数据的数量。变量 <code>lo</code> 是缓冲区槽的序号，指出将要取出的下一个数据项。类似地，<code>hi</code> 是缓冲区中下一个要放入的数据项序号。允许 lo = hi，含义是在缓冲区中有 0 个或 N 个数据。</p>\n<p>Java 中的同步方法与其他经典管程有本质差别：Java 没有内嵌的条件变量。然而，Java 提供了 wait 和 notify 分别与 sleep 和 wakeup 等价。</p>\n<p><strong>通过临界区自动的互斥，管程比信号量更容易保证并行编程的正确性</strong>。但是管程也有缺点，我们前面说到过管程是一个编程语言的概念，编译器必须要识别管程并用某种方式对其互斥作出保证。<strong>C、Pascal 以及大多数其他编程语言都没有管程</strong>，所以不能依靠编译器来遵守互斥规则。</p>\n<p>与管程和信号量有关的另一个问题是，这些机制都是设计用来解决访问共享内存的一个或多个 CPU 上的互斥问题的。通过将信号量放在共享内存中并用 <code>TSL</code> 或 <code>XCHG</code> 指令来保护它们，可以避免竞争。但是如果是在分布式系统中，可能同时具有多个 CPU 的情况，并且每个 CPU 都有自己的私有内存呢，它们通过网络相连，那么这些原语将会失效。因为信号量太低级了，而管程在少数几种编程语言之外无法使用，所以还需要其他方法。</p>\n<h3 id=\"消息传递\"><a href=\"#消息传递\" class=\"headerlink\" title=\"消息传递\"></a>消息传递</h3><p>上面提到的其他方法就是 <code>消息传递(messaage passing)</code>。这种进程间通信的方法使用两个原语 <code>send</code> 和 <code>receive</code> ，它们像信号量而不像管程，是系统调用而不是语言级别。示例如下</p>\n<pre><code>send(destination, &amp;message);\n\nreceive(source, &amp;message);</code></pre><p>send 方法用于向一个给定的目标发送一条消息，receive 从一个给定的源接受一条消息。如果没有消息，接受者可能被阻塞，直到接受一条消息或者带着错误码返回。</p>\n<h4 id=\"消息传递系统的设计要点\"><a href=\"#消息传递系统的设计要点\" class=\"headerlink\" title=\"消息传递系统的设计要点\"></a>消息传递系统的设计要点</h4><p>消息传递系统现在面临着许多信号量和管程所未涉及的问题和设计难点，尤其对那些在网络中不同机器上的通信状况。例如，消息有可能被网络丢失。为了防止消息丢失，发送方和接收方可以达成一致：一旦接受到消息后，接收方马上回送一条特殊的 <code>确认(acknowledgement)</code> 消息。如果发送方在一段时间间隔内未收到确认，则重发消息。</p>\n<p>现在考虑消息本身被正确接收，而返回给发送着的确认消息丢失的情况。发送者将重发消息，这样接受者将收到两次相同的消息。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaWMs2vSqjpXtVDia8zUVjIPup5ZQHWgGQT55NgvLs2OgkaCuw2TSdEA/640?wx_fmt=png\" alt=\"\"></p>\n<p>对于接收者来说，如何区分新的消息和一条重发的老消息是非常重要的。通常采用在每条原始消息中嵌入一个连续的序号来解决此问题。如果接受者收到一条消息，它具有与前面某一条消息一样的序号，就知道这条消息是重复的，可以忽略。</p>\n<p>消息系统还必须处理如何命名进程的问题，以便在发送或接收调用中清晰的指明进程。<code>身份验证(authentication)</code> 也是一个问题，比如客户端怎么知道它是在与一个真正的文件服务器通信，从发送方到接收方的信息有可能被中间人所篡改。</p>\n<h4 id=\"用消息传递解决生产者-消费者问题\"><a href=\"#用消息传递解决生产者-消费者问题\" class=\"headerlink\" title=\"用消息传递解决生产者 - 消费者问题\"></a>用消息传递解决生产者 - 消费者问题</h4><p>现在我们考虑如何使用消息传递来解决生产者 - 消费者问题，而不是共享缓存。下面是一种解决方式</p>\n<pre><code>/* buffer 中槽的数量 */\n#define N 100                                                    \n\nvoid producer(void){\n\n  int item;\n  /* buffer 中槽的数量 */\n  message m;                                                    \n\n  while(TRUE){\n    /* 生成放入缓冲区的数据 */\n    item = produce_item();                        \n    /* 等待消费者发送空缓冲区 */\n    receive(consumer,&amp;m);                            \n    /* 建立一个待发送的消息 */\n    build_message(&amp;m,item);                        \n    /* 发送给消费者 */\n    send(consumer,&amp;m);                                \n  }\n\n}\n\nvoid consumer(void){\n\n  int item,i;\n  message m;\n\n  /* 循环N次 */\n  for(int i = 0;i &lt; N;i++){                        \n    /* 发送N个缓冲区 */\n    send(producer,&amp;m);                                \n  }\n  while(TRUE){\n    /* 接受包含数据的消息 */\n    receive(producer,&amp;m);                            \n    /* 将数据从消息中提取出来 */\n      item = extract_item(&amp;m);                    \n    /* 将空缓冲区发送回生产者 */\n    send(producer,&amp;m);                                \n    /* 处理数据 */\n    consume_item(item);                                \n  }\n\n}</code></pre><p>假设所有的消息都有相同的大小，并且在尚未接受到发出的消息时，由操作系统自动进行缓冲。在该解决方案中共使用 N 条消息，这就类似于一块共享内存缓冲区的 N 个槽。消费者首先将 N 条空消息发送给生产者。当生产者向消费者传递一个数据项时，它取走一条空消息并返回一条填充了内容的消息。通过这种方式，系统中总的消息数量保持不变，所以消息都可以存放在事先确定数量的内存中。</p>\n<p>如果生产者的速度要比消费者快，则所有的消息最终都将被填满，等待消费者，生产者将被阻塞，等待返回一条空消息。如果消费者速度快，那么情况将正相反：所有的消息均为空，等待生产者来填充，消费者将被阻塞，以等待一条填充过的消息。</p>\n<p>消息传递的方式有许多变体，下面先介绍如何对消息进行 <code>编址</code>。</p>\n<ul>\n<li><p>一种方法是为每个进程分配一个唯一的地址，让消息按进程的地址编址。</p>\n</li>\n<li><p>另一种方式是引入一个新的数据结构，称为 <code>信箱(mailbox)</code>，信箱是一个用来对一定的数据进行缓冲的数据结构，信箱中消息的设置方法也有多种，典型的方法是在信箱创建时确定消息的数量。在使用信箱时，在 send 和 receive 调用的地址参数就是信箱的地址，而不是进程的地址。当一个进程试图向一个满的信箱发送消息时，它将被挂起，直到信箱中有消息被取走，从而为新的消息腾出地址空间。</p>\n</li>\n</ul>\n<h3 id=\"屏障\"><a href=\"#屏障\" class=\"headerlink\" title=\"屏障\"></a>屏障</h3><p>最后一个同步机制是准备用于进程组而不是进程间的生产者 - 消费者情况的。在某些应用中划分了若干阶段，并且规定，除非所有的进程都就绪准备着手下一个阶段，否则任何进程都不能进入下一个阶段，可以通过在每个阶段的结尾安装一个 <code>屏障(barrier)</code> 来实现这种行为。当一个进程到达屏障时，它会被屏障所拦截，直到所有的屏障都到达为止。屏障可用于一组进程同步，如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXktobEIdqeRzlib8Q2NE2hBvwcInsibDwCw80fyuPwWZ9GBugIdpLYMbeA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上图中我们可以看到，有四个进程接近屏障，这意味着每个进程都在进行运算，但是还没有到达每个阶段的结尾。过了一段时间后，A、B、D 三个进程都到达了屏障，各自的进程被挂起，但此时还不能进入下一个阶段呢，因为进程 B 还没有执行完毕。结果，当最后一个 C 到达屏障后，这个进程组才能够进入下一个阶段。</p>\n<h3 id=\"避免锁：读-复制-更新\"><a href=\"#避免锁：读-复制-更新\" class=\"headerlink\" title=\"避免锁：读 - 复制 - 更新\"></a>避免锁：读 - 复制 - 更新</h3><p>最快的锁是根本没有锁。问题在于没有锁的情况下，我们是否允许对共享数据结构的并发读写进行访问。答案当然是不可以。假设进程 A 正在对一个数字数组进行排序，而进程 B 正在计算其平均值，而此时你进行 A 的移动，会导致 B 会多次读到重复值，而某些值根本没有遇到过。</p>\n<p>然而，在某些情况下，我们可以允许写操作来更新数据结构，即便还有其他的进程正在使用。窍门在于确保每个读操作要么读取旧的版本，要么读取新的版本，例如下面的树</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXknibrKqGWqGZ6HbicKos4iaxdvNsfKaP6DtfTCnjYrjOeIibXzsd0mLcYlw/640?wx_fmt=png\" alt=\"\"></p>\n<p>上面的树中，读操作从根部到叶子遍历整个树。加入一个新节点 X 后，为了实现这一操作，我们要让这个节点在树中可见之前使它 “恰好正确”：我们对节点 X 中的所有值进行初始化，包括它的子节点指针。然后通过原子写操作，使 X 称为 A 的子节点。所有的读操作都不会读到前后不一致的版本</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkPU9vEZ58PLRxKcEUQIcCw118ayGmvjv9FyXrkr6XuSDxZe161dsBGA/640?wx_fmt=png\" alt=\"\"></p>\n<p>在上面的图中，我们接着移除 B 和 D。首先，将 A 的左子节点指针指向 C 。所有原本在 A 中的读操作将会后续读到节点 C ，而永远不会读到 B 和 D。也就是说，它们将只会读取到新版数据。同样，所有当前在 B 和 D 中的读操作将继续按照原始的数据结构指针并且读取旧版数据。所有操作均能正确运行，我们不需要锁住任何东西。而不需要锁住数据就能够移除 B 和 D 的主要原因就是 <code>读-复制-更新(Ready-Copy-Update,RCU)</code>，将更新过程中的移除和再分配过程分离开。</p>\n<h2 id=\"调度\"><a href=\"#调度\" class=\"headerlink\" title=\"调度\"></a>调度</h2><p>当一个计算机是多道程序设计系统时，会频繁的有很多进程或者线程来同时竞争 CPU 时间片。当两个或两个以上的进程 / 线程处于就绪状态时，就会发生这种情况。如果只有一个 CPU 可用，那么必须选择接下来哪个进程 / 线程可以运行。操作系统中有一个叫做 <code>调度程序(scheduler)</code> 的角色存在，它就是做这件事儿的，该程序使用的算法叫做 <code>调度算法(scheduling algorithm)</code> 。</p>\n<p>尽管有一些不同，但许多适用于进程调度的处理方法同样也适用于线程调度。当内核管理线程的时候，调度通常会以线程级别发生，很少或者根本不会考虑线程属于哪个进程。下面我们会首先专注于进程和线程的调度问题，然后会明确的介绍线程调度以及它产生的问题。</p>\n<h3 id=\"调度介绍\"><a href=\"#调度介绍\" class=\"headerlink\" title=\"调度介绍\"></a>调度介绍</h3><p>让我们回到早期以磁带上的卡片作为输入的批处理系统的时代，那时候的调度算法非常简单：依次运行磁带上的每一个作业。对于多道程序设计系统，会复杂一些，因为通常会有多个用户在等待服务。一些大型机仍然将 <code>批处理</code>和 <code>分时服务</code>结合使用，需要调度程序决定下一个运行的是一个批处理作业还是终端上的用户。由于在这些机器中 CPU 是稀缺资源，所以好的调度程序可以在提高性能和用户的满意度方面取得很大的成果。</p>\n<h4 id=\"进程行为\"><a href=\"#进程行为\" class=\"headerlink\" title=\"进程行为\"></a>进程行为</h4><p>几乎所有的进程（磁盘或网络）I/O 请求和计算都是交替运行的</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkhOIjeY0ia73Pm3dJCSLuhRl058IKIxx7RyI1LN1PYfthYvLHmJyicm1A/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图所示，CPU 不停顿的运行一段时间，然后发出一个系统调用等待 I/O 读写文件。完成系统调用后，CPU 又开始计算，直到它需要读更多的数据或者写入更多的数据为止。当一个进程等待外部设备完成工作而被阻塞时，才是 I/O 活动。  </p>\n<p>上面 a 是 CPU 密集型进程；b 是 I/O 密集型进程进程，a 因为在计算的时间上花费时间更长，因此称为<code>计算密集型(compute-bound)</code> 或者 <code>CPU 密集型(CPU-bound)</code>，b 因为 I/O 发生频率比较快因此称为 <code>I/O 密集型(I/O-bound)</code>。计算密集型进程有较长的 CPU 集中使用和较小频度的 I/O 等待。I/O 密集型进程有较短的 CPU 使用时间和较频繁的 I/O 等待。注意到上面两种进程的区分关键在于 CPU 的时间占用而不是 I/O 的时间占用。I/O 密集型的原因是因为它们没有在 I/O 之间花费更多的计算、而不是 I/O 请求时间特别长。无论数据到达后需要花费多少时间，它们都需要花费相同的时间来发出读取磁盘块的硬件请求。</p>\n<p>值得注意的是，随着 CPU 的速度越来越快，更多的进程倾向于 I/O 密集型。这种情况出现的原因是 CPU 速度的提升要远远高于硬盘。这种情况导致的结果是，未来对 I/O 密集型进程的调度处理似乎更为重要。这里的基本思想是，如果需要运行 I/O 密集型进程，那么就应该让它尽快得到机会，以便发出磁盘请求并保持磁盘始终忙碌。</p>\n<h4 id=\"何时调度\"><a href=\"#何时调度\" class=\"headerlink\" title=\"何时调度\"></a>何时调度</h4><p>第一个和调度有关的问题是<code>何时进行调度决策</code>。存在着需要调度处理的各种情形。首先，在创建一个新进程后，需要决定是运行父进程还是子进程。因为二者的进程都处于就绪态下，这是正常的调度决策，可以任意选择，也就是说，调度程序可以任意的选择子进程或父进程开始运行。</p>\n<p>第二，在进程退出时需要作出调度决定。因为此进程不再运行（因为它将不再存在），因此必须从就绪进程中选择其他进程运行。如果没有进程处于就绪态，系统提供的<code>空闲进程</code>通常会运行</p>\n<p><strong>什么是空闲进程</strong></p>\n<p><code>空闲进程(system-supplied idle process)</code> 是 Microsoft 公司 windows 操作系统带有的系统进程，该进程是在各个处理器上运行的单个线程，它唯一的任务是在系统没有处理其他线程时占用处理器时间。System Idle Process 并不是一个真正的进程，它是<code>核心虚拟</code>出来的，多任务操作系统都存在。在没有可用的进程时，系统处于空运行状态，此时就是 System Idle Process 在正在运行。你可以简单的理解成，它代表的是 CPU 的空闲状态，数值越大代表处理器越空闲，可以通过 Windows 任务管理器查看 Windows 中的 CPU 利用率</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkmC8dicWibXiabibrgW3hOqJ4xzMFwjPvSuicicpIKiaU711OUIUwOZO6T7pVw/640?wx_fmt=png\" alt=\"\"></p>\n<p>第三种情况是，当进程阻塞在 I/O 、信号量或其他原因时，必须选择另外一个进程来运行。有时，阻塞的原因会成为选择进程运行的关键因素。例如，如果 A 是一个重要进程，并且它正在等待 B 退出关键区域，让 B 退出关键区域从而使 A 得以运行。但是调度程序一般不会对这种情况进行考量。</p>\n<p>第四点，当 I/O 中断发生时，可以做出调度决策。如果中断来自 I/O 设备，而 I/O 设备已经完成了其工作，那么那些等待 I/O 的进程现在可以继续运行。由调度程序来决定是否准备运行新的进程还是重新运行已经中断的进程。</p>\n<p>如果硬件时钟以 50 或 60 Hz 或其他频率提供周期性中断，可以在每个时钟中断或第 k 个时钟中断处做出调度决策。根据如何处理时钟中断可以把调度算法可以分为两类。<code>非抢占式(nonpreemptive)</code> 调度算法挑选一个进程，让该进程运行直到被阻塞（阻塞在 I/O 上或等待另一个进程），或者直到该进程自动释放 CPU。即使该进程运行了若干个小时后，它也不会被强制挂起。这样会在时钟中断发生时不会进行调度。在处理完时钟中断后，如果没有更高优先级的进程等待，则被中断的进程会继续执行。</p>\n<p>另外一种情况是 <code>抢占式</code> 调度算法，它会选择一个进程，并使其在最大固定时间内运行。如果在时间间隔结束后仍在运行，这个进程会被挂起，调度程序会选择其他进程来运行（前提是存在就绪进程）。进行抢占式调度需要在时间间隔结束时发生时钟中断，以将 CPU 的控制权交还给调度程序。如果没有可用的时钟，那么非抢占式就是唯一的选择。</p>\n<h4 id=\"调度算法的分类\"><a href=\"#调度算法的分类\" class=\"headerlink\" title=\"调度算法的分类\"></a>调度算法的分类</h4><p>毫无疑问，不同的环境下需要不同的调度算法。之所以出现这种情况，是因为不同的应用程序和不同的操作系统有不同的目标。也就是说，在不同的系统中，调度程序的优化也是不同的。这里有必要划分出三种环境</p>\n<ul>\n<li><p><code>批处理(Batch)</code></p>\n</li>\n<li><p><code>交互式(Interactive)</code></p>\n</li>\n<li><p><code>实时(Real time)</code></p>\n</li>\n</ul>\n<p>批处理系统广泛应用于商业领域，比如用来处理工资单、存货清单、账目收入、账目支出、利息计算、索赔处理和其他周期性作业。在批处理系统中，一般会选择使用非抢占式算法或者周期性比较长的抢占式算法。这种方法可以减少线程切换因此能够提升性能。</p>\n<p>在交互式用户环境中，为了避免一个进程霸占 CPU 拒绝为其他进程服务，所以需要抢占式算法。即使没有进程有意要一直运行下去，但是，由于某个进程出现错误也有可能无限期的排斥其他所有进程。为了避免这种情况，抢占式也是必须的。服务器也属于此类别，因为它们通常为多个（远程）用户提供服务，而这些用户都非常着急。计算机用户总是很忙。</p>\n<p>在实时系统中，抢占有时是不需要的，因为进程知道自己可能运行不了很长时间，通常很快的做完自己的工作并阻塞。实时系统与交互式系统的差别是，实时系统只运行那些用来推进现有应用的程序，而交互式系统是通用的，它可以运行任意的非协作甚至是有恶意的程序。</p>\n<h4 id=\"调度算法的目标\"><a href=\"#调度算法的目标\" class=\"headerlink\" title=\"调度算法的目标\"></a>调度算法的目标</h4><p>为了设计调度算法，有必要考虑一下什么是好的调度算法。有一些目标取决于环境（批处理、交互式或者实时）蛋大部分是适用于所有情况的，下面是一些需要考量的因素，我们会在下面一起讨论。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkxvibibMFgiaPvgs6ltWepp136jFYSAUMsXGOYRAiaT7l4wCDy4fuKZ95Bw/640?wx_fmt=png\" alt=\"\"></p>\n<p><strong>所有系统</strong></p>\n<p>在所有的情况中，<code>公平</code>是很重要的。对一个进程给予相较于其他等价的进程更多的 CPU 时间片对其他进程来说是不公平的。当然，不同类型的进程可以采用不同的处理方式。</p>\n<p>与公平有关的是系统的<code>强制执行</code>，什么意思呢？如果某公司的薪资发放系统计划在本月的 15 号，那么碰上了疫情大家生活都很拮据，此时老板说要在 14 号晚上发放薪资，那么调度程序必须强制使进程执行 14 号晚上发放薪资的策略。</p>\n<p>另一个共同的目标是保持系统的<code>所有部分尽可能的忙碌</code>。如果 CPU 和所有的 I/O 设备能够一直运行，那么相对于让某些部件空转而言，每秒钟就可以完成更多的工作。例如，在批处理系统中，调度程序控制哪个作业调入内存运行。在内存中既有一些 CPU 密集型进程又有一些 I/O 密集型进程是一个比较好的想法，好于先调入和运行所有的 CPU 密集型作业，然后在它们完成之后再调入和运行所有 I/O 密集型作业的做法。使用后者这种方式会在 CPU 密集型进程启动后，争夺 CPU ，而磁盘却在空转，而当 I/O 密集型进程启动后，它们又要为磁盘而竞争，CPU 却又在空转。。。。。。显然，通过结合 I/O 密集型和 CPU 密集型，能够使整个系统运行更流畅，效率更高。</p>\n<p><strong>批处理系统</strong></p>\n<p>通常有三个指标来衡量系统工作状态：<strong>吞吐量、周转时间和 CPU 利用率</strong>，<code>吞吐量(throughout)</code> 是系统每小时完成的作业数量。综合考虑，每小时完成 50 个工作要比每小时完成 40 个工作好。<code>周转时间(Turnaround time)</code> 是一种平均时间，它指的是从一个批处理提交开始直到作业完成时刻为止平均时间。该数据度量了用户要得到输出所需的平均等待时间。周转时间越小越好。</p>\n<p><code>CPU 利用率(CPU utilization)</code> 通常作为批处理系统上的指标。即使如此， CPU 利用率也不是一个好的度量指标，真正有价值的衡量指标是系统每小时可以完成多少作业（吞吐量），以及完成作业需要多长时间（周转时间）。把 CPU 利用率作为度量指标，就像是引擎每小时转动了多少次来比较汽车的性能一样。而且知道 CPU 的利用率什么时候接近 100% 要比什么什么时候要求得到更多的计算能力要有用。</p>\n<p><strong>交互式系统</strong></p>\n<p>对于交互式系统，则有不同的指标。最重要的是尽量<code>减少响应时间</code>。这个时间说的是从执行指令开始到得到结果的时间。再有后台进程运行（例如，从网络上读取和保存 E-mail 文件）的个人计算机上，用户请求启动一个程序或打开一个文件应该优先于后台的工作。能够让所有的交互式请求首先运行的就是一个好的服务。</p>\n<p>一个相关的问题是 <code>均衡性(proportionality)</code>，用户对做一件事情需要多长时间总是有一种固定（不过通常不正确）的看法。当认为一个请求很复杂需要较多时间时，用户会认为很正常并且可以接受，但是一个很简单的程序却花费了很长的运行时间，用户就会很恼怒。可以拿彩印和复印来举出一个简单的例子，彩印可能需要 1 分钟的时间，但是用户觉得复杂并且愿意等待一分钟，相反，复印很简单只需要 5 秒钟，但是复印机花费 1 分钟却没有完成复印操作，用户就会很焦躁。</p>\n<p><strong>实时系统</strong></p>\n<p>实时系统则有着和交互式系统不同的考量因素，因此也就有不同的调度目标。实时系统的特点是<code>必须满足最后的截止时间</code>。例如，如果计算机控制着以固定速率产生数据的设备，未能按时运行的话可能会导致数据丢失。因此，实时系统中最重要的需求是满足所有（或大多数）时间期限。</p>\n<p>在一些实事系统中，特别是涉及到多媒体的，<code>可预测性很重要</code>。偶尔不能满足最后的截止时间不重要，但是如果音频多媒体运行不稳定，声音质量会持续恶化。视频也会造成问题，但是耳朵要比眼睛敏感很多。为了避免这些问题，进程调度必须能够高度可预测的而且是有规律的。</p>\n<h3 id=\"批处理中的调度\"><a href=\"#批处理中的调度\" class=\"headerlink\" title=\"批处理中的调度\"></a>批处理中的调度</h3><p>现在让我们把目光从一般性的调度转换为特定的调度算法。下面我们会探讨在批处理中的调度。</p>\n<h4 id=\"先来先服务\"><a href=\"#先来先服务\" class=\"headerlink\" title=\"先来先服务\"></a>先来先服务</h4><p>很像是先到先得。。。可能最简单的非抢占式调度算法的设计就是 <code>先来先服务(first-come,first-serverd)</code>。使用此算法，将按照请求顺序为进程分配 CPU。最基本的，会有一个就绪进程的等待队列。当第一个任务从外部进入系统时，将会立即启动并允许运行任意长的时间。它不会因为运行时间太长而中断。当其他作业进入时，它们排到就绪队列尾部。当正在运行的进程阻塞，处于等待队列的第一个进程就开始运行。当一个阻塞的进程重新处于就绪态时，它会像一个新到达的任务，会排在队列的末尾，即排在所有进程最后。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkqPMbFJfGBd9toxDvJn0M90Yc7fIfwm8sYaqk2GkvFWFGWqV0upj7mA/640?wx_fmt=png\" alt=\"\"></p>\n<p>这个算法的强大之处在于易于理解和编程，在这个算法中，一个单链表记录了所有就绪进程。要选取一个进程运行，只要从该队列的头部移走一个进程即可；要添加一个新的作业或者阻塞一个进程，只要把这个作业或进程附加在队列的末尾即可。这是很简单的一种实现。</p>\n<p>不过，先来先服务也是有缺点的，那就是没有优先级的关系，试想一下，如果有 100 个 I/O 进程正在排队，第 101 个是一个 CPU 密集型进程，那岂不是需要等 100 个 I/O 进程运行完毕才会等到一个 CPU 密集型进程运行，这在实际情况下根本不可能，所以需要优先级或者抢占式进程的出现来优先选择重要的进程运行。</p>\n<h4 id=\"最短作业优先\"><a href=\"#最短作业优先\" class=\"headerlink\" title=\"最短作业优先\"></a>最短作业优先</h4><p>批处理中，第二种调度算法是 <code>最短作业优先(Shortest Job First)</code>，我们假设运行时间已知。例如，一家保险公司，因为每天要做类似的工作，所以人们可以相当精确地预测处理 1000 个索赔的一批作业需要多长时间。当输入队列中有若干个同等重要的作业被启动时，调度程序应使用最短优先作业算法</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkWytiaXxLwkZ2fQ1nGYZKsZsXtRcNaRjXicn01BsqHwSjk0szP48f1qyQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>如上图 a 所示，这里有 4 个作业 A、B、C、D ，运行时间分别为 8、4、4、4 分钟。若按图中的次序运行，则 A 的周转时间为 8 分钟，B 为 12 分钟，C 为 16 分钟，D 为 20 分钟，平均时间内为 14 分钟。  </p>\n<p>现在考虑使用最短作业优先算法运行 4 个作业，如上图 b 所示，目前的周转时间分别为 4、8、12、20，平均为 11 分钟，可以证明最短作业优先是最优的。考虑有 4 个作业的情况，其运行时间分别为 a、b、c、d。第一个作业在时间 a 结束，第二个在时间 a + b 结束，以此类推。平均周转时间为 (4a + 3b + 2c + d) / 4 。显然 a 对平均值的影响最大，所以 a 应该是最短优先作业，其次是 b，然后是 c ，最后是 d 它就只能影响自己的周转时间了。</p>\n<blockquote>\n<p>需要注意的是，在所有的进程都可以运行的情况下，最短作业优先的算法才是最优的。</p>\n</blockquote>\n<h4 id=\"最短剩余时间优先\"><a href=\"#最短剩余时间优先\" class=\"headerlink\" title=\"最短剩余时间优先\"></a>最短剩余时间优先</h4><p>最短作业优先的抢占式版本被称作为 <code>最短剩余时间优先(Shortest Remaining Time Next)</code> 算法。使用这个算法，调度程序总是选择剩余运行时间最短的那个进程运行。当一个新作业到达时，其整个时间同当前进程的剩余时间做比较。如果新的进程比当前运行进程需要更少的时间，当前进程就被挂起，而运行新的进程。这种方式能够使短期作业获得良好的服务。</p>\n<h3 id=\"交互式系统中的调度\"><a href=\"#交互式系统中的调度\" class=\"headerlink\" title=\"交互式系统中的调度\"></a>交互式系统中的调度</h3><p>交互式系统中在个人计算机、服务器和其他系统中都是很常用的，所以有必要来探讨一下交互式调度</p>\n<h4 id=\"轮询调度\"><a href=\"#轮询调度\" class=\"headerlink\" title=\"轮询调度\"></a>轮询调度</h4><p>一种最古老、最简单、最公平并且最广泛使用的算法就是 <code>轮询算法(round-robin)</code>。每个进程都会被分配一个时间段，称为<code>时间片(quantum)</code>，在这个时间片内允许进程运行。如果时间片结束时进程还在运行的话，则抢占一个 CPU 并将其分配给另一个进程。如果进程在时间片结束前阻塞或结束，则 CPU 立即进行切换。轮询算法比较容易实现。调度程序所做的就是维护一个可运行进程的列表，就像下图中的 a，当一个进程用完时间片后就被移到队列的末尾，就像下图的 b。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkOxzKshMcCgeCOxI9IFypGhFvaQNgrmef5xtBTlAN8ozyHPfnQk09Kw/640?wx_fmt=png\" alt=\"\"></p>\n<p>时间片轮询调度中唯一有意思的一点就是时间片的长度。从一个进程切换到另一个进程需要一定的时间进行管理处理，包括保存寄存器的值和内存映射、更新不同的表格和列表、清除和重新调入内存高速缓存等。这种切换称作 <code>进程间切换(process switch)</code> 和 <code>上下文切换(context switch)</code>。如果进程间的切换时间需要 1ms，其中包括内存映射、清除和重新调入高速缓存等，再假设时间片设为 4 ms，那么 CPU 在做完 4 ms 有用的工作之后，CPU 将花费 1 ms 来进行进程间的切换。因此，CPU 的时间片会浪费 20% 的时间在管理开销上。耗费巨大。</p>\n<p>为了提高 CPU 的效率，我们把时间片设置为 100 ms。现在时间的浪费只有 1%。但是考虑会发现下面的情况，如果在一个非常短的时间内到达 50 个请求，并且对 CPU 有不同的需求，此时会发生什么？50 个进程都被放在可运行进程列表中。如果 CP 画 U 是空闲的，第一个进程会立即开始执行，第二个直到 100 ms 以后才会启动，以此类推。不幸的是最后一个进程需要等待 5 秒才能获得执行机会。大部分用户都会觉得对于一个简短的指令运行 5 秒中是很慢的。如果队列末尾的某些请求只需要几号秒钟的运行时间的话，这种设计就非常糟糕了。</p>\n<p>另外一个因素是如果时间片设置长度要大于 CPU 使用长度，那么抢占就不会经常发生。相反，在时间片用完之前，大多数进程都已经阻塞了，那么就会引起进程间的切换。消除抢占可提高性能，因为进程切换仅在逻辑上必要时才发生，即流程阻塞且无法继续时才发生。</p>\n<p>结论可以表述如下：将上下文切换时间设置得太短会导致过多的进程切换并降低 CPU 效率，但设置时间太长会导致一个短请求很长时间得不到响应。最好的切换时间是在 20 - 50 毫秒之间设置。</p>\n<h4 id=\"优先级调度\"><a href=\"#优先级调度\" class=\"headerlink\" title=\"优先级调度\"></a>优先级调度</h4><p>轮询调度假设了所有的进程是同等重要的。但事实情况可能不是这样。例如，在一所大学中的等级制度，首先是院长，然后是教授、秘书、后勤人员，最后是学生。这种将外部情况考虑在内就实现了<code>优先级调度(priority scheduling)</code></p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibKKcmqw7wHNaRyic2qWfZQ5mxASpo0qqPtC1M6SCloLc5QvN5rsnib3A/640?wx_fmt=png\" alt=\"\"></p>\n<p>它的基本思想很明确，每个进程都被赋予一个优先级，优先级高的进程优先运行。</p>\n<p>但是也不意味着高优先级的进程能够永远一直运行下去，调度程序会在每个时钟中断期间降低当前运行进程的优先级。如果此操作导致其优先级降低到下一个最高进程的优先级以下，则会发生进程切换。或者，可以为每个进程分配允许运行的最大时间间隔。当时间间隔用完后，下一个高优先级的进程会得到运行的机会。</p>\n<p>可以静态或者动态的为进程分配优先级。在一台军用计算机上，可以把将军所启动的进程设为优先级 100，上校为 90 ，少校为 80，上尉为 70，中尉为 60，以此类推。UNIX 中有一条命令为 <code>nice</code> ，它允许用户为了照顾他人而自愿降低自己进程的优先级，但是一般没人用。</p>\n<p>优先级也可以由系统动态分配，用于实现某种目的。例如，有些进程为 I/O 密集型，其多数时间用来等待 I/O 结束。当这样的进程需要 CPU 时，应立即分配 CPU，用来启动下一个 I/O 请求，这样就可以在另一个进程进行计算的同时执行 I/O 操作。这类 I/O 密集型进程长时间的等待 CPU 只会造成它长时间占用内存。使 I/O 密集型进程获得较好的服务的一种简单算法是，将其优先级设为 <code>1/f</code>，f 为该进程在上一时间片中所占的部分。一个在 50 ms 的时间片中只使用 1 ms 的进程将获得优先级 50 ，而在阻塞之前用掉 25 ms 的进程将具有优先级 2，而使用掉全部时间片的进程将得到优先级 1。</p>\n<p>可以很方便的将一组进程按优先级分成若干类，并且在各个类之间采用优先级调度，而在各类进程的内部采用轮转调度。下面展示了一个四个优先级类的系统</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkh7icJrRFORxCKsSnD2DEvfhTIZKYn9o5SYaCl1mvebyx6EnsweGSjnw/640?wx_fmt=png\" alt=\"\"></p>\n<p>它的调度算法主要描述如下：上面存在优先级为 4 类的可运行进程，首先会按照轮转法为每个进程运行一个时间片，此时不理会较低优先级的进程。若第 4 类进程为空，则按照轮询的方式运行第三类进程。若第 4 类和第 3 类进程都为空，则按照轮转法运行第 2 类进程。如果不对优先级进行调整，则低优先级的进程很容易产生饥饿现象。</p>\n<h4 id=\"多级队列\"><a href=\"#多级队列\" class=\"headerlink\" title=\"多级队列\"></a>多级队列</h4><p>最早使用优先级调度的系统是 <code>CTSS(Compatible TimeSharing System)</code>。CTSS 是一种兼容分时系统，它有一个问题就是进程切换太慢，其原因是 IBM 7094 内存只能放进一个进程。</p>\n<blockquote>\n<p>IBM 是哥伦比亚大学计算机中心在 1964 - 1968 年的计算机</p>\n</blockquote>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkHqGI0SaIpjW7unPiasYQV0ekRmSB3EjbVNJ8jvhic6gL8VbFvicUWOW0w/640?wx_fmt=png\" alt=\"\"></p>\n<p>CTSS 在每次切换前都需要将当前进程换出到磁盘，并从磁盘上读入一个新进程。CTSS 的设计者很快就认识到，为 CPU 密集型进程设置较长的时间片比频繁地分给他们很短的时间要更有效（减少交换次数）。另一方面，如前所述，长时间片的进程又会影响到响应时间，解决办法是设置优先级类。属于最高优先级的进程运行一个时间片，次高优先级进程运行 2 个时间片，再下面一级运行 4 个时间片，以此类推。当一个进程用完分配的时间片后，它被移到下一类。</p>\n<h4 id=\"最短进程优先\"><a href=\"#最短进程优先\" class=\"headerlink\" title=\"最短进程优先\"></a>最短进程优先</h4><p>对于批处理系统而言，由于最短作业优先常常伴随着最短响应时间，所以如果能够把它用于交互式进程，那将是非常好的。在某种程度上，的确可以做到这一点。交互式进程通常遵循下列模式：等待命令、执行命令、等待命令、执行命令。。。如果我们把每个命令的执行都看作一个分离的作业，那么我们可以通过首先运行最短的作业来使响应时间最短。这里唯一的问题是如何从当前可运行进程中找出最短的那一个进程。</p>\n<p>一种方式是根据进程过去的行为进行推测，并执行估计运行时间最短的那一个。假设每个终端上每条命令的预估运行时间为 <code>T0</code>，现在假设测量到其下一次运行时间为 <code>T1</code>，可以用两个值的加权来改进估计时间，即<code>aT0+ (1- 1)T1</code>。通过选择 a 的值，可以决定是尽快忘掉老的运行时间，还是在一段长时间内始终记住它们。当 a = 1/2 时，可以得到下面这个序列</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkVar1KhzuffcYqXhyRyOL7b8KQiciaUYCpmR2e9iaiaMF6qh60jPk4FCrgA/640?wx_fmt=png\" alt=\"\"></p>\n<p>可以看到，在三轮过后，T0 在新的估计值中所占比重下降至 1/8。  </p>\n<p>有时把这种通过当前测量值和先前估计值进行加权平均从而得到下一个估计值的技术称作 <code>老化(aging)</code>。这种方法会使用很多预测值基于当前值的情况。</p>\n<h4 id=\"保证调度\"><a href=\"#保证调度\" class=\"headerlink\" title=\"保证调度\"></a>保证调度</h4><p>一种完全不同的调度方法是对用户做出明确的性能保证。一种实际而且容易实现的保证是：若用户工作时有 n 个用户登录，则每个用户将获得 CPU 处理能力的 1/n。类似地，在一个有 n 个进程运行的单用户系统中，若所有的进程都等价，则每个进程将获得 1/n 的 CPU 时间。</p>\n<h4 id=\"彩票调度\"><a href=\"#彩票调度\" class=\"headerlink\" title=\"彩票调度\"></a>彩票调度</h4><p>对用户进行承诺并在随后兑现承诺是一件好事，不过很难实现。但是存在着一种简单的方式，有一种既可以给出预测结果而又有一种比较简单的实现方式的算法，就是 <code>彩票调度(lottery scheduling)</code>算法。</p>\n<p>其基本思想是为进程提供各种系统资源（例如 CPU 时间）的彩票。当做出一个调度决策的时候，就随机抽出一张彩票，拥有彩票的进程将获得该资源。在应用到 CPU 调度时，系统可以每秒持有 50 次抽奖，每个中奖者将获得比如 20 毫秒的 CPU 时间作为奖励。</p>\n<p><code>George Orwell</code> 关于 <strong>所有的进程是平等的，但是某些进程能够更平等一些</strong>。一些重要的进程可以给它们额外的彩票，以便增加他们赢得的机会。如果出售了 100 张彩票，而且有一个进程持有了它们中的 20 张，它就会有 20% 的机会去赢得彩票中奖。在长时间的运行中，它就会获得 20% 的 CPU。相反，对于优先级调度程序，很难说明拥有优先级 40 究竟是什么意思，这里的规则很清楚，拥有彩票 f 份额的进程大约得到系统资源的 f 份额。</p>\n<p>如果希望进程之间协作的话可以交换它们之间的票据。例如，客户端进程给服务器进程发送了一条消息后阻塞，客户端进程可能会把自己所有的票据都交给服务器，来增加下一次服务器运行的机会。当服务完成后，它会把彩票还给客户端让其有机会再次运行。事实上，如果没有客户机，服务器也根本不需要彩票。</p>\n<blockquote>\n<p>可以把彩票理解为 buff，这个 buff 有 15% 的几率能让你产生 <code>速度之靴</code> 的效果。</p>\n</blockquote>\n<h4 id=\"公平分享调度\"><a href=\"#公平分享调度\" class=\"headerlink\" title=\"公平分享调度\"></a>公平分享调度</h4><p>到目前为止，我们假设被调度的都是各个进程自身，而不用考虑该进程的拥有者是谁。结果是，如果用户 1 启动了 9 个进程，而用户 2 启动了一个进程，使用轮转或相同优先级调度算法，那么用户 1 将得到 90 % 的 CPU 时间，而用户 2 将之得到 10 % 的 CPU 时间。</p>\n<p>为了阻止这种情况的出现，一些系统在调度前会把进程的拥有者考虑在内。在这种模型下，每个用户都会分配一些 CPU 时间，而调度程序会选择进程并强制执行。因此如果两个用户每个都会有 50% 的 CPU 时间片保证，那么无论一个用户有多少个进程，都将获得相同的 CPU 份额。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkp2JUKicTTic4Mh3owkYeABOicg6zXAkfFSmoTZs7W6UtRN5Rsc3VcTqPA/640?wx_fmt=png\" alt=\"\"></p>\n<h3 id=\"实时系统中的调度\"><a href=\"#实时系统中的调度\" class=\"headerlink\" title=\"实时系统中的调度\"></a>实时系统中的调度</h3><p><code>实时系统(real-time)</code> 是一个时间扮演了重要作用的系统。典型的，一种或多种外部物理设备发给计算机一个服务请求，而计算机必须在一个确定的时间范围内恰当的做出反应。例如，在 CD 播放器中的计算机会获得从驱动器过来的位流，然后必须在非常短的时间内将位流转换为音乐播放出来。如果计算时间过长，那么音乐就会听起来有异常。再比如说医院特别护理部门的病人监护装置、飞机中的自动驾驶系统、列车中的烟雾警告装置等，在这些例子中，正确但是却缓慢的响应要比没有响应甚至还糟糕。</p>\n<p>实时系统可以分为两类，<code>硬实时(hard real time)</code> 和 <code>软实时(soft real time)</code> 系统，前者意味着必须要满足绝对的截止时间；后者的含义是虽然不希望偶尔错失截止时间，但是可以容忍。在这两种情形中，实时都是通过把程序划分为一组进程而实现的，其中每个进程的行为是可预测和提前可知的。这些进程一般寿命较短，并且极快的运行完成。在检测到一个外部信号时，调度程序的任务就是按照满足所有截止时间的要求调度进程。</p>\n<p>实时系统中的事件可以按照响应方式进一步分类为<code>周期性(以规则的时间间隔发生)</code>事件或 <code>非周期性(发生时间不可预知)</code>事件。一个系统可能要响应多个周期性事件流，根据每个事件处理所需的时间，可能甚至无法处理所有事件。例如，如果有 m 个周期事件，事件 i 以周期 Pi 发生，并需要 Ci 秒 CPU 时间处理一个事件，那么可以处理负载的条件是</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkicxWrh9f5BDPIHJU9PDzKE0HR42WWlTyA1P9rDLSVhtibSQ7VVeymJibA/640?wx_fmt=png\" alt=\"\"></p>\n<p>只有满足这个条件的实时系统称为<code>可调度的</code>，这意味着它实际上能够被实现。一个不满足此检验标准的进程不能被调度，因为这些进程共同需要的 CPU 时间总和大于 CPU 能提供的时间。</p>\n<p>举一个例子，考虑一个有三个周期性事件的软实时系统，其周期分别是 100 ms、200 m 和 500 ms。如果这些事件分别需要 50 ms、30 ms 和 100 ms 的 CPU 时间，那么该系统时可调度的，因为 0.5 + 0.15 + 0.2 &lt; 1。如果此时有第四个事件加入，其周期为 1 秒，那么此时这个事件如果不超过 150 ms，那么仍然是可以调度的。忽略上下文切换的时间。</p>\n<p>实时系统的调度算法可以是静态的或动态的。前者在系统开始运行之前做出调度决策；后者在运行过程中进行调度决策。只有在可以提前掌握所完成的工作以及必须满足的截止时间等信息时，静态调度才能工作，而动态调度不需要这些限制。</p>\n<h3 id=\"调度策略和机制\"><a href=\"#调度策略和机制\" class=\"headerlink\" title=\"调度策略和机制\"></a>调度策略和机制</h3><p>到目前为止，我们隐含的假设系统中所有进程属于不同的分组用户并且进程间存在相互竞争 CPU 的情况。通常情况下确实如此，但有时也会发生一个进程会有很多子进程并在其控制下运行的情况。例如，一个数据库管理系统进程会有很多子进程。每一个子进程可能处理不同的请求，或者每个子进程实现不同的功能（如请求分析、磁盘访问等）。主进程完全可能掌握哪一个子进程最重要（或最紧迫），而哪一个最不重要。但是，以上讨论的调度算法中没有一个算法从用户进程接收有关的调度决策信息，这就导致了调度程序很少能够做出最优的选择。</p>\n<p>解决问题的办法是将 <code>调度机制(scheduling mechanism)</code> 和 <code>调度策略(scheduling policy)</code> 分开，这是长期一贯的原则。这也就意味着调度算法在某种方式下被参数化了，但是参数可以被用户进程填写。让我们首先考虑数据库的例子。假设内核使用优先级调度算法，并提供了一条可供进程设置优先级的系统调用。这样，尽管父进程本身并不参与调度，但它可以控制如何调度子进程的细节。调度机制位于内核，而调度策略由用户进程决定，调度策略和机制分离是一种关键性思路。</p>\n<h3 id=\"线程调度\"><a href=\"#线程调度\" class=\"headerlink\" title=\"线程调度\"></a>线程调度</h3><p>当若干进程都有多个线程时，就存在两个层次的并行：进程和线程。在这样的系统中调度处理有本质的差别，这取决于所支持的是用户级线程还是内核级线程（或两者都支持）。</p>\n<p>首先考虑用户级线程，由于内核并不知道有线程存在，所以内核还是和以前一样地操作，选取一个进程，假设为 A，并给予 A 以时间片控制。A 中的线程调度程序决定哪个线程运行。假设为 A1。由于多道线程并不存在时钟中断，所以这个线程可以按其意愿任意运行多长时间。如果该线程用完了进程的全部时间片，内核就会选择另一个进程继续运行。</p>\n<p>在进程 A 终于又一次运行时，线程 A1 会接着运行。该线程会继续耗费 A 进程的所有时间，直到它完成工作。不过，线程运行不会影响到其他进程。其他进程会得到调度程序所分配的合适份额，不会考虑进程 A 内部发生的事情。</p>\n<p>现在考虑 A 线程每次 CPU 计算的工作比较少的情况，例如：在 50 ms 的时间片中有 5 ms 的计算工作。于是，每个线程运行一会儿，然后把 CPU 交回给线程调度程序。这样在内核切换到进程 B 之前，就会有序列 A1,A2,A3,A1,A2,A3,A1,A2,A3,A1 。如下所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkibIqnCiaYicYscwr55u59URicaa9iaIgcMA3zmicGaJKFtoByUkUAClg9YUA/640?wx_fmt=png\" alt=\"\"></p>\n<p>运行时系统使用的调度算法可以是上面介绍算法的任意一种。从实用方面考虑，轮转调度和优先级调度更为常用。唯一的局限是，缺乏一个时钟中断运行过长的线程。但由于线程之间的合作关系，这通常也不是问题。</p>\n<p>现在考虑使用内核线程的情况，内核选择一个特定的线程运行。它不用考虑线程属于哪个进程，不过如果有必要的话，也可以这么做。对被选择的线程赋予一个时间片，而且如果超过了时间片，就会强制挂起该线程。一个线程在 50 ms 的时间片内，5 ms 之后被阻塞，在 30 ms 的时间片中，线程的顺序会是 A1,B1,A2,B2,A3,B3。如下图所示</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/libYRuvULTdUGos87DMJibWy8Kib1P4rzXkiaejGGnPoyhnwOUWNVdDCQpicVrhQwUibbMtZRKOUEOOJGvgBh5tPMiavg/640?wx_fmt=png\" alt=\"\"></p>\n<p>用户级线程和内核级线程之间的主要差别在于<code>性能</code>。用户级线程的切换需要少量的机器指令（想象一下 Java 程序的线程切换），而内核线程需要完整的上下文切换，修改内存映像，使高速缓存失效，这会导致了若干数量级的延迟。另一方面，在使用内核级线程时，一旦线程阻塞在 I/O 上就不需要在用户级线程中那样将整个进程挂起。  </p>\n<p>从进程 A 的一个线程切换到进程 B 的一个线程，其消耗要远高于运行进程 A 的两个线程（涉及修改内存映像，修改高速缓存），内核对这种切换的消耗是了解到，可以通过这些信息作出决定。</p>\n<p>文章参考：</p>\n<p>《现代操作系统》</p>\n<p>《Modern Operating System》forth edition</p>\n<p><a href=\"https://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems\" target=\"_blank\" rel=\"noopener\">https://www.encyclopedia.com/computing/news-wires-white-papers-and-books/interactive-systems</a></p>\n<p><a href=\"https://j00ru.vexillium.org/syscalls/nt/32/\" target=\"_blank\" rel=\"noopener\">https://j00ru.vexillium.org/syscalls/nt/32/</a></p>\n<p><a href=\"https://www.bottomupcs.com/process_hierarchy.xhtml\" target=\"_blank\" rel=\"noopener\">https://www.bottomupcs.com/process_hierarchy.xhtml</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Runtime_system\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Runtime_system</a></p>\n<p><a href=\"https://en.wikipedia.org/wiki/Execution_model\" target=\"_blank\" rel=\"noopener\">https://en.wikipedia.org/wiki/Execution_model</a></p>\n<p><a href=\"https://zhidao.baidu.com/question/113227654.html\" target=\"_blank\" rel=\"noopener\">https://zhidao.baidu.com/question/113227654.html</a></p>\n<p><a href=\"https://baike.baidu.com/item/\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/</a> 等待队列 / 9223804?fr=aladdin</p>\n<p><a href=\"http://www.columbia.edu/cu/computinghistory/7094.html\" target=\"_blank\" rel=\"noopener\">http://www.columbia.edu/cu/computinghistory/7094.html</a></p>\n<p><a href=\"https://baike.baidu.com/item/\" target=\"_blank\" rel=\"noopener\">https://baike.baidu.com/item/</a> 中断向量 / 4947039?fr=aladdin</p>\n<pre><code>推荐阅读：\n\n\n\n\n完全整理 | 365篇高质技术文章目录整理\n\n算法之美 : 栈和队列\n\n\n主宰这个世界的10大算法\n\n\n彻底理解cookie、session、token\n\n\n浅谈什么是递归算法\n\n专注服务器后台技术栈知识总结分享\n\n欢迎关注交流共同进步\n\n码农有道 coding\n\n\n\n\n码农有道，为您提供通俗易懂的技术文章，让技术变的更简单！\n\n好文章，我 在看 </code></pre>"},{"title":"GNN需要解决的关键问题","date":"2020-04-16T08:24:19.000Z","_content":"\n# “图神经网络在线研讨会2020” 笔记\n\n## 1. 从同质到异质\n\n目前很多图神经网络主要是基于同质信息网络，同质信息网络只有一种类型的节点和边；\n\n在实际应用中，会存在大量由不同节点和边构成的交互系统，例如文献数据、电影数据、以及社交网络知识图谱等，在这些网络中，不同类型的对象相互交互。不同类型的对象性质不同，交互关系的特性不同会导致很大差异的分析，所以在异质网络中，需要考虑不同类型的对象交互关系对结果的影响。\n\n在异质信息网络中，网络模式是对一个网络的元级描述，刻画了网络中包含了不同类型的对象和不同类型的关系。例如在图 1 的网络实例中，描述了作者撰写论文，论文发表在会议上；这个网络实例就包含三类对象：作者、论文和会议，以及他们之间的相互交互关系。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icdwveTm3DV8picININawtSibDUFicuoyNh6DnxhxTVNnGFlWIwLyrpOoHg/640?wx_fmt=png)\n\n图 1：异质信息网络实例\n\n</center>\n\n### 元路径\n\n元路径是异质信息网络中另外一个很重要的概念。简而言之，元路径就是连接两个对象的一个关系序列。\n\n如图 2 所示，连接两个 author 可以有不同的元路径。例如：author->paper->author，描述的是两个作者之间的合作关系；还可以有 author->paper->venue->paper->author，这条元路径描述的是两个作者参加同一个会议这么一个关系。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icIYG6IA8nEH1G7xTLGdJmRRzPSqtM6iclKRWWdnVnwT8ddHaDlE8fLrA/640?wx_fmt=png)\n\n图 2：异质信息网络中的元路径\n\n</center>\n\n也提出了很多其他一些概念，例如元图，元结构，以及有约束的元路径等一些概念，它可以更细致的描述网络里面的属性信息。\n\n石川指出，异质信息网络表示学习目前存在一些挑战，例如如何解决异质性、如何融合信息以及捕捉丰富的语义信息等，主要的解决方案有**经典浅层模型**和**深度模型**两个方面。\n\n## 2. 浅层模型\n\n在同质网络中，有一些很经典的浅层模型，例如 DeepWalk、Line 等一系列方法，这些方法的核心思想是基于随机游走产生一个节点序列，然后类比于自然语言处理单词序列的方法，通过 skip-gram 的方法来学习网络表示。\n\n在异质网络中也是采用类似的思路，为了高效的随机游走，一般是采用元路径的随机游走方式，元路径在游走的过程中可以把节点类型信息和边类型信息固定下来。图 3 为基于元路径随机游走的范式，给以一个元路径，如果是按照给定元路径游走的话，转移概率就是指定类型节点的邻居数目分之一，不按照元路径游走的话，转移概率就是 0。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmFl5gia2CcLtJwvxuF6K6vyXfAG45nZPKljCKX21ZrfZCiaibqq40eeMA/640?wx_fmt=png)\n\n图 3：基于元路径的随机游走  \n\n</center>\n\n针对元路径的随机游走，然后采用 skim-gram 来进行目标优化，metapath2vec 和 metapath2vec++ 有一个区别如图 4 所示。在 soft-max 操作中，metapath2vec++ 在分母中是按照下一个节点类型中的所有节点求和的，而 metapath2vec 是不考虑节点类型，直接对所有节点求和。metapath2vec++ 的优点在于考虑下一个节点的节点类型可以使游走概率的值大一些，在很多情况下效果会好一些。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmYnOlGUjAFnQicdYvyljLbQuqfHibR8onSPvVH2en6RQc5xib2bA9Ee3g/640?wx_fmt=png)\n\n图 4：计算概率中 metapath2vector（上）和 metapath2vec++（下）\n\nMetapath2vec 是基于元路径随机游走和 skim-gram 的方式解决异质性，也基本上奠基了这个方向研究的基本思路。\n\nHERec[2] 是另外一种处理异质信息网络的浅层模型，它的基本思路是通过一些对称的元路径将异质图变成同质图，然后在同质图中用 DeepWalk、Line 等方法学习到网络表示。另外一种基于游走的方法是 HIN2Vec[3]，首先 HIN2Vec 在异质网络中游走，抽取点边序列，即节点 X、Y 和它们之间对应的关系 R，在游走的过程中点边序列抽取出来就可以构成序列样本，然后就可以通过判断节点 X、Y 是否具有关系 R 把原来的问题变成分类问题，将分类问题作为优化目标学习网络表示。\n\nMetapath2vec、HERec 和 HIN2Vec 是异质信息网络表示的三个早期的工作，给后来的工作奠定了基础。最近几年也有一些比较优秀的工作。MCRec[4] 通过刻画 user 和 item 的丰富的交互关系来学习节点表示。为了找到有代表性的负样本，HeGAN[5] 根据关系类型用 GAN 生成好的负样本。RHINE[6] 为了区分异质信息网络中不同类型的关系，借鉴知识表示的思想学习网络表示。\n\n## 3. 深层模型\n\n深层模型就是用神经网络进行深度建模。在推荐领域，一般主要分析 user 和 item 之间的交互矩阵来得到 user 和 item 之间的隐含特征，但是考虑到异质信息网络实际上包含了不同方面的交互信息，NeuACF[7] 尝试将不同方面的信息融合。如图 5 所示，先通过一些不同方面的元路径抽取不同维度的信息。例如，通过 UIU 和 IUI 抽取用户购买记录方面的特征，UIBIU 和 IBI 元路径可以抽取出品牌方面的信息。然后构造出 aspect-level 的相似性矩阵，然后用 MLP 学习 aspect-level 的潜在因子，最后用 attention 机制将 aspect-level 的潜在因子融合，得到损失函数。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icas3JGGoiaxiaT9CeU9hB1Nxns09uwIp5wgia0XM9ew8tibZ5HYDSyocHqQ/640?wx_fmt=png)\n\n图 5：NeuACF 的框架示意图\n\n</center>\n\n### Attention 机制\n\nAttention 机制在图神经网络中有着重要的应用，但是在异质信息网络中应用 attention 需要两方面的考虑：一个是节点级别的 attention，考虑节点与邻居之间的 attention；另外一个是语义级别的 attention，即在元路径上将节点信息通过 attention 聚合。基于此，HAN 模型将 attention 机制应用到异质信息网络中。如图 6 所示，HAN[8] 首先把节点映射到相同的特征空间，然后用一个 node 级别的 attention 机制，把这些邻居节点聚合起来，再用 semantic attention 机制将元路径信息融合。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ic8Sr3NxfcPWEmaxow1K7MFE6HVy4MEa4PmSzKPyAL00SGx8xVCrTtbA/640?wx_fmt=png)\n\n图 6：HAN 框架示意图\n\n</center>\n\n在异质图中，不同类型的节点有不同类型的属性特征。HetGNN 将节点的属性信息融合到异质信息网络中。如图 7 所示，HetGNN[9] 先考虑某一类型节点的属性信息，通过神经网络将节点不同模态的属性信息融合起来，然后将节点的一跳邻居中同一类型的节点用 BLSTM 融合起来，最后再将不同类型的节点信息通过神经网络聚合。HetGNN 可以处理异质关系和异质属性。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icePnrRnxAIkldibTXpj9zoicjpzJ3eOiaRslFTSWJmFq1urtfTWWj7LrTw/640?wx_fmt=png)\n\n图 7：HetGNN 架构示意图\n\n</center>\n\n### 元路径选择\n\n元路径选择是异质信息网络分析的基本步骤，一般来说，都是选择连接关系比较丰富、语义特性比较强的元路径。但是找到这样的元路径需要比较多的领域知识，在实际操作中也会存在一些问题。为此，石川给出了三种解决思路：\n\n1. 把元路径提纯，不同的元路径表示不同方面的信息，再把不同方面纯化后的信息融合起来；\n\n2. 可以舍弃元路径，元路径之所以重要是因为它能抽取高阶关系，如果不用元路径也可以通过保持网络模式的结构特性学习到高阶关系；\n\n3. 自动找寻元路径，例如知识图谱里面有些节点之间存在内在关系，可以借鉴知识补全的思路自动生成元路径。\n\n## 4. 异质图神经网络的应用\n\n### 4.1 套现用户检测\n\n套现是套取现金的简称，一般是指用违法或虚假的手段交换取得现金利益。如图８所示，判断一个用户是不是套现用户，传统方法是把套现用户检测看成一个分类问题，通过抽取出用户特征，然后用分类器来进行分类。这个过程的一个关键问题是怎么才能够抽取出足够丰富的特征。而在电商特别是互联网金融方面，用户特征大量蕴含在交互行为里面，那么怎么从这种交互行为里面抽取出用户特征，是这个问题的关键。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icicORhazwu7WUicAZicjaMJk56s3CMyCHsx2AbMPlQrg3mm1ahoQ3icNjHg/640?wx_fmt=png)\n\n图8：套现用户检测的关键问题和传统解决方案  \n\n</center>\n\n对此，[10] 提出把用户、商家、设备等信息的交互关系构建为一个**异质网络**，网络要学出用户的特征表示。进一步提出的模型首先考虑用户的自然属性信息，以及用户基于不同元路径的邻居。更进一步把用户的不同 Feature 和其邻居特征通过 Feature attention 机制融合起来，最后利用 Path 相关的 Attention，把基于不同元路径的特征融合起来。模型的相关结构说明如图 8 所示 [MOU1] 。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icOeSy2cIYD8hEXLZy3UMVXUWJYVGtWKt7xl4LrBJwCDtJDJkcCRTW0A/640?wx_fmt=png)\n\n图 9：用户套现用户检测模型的相关说明\n\n</center>\n\n### 4.2 意图推荐\n\n意图推荐就是分析用户的潜在意图。\n\n可以设计一个异质网络来解决这个问题 [11]。如图 9 所示，网络中刻划了用户、物品和查询词三者之间的交互关系，模型来学习 user、item、query 之间的表示，然后看看针对一个用户来推荐什么样的 query。我们同样是基于元路径来聚合邻居信息，在这个过程中可以利用不同的元路径来聚合不同的邻居信息。实际问题当中，user、item、query 的量级是相当大的，在亿级的规模。但是用于组成它们的 word 的数量实际上是不大的，大概是十万级别的。那么仅仅学习 word 的特征表示，然后 query 和 item 的特征由一些 word 拼接而成的，这样就减少了计算量。通过和工业界的算法对比，提出的方法利用增加的元路径信息得到了性能的稳步提升。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ictxic6OoMbEm7xcBIicl2360xxbB7Z7oIedpysRkexicFPMadibWHSJib0Zg/640?wx_fmt=png)\n\n图 10：用于意图推荐的异质图神经网络\n\n</center>\n\n### 4.3 用户聚类\n\n用户聚类是利用用户的特征信息，以及用户的社交连接关系对用户做一个类别划分，对广告推荐是很有帮助的。目前深度学习已经广泛应用于推荐、聚类任务当中。\n\n聚类主要是分析用户的特征信息，特征实际上也包含有结构信息，把结构和特征两方面联合起来做聚类：\n\n[12] 首先用深度神经网络学得用户的隐含特征表示，这是深度聚类里面常用的做法。 **另一方面，根据用户的社交关系，构造 KNN 图得到用户的关联图，学得表示过程中，把 DNN 里面学的每一层的特征和 GCN 里面的节点特征表示拼合起来再做聚合。**  如图 10 所示，在这个过程当中，由于这里的 GCN 需要有监督信息，我们把在 DNN 里面做的聚类做一个软划分，得到 Q 分布，进而取平方得到 P 分布，这里的 P 分布当作一个伪标签来指导 GNN 学习，取得了比较明显的效果。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmPwSfGAlNcj9tQg97ErEfZvgcc9Mm8x7iaGhUng41oyDs5HESZtchFw/640?wx_fmt=png)\n\n图 11：用户聚类模型中 GNN 的监督学习\n\n除了上面的介绍之外，还有一些其他的应用。如共享推荐中一个用户是否把新闻或者商品推荐给他的朋友；基于朋友关系的推荐中根据朋友的点赞信息决定是否给用户推荐。对于这些含有丰富交互信息的应用场景都可以采用异质网络建模和采用图神经网络进行分析。\n\n## 结语\n\n关于异质信息网络特别是异质图网络的未来研究方向：\n\n*   异质图神经网络内在学习机理\n    \n*   动态网络\n    \n*   多模态数据处理\n    \n\n异质信息网络的更多资料可以访问网站：www.shichuan.org.\n\n**Q&A：**\n\n**Q1: 为什么知识图谱表示学习方法很少用到异质网络表示学习中？**\n\nA1: 我认为知识图谱可以看成是一种异质网络，它是一种模式丰富的异质网络，那么在这种网络里面，它有很多不同类型的结点，有很多不同类型的关系。这个的话实际上是传统的异质网络很少分析的，也是很难分析的。网络表示学习和知识图谱的表示学习，是两种不同的角度来做不同的事情，其实我觉得二者是可以相互借鉴、相互结合的，但是目前还没有什么太多太好的工作。\n\n**Q2: 网络表示学习的结果如何与结点的属性特征、描述类的文本特征进行融合，难点在哪里？以及如何自动发现元路径？**\n\nA2: 一般的话还是要根据领域知识来选择一些语意，选择语意明确、结构丰富的这样一些元路径，这样选出的路径对于实际问题一般来说效果都还不错。\n\n**Q3: 广度学习主要是通过定义元路径来实现的吗？可以谈一谈广度学习和图神经网络的关系以及二者今后如何发展情况吗？**\n\nA3: 广度学习是近些年 Philip S Yu 教授倡导的一个研究方向，里面的主要一种技术方法也是用异质信息网络，异质信息网络可以很自然的把不同方面的信息关联起来，起到一个信息融合的作用。在这里面我们可以用元路径，那么就是说可以融合不同方面的信息，抽取不同方面的这种子结构。所以这是里面一个很重要的方法。\n\n**Q4: 异质信息网络下一步的发展方向是什么？**\n\nA3: 一个是我前面说到的，元路径选择的困境，实际上这是长期困扰这个领域的一个事情。因为这个领域的分析是严重依赖于元路径，怎么能够不依赖于元路径，或者设计一些更好的方法，能够探索语意信息，这是一个方向。在异质图神经网络里面如何更好的做聚合，实际上是研究也才刚刚开始。然后还有像这种动态网络的，在异质图里面怎么考虑这种动态性等等，都值得深入研究。\n\n**参考文献**\n\n[1] YuXiao Dong,Nitesh V. Chawla,Ananthram Swami. Metapath2vec: Scalable Representation Learning for Heterogeneous Networks. KDD， 2017.\n\n[2] Chuan Shi, Binbin Hu, Wayne XinZhao, Philip S. Yu. Heterogeneous Information Network Embedding for Recommendation.TKDE,2018.\n\n[3] Tao-yang Fu, Wang-Chien Lee, ZhenLei. HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning. CIKM,2017.\n\n[4] Binbin Hu, Chuan Shi, Wayne XinZhao, Philip S. Yu. Leveraging Meta-path based Context for Top-N Recommendation with A Neural Co-Attention Model. KDD,2018.\n\n[5] Binbin Hu, Yuan Fang, Chuan Shi.Adversarial Learning on Heterogeneous Information Networks. KDD,2019.\n\n[6] Chuan Shi, Yuanfu Lu, Linmei Hu,Zhiyuan Liu et al. RHINE: Relation Structure-Aware Heterogeneous Information Network Embedding. TKDE, 2020\n\n[7] Xiaotian Han, Chuan Shi, SenzhangWang, Philip S. Yu, Li Song.Aspect-Level Deep Collaborative Filtering viaHeterogeneous Information Networks. IJCAI,2018.\n\n[8] Wang, Xiao, Houye Ji, Chuan Shi,Bai Wang, Yanfang Ye, Peng Cui, and Philip S. Yu. Heterogeneous Graph Attention Network. WWW,2019.\n\n[9] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V. Chawla. Heterogeneous Graph Neural Network.KDD,2019.\n\n[10] Binbin Hu, Zhiqiang Zhang, Chuan Shi, Jun Zhou, XiaoLong Li, Yuan Qi Cash-out User Detection based on Attributed HeterogeneousInformation Network with a Hierarchical Attention Mechanism. AAAI,2019.\n\n[11] Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi,Linmei Hu, Biyu Ma, Yongliang Li Metapath-guided Heterogeneous Graph NeuralNetwork for Intent Recommendation. KDD,2019.\n\n[12] Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu, PengCui. Structural Deep Clustering Network. WWW,2020. \n\n## Reference\n\n[北邮教授石川：图神经网络需要解决的几个关键问题](https://mp.weixin.qq.com/s?__biz=MzU5ODg0MTAwMw==&mid=2247486047&idx=1&sn=2052f3f96135cbe48ddfa96841bc404d&chksm=febf499bc9c8c08d99bbf2cc6fee48414b4d920bdaa01ec9c68c9fba74fd634331274af10f09&mpshare=1&scene=23&srcid=&sharer_sharetime=1586774527616&sharer_shareid=fc06814c3a0ce2f45e4998813d787a8f#rd)","source":"_posts/GNN需要解决的关键问题.md","raw":"---\ntitle: GNN需要解决的关键问题\ndate: 2020-04-16 16:24:19\ntags: 科研\ncategories: 科研\n---\n\n# “图神经网络在线研讨会2020” 笔记\n\n## 1. 从同质到异质\n\n目前很多图神经网络主要是基于同质信息网络，同质信息网络只有一种类型的节点和边；\n\n在实际应用中，会存在大量由不同节点和边构成的交互系统，例如文献数据、电影数据、以及社交网络知识图谱等，在这些网络中，不同类型的对象相互交互。不同类型的对象性质不同，交互关系的特性不同会导致很大差异的分析，所以在异质网络中，需要考虑不同类型的对象交互关系对结果的影响。\n\n在异质信息网络中，网络模式是对一个网络的元级描述，刻画了网络中包含了不同类型的对象和不同类型的关系。例如在图 1 的网络实例中，描述了作者撰写论文，论文发表在会议上；这个网络实例就包含三类对象：作者、论文和会议，以及他们之间的相互交互关系。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icdwveTm3DV8picININawtSibDUFicuoyNh6DnxhxTVNnGFlWIwLyrpOoHg/640?wx_fmt=png)\n\n图 1：异质信息网络实例\n\n</center>\n\n### 元路径\n\n元路径是异质信息网络中另外一个很重要的概念。简而言之，元路径就是连接两个对象的一个关系序列。\n\n如图 2 所示，连接两个 author 可以有不同的元路径。例如：author->paper->author，描述的是两个作者之间的合作关系；还可以有 author->paper->venue->paper->author，这条元路径描述的是两个作者参加同一个会议这么一个关系。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icIYG6IA8nEH1G7xTLGdJmRRzPSqtM6iclKRWWdnVnwT8ddHaDlE8fLrA/640?wx_fmt=png)\n\n图 2：异质信息网络中的元路径\n\n</center>\n\n也提出了很多其他一些概念，例如元图，元结构，以及有约束的元路径等一些概念，它可以更细致的描述网络里面的属性信息。\n\n石川指出，异质信息网络表示学习目前存在一些挑战，例如如何解决异质性、如何融合信息以及捕捉丰富的语义信息等，主要的解决方案有**经典浅层模型**和**深度模型**两个方面。\n\n## 2. 浅层模型\n\n在同质网络中，有一些很经典的浅层模型，例如 DeepWalk、Line 等一系列方法，这些方法的核心思想是基于随机游走产生一个节点序列，然后类比于自然语言处理单词序列的方法，通过 skip-gram 的方法来学习网络表示。\n\n在异质网络中也是采用类似的思路，为了高效的随机游走，一般是采用元路径的随机游走方式，元路径在游走的过程中可以把节点类型信息和边类型信息固定下来。图 3 为基于元路径随机游走的范式，给以一个元路径，如果是按照给定元路径游走的话，转移概率就是指定类型节点的邻居数目分之一，不按照元路径游走的话，转移概率就是 0。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmFl5gia2CcLtJwvxuF6K6vyXfAG45nZPKljCKX21ZrfZCiaibqq40eeMA/640?wx_fmt=png)\n\n图 3：基于元路径的随机游走  \n\n</center>\n\n针对元路径的随机游走，然后采用 skim-gram 来进行目标优化，metapath2vec 和 metapath2vec++ 有一个区别如图 4 所示。在 soft-max 操作中，metapath2vec++ 在分母中是按照下一个节点类型中的所有节点求和的，而 metapath2vec 是不考虑节点类型，直接对所有节点求和。metapath2vec++ 的优点在于考虑下一个节点的节点类型可以使游走概率的值大一些，在很多情况下效果会好一些。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmYnOlGUjAFnQicdYvyljLbQuqfHibR8onSPvVH2en6RQc5xib2bA9Ee3g/640?wx_fmt=png)\n\n图 4：计算概率中 metapath2vector（上）和 metapath2vec++（下）\n\nMetapath2vec 是基于元路径随机游走和 skim-gram 的方式解决异质性，也基本上奠基了这个方向研究的基本思路。\n\nHERec[2] 是另外一种处理异质信息网络的浅层模型，它的基本思路是通过一些对称的元路径将异质图变成同质图，然后在同质图中用 DeepWalk、Line 等方法学习到网络表示。另外一种基于游走的方法是 HIN2Vec[3]，首先 HIN2Vec 在异质网络中游走，抽取点边序列，即节点 X、Y 和它们之间对应的关系 R，在游走的过程中点边序列抽取出来就可以构成序列样本，然后就可以通过判断节点 X、Y 是否具有关系 R 把原来的问题变成分类问题，将分类问题作为优化目标学习网络表示。\n\nMetapath2vec、HERec 和 HIN2Vec 是异质信息网络表示的三个早期的工作，给后来的工作奠定了基础。最近几年也有一些比较优秀的工作。MCRec[4] 通过刻画 user 和 item 的丰富的交互关系来学习节点表示。为了找到有代表性的负样本，HeGAN[5] 根据关系类型用 GAN 生成好的负样本。RHINE[6] 为了区分异质信息网络中不同类型的关系，借鉴知识表示的思想学习网络表示。\n\n## 3. 深层模型\n\n深层模型就是用神经网络进行深度建模。在推荐领域，一般主要分析 user 和 item 之间的交互矩阵来得到 user 和 item 之间的隐含特征，但是考虑到异质信息网络实际上包含了不同方面的交互信息，NeuACF[7] 尝试将不同方面的信息融合。如图 5 所示，先通过一些不同方面的元路径抽取不同维度的信息。例如，通过 UIU 和 IUI 抽取用户购买记录方面的特征，UIBIU 和 IBI 元路径可以抽取出品牌方面的信息。然后构造出 aspect-level 的相似性矩阵，然后用 MLP 学习 aspect-level 的潜在因子，最后用 attention 机制将 aspect-level 的潜在因子融合，得到损失函数。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icas3JGGoiaxiaT9CeU9hB1Nxns09uwIp5wgia0XM9ew8tibZ5HYDSyocHqQ/640?wx_fmt=png)\n\n图 5：NeuACF 的框架示意图\n\n</center>\n\n### Attention 机制\n\nAttention 机制在图神经网络中有着重要的应用，但是在异质信息网络中应用 attention 需要两方面的考虑：一个是节点级别的 attention，考虑节点与邻居之间的 attention；另外一个是语义级别的 attention，即在元路径上将节点信息通过 attention 聚合。基于此，HAN 模型将 attention 机制应用到异质信息网络中。如图 6 所示，HAN[8] 首先把节点映射到相同的特征空间，然后用一个 node 级别的 attention 机制，把这些邻居节点聚合起来，再用 semantic attention 机制将元路径信息融合。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ic8Sr3NxfcPWEmaxow1K7MFE6HVy4MEa4PmSzKPyAL00SGx8xVCrTtbA/640?wx_fmt=png)\n\n图 6：HAN 框架示意图\n\n</center>\n\n在异质图中，不同类型的节点有不同类型的属性特征。HetGNN 将节点的属性信息融合到异质信息网络中。如图 7 所示，HetGNN[9] 先考虑某一类型节点的属性信息，通过神经网络将节点不同模态的属性信息融合起来，然后将节点的一跳邻居中同一类型的节点用 BLSTM 融合起来，最后再将不同类型的节点信息通过神经网络聚合。HetGNN 可以处理异质关系和异质属性。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icePnrRnxAIkldibTXpj9zoicjpzJ3eOiaRslFTSWJmFq1urtfTWWj7LrTw/640?wx_fmt=png)\n\n图 7：HetGNN 架构示意图\n\n</center>\n\n### 元路径选择\n\n元路径选择是异质信息网络分析的基本步骤，一般来说，都是选择连接关系比较丰富、语义特性比较强的元路径。但是找到这样的元路径需要比较多的领域知识，在实际操作中也会存在一些问题。为此，石川给出了三种解决思路：\n\n1. 把元路径提纯，不同的元路径表示不同方面的信息，再把不同方面纯化后的信息融合起来；\n\n2. 可以舍弃元路径，元路径之所以重要是因为它能抽取高阶关系，如果不用元路径也可以通过保持网络模式的结构特性学习到高阶关系；\n\n3. 自动找寻元路径，例如知识图谱里面有些节点之间存在内在关系，可以借鉴知识补全的思路自动生成元路径。\n\n## 4. 异质图神经网络的应用\n\n### 4.1 套现用户检测\n\n套现是套取现金的简称，一般是指用违法或虚假的手段交换取得现金利益。如图８所示，判断一个用户是不是套现用户，传统方法是把套现用户检测看成一个分类问题，通过抽取出用户特征，然后用分类器来进行分类。这个过程的一个关键问题是怎么才能够抽取出足够丰富的特征。而在电商特别是互联网金融方面，用户特征大量蕴含在交互行为里面，那么怎么从这种交互行为里面抽取出用户特征，是这个问题的关键。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icicORhazwu7WUicAZicjaMJk56s3CMyCHsx2AbMPlQrg3mm1ahoQ3icNjHg/640?wx_fmt=png)\n\n图8：套现用户检测的关键问题和传统解决方案  \n\n</center>\n\n对此，[10] 提出把用户、商家、设备等信息的交互关系构建为一个**异质网络**，网络要学出用户的特征表示。进一步提出的模型首先考虑用户的自然属性信息，以及用户基于不同元路径的邻居。更进一步把用户的不同 Feature 和其邻居特征通过 Feature attention 机制融合起来，最后利用 Path 相关的 Attention，把基于不同元路径的特征融合起来。模型的相关结构说明如图 8 所示 [MOU1] 。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icOeSy2cIYD8hEXLZy3UMVXUWJYVGtWKt7xl4LrBJwCDtJDJkcCRTW0A/640?wx_fmt=png)\n\n图 9：用户套现用户检测模型的相关说明\n\n</center>\n\n### 4.2 意图推荐\n\n意图推荐就是分析用户的潜在意图。\n\n可以设计一个异质网络来解决这个问题 [11]。如图 9 所示，网络中刻划了用户、物品和查询词三者之间的交互关系，模型来学习 user、item、query 之间的表示，然后看看针对一个用户来推荐什么样的 query。我们同样是基于元路径来聚合邻居信息，在这个过程中可以利用不同的元路径来聚合不同的邻居信息。实际问题当中，user、item、query 的量级是相当大的，在亿级的规模。但是用于组成它们的 word 的数量实际上是不大的，大概是十万级别的。那么仅仅学习 word 的特征表示，然后 query 和 item 的特征由一些 word 拼接而成的，这样就减少了计算量。通过和工业界的算法对比，提出的方法利用增加的元路径信息得到了性能的稳步提升。\n\n<center>\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ictxic6OoMbEm7xcBIicl2360xxbB7Z7oIedpysRkexicFPMadibWHSJib0Zg/640?wx_fmt=png)\n\n图 10：用于意图推荐的异质图神经网络\n\n</center>\n\n### 4.3 用户聚类\n\n用户聚类是利用用户的特征信息，以及用户的社交连接关系对用户做一个类别划分，对广告推荐是很有帮助的。目前深度学习已经广泛应用于推荐、聚类任务当中。\n\n聚类主要是分析用户的特征信息，特征实际上也包含有结构信息，把结构和特征两方面联合起来做聚类：\n\n[12] 首先用深度神经网络学得用户的隐含特征表示，这是深度聚类里面常用的做法。 **另一方面，根据用户的社交关系，构造 KNN 图得到用户的关联图，学得表示过程中，把 DNN 里面学的每一层的特征和 GCN 里面的节点特征表示拼合起来再做聚合。**  如图 10 所示，在这个过程当中，由于这里的 GCN 需要有监督信息，我们把在 DNN 里面做的聚类做一个软划分，得到 Q 分布，进而取平方得到 P 分布，这里的 P 分布当作一个伪标签来指导 GNN 学习，取得了比较明显的效果。\n\n![](https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmPwSfGAlNcj9tQg97ErEfZvgcc9Mm8x7iaGhUng41oyDs5HESZtchFw/640?wx_fmt=png)\n\n图 11：用户聚类模型中 GNN 的监督学习\n\n除了上面的介绍之外，还有一些其他的应用。如共享推荐中一个用户是否把新闻或者商品推荐给他的朋友；基于朋友关系的推荐中根据朋友的点赞信息决定是否给用户推荐。对于这些含有丰富交互信息的应用场景都可以采用异质网络建模和采用图神经网络进行分析。\n\n## 结语\n\n关于异质信息网络特别是异质图网络的未来研究方向：\n\n*   异质图神经网络内在学习机理\n    \n*   动态网络\n    \n*   多模态数据处理\n    \n\n异质信息网络的更多资料可以访问网站：www.shichuan.org.\n\n**Q&A：**\n\n**Q1: 为什么知识图谱表示学习方法很少用到异质网络表示学习中？**\n\nA1: 我认为知识图谱可以看成是一种异质网络，它是一种模式丰富的异质网络，那么在这种网络里面，它有很多不同类型的结点，有很多不同类型的关系。这个的话实际上是传统的异质网络很少分析的，也是很难分析的。网络表示学习和知识图谱的表示学习，是两种不同的角度来做不同的事情，其实我觉得二者是可以相互借鉴、相互结合的，但是目前还没有什么太多太好的工作。\n\n**Q2: 网络表示学习的结果如何与结点的属性特征、描述类的文本特征进行融合，难点在哪里？以及如何自动发现元路径？**\n\nA2: 一般的话还是要根据领域知识来选择一些语意，选择语意明确、结构丰富的这样一些元路径，这样选出的路径对于实际问题一般来说效果都还不错。\n\n**Q3: 广度学习主要是通过定义元路径来实现的吗？可以谈一谈广度学习和图神经网络的关系以及二者今后如何发展情况吗？**\n\nA3: 广度学习是近些年 Philip S Yu 教授倡导的一个研究方向，里面的主要一种技术方法也是用异质信息网络，异质信息网络可以很自然的把不同方面的信息关联起来，起到一个信息融合的作用。在这里面我们可以用元路径，那么就是说可以融合不同方面的信息，抽取不同方面的这种子结构。所以这是里面一个很重要的方法。\n\n**Q4: 异质信息网络下一步的发展方向是什么？**\n\nA3: 一个是我前面说到的，元路径选择的困境，实际上这是长期困扰这个领域的一个事情。因为这个领域的分析是严重依赖于元路径，怎么能够不依赖于元路径，或者设计一些更好的方法，能够探索语意信息，这是一个方向。在异质图神经网络里面如何更好的做聚合，实际上是研究也才刚刚开始。然后还有像这种动态网络的，在异质图里面怎么考虑这种动态性等等，都值得深入研究。\n\n**参考文献**\n\n[1] YuXiao Dong,Nitesh V. Chawla,Ananthram Swami. Metapath2vec: Scalable Representation Learning for Heterogeneous Networks. KDD， 2017.\n\n[2] Chuan Shi, Binbin Hu, Wayne XinZhao, Philip S. Yu. Heterogeneous Information Network Embedding for Recommendation.TKDE,2018.\n\n[3] Tao-yang Fu, Wang-Chien Lee, ZhenLei. HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning. CIKM,2017.\n\n[4] Binbin Hu, Chuan Shi, Wayne XinZhao, Philip S. Yu. Leveraging Meta-path based Context for Top-N Recommendation with A Neural Co-Attention Model. KDD,2018.\n\n[5] Binbin Hu, Yuan Fang, Chuan Shi.Adversarial Learning on Heterogeneous Information Networks. KDD,2019.\n\n[6] Chuan Shi, Yuanfu Lu, Linmei Hu,Zhiyuan Liu et al. RHINE: Relation Structure-Aware Heterogeneous Information Network Embedding. TKDE, 2020\n\n[7] Xiaotian Han, Chuan Shi, SenzhangWang, Philip S. Yu, Li Song.Aspect-Level Deep Collaborative Filtering viaHeterogeneous Information Networks. IJCAI,2018.\n\n[8] Wang, Xiao, Houye Ji, Chuan Shi,Bai Wang, Yanfang Ye, Peng Cui, and Philip S. Yu. Heterogeneous Graph Attention Network. WWW,2019.\n\n[9] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V. Chawla. Heterogeneous Graph Neural Network.KDD,2019.\n\n[10] Binbin Hu, Zhiqiang Zhang, Chuan Shi, Jun Zhou, XiaoLong Li, Yuan Qi Cash-out User Detection based on Attributed HeterogeneousInformation Network with a Hierarchical Attention Mechanism. AAAI,2019.\n\n[11] Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi,Linmei Hu, Biyu Ma, Yongliang Li Metapath-guided Heterogeneous Graph NeuralNetwork for Intent Recommendation. KDD,2019.\n\n[12] Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu, PengCui. Structural Deep Clustering Network. WWW,2020. \n\n## Reference\n\n[北邮教授石川：图神经网络需要解决的几个关键问题](https://mp.weixin.qq.com/s?__biz=MzU5ODg0MTAwMw==&mid=2247486047&idx=1&sn=2052f3f96135cbe48ddfa96841bc404d&chksm=febf499bc9c8c08d99bbf2cc6fee48414b4d920bdaa01ec9c68c9fba74fd634331274af10f09&mpshare=1&scene=23&srcid=&sharer_sharetime=1586774527616&sharer_shareid=fc06814c3a0ce2f45e4998813d787a8f#rd)","slug":"GNN需要解决的关键问题","published":1,"updated":"2020-06-08T06:04:28.499Z","_id":"ck92uhlzl0000dcym3h938x6h","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"“图神经网络在线研讨会2020”-笔记\"><a href=\"#“图神经网络在线研讨会2020”-笔记\" class=\"headerlink\" title=\"“图神经网络在线研讨会2020” 笔记\"></a>“图神经网络在线研讨会2020” 笔记</h1><h2 id=\"1-从同质到异质\"><a href=\"#1-从同质到异质\" class=\"headerlink\" title=\"1. 从同质到异质\"></a>1. 从同质到异质</h2><p>目前很多图神经网络主要是基于同质信息网络，同质信息网络只有一种类型的节点和边；</p>\n<p>在实际应用中，会存在大量由不同节点和边构成的交互系统，例如文献数据、电影数据、以及社交网络知识图谱等，在这些网络中，不同类型的对象相互交互。不同类型的对象性质不同，交互关系的特性不同会导致很大差异的分析，所以在异质网络中，需要考虑不同类型的对象交互关系对结果的影响。</p>\n<p>在异质信息网络中，网络模式是对一个网络的元级描述，刻画了网络中包含了不同类型的对象和不同类型的关系。例如在图 1 的网络实例中，描述了作者撰写论文，论文发表在会议上；这个网络实例就包含三类对象：作者、论文和会议，以及他们之间的相互交互关系。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icdwveTm3DV8picININawtSibDUFicuoyNh6DnxhxTVNnGFlWIwLyrpOoHg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 1：异质信息网络实例</p>\n</center>\n\n<h3 id=\"元路径\"><a href=\"#元路径\" class=\"headerlink\" title=\"元路径\"></a>元路径</h3><p>元路径是异质信息网络中另外一个很重要的概念。简而言之，元路径就是连接两个对象的一个关系序列。</p>\n<p>如图 2 所示，连接两个 author 可以有不同的元路径。例如：author-&gt;paper-&gt;author，描述的是两个作者之间的合作关系；还可以有 author-&gt;paper-&gt;venue-&gt;paper-&gt;author，这条元路径描述的是两个作者参加同一个会议这么一个关系。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icIYG6IA8nEH1G7xTLGdJmRRzPSqtM6iclKRWWdnVnwT8ddHaDlE8fLrA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 2：异质信息网络中的元路径</p>\n</center>\n\n<p>也提出了很多其他一些概念，例如元图，元结构，以及有约束的元路径等一些概念，它可以更细致的描述网络里面的属性信息。</p>\n<p>石川指出，异质信息网络表示学习目前存在一些挑战，例如如何解决异质性、如何融合信息以及捕捉丰富的语义信息等，主要的解决方案有<strong>经典浅层模型</strong>和<strong>深度模型</strong>两个方面。</p>\n<h2 id=\"2-浅层模型\"><a href=\"#2-浅层模型\" class=\"headerlink\" title=\"2. 浅层模型\"></a>2. 浅层模型</h2><p>在同质网络中，有一些很经典的浅层模型，例如 DeepWalk、Line 等一系列方法，这些方法的核心思想是基于随机游走产生一个节点序列，然后类比于自然语言处理单词序列的方法，通过 skip-gram 的方法来学习网络表示。</p>\n<p>在异质网络中也是采用类似的思路，为了高效的随机游走，一般是采用元路径的随机游走方式，元路径在游走的过程中可以把节点类型信息和边类型信息固定下来。图 3 为基于元路径随机游走的范式，给以一个元路径，如果是按照给定元路径游走的话，转移概率就是指定类型节点的邻居数目分之一，不按照元路径游走的话，转移概率就是 0。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmFl5gia2CcLtJwvxuF6K6vyXfAG45nZPKljCKX21ZrfZCiaibqq40eeMA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 3：基于元路径的随机游走  </p>\n</center>\n\n<p>针对元路径的随机游走，然后采用 skim-gram 来进行目标优化，metapath2vec 和 metapath2vec++ 有一个区别如图 4 所示。在 soft-max 操作中，metapath2vec++ 在分母中是按照下一个节点类型中的所有节点求和的，而 metapath2vec 是不考虑节点类型，直接对所有节点求和。metapath2vec++ 的优点在于考虑下一个节点的节点类型可以使游走概率的值大一些，在很多情况下效果会好一些。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmYnOlGUjAFnQicdYvyljLbQuqfHibR8onSPvVH2en6RQc5xib2bA9Ee3g/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 4：计算概率中 metapath2vector（上）和 metapath2vec++（下）</p>\n<p>Metapath2vec 是基于元路径随机游走和 skim-gram 的方式解决异质性，也基本上奠基了这个方向研究的基本思路。</p>\n<p>HERec[2] 是另外一种处理异质信息网络的浅层模型，它的基本思路是通过一些对称的元路径将异质图变成同质图，然后在同质图中用 DeepWalk、Line 等方法学习到网络表示。另外一种基于游走的方法是 HIN2Vec[3]，首先 HIN2Vec 在异质网络中游走，抽取点边序列，即节点 X、Y 和它们之间对应的关系 R，在游走的过程中点边序列抽取出来就可以构成序列样本，然后就可以通过判断节点 X、Y 是否具有关系 R 把原来的问题变成分类问题，将分类问题作为优化目标学习网络表示。</p>\n<p>Metapath2vec、HERec 和 HIN2Vec 是异质信息网络表示的三个早期的工作，给后来的工作奠定了基础。最近几年也有一些比较优秀的工作。MCRec[4] 通过刻画 user 和 item 的丰富的交互关系来学习节点表示。为了找到有代表性的负样本，HeGAN[5] 根据关系类型用 GAN 生成好的负样本。RHINE[6] 为了区分异质信息网络中不同类型的关系，借鉴知识表示的思想学习网络表示。</p>\n<h2 id=\"3-深层模型\"><a href=\"#3-深层模型\" class=\"headerlink\" title=\"3. 深层模型\"></a>3. 深层模型</h2><p>深层模型就是用神经网络进行深度建模。在推荐领域，一般主要分析 user 和 item 之间的交互矩阵来得到 user 和 item 之间的隐含特征，但是考虑到异质信息网络实际上包含了不同方面的交互信息，NeuACF[7] 尝试将不同方面的信息融合。如图 5 所示，先通过一些不同方面的元路径抽取不同维度的信息。例如，通过 UIU 和 IUI 抽取用户购买记录方面的特征，UIBIU 和 IBI 元路径可以抽取出品牌方面的信息。然后构造出 aspect-level 的相似性矩阵，然后用 MLP 学习 aspect-level 的潜在因子，最后用 attention 机制将 aspect-level 的潜在因子融合，得到损失函数。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icas3JGGoiaxiaT9CeU9hB1Nxns09uwIp5wgia0XM9ew8tibZ5HYDSyocHqQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 5：NeuACF 的框架示意图</p>\n</center>\n\n<h3 id=\"Attention-机制\"><a href=\"#Attention-机制\" class=\"headerlink\" title=\"Attention 机制\"></a>Attention 机制</h3><p>Attention 机制在图神经网络中有着重要的应用，但是在异质信息网络中应用 attention 需要两方面的考虑：一个是节点级别的 attention，考虑节点与邻居之间的 attention；另外一个是语义级别的 attention，即在元路径上将节点信息通过 attention 聚合。基于此，HAN 模型将 attention 机制应用到异质信息网络中。如图 6 所示，HAN[8] 首先把节点映射到相同的特征空间，然后用一个 node 级别的 attention 机制，把这些邻居节点聚合起来，再用 semantic attention 机制将元路径信息融合。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ic8Sr3NxfcPWEmaxow1K7MFE6HVy4MEa4PmSzKPyAL00SGx8xVCrTtbA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 6：HAN 框架示意图</p>\n</center>\n\n<p>在异质图中，不同类型的节点有不同类型的属性特征。HetGNN 将节点的属性信息融合到异质信息网络中。如图 7 所示，HetGNN[9] 先考虑某一类型节点的属性信息，通过神经网络将节点不同模态的属性信息融合起来，然后将节点的一跳邻居中同一类型的节点用 BLSTM 融合起来，最后再将不同类型的节点信息通过神经网络聚合。HetGNN 可以处理异质关系和异质属性。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icePnrRnxAIkldibTXpj9zoicjpzJ3eOiaRslFTSWJmFq1urtfTWWj7LrTw/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 7：HetGNN 架构示意图</p>\n</center>\n\n<h3 id=\"元路径选择\"><a href=\"#元路径选择\" class=\"headerlink\" title=\"元路径选择\"></a>元路径选择</h3><p>元路径选择是异质信息网络分析的基本步骤，一般来说，都是选择连接关系比较丰富、语义特性比较强的元路径。但是找到这样的元路径需要比较多的领域知识，在实际操作中也会存在一些问题。为此，石川给出了三种解决思路：</p>\n<ol>\n<li><p>把元路径提纯，不同的元路径表示不同方面的信息，再把不同方面纯化后的信息融合起来；</p>\n</li>\n<li><p>可以舍弃元路径，元路径之所以重要是因为它能抽取高阶关系，如果不用元路径也可以通过保持网络模式的结构特性学习到高阶关系；</p>\n</li>\n<li><p>自动找寻元路径，例如知识图谱里面有些节点之间存在内在关系，可以借鉴知识补全的思路自动生成元路径。</p>\n</li>\n</ol>\n<h2 id=\"4-异质图神经网络的应用\"><a href=\"#4-异质图神经网络的应用\" class=\"headerlink\" title=\"4. 异质图神经网络的应用\"></a>4. 异质图神经网络的应用</h2><h3 id=\"4-1-套现用户检测\"><a href=\"#4-1-套现用户检测\" class=\"headerlink\" title=\"4.1 套现用户检测\"></a>4.1 套现用户检测</h3><p>套现是套取现金的简称，一般是指用违法或虚假的手段交换取得现金利益。如图８所示，判断一个用户是不是套现用户，传统方法是把套现用户检测看成一个分类问题，通过抽取出用户特征，然后用分类器来进行分类。这个过程的一个关键问题是怎么才能够抽取出足够丰富的特征。而在电商特别是互联网金融方面，用户特征大量蕴含在交互行为里面，那么怎么从这种交互行为里面抽取出用户特征，是这个问题的关键。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icicORhazwu7WUicAZicjaMJk56s3CMyCHsx2AbMPlQrg3mm1ahoQ3icNjHg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图8：套现用户检测的关键问题和传统解决方案  </p>\n</center>\n\n<p>对此，[10] 提出把用户、商家、设备等信息的交互关系构建为一个<strong>异质网络</strong>，网络要学出用户的特征表示。进一步提出的模型首先考虑用户的自然属性信息，以及用户基于不同元路径的邻居。更进一步把用户的不同 Feature 和其邻居特征通过 Feature attention 机制融合起来，最后利用 Path 相关的 Attention，把基于不同元路径的特征融合起来。模型的相关结构说明如图 8 所示 [MOU1] 。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icOeSy2cIYD8hEXLZy3UMVXUWJYVGtWKt7xl4LrBJwCDtJDJkcCRTW0A/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 9：用户套现用户检测模型的相关说明</p>\n</center>\n\n<h3 id=\"4-2-意图推荐\"><a href=\"#4-2-意图推荐\" class=\"headerlink\" title=\"4.2 意图推荐\"></a>4.2 意图推荐</h3><p>意图推荐就是分析用户的潜在意图。</p>\n<p>可以设计一个异质网络来解决这个问题 [11]。如图 9 所示，网络中刻划了用户、物品和查询词三者之间的交互关系，模型来学习 user、item、query 之间的表示，然后看看针对一个用户来推荐什么样的 query。我们同样是基于元路径来聚合邻居信息，在这个过程中可以利用不同的元路径来聚合不同的邻居信息。实际问题当中，user、item、query 的量级是相当大的，在亿级的规模。但是用于组成它们的 word 的数量实际上是不大的，大概是十万级别的。那么仅仅学习 word 的特征表示，然后 query 和 item 的特征由一些 word 拼接而成的，这样就减少了计算量。通过和工业界的算法对比，提出的方法利用增加的元路径信息得到了性能的稳步提升。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ictxic6OoMbEm7xcBIicl2360xxbB7Z7oIedpysRkexicFPMadibWHSJib0Zg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 10：用于意图推荐的异质图神经网络</p>\n</center>\n\n<h3 id=\"4-3-用户聚类\"><a href=\"#4-3-用户聚类\" class=\"headerlink\" title=\"4.3 用户聚类\"></a>4.3 用户聚类</h3><p>用户聚类是利用用户的特征信息，以及用户的社交连接关系对用户做一个类别划分，对广告推荐是很有帮助的。目前深度学习已经广泛应用于推荐、聚类任务当中。</p>\n<p>聚类主要是分析用户的特征信息，特征实际上也包含有结构信息，把结构和特征两方面联合起来做聚类：</p>\n<p>[12] 首先用深度神经网络学得用户的隐含特征表示，这是深度聚类里面常用的做法。 <strong>另一方面，根据用户的社交关系，构造 KNN 图得到用户的关联图，学得表示过程中，把 DNN 里面学的每一层的特征和 GCN 里面的节点特征表示拼合起来再做聚合。</strong>  如图 10 所示，在这个过程当中，由于这里的 GCN 需要有监督信息，我们把在 DNN 里面做的聚类做一个软划分，得到 Q 分布，进而取平方得到 P 分布，这里的 P 分布当作一个伪标签来指导 GNN 学习，取得了比较明显的效果。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmPwSfGAlNcj9tQg97ErEfZvgcc9Mm8x7iaGhUng41oyDs5HESZtchFw/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 11：用户聚类模型中 GNN 的监督学习</p>\n<p>除了上面的介绍之外，还有一些其他的应用。如共享推荐中一个用户是否把新闻或者商品推荐给他的朋友；基于朋友关系的推荐中根据朋友的点赞信息决定是否给用户推荐。对于这些含有丰富交互信息的应用场景都可以采用异质网络建模和采用图神经网络进行分析。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>关于异质信息网络特别是异质图网络的未来研究方向：</p>\n<ul>\n<li><p>异质图神经网络内在学习机理</p>\n</li>\n<li><p>动态网络</p>\n</li>\n<li><p>多模态数据处理</p>\n</li>\n</ul>\n<p>异质信息网络的更多资料可以访问网站：<a href=\"http://www.shichuan.org\" target=\"_blank\" rel=\"noopener\">www.shichuan.org</a>.</p>\n<p><strong>Q&amp;A：</strong></p>\n<p><strong>Q1: 为什么知识图谱表示学习方法很少用到异质网络表示学习中？</strong></p>\n<p>A1: 我认为知识图谱可以看成是一种异质网络，它是一种模式丰富的异质网络，那么在这种网络里面，它有很多不同类型的结点，有很多不同类型的关系。这个的话实际上是传统的异质网络很少分析的，也是很难分析的。网络表示学习和知识图谱的表示学习，是两种不同的角度来做不同的事情，其实我觉得二者是可以相互借鉴、相互结合的，但是目前还没有什么太多太好的工作。</p>\n<p><strong>Q2: 网络表示学习的结果如何与结点的属性特征、描述类的文本特征进行融合，难点在哪里？以及如何自动发现元路径？</strong></p>\n<p>A2: 一般的话还是要根据领域知识来选择一些语意，选择语意明确、结构丰富的这样一些元路径，这样选出的路径对于实际问题一般来说效果都还不错。</p>\n<p><strong>Q3: 广度学习主要是通过定义元路径来实现的吗？可以谈一谈广度学习和图神经网络的关系以及二者今后如何发展情况吗？</strong></p>\n<p>A3: 广度学习是近些年 Philip S Yu 教授倡导的一个研究方向，里面的主要一种技术方法也是用异质信息网络，异质信息网络可以很自然的把不同方面的信息关联起来，起到一个信息融合的作用。在这里面我们可以用元路径，那么就是说可以融合不同方面的信息，抽取不同方面的这种子结构。所以这是里面一个很重要的方法。</p>\n<p><strong>Q4: 异质信息网络下一步的发展方向是什么？</strong></p>\n<p>A3: 一个是我前面说到的，元路径选择的困境，实际上这是长期困扰这个领域的一个事情。因为这个领域的分析是严重依赖于元路径，怎么能够不依赖于元路径，或者设计一些更好的方法，能够探索语意信息，这是一个方向。在异质图神经网络里面如何更好的做聚合，实际上是研究也才刚刚开始。然后还有像这种动态网络的，在异质图里面怎么考虑这种动态性等等，都值得深入研究。</p>\n<p><strong>参考文献</strong></p>\n<p>[1] YuXiao Dong,Nitesh V. Chawla,Ananthram Swami. Metapath2vec: Scalable Representation Learning for Heterogeneous Networks. KDD， 2017.</p>\n<p>[2] Chuan Shi, Binbin Hu, Wayne XinZhao, Philip S. Yu. Heterogeneous Information Network Embedding for Recommendation.TKDE,2018.</p>\n<p>[3] Tao-yang Fu, Wang-Chien Lee, ZhenLei. HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning. CIKM,2017.</p>\n<p>[4] Binbin Hu, Chuan Shi, Wayne XinZhao, Philip S. Yu. Leveraging Meta-path based Context for Top-N Recommendation with A Neural Co-Attention Model. KDD,2018.</p>\n<p>[5] Binbin Hu, Yuan Fang, Chuan Shi.Adversarial Learning on Heterogeneous Information Networks. KDD,2019.</p>\n<p>[6] Chuan Shi, Yuanfu Lu, Linmei Hu,Zhiyuan Liu et al. RHINE: Relation Structure-Aware Heterogeneous Information Network Embedding. TKDE, 2020</p>\n<p>[7] Xiaotian Han, Chuan Shi, SenzhangWang, Philip S. Yu, Li Song.Aspect-Level Deep Collaborative Filtering viaHeterogeneous Information Networks. IJCAI,2018.</p>\n<p>[8] Wang, Xiao, Houye Ji, Chuan Shi,Bai Wang, Yanfang Ye, Peng Cui, and Philip S. Yu. Heterogeneous Graph Attention Network. WWW,2019.</p>\n<p>[9] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V. Chawla. Heterogeneous Graph Neural Network.KDD,2019.</p>\n<p>[10] Binbin Hu, Zhiqiang Zhang, Chuan Shi, Jun Zhou, XiaoLong Li, Yuan Qi Cash-out User Detection based on Attributed HeterogeneousInformation Network with a Hierarchical Attention Mechanism. AAAI,2019.</p>\n<p>[11] Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi,Linmei Hu, Biyu Ma, Yongliang Li Metapath-guided Heterogeneous Graph NeuralNetwork for Intent Recommendation. KDD,2019.</p>\n<p>[12] Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu, PengCui. Structural Deep Clustering Network. WWW,2020. </p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU5ODg0MTAwMw==&mid=2247486047&idx=1&sn=2052f3f96135cbe48ddfa96841bc404d&chksm=febf499bc9c8c08d99bbf2cc6fee48414b4d920bdaa01ec9c68c9fba74fd634331274af10f09&mpshare=1&scene=23&srcid=&sharer_sharetime=1586774527616&sharer_shareid=fc06814c3a0ce2f45e4998813d787a8f#rd\" target=\"_blank\" rel=\"noopener\">北邮教授石川：图神经网络需要解决的几个关键问题</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"“图神经网络在线研讨会2020”-笔记\"><a href=\"#“图神经网络在线研讨会2020”-笔记\" class=\"headerlink\" title=\"“图神经网络在线研讨会2020” 笔记\"></a>“图神经网络在线研讨会2020” 笔记</h1><h2 id=\"1-从同质到异质\"><a href=\"#1-从同质到异质\" class=\"headerlink\" title=\"1. 从同质到异质\"></a>1. 从同质到异质</h2><p>目前很多图神经网络主要是基于同质信息网络，同质信息网络只有一种类型的节点和边；</p>\n<p>在实际应用中，会存在大量由不同节点和边构成的交互系统，例如文献数据、电影数据、以及社交网络知识图谱等，在这些网络中，不同类型的对象相互交互。不同类型的对象性质不同，交互关系的特性不同会导致很大差异的分析，所以在异质网络中，需要考虑不同类型的对象交互关系对结果的影响。</p>\n<p>在异质信息网络中，网络模式是对一个网络的元级描述，刻画了网络中包含了不同类型的对象和不同类型的关系。例如在图 1 的网络实例中，描述了作者撰写论文，论文发表在会议上；这个网络实例就包含三类对象：作者、论文和会议，以及他们之间的相互交互关系。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icdwveTm3DV8picININawtSibDUFicuoyNh6DnxhxTVNnGFlWIwLyrpOoHg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 1：异质信息网络实例</p>\n</center>\n\n<h3 id=\"元路径\"><a href=\"#元路径\" class=\"headerlink\" title=\"元路径\"></a>元路径</h3><p>元路径是异质信息网络中另外一个很重要的概念。简而言之，元路径就是连接两个对象的一个关系序列。</p>\n<p>如图 2 所示，连接两个 author 可以有不同的元路径。例如：author-&gt;paper-&gt;author，描述的是两个作者之间的合作关系；还可以有 author-&gt;paper-&gt;venue-&gt;paper-&gt;author，这条元路径描述的是两个作者参加同一个会议这么一个关系。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icIYG6IA8nEH1G7xTLGdJmRRzPSqtM6iclKRWWdnVnwT8ddHaDlE8fLrA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 2：异质信息网络中的元路径</p>\n</center>\n\n<p>也提出了很多其他一些概念，例如元图，元结构，以及有约束的元路径等一些概念，它可以更细致的描述网络里面的属性信息。</p>\n<p>石川指出，异质信息网络表示学习目前存在一些挑战，例如如何解决异质性、如何融合信息以及捕捉丰富的语义信息等，主要的解决方案有<strong>经典浅层模型</strong>和<strong>深度模型</strong>两个方面。</p>\n<h2 id=\"2-浅层模型\"><a href=\"#2-浅层模型\" class=\"headerlink\" title=\"2. 浅层模型\"></a>2. 浅层模型</h2><p>在同质网络中，有一些很经典的浅层模型，例如 DeepWalk、Line 等一系列方法，这些方法的核心思想是基于随机游走产生一个节点序列，然后类比于自然语言处理单词序列的方法，通过 skip-gram 的方法来学习网络表示。</p>\n<p>在异质网络中也是采用类似的思路，为了高效的随机游走，一般是采用元路径的随机游走方式，元路径在游走的过程中可以把节点类型信息和边类型信息固定下来。图 3 为基于元路径随机游走的范式，给以一个元路径，如果是按照给定元路径游走的话，转移概率就是指定类型节点的邻居数目分之一，不按照元路径游走的话，转移概率就是 0。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmFl5gia2CcLtJwvxuF6K6vyXfAG45nZPKljCKX21ZrfZCiaibqq40eeMA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 3：基于元路径的随机游走  </p>\n</center>\n\n<p>针对元路径的随机游走，然后采用 skim-gram 来进行目标优化，metapath2vec 和 metapath2vec++ 有一个区别如图 4 所示。在 soft-max 操作中，metapath2vec++ 在分母中是按照下一个节点类型中的所有节点求和的，而 metapath2vec 是不考虑节点类型，直接对所有节点求和。metapath2vec++ 的优点在于考虑下一个节点的节点类型可以使游走概率的值大一些，在很多情况下效果会好一些。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmYnOlGUjAFnQicdYvyljLbQuqfHibR8onSPvVH2en6RQc5xib2bA9Ee3g/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 4：计算概率中 metapath2vector（上）和 metapath2vec++（下）</p>\n<p>Metapath2vec 是基于元路径随机游走和 skim-gram 的方式解决异质性，也基本上奠基了这个方向研究的基本思路。</p>\n<p>HERec[2] 是另外一种处理异质信息网络的浅层模型，它的基本思路是通过一些对称的元路径将异质图变成同质图，然后在同质图中用 DeepWalk、Line 等方法学习到网络表示。另外一种基于游走的方法是 HIN2Vec[3]，首先 HIN2Vec 在异质网络中游走，抽取点边序列，即节点 X、Y 和它们之间对应的关系 R，在游走的过程中点边序列抽取出来就可以构成序列样本，然后就可以通过判断节点 X、Y 是否具有关系 R 把原来的问题变成分类问题，将分类问题作为优化目标学习网络表示。</p>\n<p>Metapath2vec、HERec 和 HIN2Vec 是异质信息网络表示的三个早期的工作，给后来的工作奠定了基础。最近几年也有一些比较优秀的工作。MCRec[4] 通过刻画 user 和 item 的丰富的交互关系来学习节点表示。为了找到有代表性的负样本，HeGAN[5] 根据关系类型用 GAN 生成好的负样本。RHINE[6] 为了区分异质信息网络中不同类型的关系，借鉴知识表示的思想学习网络表示。</p>\n<h2 id=\"3-深层模型\"><a href=\"#3-深层模型\" class=\"headerlink\" title=\"3. 深层模型\"></a>3. 深层模型</h2><p>深层模型就是用神经网络进行深度建模。在推荐领域，一般主要分析 user 和 item 之间的交互矩阵来得到 user 和 item 之间的隐含特征，但是考虑到异质信息网络实际上包含了不同方面的交互信息，NeuACF[7] 尝试将不同方面的信息融合。如图 5 所示，先通过一些不同方面的元路径抽取不同维度的信息。例如，通过 UIU 和 IUI 抽取用户购买记录方面的特征，UIBIU 和 IBI 元路径可以抽取出品牌方面的信息。然后构造出 aspect-level 的相似性矩阵，然后用 MLP 学习 aspect-level 的潜在因子，最后用 attention 机制将 aspect-level 的潜在因子融合，得到损失函数。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icas3JGGoiaxiaT9CeU9hB1Nxns09uwIp5wgia0XM9ew8tibZ5HYDSyocHqQ/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 5：NeuACF 的框架示意图</p>\n</center>\n\n<h3 id=\"Attention-机制\"><a href=\"#Attention-机制\" class=\"headerlink\" title=\"Attention 机制\"></a>Attention 机制</h3><p>Attention 机制在图神经网络中有着重要的应用，但是在异质信息网络中应用 attention 需要两方面的考虑：一个是节点级别的 attention，考虑节点与邻居之间的 attention；另外一个是语义级别的 attention，即在元路径上将节点信息通过 attention 聚合。基于此，HAN 模型将 attention 机制应用到异质信息网络中。如图 6 所示，HAN[8] 首先把节点映射到相同的特征空间，然后用一个 node 级别的 attention 机制，把这些邻居节点聚合起来，再用 semantic attention 机制将元路径信息融合。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ic8Sr3NxfcPWEmaxow1K7MFE6HVy4MEa4PmSzKPyAL00SGx8xVCrTtbA/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 6：HAN 框架示意图</p>\n</center>\n\n<p>在异质图中，不同类型的节点有不同类型的属性特征。HetGNN 将节点的属性信息融合到异质信息网络中。如图 7 所示，HetGNN[9] 先考虑某一类型节点的属性信息，通过神经网络将节点不同模态的属性信息融合起来，然后将节点的一跳邻居中同一类型的节点用 BLSTM 融合起来，最后再将不同类型的节点信息通过神经网络聚合。HetGNN 可以处理异质关系和异质属性。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icePnrRnxAIkldibTXpj9zoicjpzJ3eOiaRslFTSWJmFq1urtfTWWj7LrTw/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 7：HetGNN 架构示意图</p>\n</center>\n\n<h3 id=\"元路径选择\"><a href=\"#元路径选择\" class=\"headerlink\" title=\"元路径选择\"></a>元路径选择</h3><p>元路径选择是异质信息网络分析的基本步骤，一般来说，都是选择连接关系比较丰富、语义特性比较强的元路径。但是找到这样的元路径需要比较多的领域知识，在实际操作中也会存在一些问题。为此，石川给出了三种解决思路：</p>\n<ol>\n<li><p>把元路径提纯，不同的元路径表示不同方面的信息，再把不同方面纯化后的信息融合起来；</p>\n</li>\n<li><p>可以舍弃元路径，元路径之所以重要是因为它能抽取高阶关系，如果不用元路径也可以通过保持网络模式的结构特性学习到高阶关系；</p>\n</li>\n<li><p>自动找寻元路径，例如知识图谱里面有些节点之间存在内在关系，可以借鉴知识补全的思路自动生成元路径。</p>\n</li>\n</ol>\n<h2 id=\"4-异质图神经网络的应用\"><a href=\"#4-异质图神经网络的应用\" class=\"headerlink\" title=\"4. 异质图神经网络的应用\"></a>4. 异质图神经网络的应用</h2><h3 id=\"4-1-套现用户检测\"><a href=\"#4-1-套现用户检测\" class=\"headerlink\" title=\"4.1 套现用户检测\"></a>4.1 套现用户检测</h3><p>套现是套取现金的简称，一般是指用违法或虚假的手段交换取得现金利益。如图８所示，判断一个用户是不是套现用户，传统方法是把套现用户检测看成一个分类问题，通过抽取出用户特征，然后用分类器来进行分类。这个过程的一个关键问题是怎么才能够抽取出足够丰富的特征。而在电商特别是互联网金融方面，用户特征大量蕴含在交互行为里面，那么怎么从这种交互行为里面抽取出用户特征，是这个问题的关键。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icicORhazwu7WUicAZicjaMJk56s3CMyCHsx2AbMPlQrg3mm1ahoQ3icNjHg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图8：套现用户检测的关键问题和传统解决方案  </p>\n</center>\n\n<p>对此，[10] 提出把用户、商家、设备等信息的交互关系构建为一个<strong>异质网络</strong>，网络要学出用户的特征表示。进一步提出的模型首先考虑用户的自然属性信息，以及用户基于不同元路径的邻居。更进一步把用户的不同 Feature 和其邻居特征通过 Feature attention 机制融合起来，最后利用 Path 相关的 Attention，把基于不同元路径的特征融合起来。模型的相关结构说明如图 8 所示 [MOU1] 。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icOeSy2cIYD8hEXLZy3UMVXUWJYVGtWKt7xl4LrBJwCDtJDJkcCRTW0A/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 9：用户套现用户检测模型的相关说明</p>\n</center>\n\n<h3 id=\"4-2-意图推荐\"><a href=\"#4-2-意图推荐\" class=\"headerlink\" title=\"4.2 意图推荐\"></a>4.2 意图推荐</h3><p>意图推荐就是分析用户的潜在意图。</p>\n<p>可以设计一个异质网络来解决这个问题 [11]。如图 9 所示，网络中刻划了用户、物品和查询词三者之间的交互关系，模型来学习 user、item、query 之间的表示，然后看看针对一个用户来推荐什么样的 query。我们同样是基于元路径来聚合邻居信息，在这个过程中可以利用不同的元路径来聚合不同的邻居信息。实际问题当中，user、item、query 的量级是相当大的，在亿级的规模。但是用于组成它们的 word 的数量实际上是不大的，大概是十万级别的。那么仅仅学习 word 的特征表示，然后 query 和 item 的特征由一些 word 拼接而成的，这样就减少了计算量。通过和工业界的算法对比，提出的方法利用增加的元路径信息得到了性能的稳步提升。</p>\n<center>\n\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9ictxic6OoMbEm7xcBIicl2360xxbB7Z7oIedpysRkexicFPMadibWHSJib0Zg/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 10：用于意图推荐的异质图神经网络</p>\n</center>\n\n<h3 id=\"4-3-用户聚类\"><a href=\"#4-3-用户聚类\" class=\"headerlink\" title=\"4.3 用户聚类\"></a>4.3 用户聚类</h3><p>用户聚类是利用用户的特征信息，以及用户的社交连接关系对用户做一个类别划分，对广告推荐是很有帮助的。目前深度学习已经广泛应用于推荐、聚类任务当中。</p>\n<p>聚类主要是分析用户的特征信息，特征实际上也包含有结构信息，把结构和特征两方面联合起来做聚类：</p>\n<p>[12] 首先用深度神经网络学得用户的隐含特征表示，这是深度聚类里面常用的做法。 <strong>另一方面，根据用户的社交关系，构造 KNN 图得到用户的关联图，学得表示过程中，把 DNN 里面学的每一层的特征和 GCN 里面的节点特征表示拼合起来再做聚合。</strong>  如图 10 所示，在这个过程当中，由于这里的 GCN 需要有监督信息，我们把在 DNN 里面做的聚类做一个软划分，得到 Q 分布，进而取平方得到 P 分布，这里的 P 分布当作一个伪标签来指导 GNN 学习，取得了比较明显的效果。</p>\n<p><img src=\"https://mmbiz.qpic.cn/mmbiz_png/ZkgfUziaPIO27tLwdPiaqjuwQqgjSG0x9icmPwSfGAlNcj9tQg97ErEfZvgcc9Mm8x7iaGhUng41oyDs5HESZtchFw/640?wx_fmt=png\" alt=\"\"></p>\n<p>图 11：用户聚类模型中 GNN 的监督学习</p>\n<p>除了上面的介绍之外，还有一些其他的应用。如共享推荐中一个用户是否把新闻或者商品推荐给他的朋友；基于朋友关系的推荐中根据朋友的点赞信息决定是否给用户推荐。对于这些含有丰富交互信息的应用场景都可以采用异质网络建模和采用图神经网络进行分析。</p>\n<h2 id=\"结语\"><a href=\"#结语\" class=\"headerlink\" title=\"结语\"></a>结语</h2><p>关于异质信息网络特别是异质图网络的未来研究方向：</p>\n<ul>\n<li><p>异质图神经网络内在学习机理</p>\n</li>\n<li><p>动态网络</p>\n</li>\n<li><p>多模态数据处理</p>\n</li>\n</ul>\n<p>异质信息网络的更多资料可以访问网站：<a href=\"http://www.shichuan.org\" target=\"_blank\" rel=\"noopener\">www.shichuan.org</a>.</p>\n<p><strong>Q&amp;A：</strong></p>\n<p><strong>Q1: 为什么知识图谱表示学习方法很少用到异质网络表示学习中？</strong></p>\n<p>A1: 我认为知识图谱可以看成是一种异质网络，它是一种模式丰富的异质网络，那么在这种网络里面，它有很多不同类型的结点，有很多不同类型的关系。这个的话实际上是传统的异质网络很少分析的，也是很难分析的。网络表示学习和知识图谱的表示学习，是两种不同的角度来做不同的事情，其实我觉得二者是可以相互借鉴、相互结合的，但是目前还没有什么太多太好的工作。</p>\n<p><strong>Q2: 网络表示学习的结果如何与结点的属性特征、描述类的文本特征进行融合，难点在哪里？以及如何自动发现元路径？</strong></p>\n<p>A2: 一般的话还是要根据领域知识来选择一些语意，选择语意明确、结构丰富的这样一些元路径，这样选出的路径对于实际问题一般来说效果都还不错。</p>\n<p><strong>Q3: 广度学习主要是通过定义元路径来实现的吗？可以谈一谈广度学习和图神经网络的关系以及二者今后如何发展情况吗？</strong></p>\n<p>A3: 广度学习是近些年 Philip S Yu 教授倡导的一个研究方向，里面的主要一种技术方法也是用异质信息网络，异质信息网络可以很自然的把不同方面的信息关联起来，起到一个信息融合的作用。在这里面我们可以用元路径，那么就是说可以融合不同方面的信息，抽取不同方面的这种子结构。所以这是里面一个很重要的方法。</p>\n<p><strong>Q4: 异质信息网络下一步的发展方向是什么？</strong></p>\n<p>A3: 一个是我前面说到的，元路径选择的困境，实际上这是长期困扰这个领域的一个事情。因为这个领域的分析是严重依赖于元路径，怎么能够不依赖于元路径，或者设计一些更好的方法，能够探索语意信息，这是一个方向。在异质图神经网络里面如何更好的做聚合，实际上是研究也才刚刚开始。然后还有像这种动态网络的，在异质图里面怎么考虑这种动态性等等，都值得深入研究。</p>\n<p><strong>参考文献</strong></p>\n<p>[1] YuXiao Dong,Nitesh V. Chawla,Ananthram Swami. Metapath2vec: Scalable Representation Learning for Heterogeneous Networks. KDD， 2017.</p>\n<p>[2] Chuan Shi, Binbin Hu, Wayne XinZhao, Philip S. Yu. Heterogeneous Information Network Embedding for Recommendation.TKDE,2018.</p>\n<p>[3] Tao-yang Fu, Wang-Chien Lee, ZhenLei. HIN2Vec: Explore Meta-paths in Heterogeneous Information Networks for Representation Learning. CIKM,2017.</p>\n<p>[4] Binbin Hu, Chuan Shi, Wayne XinZhao, Philip S. Yu. Leveraging Meta-path based Context for Top-N Recommendation with A Neural Co-Attention Model. KDD,2018.</p>\n<p>[5] Binbin Hu, Yuan Fang, Chuan Shi.Adversarial Learning on Heterogeneous Information Networks. KDD,2019.</p>\n<p>[6] Chuan Shi, Yuanfu Lu, Linmei Hu,Zhiyuan Liu et al. RHINE: Relation Structure-Aware Heterogeneous Information Network Embedding. TKDE, 2020</p>\n<p>[7] Xiaotian Han, Chuan Shi, SenzhangWang, Philip S. Yu, Li Song.Aspect-Level Deep Collaborative Filtering viaHeterogeneous Information Networks. IJCAI,2018.</p>\n<p>[8] Wang, Xiao, Houye Ji, Chuan Shi,Bai Wang, Yanfang Ye, Peng Cui, and Philip S. Yu. Heterogeneous Graph Attention Network. WWW,2019.</p>\n<p>[9] Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V. Chawla. Heterogeneous Graph Neural Network.KDD,2019.</p>\n<p>[10] Binbin Hu, Zhiqiang Zhang, Chuan Shi, Jun Zhou, XiaoLong Li, Yuan Qi Cash-out User Detection based on Attributed HeterogeneousInformation Network with a Hierarchical Attention Mechanism. AAAI,2019.</p>\n<p>[11] Shaohua Fan, Junxiong Zhu, Xiaotian Han, Chuan Shi,Linmei Hu, Biyu Ma, Yongliang Li Metapath-guided Heterogeneous Graph NeuralNetwork for Intent Recommendation. KDD,2019.</p>\n<p>[12] Deyu Bo, Xiao Wang, Chuan Shi, Meiqi Zhu, Emiao Lu, PengCui. Structural Deep Clustering Network. WWW,2020. </p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://mp.weixin.qq.com/s?__biz=MzU5ODg0MTAwMw==&mid=2247486047&idx=1&sn=2052f3f96135cbe48ddfa96841bc404d&chksm=febf499bc9c8c08d99bbf2cc6fee48414b4d920bdaa01ec9c68c9fba74fd634331274af10f09&mpshare=1&scene=23&srcid=&sharer_sharetime=1586774527616&sharer_shareid=fc06814c3a0ce2f45e4998813d787a8f#rd\" target=\"_blank\" rel=\"noopener\">北邮教授石川：图神经网络需要解决的几个关键问题</a></p>\n"},{"title":"可视化","date":"2020-04-06T06:13:26.000Z","mathjax":true,"_content":"\n# 从SNE到t-SNE\n\nt-SNE 算法对每个数据点近邻的分布进行建模，其中近邻是指相互靠近数据点的集合。在原始高维空间中，我们将高维空间建模为高斯分布，而在二维输出空间中，我们可以将其建模为 t 分布。该过程的目标是找到将高维空间映射到二维空间的变换，并且最小化所有点在这两个分布之间的差距。与高斯分布相比 t 分布有较长的尾部，这有助于数据点在二维空间中更均匀地分布。\n\n## Preparation\n\n### 条件概率：\n\n![](https://img-blog.csdnimg.cn/20181206221325577.png)\n\n## 1. SNE\n\n### 高维：\n\n先把欧氏距离转化为条件概率。条件概率定义为$x_j$对于$x_i$的相似性。\n假设一个高斯分布以$x_i$为中心，则条件概率：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/91665image.png)\n\n即为在以$x_i$为中心的高斯分布下，若以邻域的概率密度成比例地选取邻域，$p_{j|i}$为$x_i$选择$x_j$作为近邻的概率。\n\n这个条件概率分布函数是一个softmax函数，变量是点的**相似度**，这个相似度通过欧氏距离来定义。\n\n设定 $p_{i|i} = 0$。\n\n### 低维：\n\n构建与高维相似的分布将计算条件概率 $q_{j|i}$ 中用到的高斯分布的方差设置为 1/2。\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/27934image%20(1).png)\n\n设定 $q_{i|i} = 0$。\n\n### 目标：\n\n让p、q的条件概率分布尽可能相似。通过最小化高低维分布之间的 **KL散度**。\n\n通过梯度下降法进行迭代更新。\n\n![KL散度](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/46259image%20(2).png)\n\n#### 关于 KL散度 的进一步说明\n\n**KL散度具有不对称性**，即在低维映射中不同的距离对应的惩罚权重是不同的。具体地，距离远的两点来表达距离近的两代男会产生很大的cost，而距离近的两点来表达距离远的两点则产生较小的cost，cost就是KL散度的结果C。\n\n举个例子，假如高维中 $p_{j|i} = 0.8$，若在低维中用较小的 $q_{j|i} = 0.2$ 来表示它的话， $cost = 1.11$。反之，如果高维中，$p_{j|i} = 0.2$， 低维 $q_{j|i} = 0.8$, 则 $cost = -0.277$。\n\n因此，**SNE倾向于表达局部信息**。\n\n### 困惑度\n\n困惑度与之前提到的高斯分布中的方差$\\sigma_i$的确定有关。它是随 $\\sigma_i$ 单调递增的。 \n\n条件概率矩阵 P 任意行的困惑度定义为：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/99046image%20(3).png)\n\n其中 $H(P_i)$ 为 $P_i$ 的香农熵，即表达式如下：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/24181image%20(4).png)\n\n#### 困惑度的设置来确定高斯分布方差\n\n在 SNE 和 t-SNE 中，**困惑度是我们设置的参数（通常为 5 到 50 ）**。困惑度随着熵增而变大，因此如果我们希望有更高的困惑度，那么所有的 $p_{j|i}$（对于给定的 i）就会彼此更相近一些。\n\n为了达到相应的困惑度，我们就得利用困惑度与 $\\sigma_i$ 单调递增的关系去进行**二分查找**，然后确定一个最优的 $\\sigma_i$，从而达到我们要设置的困惑度值。于是$\\sigma_i$就通过这个过程被确定下来了。\n\n## 2. 对称SNE\n\nSNE的条件概率对于 $p_{j|i}$ 和 $p_{i|j}$ 是不对称的，它的梯度实现起来比较困难。对称SNE是为了解决SNE梯度实现困难的问题。对称SNE使用了联合概率分布，取缔了条件概率分布。\n\n### 高维\n\n定义新的**联合概率分布** $p_{ij}$ 是原来的条件概率分布 $p_{j|i}$ 和 $p_{i|j}$ 两项的均值。这样实现了$p_{ij} = p_{ji}$。\n\n### 低维\n\n低维中同样变成了联合概率分布，具体做法：把SNE中的分母做了改动，现在分母中的求和是对整个矩阵进行的。\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/12130image%20(5).png)\n\n### 优化求解\n\n对称SNE 最小化 $p_{ij}$ 和 $q_{ij}$ 的联合概率分布与 $p_{i|j}$ 和 $q_{i|j}$ 的条件概率之间的 KL 散度。\n\n对称SNE的梯度变简单了。\n\n## 3. t-SNE\n\nt-SNE使用了对称SNE，**高维空间是之前的高斯分布，低维空间采用了t分布**。\n\n假设 $q_{ij}$ 服从自由度为1的 t分布，t-分布是一个**长尾分布**。\n\n- t分布相对高斯分布比较矮宽，t分布让高维空间中中低距离在映射后能有一个较大的距离。\n- t分布尾部更高，受异常值的影响更小。\n- t分布自由度越大，越接近高斯分布。\n\n![t分布](http://www.datakit.cn/images/statistics/norm_t_dict.png)\n\n![](http://www.datakit.cn/images/machinelearning/sne_norm_t_dist_cost.png)\n\n如上图所示，是高斯分布与t分布的对比。横轴表示点之间距离，纵轴表示相似度（联合概率）。t分布代表低维空间，高斯分布代表高维空间。\n\nt分布实现了簇内聚集，簇间疏远的特点：\n- 对于相似度大的点，t分布在低维空间的距离更小；\n- 对于相似对小的点，t分布在低维空间中的距离更大；\n\n### 低维空间的t分布定义\n\n使用自由度为1的t分布来重新定义 $q_{ij}$.\n\n$q_{ij}=\\frac{ (1 + \\left \\| y_i-y_j \\right \\|^2)^{-1}}{\\sum_{k \\neq l} (1 + \\left \\| y_k-y_l \\right \\|^2)^{-1}}$\n\n梯度变为：\n\n$\\frac{\\delta C}{\\delta y_i}=4\\sum_{j}(p_{ij}-q_{ij})(y_i-y_j)(1 + \\left \\| y_i-y_j \\right \\|^2)^{-1}$\n\n### 拥挤问题\n\n当我们试图将一个高维数据集表征为 2 或 3 个维度时，很难将邻近的数据点与中等距离的数据点区分开来，因为这些数据点都聚集在一块区域。再比如，假如一个三维球体内部均匀分布了很多点，如果想把所有点直接投影到同一个二维平面上，那会有很多点是重合的。\n\n**t-分布用来解决拥挤问题**的思路：假如我们想把之前球体内的所有点的信息尽可能都表达出来，可以把由于投影所重合的点用不同的距离表示，其中距离的差别很小，这样原来在那些距离上的点会被赶到更远的地方。\n\n**t分布的长尾特性意味着**：距离更远的点依然能给和高斯分布下距离小的点相同的概率值，从而达到高、低维空间对应点概率相同的目的。\n\n\n\n## References\n\n[1][详解可视化利器 t-SNE 算法：数无形时少直觉](https://www.jiqizhixin.com/articles/2017-11-13-7)\n\n[2][t-SNE完整笔记](http://www.datakit.cn/blog/2017/02/05/t_sne_full.html)\n\n[3][t-SNE分析的原理](http://www.360doc.com/content/19/0504/12/51784026_833261482.shtml)\n\n[4][从SNE到t-SNE再到LargeVis](http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/)","source":"_posts/可视化.md","raw":"---\ntitle: 可视化\ndate: 2020-04-06 14:13:26\ntags: 科研\ncategories: 科研\nmathjax: true\n---\n\n# 从SNE到t-SNE\n\nt-SNE 算法对每个数据点近邻的分布进行建模，其中近邻是指相互靠近数据点的集合。在原始高维空间中，我们将高维空间建模为高斯分布，而在二维输出空间中，我们可以将其建模为 t 分布。该过程的目标是找到将高维空间映射到二维空间的变换，并且最小化所有点在这两个分布之间的差距。与高斯分布相比 t 分布有较长的尾部，这有助于数据点在二维空间中更均匀地分布。\n\n## Preparation\n\n### 条件概率：\n\n![](https://img-blog.csdnimg.cn/20181206221325577.png)\n\n## 1. SNE\n\n### 高维：\n\n先把欧氏距离转化为条件概率。条件概率定义为$x_j$对于$x_i$的相似性。\n假设一个高斯分布以$x_i$为中心，则条件概率：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/91665image.png)\n\n即为在以$x_i$为中心的高斯分布下，若以邻域的概率密度成比例地选取邻域，$p_{j|i}$为$x_i$选择$x_j$作为近邻的概率。\n\n这个条件概率分布函数是一个softmax函数，变量是点的**相似度**，这个相似度通过欧氏距离来定义。\n\n设定 $p_{i|i} = 0$。\n\n### 低维：\n\n构建与高维相似的分布将计算条件概率 $q_{j|i}$ 中用到的高斯分布的方差设置为 1/2。\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/27934image%20(1).png)\n\n设定 $q_{i|i} = 0$。\n\n### 目标：\n\n让p、q的条件概率分布尽可能相似。通过最小化高低维分布之间的 **KL散度**。\n\n通过梯度下降法进行迭代更新。\n\n![KL散度](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/46259image%20(2).png)\n\n#### 关于 KL散度 的进一步说明\n\n**KL散度具有不对称性**，即在低维映射中不同的距离对应的惩罚权重是不同的。具体地，距离远的两点来表达距离近的两代男会产生很大的cost，而距离近的两点来表达距离远的两点则产生较小的cost，cost就是KL散度的结果C。\n\n举个例子，假如高维中 $p_{j|i} = 0.8$，若在低维中用较小的 $q_{j|i} = 0.2$ 来表示它的话， $cost = 1.11$。反之，如果高维中，$p_{j|i} = 0.2$， 低维 $q_{j|i} = 0.8$, 则 $cost = -0.277$。\n\n因此，**SNE倾向于表达局部信息**。\n\n### 困惑度\n\n困惑度与之前提到的高斯分布中的方差$\\sigma_i$的确定有关。它是随 $\\sigma_i$ 单调递增的。 \n\n条件概率矩阵 P 任意行的困惑度定义为：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/99046image%20(3).png)\n\n其中 $H(P_i)$ 为 $P_i$ 的香农熵，即表达式如下：\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/24181image%20(4).png)\n\n#### 困惑度的设置来确定高斯分布方差\n\n在 SNE 和 t-SNE 中，**困惑度是我们设置的参数（通常为 5 到 50 ）**。困惑度随着熵增而变大，因此如果我们希望有更高的困惑度，那么所有的 $p_{j|i}$（对于给定的 i）就会彼此更相近一些。\n\n为了达到相应的困惑度，我们就得利用困惑度与 $\\sigma_i$ 单调递增的关系去进行**二分查找**，然后确定一个最优的 $\\sigma_i$，从而达到我们要设置的困惑度值。于是$\\sigma_i$就通过这个过程被确定下来了。\n\n## 2. 对称SNE\n\nSNE的条件概率对于 $p_{j|i}$ 和 $p_{i|j}$ 是不对称的，它的梯度实现起来比较困难。对称SNE是为了解决SNE梯度实现困难的问题。对称SNE使用了联合概率分布，取缔了条件概率分布。\n\n### 高维\n\n定义新的**联合概率分布** $p_{ij}$ 是原来的条件概率分布 $p_{j|i}$ 和 $p_{i|j}$ 两项的均值。这样实现了$p_{ij} = p_{ji}$。\n\n### 低维\n\n低维中同样变成了联合概率分布，具体做法：把SNE中的分母做了改动，现在分母中的求和是对整个矩阵进行的。\n\n![](https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/12130image%20(5).png)\n\n### 优化求解\n\n对称SNE 最小化 $p_{ij}$ 和 $q_{ij}$ 的联合概率分布与 $p_{i|j}$ 和 $q_{i|j}$ 的条件概率之间的 KL 散度。\n\n对称SNE的梯度变简单了。\n\n## 3. t-SNE\n\nt-SNE使用了对称SNE，**高维空间是之前的高斯分布，低维空间采用了t分布**。\n\n假设 $q_{ij}$ 服从自由度为1的 t分布，t-分布是一个**长尾分布**。\n\n- t分布相对高斯分布比较矮宽，t分布让高维空间中中低距离在映射后能有一个较大的距离。\n- t分布尾部更高，受异常值的影响更小。\n- t分布自由度越大，越接近高斯分布。\n\n![t分布](http://www.datakit.cn/images/statistics/norm_t_dict.png)\n\n![](http://www.datakit.cn/images/machinelearning/sne_norm_t_dist_cost.png)\n\n如上图所示，是高斯分布与t分布的对比。横轴表示点之间距离，纵轴表示相似度（联合概率）。t分布代表低维空间，高斯分布代表高维空间。\n\nt分布实现了簇内聚集，簇间疏远的特点：\n- 对于相似度大的点，t分布在低维空间的距离更小；\n- 对于相似对小的点，t分布在低维空间中的距离更大；\n\n### 低维空间的t分布定义\n\n使用自由度为1的t分布来重新定义 $q_{ij}$.\n\n$q_{ij}=\\frac{ (1 + \\left \\| y_i-y_j \\right \\|^2)^{-1}}{\\sum_{k \\neq l} (1 + \\left \\| y_k-y_l \\right \\|^2)^{-1}}$\n\n梯度变为：\n\n$\\frac{\\delta C}{\\delta y_i}=4\\sum_{j}(p_{ij}-q_{ij})(y_i-y_j)(1 + \\left \\| y_i-y_j \\right \\|^2)^{-1}$\n\n### 拥挤问题\n\n当我们试图将一个高维数据集表征为 2 或 3 个维度时，很难将邻近的数据点与中等距离的数据点区分开来，因为这些数据点都聚集在一块区域。再比如，假如一个三维球体内部均匀分布了很多点，如果想把所有点直接投影到同一个二维平面上，那会有很多点是重合的。\n\n**t-分布用来解决拥挤问题**的思路：假如我们想把之前球体内的所有点的信息尽可能都表达出来，可以把由于投影所重合的点用不同的距离表示，其中距离的差别很小，这样原来在那些距离上的点会被赶到更远的地方。\n\n**t分布的长尾特性意味着**：距离更远的点依然能给和高斯分布下距离小的点相同的概率值，从而达到高、低维空间对应点概率相同的目的。\n\n\n\n## References\n\n[1][详解可视化利器 t-SNE 算法：数无形时少直觉](https://www.jiqizhixin.com/articles/2017-11-13-7)\n\n[2][t-SNE完整笔记](http://www.datakit.cn/blog/2017/02/05/t_sne_full.html)\n\n[3][t-SNE分析的原理](http://www.360doc.com/content/19/0504/12/51784026_833261482.shtml)\n\n[4][从SNE到t-SNE再到LargeVis](http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/)","slug":"可视化","published":1,"updated":"2020-06-08T06:05:03.391Z","_id":"ck92uhlzp0001dcym712oe7il","comments":1,"layout":"post","photos":[],"link":"","content":"<h1 id=\"从SNE到t-SNE\"><a href=\"#从SNE到t-SNE\" class=\"headerlink\" title=\"从SNE到t-SNE\"></a>从SNE到t-SNE</h1><p>t-SNE 算法对每个数据点近邻的分布进行建模，其中近邻是指相互靠近数据点的集合。在原始高维空间中，我们将高维空间建模为高斯分布，而在二维输出空间中，我们可以将其建模为 t 分布。该过程的目标是找到将高维空间映射到二维空间的变换，并且最小化所有点在这两个分布之间的差距。与高斯分布相比 t 分布有较长的尾部，这有助于数据点在二维空间中更均匀地分布。</p>\n<h2 id=\"Preparation\"><a href=\"#Preparation\" class=\"headerlink\" title=\"Preparation\"></a>Preparation</h2><h3 id=\"条件概率：\"><a href=\"#条件概率：\" class=\"headerlink\" title=\"条件概率：\"></a>条件概率：</h3><p><img src=\"https://img-blog.csdnimg.cn/20181206221325577.png\" alt=\"\"></p>\n<h2 id=\"1-SNE\"><a href=\"#1-SNE\" class=\"headerlink\" title=\"1. SNE\"></a>1. SNE</h2><h3 id=\"高维：\"><a href=\"#高维：\" class=\"headerlink\" title=\"高维：\"></a>高维：</h3><p>先把欧氏距离转化为条件概率。条件概率定义为$x_j$对于$x_i$的相似性。<br>假设一个高斯分布以$x_i$为中心，则条件概率：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/91665image.png\" alt=\"\"></p>\n<p>即为在以$x_i$为中心的高斯分布下，若以邻域的概率密度成比例地选取邻域，$p_{j|i}$为$x_i$选择$x_j$作为近邻的概率。</p>\n<p>这个条件概率分布函数是一个softmax函数，变量是点的<strong>相似度</strong>，这个相似度通过欧氏距离来定义。</p>\n<p>设定 $p_{i|i} = 0$。</p>\n<h3 id=\"低维：\"><a href=\"#低维：\" class=\"headerlink\" title=\"低维：\"></a>低维：</h3><p>构建与高维相似的分布将计算条件概率 $q_{j|i}$ 中用到的高斯分布的方差设置为 1/2。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/27934image%20(1).png\" alt=\"\"></p>\n<p>设定 $q_{i|i} = 0$。</p>\n<h3 id=\"目标：\"><a href=\"#目标：\" class=\"headerlink\" title=\"目标：\"></a>目标：</h3><p>让p、q的条件概率分布尽可能相似。通过最小化高低维分布之间的 <strong>KL散度</strong>。</p>\n<p>通过梯度下降法进行迭代更新。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/46259image%20(2).png\" alt=\"KL散度\"></p>\n<h4 id=\"关于-KL散度-的进一步说明\"><a href=\"#关于-KL散度-的进一步说明\" class=\"headerlink\" title=\"关于 KL散度 的进一步说明\"></a>关于 KL散度 的进一步说明</h4><p><strong>KL散度具有不对称性</strong>，即在低维映射中不同的距离对应的惩罚权重是不同的。具体地，距离远的两点来表达距离近的两代男会产生很大的cost，而距离近的两点来表达距离远的两点则产生较小的cost，cost就是KL散度的结果C。</p>\n<p>举个例子，假如高维中 $p_{j|i} = 0.8$，若在低维中用较小的 $q_{j|i} = 0.2$ 来表示它的话， $cost = 1.11$。反之，如果高维中，$p_{j|i} = 0.2$， 低维 $q_{j|i} = 0.8$, 则 $cost = -0.277$。</p>\n<p>因此，<strong>SNE倾向于表达局部信息</strong>。</p>\n<h3 id=\"困惑度\"><a href=\"#困惑度\" class=\"headerlink\" title=\"困惑度\"></a>困惑度</h3><p>困惑度与之前提到的高斯分布中的方差$\\sigma_i$的确定有关。它是随 $\\sigma_i$ 单调递增的。 </p>\n<p>条件概率矩阵 P 任意行的困惑度定义为：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/99046image%20(3).png\" alt=\"\"></p>\n<p>其中 $H(P_i)$ 为 $P_i$ 的香农熵，即表达式如下：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/24181image%20(4).png\" alt=\"\"></p>\n<h4 id=\"困惑度的设置来确定高斯分布方差\"><a href=\"#困惑度的设置来确定高斯分布方差\" class=\"headerlink\" title=\"困惑度的设置来确定高斯分布方差\"></a>困惑度的设置来确定高斯分布方差</h4><p>在 SNE 和 t-SNE 中，<strong>困惑度是我们设置的参数（通常为 5 到 50 ）</strong>。困惑度随着熵增而变大，因此如果我们希望有更高的困惑度，那么所有的 $p_{j|i}$（对于给定的 i）就会彼此更相近一些。</p>\n<p>为了达到相应的困惑度，我们就得利用困惑度与 $\\sigma_i$ 单调递增的关系去进行<strong>二分查找</strong>，然后确定一个最优的 $\\sigma_i$，从而达到我们要设置的困惑度值。于是$\\sigma_i$就通过这个过程被确定下来了。</p>\n<h2 id=\"2-对称SNE\"><a href=\"#2-对称SNE\" class=\"headerlink\" title=\"2. 对称SNE\"></a>2. 对称SNE</h2><p>SNE的条件概率对于 $p_{j|i}$ 和 $p_{i|j}$ 是不对称的，它的梯度实现起来比较困难。对称SNE是为了解决SNE梯度实现困难的问题。对称SNE使用了联合概率分布，取缔了条件概率分布。</p>\n<h3 id=\"高维\"><a href=\"#高维\" class=\"headerlink\" title=\"高维\"></a>高维</h3><p>定义新的<strong>联合概率分布</strong> $p_{ij}$ 是原来的条件概率分布 $p_{j|i}$ 和 $p_{i|j}$ 两项的均值。这样实现了$p_{ij} = p_{ji}$。</p>\n<h3 id=\"低维\"><a href=\"#低维\" class=\"headerlink\" title=\"低维\"></a>低维</h3><p>低维中同样变成了联合概率分布，具体做法：把SNE中的分母做了改动，现在分母中的求和是对整个矩阵进行的。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/12130image%20(5).png\" alt=\"\"></p>\n<h3 id=\"优化求解\"><a href=\"#优化求解\" class=\"headerlink\" title=\"优化求解\"></a>优化求解</h3><p>对称SNE 最小化 $p_{ij}$ 和 $q_{ij}$ 的联合概率分布与 $p_{i|j}$ 和 $q_{i|j}$ 的条件概率之间的 KL 散度。</p>\n<p>对称SNE的梯度变简单了。</p>\n<h2 id=\"3-t-SNE\"><a href=\"#3-t-SNE\" class=\"headerlink\" title=\"3. t-SNE\"></a>3. t-SNE</h2><p>t-SNE使用了对称SNE，<strong>高维空间是之前的高斯分布，低维空间采用了t分布</strong>。</p>\n<p>假设 $q_{ij}$ 服从自由度为1的 t分布，t-分布是一个<strong>长尾分布</strong>。</p>\n<ul>\n<li>t分布相对高斯分布比较矮宽，t分布让高维空间中中低距离在映射后能有一个较大的距离。</li>\n<li>t分布尾部更高，受异常值的影响更小。</li>\n<li>t分布自由度越大，越接近高斯分布。</li>\n</ul>\n<p><img src=\"http://www.datakit.cn/images/statistics/norm_t_dict.png\" alt=\"t分布\"></p>\n<p><img src=\"http://www.datakit.cn/images/machinelearning/sne_norm_t_dist_cost.png\" alt=\"\"></p>\n<p>如上图所示，是高斯分布与t分布的对比。横轴表示点之间距离，纵轴表示相似度（联合概率）。t分布代表低维空间，高斯分布代表高维空间。</p>\n<p>t分布实现了簇内聚集，簇间疏远的特点：</p>\n<ul>\n<li>对于相似度大的点，t分布在低维空间的距离更小；</li>\n<li>对于相似对小的点，t分布在低维空间中的距离更大；</li>\n</ul>\n<h3 id=\"低维空间的t分布定义\"><a href=\"#低维空间的t分布定义\" class=\"headerlink\" title=\"低维空间的t分布定义\"></a>低维空间的t分布定义</h3><p>使用自由度为1的t分布来重新定义 $q_{ij}$.</p>\n<p>$q_{ij}=\\frac{ (1 + \\left | y_i-y_j \\right |^2)^{-1}}{\\sum_{k \\neq l} (1 + \\left | y_k-y_l \\right |^2)^{-1}}$</p>\n<p>梯度变为：</p>\n<p>$\\frac{\\delta C}{\\delta y_i}=4\\sum_{j}(p_{ij}-q_{ij})(y_i-y_j)(1 + \\left | y_i-y_j \\right |^2)^{-1}$</p>\n<h3 id=\"拥挤问题\"><a href=\"#拥挤问题\" class=\"headerlink\" title=\"拥挤问题\"></a>拥挤问题</h3><p>当我们试图将一个高维数据集表征为 2 或 3 个维度时，很难将邻近的数据点与中等距离的数据点区分开来，因为这些数据点都聚集在一块区域。再比如，假如一个三维球体内部均匀分布了很多点，如果想把所有点直接投影到同一个二维平面上，那会有很多点是重合的。</p>\n<p><strong>t-分布用来解决拥挤问题</strong>的思路：假如我们想把之前球体内的所有点的信息尽可能都表达出来，可以把由于投影所重合的点用不同的距离表示，其中距离的差别很小，这样原来在那些距离上的点会被赶到更远的地方。</p>\n<p><strong>t分布的长尾特性意味着</strong>：距离更远的点依然能给和高斯分布下距离小的点相同的概率值，从而达到高、低维空间对应点概率相同的目的。</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>[1]<a href=\"https://www.jiqizhixin.com/articles/2017-11-13-7\" target=\"_blank\" rel=\"noopener\">详解可视化利器 t-SNE 算法：数无形时少直觉</a></p>\n<p>[2]<a href=\"http://www.datakit.cn/blog/2017/02/05/t_sne_full.html\" target=\"_blank\" rel=\"noopener\">t-SNE完整笔记</a></p>\n<p>[3]<a href=\"http://www.360doc.com/content/19/0504/12/51784026_833261482.shtml\" target=\"_blank\" rel=\"noopener\">t-SNE分析的原理</a></p>\n<p>[4]<a href=\"http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/\" target=\"_blank\" rel=\"noopener\">从SNE到t-SNE再到LargeVis</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"从SNE到t-SNE\"><a href=\"#从SNE到t-SNE\" class=\"headerlink\" title=\"从SNE到t-SNE\"></a>从SNE到t-SNE</h1><p>t-SNE 算法对每个数据点近邻的分布进行建模，其中近邻是指相互靠近数据点的集合。在原始高维空间中，我们将高维空间建模为高斯分布，而在二维输出空间中，我们可以将其建模为 t 分布。该过程的目标是找到将高维空间映射到二维空间的变换，并且最小化所有点在这两个分布之间的差距。与高斯分布相比 t 分布有较长的尾部，这有助于数据点在二维空间中更均匀地分布。</p>\n<h2 id=\"Preparation\"><a href=\"#Preparation\" class=\"headerlink\" title=\"Preparation\"></a>Preparation</h2><h3 id=\"条件概率：\"><a href=\"#条件概率：\" class=\"headerlink\" title=\"条件概率：\"></a>条件概率：</h3><p><img src=\"https://img-blog.csdnimg.cn/20181206221325577.png\" alt=\"\"></p>\n<h2 id=\"1-SNE\"><a href=\"#1-SNE\" class=\"headerlink\" title=\"1. SNE\"></a>1. SNE</h2><h3 id=\"高维：\"><a href=\"#高维：\" class=\"headerlink\" title=\"高维：\"></a>高维：</h3><p>先把欧氏距离转化为条件概率。条件概率定义为$x_j$对于$x_i$的相似性。<br>假设一个高斯分布以$x_i$为中心，则条件概率：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/91665image.png\" alt=\"\"></p>\n<p>即为在以$x_i$为中心的高斯分布下，若以邻域的概率密度成比例地选取邻域，$p_{j|i}$为$x_i$选择$x_j$作为近邻的概率。</p>\n<p>这个条件概率分布函数是一个softmax函数，变量是点的<strong>相似度</strong>，这个相似度通过欧氏距离来定义。</p>\n<p>设定 $p_{i|i} = 0$。</p>\n<h3 id=\"低维：\"><a href=\"#低维：\" class=\"headerlink\" title=\"低维：\"></a>低维：</h3><p>构建与高维相似的分布将计算条件概率 $q_{j|i}$ 中用到的高斯分布的方差设置为 1/2。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/27934image%20(1).png\" alt=\"\"></p>\n<p>设定 $q_{i|i} = 0$。</p>\n<h3 id=\"目标：\"><a href=\"#目标：\" class=\"headerlink\" title=\"目标：\"></a>目标：</h3><p>让p、q的条件概率分布尽可能相似。通过最小化高低维分布之间的 <strong>KL散度</strong>。</p>\n<p>通过梯度下降法进行迭代更新。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/46259image%20(2).png\" alt=\"KL散度\"></p>\n<h4 id=\"关于-KL散度-的进一步说明\"><a href=\"#关于-KL散度-的进一步说明\" class=\"headerlink\" title=\"关于 KL散度 的进一步说明\"></a>关于 KL散度 的进一步说明</h4><p><strong>KL散度具有不对称性</strong>，即在低维映射中不同的距离对应的惩罚权重是不同的。具体地，距离远的两点来表达距离近的两代男会产生很大的cost，而距离近的两点来表达距离远的两点则产生较小的cost，cost就是KL散度的结果C。</p>\n<p>举个例子，假如高维中 $p_{j|i} = 0.8$，若在低维中用较小的 $q_{j|i} = 0.2$ 来表示它的话， $cost = 1.11$。反之，如果高维中，$p_{j|i} = 0.2$， 低维 $q_{j|i} = 0.8$, 则 $cost = -0.277$。</p>\n<p>因此，<strong>SNE倾向于表达局部信息</strong>。</p>\n<h3 id=\"困惑度\"><a href=\"#困惑度\" class=\"headerlink\" title=\"困惑度\"></a>困惑度</h3><p>困惑度与之前提到的高斯分布中的方差$\\sigma_i$的确定有关。它是随 $\\sigma_i$ 单调递增的。 </p>\n<p>条件概率矩阵 P 任意行的困惑度定义为：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/99046image%20(3).png\" alt=\"\"></p>\n<p>其中 $H(P_i)$ 为 $P_i$ 的香农熵，即表达式如下：</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/24181image%20(4).png\" alt=\"\"></p>\n<h4 id=\"困惑度的设置来确定高斯分布方差\"><a href=\"#困惑度的设置来确定高斯分布方差\" class=\"headerlink\" title=\"困惑度的设置来确定高斯分布方差\"></a>困惑度的设置来确定高斯分布方差</h4><p>在 SNE 和 t-SNE 中，<strong>困惑度是我们设置的参数（通常为 5 到 50 ）</strong>。困惑度随着熵增而变大，因此如果我们希望有更高的困惑度，那么所有的 $p_{j|i}$（对于给定的 i）就会彼此更相近一些。</p>\n<p>为了达到相应的困惑度，我们就得利用困惑度与 $\\sigma_i$ 单调递增的关系去进行<strong>二分查找</strong>，然后确定一个最优的 $\\sigma_i$，从而达到我们要设置的困惑度值。于是$\\sigma_i$就通过这个过程被确定下来了。</p>\n<h2 id=\"2-对称SNE\"><a href=\"#2-对称SNE\" class=\"headerlink\" title=\"2. 对称SNE\"></a>2. 对称SNE</h2><p>SNE的条件概率对于 $p_{j|i}$ 和 $p_{i|j}$ 是不对称的，它的梯度实现起来比较困难。对称SNE是为了解决SNE梯度实现困难的问题。对称SNE使用了联合概率分布，取缔了条件概率分布。</p>\n<h3 id=\"高维\"><a href=\"#高维\" class=\"headerlink\" title=\"高维\"></a>高维</h3><p>定义新的<strong>联合概率分布</strong> $p_{ij}$ 是原来的条件概率分布 $p_{j|i}$ 和 $p_{i|j}$ 两项的均值。这样实现了$p_{ij} = p_{ji}$。</p>\n<h3 id=\"低维\"><a href=\"#低维\" class=\"headerlink\" title=\"低维\"></a>低维</h3><p>低维中同样变成了联合概率分布，具体做法：把SNE中的分母做了改动，现在分母中的求和是对整个矩阵进行的。</p>\n<p><img src=\"https://image.jiqizhixin.com/uploads/wangeditor/40d1bbf8-94d8-464c-b6be-54534c1c509e/12130image%20(5).png\" alt=\"\"></p>\n<h3 id=\"优化求解\"><a href=\"#优化求解\" class=\"headerlink\" title=\"优化求解\"></a>优化求解</h3><p>对称SNE 最小化 $p_{ij}$ 和 $q_{ij}$ 的联合概率分布与 $p_{i|j}$ 和 $q_{i|j}$ 的条件概率之间的 KL 散度。</p>\n<p>对称SNE的梯度变简单了。</p>\n<h2 id=\"3-t-SNE\"><a href=\"#3-t-SNE\" class=\"headerlink\" title=\"3. t-SNE\"></a>3. t-SNE</h2><p>t-SNE使用了对称SNE，<strong>高维空间是之前的高斯分布，低维空间采用了t分布</strong>。</p>\n<p>假设 $q_{ij}$ 服从自由度为1的 t分布，t-分布是一个<strong>长尾分布</strong>。</p>\n<ul>\n<li>t分布相对高斯分布比较矮宽，t分布让高维空间中中低距离在映射后能有一个较大的距离。</li>\n<li>t分布尾部更高，受异常值的影响更小。</li>\n<li>t分布自由度越大，越接近高斯分布。</li>\n</ul>\n<p><img src=\"http://www.datakit.cn/images/statistics/norm_t_dict.png\" alt=\"t分布\"></p>\n<p><img src=\"http://www.datakit.cn/images/machinelearning/sne_norm_t_dist_cost.png\" alt=\"\"></p>\n<p>如上图所示，是高斯分布与t分布的对比。横轴表示点之间距离，纵轴表示相似度（联合概率）。t分布代表低维空间，高斯分布代表高维空间。</p>\n<p>t分布实现了簇内聚集，簇间疏远的特点：</p>\n<ul>\n<li>对于相似度大的点，t分布在低维空间的距离更小；</li>\n<li>对于相似对小的点，t分布在低维空间中的距离更大；</li>\n</ul>\n<h3 id=\"低维空间的t分布定义\"><a href=\"#低维空间的t分布定义\" class=\"headerlink\" title=\"低维空间的t分布定义\"></a>低维空间的t分布定义</h3><p>使用自由度为1的t分布来重新定义 $q_{ij}$.</p>\n<p>$q_{ij}=\\frac{ (1 + \\left | y_i-y_j \\right |^2)^{-1}}{\\sum_{k \\neq l} (1 + \\left | y_k-y_l \\right |^2)^{-1}}$</p>\n<p>梯度变为：</p>\n<p>$\\frac{\\delta C}{\\delta y_i}=4\\sum_{j}(p_{ij}-q_{ij})(y_i-y_j)(1 + \\left | y_i-y_j \\right |^2)^{-1}$</p>\n<h3 id=\"拥挤问题\"><a href=\"#拥挤问题\" class=\"headerlink\" title=\"拥挤问题\"></a>拥挤问题</h3><p>当我们试图将一个高维数据集表征为 2 或 3 个维度时，很难将邻近的数据点与中等距离的数据点区分开来，因为这些数据点都聚集在一块区域。再比如，假如一个三维球体内部均匀分布了很多点，如果想把所有点直接投影到同一个二维平面上，那会有很多点是重合的。</p>\n<p><strong>t-分布用来解决拥挤问题</strong>的思路：假如我们想把之前球体内的所有点的信息尽可能都表达出来，可以把由于投影所重合的点用不同的距离表示，其中距离的差别很小，这样原来在那些距离上的点会被赶到更远的地方。</p>\n<p><strong>t分布的长尾特性意味着</strong>：距离更远的点依然能给和高斯分布下距离小的点相同的概率值，从而达到高、低维空间对应点概率相同的目的。</p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>[1]<a href=\"https://www.jiqizhixin.com/articles/2017-11-13-7\" target=\"_blank\" rel=\"noopener\">详解可视化利器 t-SNE 算法：数无形时少直觉</a></p>\n<p>[2]<a href=\"http://www.datakit.cn/blog/2017/02/05/t_sne_full.html\" target=\"_blank\" rel=\"noopener\">t-SNE完整笔记</a></p>\n<p>[3]<a href=\"http://www.360doc.com/content/19/0504/12/51784026_833261482.shtml\" target=\"_blank\" rel=\"noopener\">t-SNE分析的原理</a></p>\n<p>[4]<a href=\"http://bindog.github.io/blog/2016/06/04/from-sne-to-tsne-to-largevis/\" target=\"_blank\" rel=\"noopener\">从SNE到t-SNE再到LargeVis</a></p>\n"},{"title":"Tex与论文技巧","date":"2020-04-24T14:48:40.000Z","_content":"\n## tex 引文引用网址\n\n首先tex文件导包 `\\usepackage{url}`\n\n其次bib文件中写入\n\n```tex\n@Misc{timmurphy.org,\nauthor = {Murphy, Timothy I},\ntitle = {Line Spacing in LaTeX documents},\nhowpublished = {\\url{http://timmurphy.org/2009/07/22/line-spacing-in-latex-documents/}},\nnote = {Accessed April 4, 2010}\n}\n```\n\n## PPT 画图的导出问题\n\n把某页ppt导出成pdf格式的图片\n在pptx文件中，文件 - 导出 - 导出pdf - 选项（当前页）。\n\n导出时选择PDF，会保存成矢量图\n不要选择Adobe PDF，否则图片会失真\n\n## pdf 矢量图的裁剪问题\n\ntex编辑软件内集成了一个叫做 `pdfcrop` 的工具， 可以自动裁剪pdf使之适应图片大小.\n\n在文件目录下打开终端，调用指令：\n\n`pdfcrop name1.pdf name2.pdf`\n\n## pdf结果图中添加箭头等额外元素\n\n例如：HNE里对降维结果pdf中缺点指向的箭头添加。\n使用编辑pdf功能 -> 插入图像。\n图像来源可以是用ppt的元素组合，另存为png图像。","source":"_posts/Tex与论文技巧.md","raw":"---\ntitle: Tex与论文技巧\ndate: 2020-04-24 22:48:40\ntags: 科研\ncategories: 科研\n---\n\n## tex 引文引用网址\n\n首先tex文件导包 `\\usepackage{url}`\n\n其次bib文件中写入\n\n```tex\n@Misc{timmurphy.org,\nauthor = {Murphy, Timothy I},\ntitle = {Line Spacing in LaTeX documents},\nhowpublished = {\\url{http://timmurphy.org/2009/07/22/line-spacing-in-latex-documents/}},\nnote = {Accessed April 4, 2010}\n}\n```\n\n## PPT 画图的导出问题\n\n把某页ppt导出成pdf格式的图片\n在pptx文件中，文件 - 导出 - 导出pdf - 选项（当前页）。\n\n导出时选择PDF，会保存成矢量图\n不要选择Adobe PDF，否则图片会失真\n\n## pdf 矢量图的裁剪问题\n\ntex编辑软件内集成了一个叫做 `pdfcrop` 的工具， 可以自动裁剪pdf使之适应图片大小.\n\n在文件目录下打开终端，调用指令：\n\n`pdfcrop name1.pdf name2.pdf`\n\n## pdf结果图中添加箭头等额外元素\n\n例如：HNE里对降维结果pdf中缺点指向的箭头添加。\n使用编辑pdf功能 -> 插入图像。\n图像来源可以是用ppt的元素组合，另存为png图像。","slug":"Tex与论文技巧","published":1,"updated":"2020-06-08T06:04:49.137Z","_id":"ck9ebiyww0000esymbmz48o9l","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"tex-引文引用网址\"><a href=\"#tex-引文引用网址\" class=\"headerlink\" title=\"tex 引文引用网址\"></a>tex 引文引用网址</h2><p>首先tex文件导包 <code>\\usepackage{url}</code></p>\n<p>其次bib文件中写入</p>\n<pre class=\"line-numbers language-tex\"><code class=\"language-tex\">@Misc{timmurphy.org,\nauthor = {Murphy, Timothy I},\ntitle = {Line Spacing in LaTeX documents},\nhowpublished = {\\url{http://timmurphy.org/2009/07/22/line-spacing-in-latex-documents/}},\nnote = {Accessed April 4, 2010}\n}<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n<h2 id=\"PPT-画图的导出问题\"><a href=\"#PPT-画图的导出问题\" class=\"headerlink\" title=\"PPT 画图的导出问题\"></a>PPT 画图的导出问题</h2><p>把某页ppt导出成pdf格式的图片<br>在pptx文件中，文件 - 导出 - 导出pdf - 选项（当前页）。</p>\n<p>导出时选择PDF，会保存成矢量图<br>不要选择Adobe PDF，否则图片会失真</p>\n<h2 id=\"pdf-矢量图的裁剪问题\"><a href=\"#pdf-矢量图的裁剪问题\" class=\"headerlink\" title=\"pdf 矢量图的裁剪问题\"></a>pdf 矢量图的裁剪问题</h2><p>tex编辑软件内集成了一个叫做 <code>pdfcrop</code> 的工具， 可以自动裁剪pdf使之适应图片大小.</p>\n<p>在文件目录下打开终端，调用指令：</p>\n<p><code>pdfcrop name1.pdf name2.pdf</code></p>\n<h2 id=\"pdf结果图中添加箭头等额外元素\"><a href=\"#pdf结果图中添加箭头等额外元素\" class=\"headerlink\" title=\"pdf结果图中添加箭头等额外元素\"></a>pdf结果图中添加箭头等额外元素</h2><p>例如：HNE里对降维结果pdf中缺点指向的箭头添加。<br>使用编辑pdf功能 -&gt; 插入图像。<br>图像来源可以是用ppt的元素组合，另存为png图像。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"tex-引文引用网址\"><a href=\"#tex-引文引用网址\" class=\"headerlink\" title=\"tex 引文引用网址\"></a>tex 引文引用网址</h2><p>首先tex文件导包 <code>\\usepackage{url}</code></p>\n<p>其次bib文件中写入</p>\n<pre><code class=\"tex\">@Misc{timmurphy.org,\nauthor = {Murphy, Timothy I},\ntitle = {Line Spacing in LaTeX documents},\nhowpublished = {\\url{http://timmurphy.org/2009/07/22/line-spacing-in-latex-documents/}},\nnote = {Accessed April 4, 2010}\n}</code></pre>\n<h2 id=\"PPT-画图的导出问题\"><a href=\"#PPT-画图的导出问题\" class=\"headerlink\" title=\"PPT 画图的导出问题\"></a>PPT 画图的导出问题</h2><p>把某页ppt导出成pdf格式的图片<br>在pptx文件中，文件 - 导出 - 导出pdf - 选项（当前页）。</p>\n<p>导出时选择PDF，会保存成矢量图<br>不要选择Adobe PDF，否则图片会失真</p>\n<h2 id=\"pdf-矢量图的裁剪问题\"><a href=\"#pdf-矢量图的裁剪问题\" class=\"headerlink\" title=\"pdf 矢量图的裁剪问题\"></a>pdf 矢量图的裁剪问题</h2><p>tex编辑软件内集成了一个叫做 <code>pdfcrop</code> 的工具， 可以自动裁剪pdf使之适应图片大小.</p>\n<p>在文件目录下打开终端，调用指令：</p>\n<p><code>pdfcrop name1.pdf name2.pdf</code></p>\n<h2 id=\"pdf结果图中添加箭头等额外元素\"><a href=\"#pdf结果图中添加箭头等额外元素\" class=\"headerlink\" title=\"pdf结果图中添加箭头等额外元素\"></a>pdf结果图中添加箭头等额外元素</h2><p>例如：HNE里对降维结果pdf中缺点指向的箭头添加。<br>使用编辑pdf功能 -&gt; 插入图像。<br>图像来源可以是用ppt的元素组合，另存为png图像。</p>\n"},{"title":"于式麻酱拌面","date":"2020-04-24T15:27:24.000Z","_content":"\n## 于式麻酱拌面\n\n根据我个人吃火锅的习惯，再加上家里有限的材料，低配版的麻酱拌面。\n\n**做法**：\n\n1. 取面（泡面面饼、手擀面、挂面皆可）适量入锅煮熟，如果是泡面则加入酱包一块煮，泡面的话宜水开后再下面饼。手擀面和挂面，有条件可以自己切一小块火锅底料，个人的话家里一般常备火锅底料炒菜（小龙虾什么的）、吃火锅。没有也可以不放。\n2. 面快熟的时候，下入青菜（最好是菠菜、油菜、小白菜）一块焯熟。注意：小白菜和大白菜不是一个东西，没买过菜做过饭的先科普一下。\n3. 煮面的时候调个酱料：碗中放入适量盐、适量蚝油、花生碎、熟芝麻、适量麻油、一勺白糖、多来点醋、少放点酱油（酱油有很多种，每种味道差别都挺大，没做过菜的建议先熟悉一下，放错了很难吃）、辣椒油，然后放几勺芝麻酱（花生酱不如芝麻酱好吃）。\n4. 煮面的水用勺子舀出适量倒进碗里把芝麻酱调稀，并把所有调料拌匀。\n5. 面熟了出锅，拌匀开吃。巨TM香！","source":"_posts/于式麻酱拌面.md","raw":"---\ntitle: 于式麻酱拌面\ndate: 2020-04-24 23:27:24\ntags: 程序员美食\ncategories: 美食\n---\n\n## 于式麻酱拌面\n\n根据我个人吃火锅的习惯，再加上家里有限的材料，低配版的麻酱拌面。\n\n**做法**：\n\n1. 取面（泡面面饼、手擀面、挂面皆可）适量入锅煮熟，如果是泡面则加入酱包一块煮，泡面的话宜水开后再下面饼。手擀面和挂面，有条件可以自己切一小块火锅底料，个人的话家里一般常备火锅底料炒菜（小龙虾什么的）、吃火锅。没有也可以不放。\n2. 面快熟的时候，下入青菜（最好是菠菜、油菜、小白菜）一块焯熟。注意：小白菜和大白菜不是一个东西，没买过菜做过饭的先科普一下。\n3. 煮面的时候调个酱料：碗中放入适量盐、适量蚝油、花生碎、熟芝麻、适量麻油、一勺白糖、多来点醋、少放点酱油（酱油有很多种，每种味道差别都挺大，没做过菜的建议先熟悉一下，放错了很难吃）、辣椒油，然后放几勺芝麻酱（花生酱不如芝麻酱好吃）。\n4. 煮面的水用勺子舀出适量倒进碗里把芝麻酱调稀，并把所有调料拌匀。\n5. 面熟了出锅，拌匀开吃。巨TM香！","slug":"于式麻酱拌面","published":1,"updated":"2020-06-08T06:05:00.003Z","_id":"ck9ed4obe0000nwymbxhyex3f","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"于式麻酱拌面\"><a href=\"#于式麻酱拌面\" class=\"headerlink\" title=\"于式麻酱拌面\"></a>于式麻酱拌面</h2><p>根据我个人吃火锅的习惯，再加上家里有限的材料，低配版的麻酱拌面。</p>\n<p><strong>做法</strong>：</p>\n<ol>\n<li>取面（泡面面饼、手擀面、挂面皆可）适量入锅煮熟，如果是泡面则加入酱包一块煮，泡面的话宜水开后再下面饼。手擀面和挂面，有条件可以自己切一小块火锅底料，个人的话家里一般常备火锅底料炒菜（小龙虾什么的）、吃火锅。没有也可以不放。</li>\n<li>面快熟的时候，下入青菜（最好是菠菜、油菜、小白菜）一块焯熟。注意：小白菜和大白菜不是一个东西，没买过菜做过饭的先科普一下。</li>\n<li>煮面的时候调个酱料：碗中放入适量盐、适量蚝油、花生碎、熟芝麻、适量麻油、一勺白糖、多来点醋、少放点酱油（酱油有很多种，每种味道差别都挺大，没做过菜的建议先熟悉一下，放错了很难吃）、辣椒油，然后放几勺芝麻酱（花生酱不如芝麻酱好吃）。</li>\n<li>煮面的水用勺子舀出适量倒进碗里把芝麻酱调稀，并把所有调料拌匀。</li>\n<li>面熟了出锅，拌匀开吃。巨TM香！</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"于式麻酱拌面\"><a href=\"#于式麻酱拌面\" class=\"headerlink\" title=\"于式麻酱拌面\"></a>于式麻酱拌面</h2><p>根据我个人吃火锅的习惯，再加上家里有限的材料，低配版的麻酱拌面。</p>\n<p><strong>做法</strong>：</p>\n<ol>\n<li>取面（泡面面饼、手擀面、挂面皆可）适量入锅煮熟，如果是泡面则加入酱包一块煮，泡面的话宜水开后再下面饼。手擀面和挂面，有条件可以自己切一小块火锅底料，个人的话家里一般常备火锅底料炒菜（小龙虾什么的）、吃火锅。没有也可以不放。</li>\n<li>面快熟的时候，下入青菜（最好是菠菜、油菜、小白菜）一块焯熟。注意：小白菜和大白菜不是一个东西，没买过菜做过饭的先科普一下。</li>\n<li>煮面的时候调个酱料：碗中放入适量盐、适量蚝油、花生碎、熟芝麻、适量麻油、一勺白糖、多来点醋、少放点酱油（酱油有很多种，每种味道差别都挺大，没做过菜的建议先熟悉一下，放错了很难吃）、辣椒油，然后放几勺芝麻酱（花生酱不如芝麻酱好吃）。</li>\n<li>煮面的水用勺子舀出适量倒进碗里把芝麻酱调稀，并把所有调料拌匀。</li>\n<li>面熟了出锅，拌匀开吃。巨TM香！</li>\n</ol>\n"},{"title":"于氏炸鸡翅","date":"2020-05-05T14:05:12.000Z","_content":"\n## 于式炸鸡翅\n\n1. 鸡翅泡凉水中解冻，用牙签扎眼儿。\n2. 腌制鸡翅：加入盐、胡椒面、辣椒面、五香粉，抓匀，腌制30~60分钟。\n3. 调裹粉：面粉中加入盐、五香粉，拌匀。\n4. 裹粉：鸡翅先裹一遍粉，然后蘸水，蘸水要快，蘸水后再裹一遍粉。\n5. 首炸把肉炸熟：大火把油烧热，小火炸鸡翅，8~10分钟，捞出控油。\n6. 复炸把粉炸酥：大火把油烧热，大火复炸鸡翅40~60秒，控油捞出。\n7. 配冰可乐，巨TM爽！","source":"_posts/于氏炸鸡翅.md","raw":"---\ntitle: 于氏炸鸡翅\ndate: 2020-05-05 22:05:12\ntags: 程序员美食\ncategories: 美食\n---\n\n## 于式炸鸡翅\n\n1. 鸡翅泡凉水中解冻，用牙签扎眼儿。\n2. 腌制鸡翅：加入盐、胡椒面、辣椒面、五香粉，抓匀，腌制30~60分钟。\n3. 调裹粉：面粉中加入盐、五香粉，拌匀。\n4. 裹粉：鸡翅先裹一遍粉，然后蘸水，蘸水要快，蘸水后再裹一遍粉。\n5. 首炸把肉炸熟：大火把油烧热，小火炸鸡翅，8~10分钟，捞出控油。\n6. 复炸把粉炸酥：大火把油烧热，大火复炸鸡翅40~60秒，控油捞出。\n7. 配冰可乐，巨TM爽！","slug":"于氏炸鸡翅","published":1,"updated":"2020-06-08T06:05:01.191Z","_id":"ck9tzprsw0000woym8fyz17fe","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"于式炸鸡翅\"><a href=\"#于式炸鸡翅\" class=\"headerlink\" title=\"于式炸鸡翅\"></a>于式炸鸡翅</h2><ol>\n<li>鸡翅泡凉水中解冻，用牙签扎眼儿。</li>\n<li>腌制鸡翅：加入盐、胡椒面、辣椒面、五香粉，抓匀，腌制30~60分钟。</li>\n<li>调裹粉：面粉中加入盐、五香粉，拌匀。</li>\n<li>裹粉：鸡翅先裹一遍粉，然后蘸水，蘸水要快，蘸水后再裹一遍粉。</li>\n<li>首炸把肉炸熟：大火把油烧热，小火炸鸡翅，8~10分钟，捞出控油。</li>\n<li>复炸把粉炸酥：大火把油烧热，大火复炸鸡翅40~60秒，控油捞出。</li>\n<li>配冰可乐，巨TM爽！</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"于式炸鸡翅\"><a href=\"#于式炸鸡翅\" class=\"headerlink\" title=\"于式炸鸡翅\"></a>于式炸鸡翅</h2><ol>\n<li>鸡翅泡凉水中解冻，用牙签扎眼儿。</li>\n<li>腌制鸡翅：加入盐、胡椒面、辣椒面、五香粉，抓匀，腌制30~60分钟。</li>\n<li>调裹粉：面粉中加入盐、五香粉，拌匀。</li>\n<li>裹粉：鸡翅先裹一遍粉，然后蘸水，蘸水要快，蘸水后再裹一遍粉。</li>\n<li>首炸把肉炸熟：大火把油烧热，小火炸鸡翅，8~10分钟，捞出控油。</li>\n<li>复炸把粉炸酥：大火把油烧热，大火复炸鸡翅40~60秒，控油捞出。</li>\n<li>配冰可乐，巨TM爽！</li>\n</ol>\n"},{"title":"于氏麻辣小龙虾","date":"2020-05-05T14:11:16.000Z","_content":"\n## 于氏麻辣小龙虾\n\n1. 浸泡吐脏东西：泡小龙虾的水加盐，泡2小时。\n2. 清洗：戴手套，用刷子清洗小龙虾，并去虾线。\n3. 再次浸泡去血水：水里加盐去血水。\n4. 炒制：锅里热油两勺，加大葱段、姜片、大蒜、小葱结、干花椒，加火锅底料一小块，炒制出香。然后下入小龙虾，翻炒至虾壳变红。然后加盐、料酒、生抽、老抽、蚝油。\n5. 炖：500ml啤酒一瓶，中火盖盖炖10分钟。十分钟后汤汁收掉大半，盛出即可。","source":"_posts/于氏麻辣小龙虾.md","raw":"---\ntitle: 于氏麻辣小龙虾\ndate: 2020-05-05 22:11:16\ntags: 程序员美食\ncategories: 美食\n---\n\n## 于氏麻辣小龙虾\n\n1. 浸泡吐脏东西：泡小龙虾的水加盐，泡2小时。\n2. 清洗：戴手套，用刷子清洗小龙虾，并去虾线。\n3. 再次浸泡去血水：水里加盐去血水。\n4. 炒制：锅里热油两勺，加大葱段、姜片、大蒜、小葱结、干花椒，加火锅底料一小块，炒制出香。然后下入小龙虾，翻炒至虾壳变红。然后加盐、料酒、生抽、老抽、蚝油。\n5. 炖：500ml啤酒一瓶，中火盖盖炖10分钟。十分钟后汤汁收掉大半，盛出即可。","slug":"于氏麻辣小龙虾","published":1,"updated":"2020-06-08T06:04:57.004Z","_id":"ck9tzyg680000pwymepwhgjow","comments":1,"layout":"post","photos":[],"link":"","content":"<h2 id=\"于氏麻辣小龙虾\"><a href=\"#于氏麻辣小龙虾\" class=\"headerlink\" title=\"于氏麻辣小龙虾\"></a>于氏麻辣小龙虾</h2><ol>\n<li>浸泡吐脏东西：泡小龙虾的水加盐，泡2小时。</li>\n<li>清洗：戴手套，用刷子清洗小龙虾，并去虾线。</li>\n<li>再次浸泡去血水：水里加盐去血水。</li>\n<li>炒制：锅里热油两勺，加大葱段、姜片、大蒜、小葱结、干花椒，加火锅底料一小块，炒制出香。然后下入小龙虾，翻炒至虾壳变红。然后加盐、料酒、生抽、老抽、蚝油。</li>\n<li>炖：500ml啤酒一瓶，中火盖盖炖10分钟。十分钟后汤汁收掉大半，盛出即可。</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"于氏麻辣小龙虾\"><a href=\"#于氏麻辣小龙虾\" class=\"headerlink\" title=\"于氏麻辣小龙虾\"></a>于氏麻辣小龙虾</h2><ol>\n<li>浸泡吐脏东西：泡小龙虾的水加盐，泡2小时。</li>\n<li>清洗：戴手套，用刷子清洗小龙虾，并去虾线。</li>\n<li>再次浸泡去血水：水里加盐去血水。</li>\n<li>炒制：锅里热油两勺，加大葱段、姜片、大蒜、小葱结、干花椒，加火锅底料一小块，炒制出香。然后下入小龙虾，翻炒至虾壳变红。然后加盐、料酒、生抽、老抽、蚝油。</li>\n<li>炖：500ml啤酒一瓶，中火盖盖炖10分钟。十分钟后汤汁收掉大半，盛出即可。</li>\n</ol>\n"}],"PostAsset":[{"_id":"source/_posts/CNN卷积/空间可分卷积2.jpg","slug":"空间可分卷积2.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/深度可分卷积.jpg","slug":"深度可分卷积.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/转置卷积2.jpg","slug":"转置卷积2.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/分组卷积.jpg","slug":"分组卷积.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/扩张卷积.jpg","slug":"扩张卷积.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/普通卷积的实现.jpg","slug":"普通卷积的实现.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/3d.jpg","slug":"3d.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/空间可分卷积.jpg","slug":"空间可分卷积.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/转置卷积1.jpg","slug":"转置卷积1.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/CNN卷积/转置卷积的实现.jpg","slug":"转置卷积的实现.jpg","post":"ck6ewuw1i000044ym6u4eeblf","modified":0,"renderable":0},{"_id":"source/_posts/GCN原理/GCN-2nd.png","slug":"GCN-2nd.png","post":"ck6d7oxkn00002sym510c6icq","modified":0,"renderable":0},{"_id":"source/_posts/GCN原理/Simple-GCN-schematic.png","slug":"Simple-GCN-schematic.png","post":"ck6d7oxkn00002sym510c6icq","modified":0,"renderable":0},{"_id":"source/_posts/GCN原理/GCN-1st.png","slug":"GCN-1st.png","post":"ck6d7oxkn00002sym510c6icq","modified":0,"renderable":0},{"_id":"source/_posts/GCN原理/GCN-schematic.png","slug":"GCN-schematic.png","post":"ck6d7oxkn00002sym510c6icq","modified":0,"renderable":0},{"_id":"source/_posts/GCN原理/LandL2.png","slug":"LandL2.png","post":"ck6d7oxkn00002sym510c6icq","modified":0,"renderable":0},{"_id":"source/_posts/操作系统复习/进程调度.png","slug":"进程调度.png","post":"ck6onkcvj0000z8ymb13k6dya","modified":0,"renderable":0},{"_id":"source/_posts/操作系统复习/生产者吸烟者.png","slug":"生产者吸烟者.png","post":"ck6onkcvj0000z8ymb13k6dya","modified":0,"renderable":0},{"_id":"source/_posts/操作系统复习/进程七状态模型.png","slug":"进程七状态模型.png","post":"ck6onkcvj0000z8ymb13k6dya","modified":0,"renderable":0},{"_id":"source/_posts/操作系统复习/文件的层次结构.jpg","slug":"文件的层次结构.jpg","post":"ck6onkcvj0000z8ymb13k6dya","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTP报文.jpg","slug":"HTTP报文.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTP报文2.jpg","slug":"HTTP报文2.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTP状态码.jpg","slug":"HTTP状态码.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/代理.jpg","slug":"代理.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/实体首部字段.jpg","slug":"实体首部字段.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/响应首部字段.jpg","slug":"响应首部字段.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/请求首部字段.jpg","slug":"请求首部字段.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/通用首部字段.jpg","slug":"通用首部字段.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/缓存请求指令.jpg","slug":"缓存请求指令.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/缓存响应指令.jpg","slug":"缓存响应指令.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS.jpg","slug":"HTTPS.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS混合加密机制.jpg","slug":"HTTPS混合加密机制.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS通信步骤.jpg","slug":"HTTPS通信步骤.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/HTTPS通信细节.jpg","slug":"HTTPS通信细节.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/图解HTTP读书笔记/SPDY.jpg","slug":"SPDY.jpg","post":"ck7gch1d40000iwym03bb2esa","modified":0,"renderable":0},{"_id":"source/_posts/计算机网络复习/HTTP2二进制报文.jpg","slug":"HTTP2二进制报文.jpg","post":"ck79wtrez0000fcym2x2i00t7","modified":0,"renderable":0},{"_id":"source/_posts/计算机网络复习/HTTP1.1-HTTP3对比.jpg","slug":"HTTP1.1-HTTP3对比.jpg","post":"ck79wtrez0000fcym2x2i00t7","modified":0,"renderable":0},{"_id":"source/_posts/计算机网络复习/QUIC-HTTPS.jpg","slug":"QUIC-HTTPS.jpg","post":"ck79wtrez0000fcym2x2i00t7","modified":0,"renderable":0},{"_id":"source/_posts/可视化/t分布的q公式.jpg","slug":"t分布的q公式.jpg","post":"ck92uhlzp0001dcym712oe7il","modified":0,"renderable":0}],"PostCategory":[{"post_id":"ck6ewuw1i000044ym6u4eeblf","category_id":"ckb63ddfi0000boyma36jdyc8","_id":"ckb63ddfr0003boym19rndsvh"},{"post_id":"ck9ebiyww0000esymbmz48o9l","category_id":"ckb63ddfi0000boyma36jdyc8","_id":"ckb63ddfs0004boymgcq2cu1m"},{"post_id":"ck6d7oxkn00002sym510c6icq","category_id":"ckb63ddfi0000boyma36jdyc8","_id":"ckb63ddft0006boymdc0e20z9"},{"post_id":"ck92uhlzp0001dcym712oe7il","category_id":"ckb63ddfi0000boyma36jdyc8","_id":"ckb63ddfu0007boym7ye9bvz9"},{"post_id":"ck92uhlzl0000dcym3h938x6h","category_id":"ckb63ddfi0000boyma36jdyc8","_id":"ckb63ddfv0008boymhtm857wh"},{"post_id":"ck6vr4tl900000cymalysbnud","category_id":"ckb63ddft0005boym5t7j5l8v","_id":"ckb63ddfw000aboymaysj5cz4"},{"post_id":"ck9ed4obe0000nwymbxhyex3f","category_id":"ckb63ddfv0009boym0f0m4a3y","_id":"ckb63ddfx000dboym202e90ko"},{"post_id":"ck9tzprsw0000woym8fyz17fe","category_id":"ckb63ddfv0009boym0f0m4a3y","_id":"ckb63ddfx000fboymdb2d3uo3"},{"post_id":"ck9tzyg680000pwymepwhgjow","category_id":"ckb63ddfv0009boym0f0m4a3y","_id":"ckb63ddfy000gboymhear9oos"},{"post_id":"ck7gch1d40000iwym03bb2esa","category_id":"ckb63ddfx000eboym8ifb94fh","_id":"ckb63ddfy000iboymc9yt66rs"},{"post_id":"ck6onkcvj0000z8ymb13k6dya","category_id":"ckb63ddfx000eboym8ifb94fh","_id":"ckb63ddfy000jboymhg8le2fs"},{"post_id":"ck79wtrez0000fcym2x2i00t7","category_id":"ckb63ddfx000eboym8ifb94fh","_id":"ckb63ddg2000kboymbvsk1lbc"},{"post_id":"ck7hczcxk0000bwym2xsyab17","category_id":"ckb63ddfx000eboym8ifb94fh","_id":"ckb63ddg6000lboym3qi0bcpx"}],"PostTag":[{"post_id":"ck6onkcvj0000z8ymb13k6dya","tag_id":"ck6pzvdta0000jkym8u351thd","_id":"ck6pzvdtn0001jkymdqtu17k2"},{"post_id":"ck79wtrez0000fcym2x2i00t7","tag_id":"ck79wtrf40001fcymb5dpdtp2","_id":"ck79wtrf60002fcym41xaaoq9"},{"post_id":"ck7gch1d40000iwym03bb2esa","tag_id":"ck79wtrf40001fcymb5dpdtp2","_id":"ck7gch1dc0001iwymaw8q8a7y"},{"post_id":"ck7hczcxk0000bwym2xsyab17","tag_id":"ck6pzvdta0000jkym8u351thd","_id":"ck7hczcxm0001bwymeg2dfcnr"},{"post_id":"ck92uhlzl0000dcym3h938x6h","tag_id":"ck92uhlzq0002dcym0wr75p1d","_id":"ck92uhlzv0004dcymczm76ucz"},{"post_id":"ck92uhlzp0001dcym712oe7il","tag_id":"ck92uhlzq0002dcym0wr75p1d","_id":"ck92uhlzv0005dcymcmyvcjar"},{"post_id":"ck6d7oxkn00002sym510c6icq","tag_id":"ck92uhlzq0002dcym0wr75p1d","_id":"ck92uhm000006dcym21wqh9pa"},{"post_id":"ck6ewuw1i000044ym6u4eeblf","tag_id":"ck92uhlzq0002dcym0wr75p1d","_id":"ck92uhm010007dcym58xo731e"},{"post_id":"ck6vr4tl900000cymalysbnud","tag_id":"ck92uhm010008dcymf3tohygm","_id":"ck92uhm020009dcym6u6da81n"},{"post_id":"ck9ebiyww0000esymbmz48o9l","tag_id":"ck92uhlzq0002dcym0wr75p1d","_id":"ck9ebiyx00001esym6o279b7o"},{"post_id":"ck9ed4obe0000nwymbxhyex3f","tag_id":"ck9ed4obi0001nwymgcfn17vv","_id":"ck9ed4obk0002nwymet7jakys"},{"post_id":"ck9tzprsw0000woym8fyz17fe","tag_id":"ck9ed4obi0001nwymgcfn17vv","_id":"ck9tzprt10001woymfvh454m6"},{"post_id":"ck9tzyg680000pwymepwhgjow","tag_id":"ck9ed4obi0001nwymgcfn17vv","_id":"ck9tzyg6c0001pwymcnieadx6"}],"Tag":[{"name":"GCN,科研","_id":"ck6d9hjah0000g8ym6c693mpn"},{"name":"CNN,卷积,深度学习","_id":"ck6ddtsgl0000o4ymbhq33h6u"},{"name":"计算机操作系统","_id":"ck6onkcvt0001z8ym77u9bylk"},{"name":"操作系统","_id":"ck6pzvdta0000jkym8u351thd"},{"name":"java","_id":"ck6vr4tlf00010cymf75g8egw"},{"name":"计算机网络","_id":"ck79wtrf40001fcymb5dpdtp2"},{"name":"科研","_id":"ck92uhlzq0002dcym0wr75p1d"},{"name":"Java","_id":"ck92uhm010008dcymf3tohygm"},{"name":"程序员美食","_id":"ck9ed4obi0001nwymgcfn17vv"}]}}